check out rpp, it has a c++ preprocessor, processor and binder.  no need to reinvent the wheel again

http://repo.or.cz/w/rpp.git

&gt; pretty much every properly funded survey reports the same findings. 

please post a link to one (or more) of these surveys.  if i still don't believe them then i'll ask my mother.  i bet she doesn't say windows.

this is strange. with no comments, there's a red error message:

&gt;there are no results here

*edit:* even more interesting: because the comment is submitted ajaxically, the "no results" message stayed after this comment was posted, and didn't disappear until i refreshed the page.
we're discussing user friendliness, not familiarity.  i stand by my point that microsoft produces terrible user interfaces.  the fact that a significant proportion of computer users have had no choice but to become familiar with them doesn't make them any better.

ps i'm not kicking or screaming.  well, only when i'm forced to use win xp (under osx + parallels) so that i can use a web site under ie.





outlook is not "dead". outlook doesn't even compete for the same users as gmail. it's for corporates with exchange servers running email on desktops in the organisation. (mainly)

gmail is a light and simple mail client for people who just want mail. outlook is mail, scheduling, calendars, and god knows what else. it isn't neccesarily fun, or cool, but it does a lot of things.

back closer to topic - well, good for them - there's never really been a particularly great open challenger in that space. best of luck to them.


myanmar is the second largest opium producer in the world, next only to afghanistan. it has recorded a 29 per cent growth this year. it is worrisome and undermines progress towards a drug-free south east asia, according to undoc.
thank god there were no bugs.
shopped!
i'm skeptical. right now, i don't think they have the "language for the masses" appeal that languages seem to need to become popular. 

actually, i think pg got it right when he said that the key was to be the scripting language of something else that mattered -- as c was for unix, or javascript is for browsers. (java was once *perceived* as the scripting language of the web, which helped it get started.) so, when haskell becomes the way to control something that matters to everyone, it will get hot.
&gt; if you did not cmd-q-ed a program, the next time you're "trying" to open that particular program by clicking its icon, you won't see the program on your desktop, just the menu on top.
&gt; odd.

not really, you closed the applications windows but not the application. when you attempt to start the app again nothing happens, because you are already running it!

&gt; if you minimized a program, if you use option-tab to scroll over programs, once you selected the program you wanted to activate, the windows still a no-show; you have to click it from the dock to maximize.

you minimised the window for a reason, why would you want reselecting that application to raise its windows? cmd-tabbing to the app you want gives you that app exactly as you left it - with windows still minimised, this is exactly what should happen. 
there's also ken shoemake's famous paper, which introduced them into computer graphics and popularized their use:

http://graphics.ucmerced.edu/~mkallmann/courses/papers/shoemake1985-quat.pdf  
i think you don't get it. "friendliness" is a function of familiarity (and vice versa).

e.g: on your trip to ghana, a native wanted to be super-friendly to you and so a used super-friendly ghanaian greeting gesture. let's say that in ghana, this gesture involves a middle finger. not knowing local customs, would you think he was friendly?

well, that's how joe sixpack feels when greeted by anything non-windows.
i wrote it and even months later - i still like many parts of it. 
sorry, but i fail to see the beautiful in this code. the c-code actually looks better and that is saying something.
why the mozilla programmers are fond of rewriting mozilla?
 &gt; well, good for them - there's never really been a particularly great open challenger in that space.

and it doesn't appear that this will change—they're just bundling thunderbird/lightning into openoffice. is there any way someone would be able to get that to play nice with exchange? 
$15k? a bargain!

[a quote from late 1985](http://lemonodor.com/archives/001190.html) was for about ten times that.

once cheap sun boxes could do dumb number crunching faster (making the $15,000 price tag seem reasonable), the special-purpose workstation model was in deep trouble.

edit: actually, your $15k pricetag seems to be what the macivory 3 [was introduced at](http://home.rbcarleton.com/rbc/symbolics/announcements/19910826-macivoryiii.txt). 

but by this point, i think the original 'chineual' was irrelevant compared to the genera doc set; but i could be wrong.
haskell - lol.
if "usability studies" existed in the late 19th century, all cars would have reins in place of steering wheels. and burn oats rather than gasoline.

most people seem to have ossified minds. for them, the word "usable" means "does not force me to learn anything."
why? documentation better than sketchy man pages?
who is this joker? what is lisp? doesn't he know that vb .net is the de-facto extension language?
preaching to the converted, man.
no, friendliness is not a function of familiarity.  i can be very friendly towards people i'm not familiar with and there are people i'm familiar with who i'm not particularly friendly to, or aren't particularly friendly towards me.

what you're actually saying is that windows is only (barely) usable once people have become familiar with it enough to work past the unfriendliness.


why assume that google acted logically by firing him?  google managers are human beings and prone to all the irrational impulses and errors of judgement that flesh is heir to.

sure, in a perfectly competitive market google would be damaging its own bottom line by firing a talented employee for no logical reason.  but i don't think the market for advertising-driven search engines is very competitive these days, and against all the other things that affect google's profits, the effect of losing one employee, even one as talented as reid, is practically lost in the noise.
rant, ok so a rant with a lot of true statements. but still a huge pile of angry words.

can't we just keep it scientific. each language for its place.
"in the long run, we are all dead."  --keynes
 some good points... some crap.

some of his complaints about language usability are easily solved with trivial macros or programming creativity.

the complaint about parallel programming is almost complete crap.  cpus optimize parallel code in all but the more complicated intents, which shouldn't need to be "easy by design".

i'd rather use c than erlang because i'm not looking to learn a new language whose biggest feature is parallel programming.

i'd rather use c than haskell in a critical project because i don't want to worry about getting my mind around monads just to implement state, a feature critical to almost every nontrivial program.  

why should i use c?  because i can implement objects in less lines of c code than it takes for me to implement variables in haskell.  because i can implement almost any functionality in c that those language have, if i'm willing to give up on syntactic sugar.  i like haskell a lot, but it's not often the right tool for the job.  when c is the wrong tool for the job, it's an extra hundred lines of code.  when haskell is the wrong tool for the job, it's a matter of wrapping the philosophical ideology around the program.

i am still more frustrated by monads in haskell, after reading a dozen articles, than i was the first time i saw a char * * * foo;.

do i use c?  not really.  it's still my best backup for when the program is simple and has to run fast.  i'm stuck using perl day-to-day because it's the "best tool for the job" (combine the triviality of the job with regexps with the fact that it's the only language the entire department knows).  i use lisp and haskell at home.  i still think c is taking a bad rap on these one-sided arguments.  speed isn't the *only* reason to use c. 
well, there is of course. there are closed source products which work happily with exchange. it just requires quite a lot of probably uninteresting work. without someone to add some interesting motivation (if not intellectual, it needs to be financial presumably) it'll probably never happen.

which of course isn't neccesarily a bad thing. what would the world gain from having an open alternative to outlook? 
are you using it in serving public requests? how well has it worked out?
embedded systems, thats all.
so he doesn't like c, but he's not giving a lot of options that truly fill c's niche.  suppose i want to write code for the xbox or some oddball custom embedded system that isn't x86 and isn't running a unix-like os.  would i really want to use haskell?  is that even a realistic choice?
or they're the ones who couldn't hack it as consultants.
why c:

1.  c is fast.  

2.  c binaries are small and compact.

3.  c is everywhere.  it is really hard to find a platform that doesn't support c.

4.  c is easy.  there isn't very much to c.  you don't even have to know oo programming to use it.

5.  if you have to "go native" in a higher order programming language, odds are you are going to be using c.
ever since the update, the filter doesn't seem to be working properly. when it's turned on it blocks all the stories. and turning it off defeats the purpose. now i have to sift through all the crap manually.
please don't code like this in ruby. most of this stuff is built into the language anyway.
http/json layer aside, how does this differ from [sqlrelay](http://sqlrelay.sourceforge.net/)?
assertion != argument.

where i live, showing teeth is a threatening gesture. come here and smile trying to be friendly. see how your friendliness goes.

get it now?

what i am saying is that ways of interaction with a machine depend of a whole set of issues, historical precedents notwithstanding. *that* (to a point, obviously) equates friendliness to familiarity.
1. c *is* fast, but it's been demonstrated many times over that other languages can be faster at some tasks.

2. i don't have much to say there.

3. that's probably the biggest point in c's favor: it's unlikely that o'caml or erlang are available for a new exotic embedded device, but it's quite certain that c is available.

4. c is simple, not easy.  if it was easy, we wouldn't read about buffer overflows, off-by-one errors, etc. on bugtraq every week.

5. i don't quite understand what you mean.  are you talking about languages like python or ruby?  in that case, yes.  but in o'caml, haskell, common lisp or factor's cases, they are high level languages, and they compile to native code.

even though c clearly has flaws and is out of date, i am learning it right now, because i figure it's a useful skill to know.  that doesn't mean i'll be writing production c code any time soon.
nice :)

going back to the meat of the article, the claim is that one can easily implement objects with closures and viceversa. you have just shown that we can do the same for brainfuck + a reasonable preprocessor. thus my point stands, the discussion is moot as stated.

however. less is more; to my limited experience, closures compose in substantially more generic and interesting ways than multi-slotted objects. less is more; closures (if used right) have also the nice property of being immutable, thus one can actually reason about them. not to mention that the only interesting thing about object theory is subtyping polymorphism, which is a mere crutch. the content of the methods is never proved covariant, not even in theory. serious question: what does 'covariant' actually mean, i.e. what is its formal semantics, in context of mutable entities?
1. there are other fast languages
2. there are other small &amp; compact languages
3. just because it's everywhere isn't anything but a historical happenstance
4. there are other easier languages
5. this is just a consequence of #3

that said, the *ecosystem* is a big part of what makes software successful.  it may not be the best, but it's apparently "good enough" in the eyes of enough people, so their collective effort creates a lot of value.  but please note, this is not only true for c, but windows as well.  
when arguing against linus, it's hard to keep it scientific.  his statements are purposefully inflammatory; most responses will be as well.
&gt; c is easy. there isn't very much to c. you don't even have to know oo programming to use it.

because i definitely want to program in a language where the barrier to entry is so low that just about anyone could be my coworker...
as a critic of mozilla, i feel i should offer them public kudos and well-wishes for taking this project on. here's hoping it goes very well, and the end result is something much better than what they have now.
because there's so much boilerplate?
i think this deserves some serious examination.

one of the interesting things about extracting your db access out to json over http is that you can later then exchange something else that does json over http that perhaps isn't an sql database. or, perhaps best of all, you can easily mix and match, once you're no longer tied to being on a "sql database connection".

which is making interesting wheels spin in my mind.
&gt; but, in 1980, it was clear that *slower* c made more sense than
*faster* assembly. in 2007, the c clan doesn't see that slower *insert your
fave* makes more sense than faster c.

going from assembly to c is a huge difference. not only is the code much easier to read, write and debug, it also makes the code portable.

going from c to a higher level language does not make as large a difference.
i'm learning c now.  but i have a happy day job using java/.net technologies.  i don't tell my co-workers, because they would think i was as crazy as this post says i am.  why am i learning c?  why would anyone use c?

1. to better understand how memory is used.  if you saw some of the code i see daily, it's clear that your average coder has no idea, for example, why in java to use a stringbuffer instead of + for joining strings.

2. like it or not, it will be around forever.    a friend of mine writes video codecs, entirely in c, then optimizes in assembler.  for this task there's no better tool.  also, the linux kernel, and in fact a good part of all linux programs are written in c.  and, as the poster points out, all language runtimes and os'es are written in c or c++.

3. does memory footprint matter?  if virtualization is the future, then memory footprint matters more than ever.  a virtualized server won't have 2g of ram (no vista here!), but closer to 128/256m.

4. oop is not so special that it renders all other technologies obsolete (and this from a java/.net programmer!)  good use of design patterns (strategy, etc.) often involves replacing inheritance with composition.  in real-life oop, it's rare to see useful inheritance more than two levels away from object (outside of maybe ui toolkit code).  anyway, inheritance can be simulated easily enough in c, for those moments when inheritance would be really helpful.

that's why i'm learning c.
you could talk about programming all day, or you could just do it! 

come on, this is a clean problem, and it's no fizzbuzz either. 
can you solve it with monads, callcc's or neither?


great list of resources for us lazy developer that don't like to go looking around.
because i'll be out of a job! i don't know c# or java, and no one is hiring for python, scheme, lua or erlang.
it is part of a production setup. it has worked out rather well so far.
&gt;`[...] inefficient abstracted programming models where two years down the road 
you notice that some abstraction wasn't very efficient, but now all your code
depends on all the nice object models around it, and you cannot fix it without
rewriting your app.'

&gt;this guy doesn't seem to know that the point of classes in oop is so they can be
replaced without any effect on any other parts.

i'm pretty sure that he was complaining that people don't encapsulate *enough*. and that c++ encourages that.
absurd web 2.0 startups
wow, this thread is filling up with tons of c lovers arguing the same points the writer has proven not to be important.

the one reason to consider c in my opinion? it's procedural programming. not object-orientated. sometimes it may just suit the problem better. sometimes it may not. whilst it's not the only procedural language it's one of the highest level languages (which isn't scripted).

anyway, i'm a vb.net guy ;-)
i've been using a similar setup for a few months...  it simplifies things a lot and gets around either having to dream up your own data transport encoding or having to use xml...

personally i always recommend (to others) having an abstraction layer between your back end storage and your business logic...  (actually i usually use 2 layers for various reasons)
c is good to know because it makes you appreciate (and fear) some functions used in higher order languages. a good example of such a function, fgetcsv() in php. [http://www.php.net/manual/en/function.fgetcsv.php]

it's good to know c well, if only to know what must be done by other languages to do what you're doing.
&gt; get it now?

yes.  different people have different customs. the more familiar you are with a particular set of customs, the more likely you are to feel comfortable with them, and less likely to feel threatened.

which is why most people (i.e. those who haven't used any operating system other than windows) say they "prefer" windows or believe windows to be the most "user friendly" interface.

as i stated in my original comment, i think vixta is a good thing because it puts a familiar face on linux that will make the average windows user feel less threatened by it.

however, being the most widely used and therefore, familiar user interface is not a direct function of how well designed it is or how usable it is.  you're confusing correlation with causation.

market share != good design

get it now?

i wonder if the abstraction would start to "leak" if a non-database were used on the other end. it seems pretty geared towards tabular data.

that being said, i wonder if the syntax could be tweaked to have this return pojo/pocos from an object database.

interesting indeed.
amen brother. the name was intentional - we want to slay the db. we have a whole host of ideas of how we might take this abstraction further. 
well, haskell can target c code instead of machine code. so, if you port the haskell runtime to your device, then sure you could.

also, lisp would be a nice alternative. i would really like to see lisp compilers for embedded devices.
like i said in an earlier comment, i am learning c too at the moment.  and my number one reason is to help my comprehension of other  languages, the costs involved in certain operations, etc.
sqlrelay using a pre-fork model while dbslayer is threaded which for high traffic sites makes a performance difference. this also forces users into a stateless model (ie don't mess then the connection attributes, or run transactions accross multiple requests), which might feel uncomfortable at first but we believe is a better model. http reduces the client side burden since no specialized libs are required. 
a more complex language does not ensure that your coworkers will be any brighter.
he's missing the single biggest point about c here:

there is a massive library of fully functioning, meticulously tested and optimized c code out there. if you want to talk about code reuse and elegant architectures, what could be more elegant that using code that millions of eyes have been looking over for a decade or more? yes, there are bad c programs &amp; programmers. but there are rotten programmers for every language, that's just a fact of life.

i'm not a c devotee, but the fact is, it does it's job well, and has more momentum than any other language (see above posts about c being the first implemented high level language on any new chip); so, by definition, if haskell/erlang/trendy-language-of-the-now were better, they would have unseated c by now.
we have some folks looking at orm mapping that would live in dbslayer. also having the ability to do some data manipulation in lua in dbslayer very much like mysqlrelay is being worked on. 
the standard language on xbox is c++.
&gt;there are other fast languages

but not as fast (excluding assembly).

&gt;there are other small &amp; compact languages

but not as small and compact (excluding assembly again).

&gt;just because it's everywhere isn't anything but a historical happenstance

c is historical, present, and foreseeable future.  not learning it is just stubborn ignorance.

&gt;there are other easier languages

but that is not an excuse not to know or use c.
&gt;writer has proven not to be important.

actually the writer only proved his stupidity.  i can write an article for any language and say everything about the language is not important but that does not make it so.
here is how to use c: build a system using a lovely language like python, optimize on algorithms first, then optimize on languages. python makes it easy to call c routines. 

python too slow for image processing? get your whole suite working, and drop in replacement modules for things that need to be fast. luckily, lots of libraries already exist to do this.

i'm beginning to think that c++ is less suited for this optimization approach than c. thoughts?
why the mozilla are mozilla programmers fond of rewriting mozilla?
yet the op has not answered linus's challenge. he hasn't implemented the git core in a "better" language. why? because he likely knows it will be 100% slower.

it's hard to refrain from going for all the easy jokes here due to the errors.

yes, it would be great if we could write our code in a language that carries correctness proofs (validated by the compiler), has a powerful type system, a sane turing-complete compile-time language and allows us to write high-level code, yet has enough information for the compiler to form really fast sequential code and decompose the problem for parallelization. memory use should be only the size of the working set unless the programmer chooses to trade memory resizing for performance.

alas, all languages i know of are sorely lacking in one (or more) of these departments, so you'll still have to use the right tool for the job -- there's no silver programming language bullet, yet.

"when c is better

it isn't all roses, of course. the c quicksort uses an extremely ingenious technique, invented by hoare, whereby it sorts the array in place; that is, without using any extra storage. as a result, it runs quickly, and in a small amount of memory. in contrast, the haskell program allocates quite a lot of extra memory behind the scenes, and runs rather slower than the c program.

in effect, the c quicksort does some very ingenious storage management, trading this algorithmic complexity for a reduction in run-time storage management costs.

in applications where performance is required at any cost, or when the goal is detailed tuning of a low-level algorithm, an imperative language like c would probably be a better choice than haskell, exactly because it provides more intimate control over the exact way in which the computation is carried out."
 5. i think he meant "call the os" (because your higher level language doesn't wrap os functionality you need).

edit: when i edited my comment it read "5. i think...", (i see it now, too) but it shows as "1. i think...".

what's up with that, reddit?! ;-)
say you decided to swap out the db backend in place of something else, still returning json in the same format. your app is still requesting query strings with raw sql, right? so now the new system you have put in its place either has to a) parse sql, or b) have the query mapped to some other functionality? or am i missing something?

i would imaging migration wouldn't be as simple replacing dbslayer with a service that took the same urls but provided results in a different manner.

it still looks like an awesome project.  any plans on extending it to other database engines?
i disagree.  in many cases the difference is as extreme.  a lot of languages do most of the work for you at compile or run-time.  and i like c, don't get me wrong.

show me a c program that can evaluate arbitrary code at runtime, for example.
hmmmm, the title is rather misleading. the article has nothing to do with differentiation. but it was a nice article nevertheless :-)
i can't get to the site.
i don't know why people down-rated you.  getting a job is a non-trivial consideration. it's sad but true, but there are always jobs available for languages with a high degree of suck (java, c, php).
good stuff. my concern is avoiding relatives of [bobby tables](http://www.xkcd.com/327/).

your security page says:

&gt; the account dbslayer uses to access the mysql database should not be allowed to execute dangerous operations like dropping tables or deleting rows. ideally, the account would only be able to run selects and/or certain stored procedures.

that still doesn't prevent someone from completely locking up my db and rendering it useless by doing nested subselects and all that. if i have a public-facing site and someone can just run:

    select z1.*, z2.*, z3.*, z4.* from zipcode as z1, zipcode as z2, zipcode as z3, zipcode as z4

then my db will indeed be hosed. now you gotta worry about mysql timeouts and all that. hmmm.
&gt;but not as fast (excluding assembly).

not true. some languages are faster than c when compiled in certain situations that aren't particularly rare situations.

&gt;c is historical, present, and foreseeable future. not learning it is just stubborn ignorance.

it's people saying that very thing that keeps languages from evolving faster.  i see c being used in mission-critical systems, but people being too attached to it are why bad languages that are similar to c are kept above water.
xbox, you mean the oddball x86 celeron? :p
right tool for the job i say.  i currently have an implementation that would scale no where near as easily if i didn't use c for some of the parts demanding the most performance.  the rest is in various scripting languages where power and flexibility matters.

even though ram is cheap nowadays, memory footprint still makes a huge difference when we start to scale seriously.  executable code and data still needs to be shifted through all sorts of parts of the computer and this still takes time.  the fact that doesn't need to be read from disk constantly because it can all stay in ram might speed things up 1000 fold, but not having to use huge chunks of ram bandwidth can increase things by another 1000 fold.  that is assuming that you need that kind of performance for a particular task.
int main(int argc,char** argv)
{
   if(argc==2)system(argv[1]);
   return 0;
} 
lispworks is probably between a rock and a hard place.  it's good; but faces an uncertain future, one that even an altered pricing model can't solve.

sbcl is looming over them - it's becoming a defacto standard (lib developers will start to lean toward sbcl-only extensions), it is full multithreaded (as in, can use multiple cpus).

(putting aside allegro, i know little about it and the pricing model concerns some) - lispworks is currently *the* lisp for win32, and its ide is somewhat familiar for windows users.

a bit of attention to sbcl and that could change as well.





ok, i believe we rather consolidated on a common ground?

i never wanted to say that windows is good *because* it's familiar, nor to advocate "market share = good design" stance. sorry if it sounded like that.
yep. you need to run it in a trusted environment. 
also, whatever language you are using instead of c probably has parts of it written in c.
the original poster said "for the xbox **or** some oddball embedded system that isn't x86."
 by way of feedback, the one i'd be most interested in is providing dbslayer with a function specification, such as "get\_current\_users(domain, since\_time)", which it can _either_ convert to sql _or_ do something else entirely.

i'm _sure_ you've thought of this, i'm not trying to pretend this is an original idea. i'm just feeding back to say it's the one that most intrigues me. 
but you would be truly insane to go that route.
&gt; c has no closures. well ... i don't
know what the argument against closures is.

the natural implementation of pointers is incompatible with a good garbage collector, and you need a good gc to do closures right.
a simple wrapper around a c compiler will do this, which is basically what 'eval' is in all the languages that have it.
cool glad to hear other share the same idea. 
yep. we want to create a backend for apr-util db so it will map to postgres,sqlite, and oracle in addition to mysql. should be fairly straight forward if people are interested in helping out. 
true. well, my trusted environment dbs can run off a 286 because i work in a small company. maybe some day...
in the context of the sentence it was implying that xbox was an oddball embedded system
i think c killed the authors family or something.
here i am! your insane target!

actually i am trying to create a scheme compiler for small efficient code. might not be the whole scheme or a complete lisp to start with but it is actually less hard than you might think. =)
we do plan on adding some simple security but i think you would still want to run everything in a trusted environment. if set privileges for a user to just stored procs then it might be okay but i would be wary of it. 
well, mostly not... a lot of non interpreted languages are self hosting. a lot of the lisps, smalltalks and haskells for example.
it's called markdown.
while i appreciate and agree with _most_ of the values rms has fought, and does fight for, he is fading into irrelevance and obscurity, along with his ability to crank out tons of code that the community finds useful and interesting.

i feel there's a space opening for a group and/or individual to take the place of the fsf and rms, but with the modern idea of operating in environments with mixed sofware, both closed and open, free and not.  basically the fsf except with a firm grasp on reality.
well written article, i hope this kid gets some response from the politicians/groups responsible for whats so far been a massive waste of taxpayers money.
try to find coworkers that wouldn't think that you're crazy just for learning something.
heh... i get a script error when loading the page. 
quantity vs quality i see. i mean who the heck calls himself web developer and visits hotscripts.com?
object-orientation is not strictly a feature of a language, it's a way of doing stuff ("programming paradigm" is a fancier term); for a good example of an object-oriented c codebase, just look at [gtk+](http://library.gnome.org/devel/gtk/unstable/index.html).
all cars have similar ui's. you can switch easily between them.





&gt; i don't think it really helps the users 
&gt; understand the product that well

but it helps the developer to understand the product, especially when the client doesn't know what he really wants. 
a runtime interpreter is just as extreme a difference as being able to write one program which works on multiple architectures? somehow i am skeptical.
yeah, i know, i still managed to hit the weird case. :-(
sure, it's just not language-native to c right yet.  i highly doubt it'll be so trivial to do something like this:

int a = 1;
int b = 2;
int c = 0;
evalc("c = a + b;");
printf("c = %d\n",c);

and get c = 3.

ps: is there a way to paste code cleanly into reddit?
that would get you an object file, but you still need to link and load it.  to be equivalent, you need to load it into your own process.  otherwise, it is no different than running system().
 i'd like to see this _simple_ wrapper that gives c an eval. 

actually, i'd like to see anything that gives c an eval. i'm aware of one interpreter which could probably be easily hacked to do this, but what about the compilers which everyone uses? 
&gt; but not as fast (excluding assembly).

forth.

&gt; but not as small and compact (excluding assembly again).

forth.

&gt; because he likely knows it will be 100% slower.

improbable, but possible, i suppose.

depending on the language chosen i'd bet you could get within 10% at a minimum. if you have an ffi and want to write the intense parts in c then you have the best of both worlds.
understanding "coalgebras and automata" is not required to be a functional programmer. you need to understand higher-order functions, and you should understand side-effects (though not necessarily avoid them at all costs; that's a religious issue).
 calculating etag is fairly cpu intensive the way django does it (it still creates the response).

calculating etag the way apache and lightty do it doesn't work well in server farms, since they use inode, which of course varies for the same file between servers.

there was a good discussion of this stuff a while ago:
http://www.tbray.org/ongoing/when/200x/2007/07/31/design-for-the-web
http://technorati.com/search/http://www.tbray.org/ongoing/when/200x/2007/07/31/design-for-the-web
 
update: oh, and mnot seems to have made a career of consulting on http, most specifically with caching; he's worth listenting to:
http://www.mnot.net/blog/http/index.html
put four spaces before your code.  they won't show in the message, but the indented block will appear in a &lt;pre&gt; tag

    like this
 some arguments are good, but why in the pratice i continue to see different things?

example: 'utorrent' is written in c and is a very cool, stable, full featured application. it's fast, small, and so on.

there are mature tools to write this kind of applications in dynamic languages with a much higher level of abstraction, in little time (compared to c development), and with fewer bug.

well all this is in theory, in the pratice it looks different.

i think i know why... or at least i'm starting to figure why.

c is not so low level, **if** you improve the standard library enough to have dynamic strings, good data structures, a good library for event-driver programming, and so on.

once you start using an enhanced version of the standard library the difference of abstraction between ruby and c starts to get much smaller. ok you don't have a closures, the memory business is still manual (even if with good libraries and valgrind it's much simpler than raw c), and so on, but using 'structures' and a good dose of functional approach and bottom-up design you can write good modular c programs that are simple to develop, read, fix.

so... if the difference gets smaller you start *seriously* to see the good points of c: it's fast, the interface with the operating system is not mediated, there are **static checks!** when you compile. if everything compiles well and you test the application there are very little chances that the user will see a runtime error because a name of a var was a typo.

there are even advantages that are about being low-level: programmers able good c programs care a lot about a data structure being o(1) or o(n^2) in certain kind of operations, it's like if every part of the program is written with more "computer science" in mind.

i think this all the reasons why in pratice a lot of the best software available is written  in c. 
example please.
unless your site has massive amounts of page views, some of the speed optimizations here are really not that important.

avoid speed optimizations that make your code less succinct, harder to read and harder to debug unless you really need the speed.

that being said, many of the tips here would benefit novice php programmers.
&gt; in contrast, the haskell program allocates quite a lot of extra memory behind the scenes

not [necessarily](http://augustss.blogspot.com/2007/08/quicksort-in-haskell-quicksort-is.html). not that i'll argue that it's natural to do so in haskell, i'm just pointing out that it can be done.
c-repl
http://neugierig.org/software/c-repl/
the same way you would load any other shared object at runtime : by calling dlopen(3).
nonsense.  embrace the [singular they](http://en.wikipedia.org/wiki/singular_they)!
why should i care which language you use?
  he definitely has nothing against linus here, just all talk. linus always backs up his proclamations with real code. git in c is much faster than [darcs] in haskell. the speed difference likely more a question of algorithm than anything, but the point of using high-level languages like haskell is so you can do lots of experimentation with algorithms flexibly--which cogito has attempted, and yet still lags behind a "stupid content tracker."

i don't know why c is being compared to high-level languages in the first place here. right tool for the right job. yes, we're aware of the myriad of problems with c. doesn't stop it from being a good, pragmatic choice sometimes. git was [not!] written in perl the first time. [not!] prototyped in a higher-level language, then quietly ported to c. [which is what linus was talking about i suppose.] and it's by far the fastest dscm tool out there, and quite possibly the best-designed.

edit: haha, whoops, i meant darcs, not cogito. and my bad about the perl bit. 
though i hate outlook it’s what corporate types want. i can’t believe you’re comparing it to gmail. gmail doesn’t have integrated group calendaring and scheduling and doesn’t have the server side (exchange server) that the ceo’s latest phone gadget can sync with.

google has most of the pieces: gmail + google calendar + google groups + google talk could approximate the functionality of exchange/outlook, but they are a long way from integrating it into a single platform, convincing corporate it departments to use it, and getting pda cell-phones to sync with it.
  many business won't use opensourse for stupid legal reasons, secondly if they kept the opensource separate from there commercial offering many people would still buy it even it its just because they didn't know there was a free alternative.

in exchange for loss of profit from people who download the free version rather than buy it they gain a horde of free developers. also inkscape was already around so people would use that if they wanted free anyway, but having xara as a choice would have increased awareness of it, i doubt i would never have heard of it if it wasn't for the opensourcing and i wouldn't have bothered with it over inkscape. my not releasing a necessary component they imminently killed developers interests in the product, other than replacing that part with something else but that never happened.

people have been known to purchase burned copies of openoffice off ebay and many people will buy it and linux distros (even when they don't want the support) off the shelf in boxes.

vector graphics software isn't something that is marketed to individuals much.  
99% of php (or any web site) speed problems are due to poor database design and indexing. the remaining 1% are due to very poor programming choices such as bad algorithms.

once your code already runs very well you can look at these 40 tips to get that extra hundredth of a second speed improvement.
that's called mercurial
lisp
ok, you got me -- simple is exaggerating it.

you would compile/link the code to a shared object. the tricky bit is the communication between that shared object and the code surrounding the eval. variables in your surrounding code that need to be written to from inside the eval would have to be declared 'extern' in the eval code and you would have to pass the addresses you want these variables written to to the eval function.
yes.
it's about the simplicity of a finite state machine with the power of a pushdown machine.
actually, git was written in c from scratch.
funny!
quick nit-pick, utorrent is c++.
"to check, i used timelord to overlay a national bureau of economic research official measure of economic expansions and contractions, and sure enough, these patterns intersected with nber recessions."

why in the world is he telling us this?  if he can forecast recessions, he could clean up in the market.  if this really is a startup company product, the need to drop whatever business model they have in mind and prepare to strategically short stocks right before the next recession.

or if that's too risky, just sell to wall street and retire to a tropical island somewhere.
chine nual ftw!

also check out stallman's "personal note".
wow...this is definitely a c-fan dominated thread.  my valid points supporting c have been upmodded to no tomorrow.  my equally valid points opposing c have been argued against viciously.
the funny thing about this blog post is that the title complains about commercial common lisp. he states the price of commercial developments products, concedes that this is about the same price range as visual studio, states that this is small change for a commercial operation, and then goes on to complain that this is a lot of money for hobbyist. so what is the problem with commercial common lisp?

(note, i have nothing against cl. i'm just commenting on the incongruities within the blog post)
 every shootout shows bigforth losing to gcc, but i would hazard to guess there is probably another forth compiler out there that is faster than gcc.  the funny thing is is that gcc is neither the fastest nor slimmest of the c compilers, since its popularity is due largely to its large support for various platforms (something no version of forth comes close to).   feel free to enlighten with proof otherwise.
i think it is quaint that even 'progressive' c programmers regard object-orientation as 'trendy'

long live c and all it's daftness! we love its idiosyncracies- it's the britain of programming languages.
i always thought of it as the new jersey of programming languages, or is that the programming language of new jersey, i can't remember.
c has its (legitimate) place:  see ["the fundamental theory of c"](http://kickin-the-darkness.blogspot.com/2007/09/fundamental-theory-of-c.html).
 i think #5 is the absolutely critical one for me.  i love using higher level languages but always find myself coming back to c because i need to extend those languages to interface with other libraries.  having wonderful tools like swig available have helped in this regard but i will not be throwing out my c books any time soon. 
&gt; why should i use c? because i can implement objects in less lines of c code than it takes for me to implement variables in haskell.

most of the time you can use the state monad for this:

    import control.monad.state

    incr x = do n &lt;- get
                put n + x
                return n + x

compare this to c:

    int n;

    int incr(int x)
    {
        n = n + x;
        return n;
    }

obviously there's a lot more going on behind the scenes in the haskell version, but i don't think it's not as complex as you make it out to be.
oh, now that's cool and useful. and it works in konqueror pretty well.
"because i can implement almost any functionality in c that those language have, if i'm willing to give up on syntactic sugar."

you can implement almost any functionality in assembly if you're willing to give up on syntactic sugar, too.
yeah, but then it is not portable.

i really don't understand where this false analogy comes from: assembly:c :: c:&lt;language x&gt;
agreed on the mnot recommendation.  [his caching tutorial](http://www.mnot.net/cache_docs/) has been a staple recommendation of mine to http newbies for years.

although, having said that, i really do think that a solid understanding of http is mandatory for any competent web developer, and you aren't going to be able to get that from a couple of tutorials.  read rfc 2616, buy a couple of books on the subject, hang out on the newsgroups/mailing lists/weblogs, etc.

whatever happened to waka, roy fielding's successor to http?

c is the high level language that most accurately represents when is happening on the silicon.  when one is programming on the hardware instead of in a mathematical fantasy, this is very important.
i figured i'd post this here and give the math geeks a chance to show off, by embarassing me with an incredibly simple answer.
i didn't actually say that analogy was false in my op.  actually, i think the analogy is utterly true.  

it still doesn't make c useless.  i think in the modern world, assembly is all but.
i'm doing just that and prefer c++ for three reasons:

1. i want smart pointers for reference counting.
2. i want my functions to return values, not error codes, so i use exception handling.
3. my current main target library netcdf has lot of basically same functions differing only by data type (nc_get_var_float, nc_get_var_double) so i can write generic algorithms with templates instead of macro hackery

thats about it. obviously, learning stl made a big difference in my coding style. i use virtuals very little. 
sure.  i can create object implementations on the fly using arrays of void pointers.  it's ugly, but it's a line or two of code.

i wasn't aware that just adding the state monad ties it in to everything, though...
then simply use java assembly, not the i386 assembly. that's portable and there is no superfluous syntactic sugar !
true, but most languages make it easy to call c libraries just because you can do so much with them. so it's not necessarily a good reason to choose c.
they have trouble getting it right i suppose.
calling c "high level" is like calling a baseball bat a weapon of mass destruction.
i'd say that he didn't prove anything at all. 
i think the reason to use c is greater control, more so than just program execution speed.

as many people have pointed out, there are times when programs written in "higher level" languages will be faster than a comparable program written in c.  but c gives you more fine grained control over resources like memory, file handles, etc.  there may be very good reasons, for example, that you don't want the specific characteristics of java or python or common lisp's memory management.  the ranter kind of gets at this when he says that c's one legitimate rule is to write runtimes for other languages.  this is because c gives you a lot of control to give those runtimes exactly the characteristics you want.

you may need to consider these things even if you are not creating a new language runtime, however.  these are the times you want to strongly consider c.
 good use.  that's the problem with all oop.  given that many "professional" developers i know (in gov't and industry) don't know how to do procedural programming well, i'm always amazed when i see their good use of "design patterns."

for all the wonders of c++ reuse, i've seen a lot more c++ code rewritten than c. 
"because i can implement almost any functionality in c that those language have, if i'm willing to give up on syntactic sugar."

right. all programming languages are just syntactic sugar. why did mankind even bother with inventing them ? we could simply just be writing machine code instead ! things like functions calls in c are merely syntactic sugar !
&gt;i'm beginning to think that c++ is less suited for this optimization approach than c. 

c++ alone is a pain to embed in python.  however c++ with swig or boost.python allow you to directly embed objects in python, and makes c++ much eaiser to use.   

the big gain is you can use things like std::string.  it isn't hard to write c++ code that does everything you do on python srings with std::string, and this makes porting python to c++ much easier.   the other gain is you can max c++ and python objects.  

i was able to take a python module that was too slow, and translate it to c++ with very little effort.  (almost as easy as adding braces and types)  swig then let the rest of my python program work just fine.   an experienced programmer would notice that the resulting c++ code looked like python, but it was fast enough.
anyone got something similar for ruby or python?
what editor handles that?
and if you drop apostrophes, you save another character!
i want to test this theory. anyone want to help me write a language that requires iq tests as preprocessor pragmas?
chaining of functions in state monad is much more comples that simple increment, and you need to understand it, it's not something hidden by compiler. i don't think languages like haskell can ever become mainstream.
hey, i started this wiki to be a simple handbook or cross-section of interesting facts that should be useful when thinking about performance. let me know what you think.

cheers
  even that only gets you part way. consider this:

    sub x { print 2; } 
    eval 'sub x { print 1; }'; 
    x();

so any eval() you might come up with for c either will be hideously complicated, or will require changing the code. 

changing the code to accommodate an eval limits the eval's effectiveness, since it is limited to those things you had the foresight to prepare to be changed by eval. in the meantime that code will also be more ugly.

a more powerful version that can change anything and doesn't get in the way will have to muck around within the guts of an optimized binary with plenty of inlining, not to mention adding a whole slew of hooks to the compiler so you can maintain the necessary data structures for this. i feel pity for the sod who'd try to write that.  
 the state monad provides the get and put functions, which provide approximate functionality to a procedural function or method that updates a single, external variable.

and if you're willing to accept "ugly":

    incr x = get &gt;&gt;= put.(+x) &gt;&gt;= return.get

but personally i prefer the sugar that the do-notation provides ;)

**edit:** incidentally, i believe that you could rewrite the above to use "modify":

    incr x = modify (+ x) &gt;&gt;= return . get
and even some of them have parts of their runtimes written in c.  (cmucl/sbcl comes to mind).
the thing to do is to record a videotape of yourself mocking them and being all crotchety while you're young and energetic; that way when you become old/dead, you can just roll the film and save yourself the energy (which as a crotchety/dead old man, you don't have to spare).
this is nice.
does anyone else shiver with fear at the idea of having sql anywhere near the presentation layer (the browser)? or am i the only one? 

it's also possible i don't fully grok how dbslayer is used in a production environment but to me is just seems evil.
i would shiver. mainly php,python,ruby, even c code is used to consume the json. 
  "c is not so low level, if you improve the standard library enough to have dynamic strings, good data structures, a good library for event-driver programming, and so on."


so you mean we should use c++ instead of c ? ;)


"if everything compiles well and you test the application there are very little chances that the user will see a runtime error because a name of a var was a typo."


nice, but c brings its own type of bugs, much worse than typos in varibles ...
  
i've never had to optimize string processing. that's probably because i do lots of sensor processing.

the point is that in choosing the components to optimize to get the desired performance, python string processing is good enough. no?
it's sad that this "assembly is faster than c" idea hasn't died yet.  it may still be true in very limited situations (things like bitblt or rle or strlen) when the person writing the assembly is really fricking smart and has an intimate understanding of the architecture that the code will run on.  but with any reasonably large piece of code, modern c compilers will beat you every time.  you think you understand how to write machine code to keep all your pipelines full?  you think you can allocate registers better than the compiler?  you think you can sustain that sort of mental effort for more than the equivalent of a few thousand lines of c?  i doubt it.
ah yes, i see now. i read more of the documentation and now i get it. oops. :)

pretty sweet project you have here. i might play with it for the software i work on, we have an immense number of small selects in most cases.
php teaches you to fear php.
do you have a good overview link? i'm interested, but i'm faced with what appears to be a mass of perl 5 docs, not anything saying what kurila really is.
this would probably be upvoted more if the page weren't so spammy...

"# igf2 pen1s growth solution, olin stover"
&gt; c is the high level language that most accurately represents when is happening on the silicon. when one is programming on the hardware instead of in a mathematical fantasy, this is very important.

your descriptions of c seem to contradict any description of a high level language i've ever heard of.
c is the first modern syntactical programming language. that is why we don't program in assembly. because it is hard. c isn't the answer for everything, but neither is any other programming language. if you just need to do a generic task, java is great. but what about embedded system, you can't write java for a portable device. and like it or not, other programming languages aren't that fast yet. whenever i use any java program ever, it quickly bloats up to be unuseable very quickly. the user gets no benefit, just the developer. sure in the future computers will be so fast that optimization will be nearly pointless, but we still aren't there yet.
forth loses out these days since most compilers are trivial and don't bother with fancy optimizations like register allocation (which matter more and more). the claims of forth being faster are more to do with the philosophy and development practices of forthers which eschews bloated c programming style.
  terrible. the c should read:

int inrc(int \*n, int x) {return ( \*n += x);}

because you want to manage the n, right?

so monads are like the yield-statements in languages with syntax. that and exception handling, what are the other uses for those?

  
i'm a professional c coder.

i write gobs of c for a proprietary embedded platform. 

i love c because it's close to the machine but not assembly. 
i love c because it lets me do whatever i want with memory. 
i love c because it's simple yet very powerful. 
i often write oo c, it's not hard at all.

i hate c because it lets me do what i want with memory. the lack of memory management is a huge time suck when debugging. 

when i'm writing code outside of my job i use python, javascript, and c. depending on the task. i mostly use python, love it.

this is an old argument that comes down to using the right tool for the job and knowing how to use the tool well.
my issue is purely that it makes things expensive for people who want to produce applications for multiple platforms, which, these days, is just about everyone. i have no issue with them charging for it, and if they supplied a mechanism to compile for the big desktop platforms with it (even if it cost a bit extra), i'd seriously consider buying it. i suspect that a reasonable number of other people are in the same position. on the other hand, i'm sure most commercial users have one f the more expensive packages, and wouldn't be bothered. this sort of thing wasn't important a few years ago, but these days people expect multi-platform applications, and lispworks, with its platform-independent gui stuff, could be a great way to produce them. 

typically, with other languages, there exist free or very cheap tools which allow hobbyists to create their own distributable, easy-to-install, gui applications. this isn't really the case with common lisp at the moment, but if lispworks were to allow people to produce binaries for multiple platforms with one license, it would move a little closer to being.
yes, but don't you normally have to write c to call those libraries?  i've had to write plenty of wrapper code to get access to libraries that i have wanted to use in other languages.  the bottom line is that c remains the lingua franca of computing and you are going to be very limited if you cannot program in it reasonably well.
1. press ctrl-a
2. hit backspace

100% optimization
scite does.
i know with db2 you have the ability to view the execution plan and get a cost estimate.  

not 100% on how you'd get that from an explain statement in mysql, but it's just a thought that if you could rapidly parse through that you could somehow cap the select statements performance cost so you don't hang the db as chime pointed out.
if you're writing php you're probably not mature enough a programmer to know when to optimize.
have you guys taken a look at couchdb?
http://www.google.co.uk/search?q=optimizing+%28ruby%7cpython%29

edit: markdown hates parentheses :( 
yeah. very interested to see how that develops. 
delete the newline character on the previous line?
'cuz i like using it.

that should be your number 1 criterion in choosing a programming language.
function pointers, variable argument lists. piece of cake. as for inlining and optimizing, well, you have to hunt down the references. but you'd have to do that anyway. but you're right, you're better of a jit all the time in that case.

it's really not that complicated if you know how to do it.


this bugs me too.  there's a perfectly suitable standard way of doing things, and they eschew it for a non-standard, sucky hack.

i believe the usual excuse is that lots of non-english people download illegal copies of windows and get the `en-us` locale by default.

by the way, it's `accept-language`, not `accept-lang`.  you're probably confusing it with the `lang` html attribute.

&gt;the claims of forth being faster are more to do with the philosophy and development practices of forthers which eschews bloated c programming style.

no argument there.  c is by no means a rapid application development language.
as always, it depends. i use python a lot, so i have to know c. with vb 1-6 you could call windows dll's directly, you will only need to know the windows memory model. of course knowing c was a great help.

but for example you don't need to write an image processing system in 100% c even if all the real image processing is done in c libraries.

not very professional, because he doesn't give the code used to measure. and he doesn't emphasize clarity over speed. and doesn't have comments on his blog.
also, read the note on this section: http://www.php.net/types.string#language.types.string.substr
and look at the code for number 39 on his list.
and while he claims in number 40 that this is only true for php, ++i _is_ faster in c++, because of the temp copy.
it's perl 5.9.x with some syntax removed and a couple of additional modules included.  mostly it's an experiment to see if breaking backwards compatibility with the perl 5.9.x source code makes it possible to clean up the internals and add some desirable new features.
assuming that most people use a localized version of their web browser, the accept-lang header should already give the correct language, i think.

if such sites want to help people who for some reason or another have a vanilla english browser installation, they could compare the accept-lang header to the most common "unconfigured" ones, and let the people who have configured theirs ([mine](http://www.ericgiguere.com/tools/http-header-viewer.html) is "vo,eo;q=0.8,sv;q=0.6,en-us;q=0.4,en;q=0.2") get what they want...
the problem is that a half-decent assembly programmer can code a tight inner loop using inline assembly that is, in many cases, slightly more efficient than one compiled from c.

everything else should be coded in a real language, no matter what.
   &gt; function pointers, variable argument lists.

wow, what wonderfully readable code we have. you planning to do that for everything?

&gt; as for inlining and optimizing, well, you have to hunt down the references.

and recompile everything that it touches. and then recompile everything _that_ touches. and so on. how do you plan to untangle register allocation through an inlined section exactly?

&gt; it's really not that complicated if you know how to do it.

say that again once you've actually done it. 
ah, well then i would say that this is a problem with the availability of free/free multiplatform lisp tools. perhaps this would be better received as a rallying cry for the lisp community to improve their free versions of the tools.


(in any case, i'll have to take your word for it as i haven't any experience with these tools)
&gt; every shootout shows bigforth losing to gcc...

[bigforth :: gcc (partial-sums)](http://shootout.alioth.debian.org/gp4/fulldata.php?test=partialsums&amp;p1=bigforth-0&amp;p2=dlang-4&amp;p3=gcc-4&amp;p4=gpp-3)
i considered google might be doing this, but adding nl (dutch) to my accept-lang configuration still gives me the croatian google :(
woops, good point about the header name, fixed.
okay, point well taken.  i think you are correct, you would still need to be able to read c just to understand what you were getting back when a function returned a pointer, a struct, etc.

i did not mean to imply that anyone had to write all of their code in c, just that somebody usually has to know enough c to wrap those functions for you so that you can use them.

i guess i don't like the idea of people looking a c and thinking, "man, i really don't need to know this."  you may be able to squeeze by without it but i can't imagine not wanting to understand it.
i'm amused that he doesn't seem to know the answer to his question.  one word: infrastructure.

the toolset, the libraries, the ides, the documentation, the millions of fellow c programmers worldwide, all of that; it's all more numerous, more debugged, more mature in c.

languages that succeed in wide adoption either build on existing popular languages (c++, objective-c) or have major capital to build these resources from scratch (java, c#).
  yes... engineering without vision. that is exactly the process by which linux has evolved.  well, that's misleading.  the vision has been to produce a kernel that does something, whatever the users of the time wanted it to do.  at first it ran on linus' box, then others.  there isn't a long term goal.

http://www.kroah.com/log/linux/ols_2006_keynote.html  
&gt; c is the high level language that most accurately represents when is happening on the silicon.

maybe pdp-11 silicon, but i'm not sure c accurately represents what happens on any processor designed in the past ten years.
summary for lazy people:

 - allegro can't do mac guis, and charges per-user
 - lispworks is not cheap (us$1300 per platform), and can't cross-compile
 
better: display what's suitable according to the `accept-language` header, and if the location of the ip address doesn't match, display a prominent message in the other language offering them the other language.

of course, any localisation scheme should be offering alternatives that can be selected manually anyway, but it sometimes makes sense to specifically call attention to it.

i'd be interested in knowing what they do for places like switzerland, where there are multiple official languages, and places like ireland, where picking the wrong "official" language can seriously alienate some people.

regarding os x: i haven't checked recently, but when i last set up os x, the british edition, installed on a laptop bought in the uk, safari was set up to transmit `accept-language: en-us` and i couldn't find any way of changing it.

 yet there's a free version of almost every compiler in visual studio.  you get the financially backed strength of a commercial compiler and full redistribution permissions on any product developed in the software at any time.

further, cl is one of the only languages where quality native compilation is unavailble for &lt;$1000.

it's the lack of commercial-quality common lisps at a reasonable price to an individual developer.  that's what i get out of it. (and sorry if this disagrees with the original intent of it, but the point i got out of it is still valid)
he is an angry, angry man.
well but writing code for short term goal one of the things to take in mind is "how happy will be users about this". i don't think this is very often taken into account, or for some reason does not work very well in practice.

**edit:** btw my guess is that the term *vision* is misleading translated to english. for "vision" i don't mean "very long term goal", but "what is the effect of my work in general terms and not just about the tech aspect".
as pointed out below, there are languages that are as fast &amp; compact as c.  and no one is looking for an excuse not to know c.  i know c.  it is a good way to do many things.  but there are in fact better languages for a variety of purposes.  
more people falling for the same old joke. yawn.

yeah, but if kernihan &amp; ritchie had written a forth instead, then all those languages would have parts of their runtimes written in that instead.  

the ubiquity of c is just as much a bit of happenstance as the ubiquity of microsoft windows.  something good enough happened to be there at the right place and right time.  
ah yes, there's another rant: the way browsers hide their language settings. (at least, on firefox going to about:config seems to be the only way to change this. not very friendly to the computer-illiterate people.)

maybe when china becomes the new economic superpower, and india the new technological hotspot, internationalization will no longer be an afterthought.
it is important to remember two things.
- define the data structures to support all your features at once. these must be super duper.
- abstract access. the access must be super duper also. no mess.

the only thing that i can see lisp et al are especially good at is if you can't meet the first requirement.

if you write self-modifying code instead of a complete jit, then you can't propagate instructions across the function boundary, but that is usually a small hit. you can still do register allocation. why couldn't you?

 that page itself has a nice "blooper":

(before publishing, come up with a sentence or two about this picture from hank)
 
&gt; 99% of php (or any web site) speed problems are due to poor database design and indexing. the remaining 1% are due to very poor programming choices such as bad algorithms.

agreed
 i suppose, if i were looking and faced that choice, that i'd rather take a c job than a java job. 

but that's mainly based on my own prejudice: i'd expect my c-only coworkers to produce pretty good c code, even if they're a little set in their ways. i'd expect my java-only coworkers to produce lousy java code.

now why do i think that? come to think about it, it's exactly what linus said.
it is funny, how dbslayer provides strictly tabular data, completely ignoring oo aspect of javascript, dom and xml.

pushing impedance mismatch to the client ? :))

&gt; the way browsers hide their language settings. (at least, on firefox going to about:config seems to be the only way to change this.

in firefox 2, look in the advanced pane of the preferences.  you can't add a language that firefox doesn't know about though (and i believe this is a regression from previous versions).

tell that to the facebook devs.
&gt; yeah, but if kernihan &amp; ritchie had written a forth instead, then all those languages would have parts of their runtimes written in that instead.

true, but that really doesn't have anything to do with my point. (see kokey's an joeldevahl's [comments](http://programming.reddit.com/info/5ybcs/comments/c029abx) above).
yes, i agree. not understanding c seriously limits what you can do.
[kurilaintro.pod](http://search.cpan.org/dist/kurila/pod/kurilaintro.pod) is the main writeup, and then there's the changelogs for [v0.1](http://search.cpan.org/dist/kurila/pod/kurila01delta.pod), [v0.2](http://search.cpan.org/dist/kurila/pod/kurila02delta.pod), [v1.3](http://search.cpan.org/dist/kurila/pod/kurila13delta.pod), and [v1.4](http://search.cpan.org/dist/kurila/pod/kurila14delta.pod).

too late
 yeah i fucking hate that. if a compiler is "self hosted" that immediately excludes it from  consideration for me. it's a real shame darcs is written for ghc (which in turn is "self hosted"), because that makes it unusable for me.

on a side note:
the person writing tfa doesn't understand portability. i've programmed for lots of platforms. from big iron down to embedded devices. you can't really say "yeah, we could re-use code... as soon as someone ports python to our target platform". c probably is the most portable language there is. i mean what platform doesn't support c? (except fpga/asics, but be serious)
right now, though, sbcl is, while very nice (i use it for running webapps), a little inadequate on windows and some other platforms. there's a lot of work going into improving this at the moment, but it's taking time.

i doubt that people will go sbcl-only when writing libraries. if anything, the trend has been against that sort of standardisation; a few years ago there were a lot of cmucl-only libraries, or clisp-only libraries, or allegro-only libraries; today, just about everything coming out works in every environment where it's practical for it to work. this may partly be because a lot of work (eg. usocket, cffi) has been put into abstracting out low-level stuff, so it's easier to write compatible libraries.

win32 is particularly interesting, really, because there is no major free lisp implementation which can do multi-threading on it. in fact, about the only free one which runs well on windows, afaik, is clisp, which comes with its own wacky license issues. lispworks et al. still have a vast advantage on win32.
not only a joke, but not a remarkably entertaining one.

http://www.research.att.com/~bs/bs_faq.html#ieee
very interesting. thanks for the info.
&gt;python string processing is good enough

agreed.   however the code i was optimizing did a bunch of things related to strings mixed in with the code that needed optimizing.   the string code itself was fast enough, but it had to do other things using the strings that needed work.  (i can't recall the details anymore but iirc the problem wasn't speed, but some other limit of python that we hit) 
that has *everything* to do with your point.  there is nothing inherent about c that makes it predestined to be the ubiquitous system implementing language that it is today.  it was just there at the right place and right time.  
a picture really is worth a thousand words.
is the "you have comments on your comments" feature, ie. the little email type envelope function next to username working for anybody? did the upgrade wipe it and the "recommended" features out? neither works for me. the comment envelope turns red when someone responds, but clicking it doesn't take me to comments anymore. (edit: incidently, i tried emailing reddit through the help section directly about this. that didn't work, either. using firefox if it matters.)
there might come a time when you can be considered a great programmer without knowing c, but 2007 is not that time.  even if you don't use it, not knowing c is like an expert in foreign and ancient languages who doesn't know latin.

steven yegge puts it very well in his oft-posted [tour de babel](http://steve.yegge.googlepages.com/tour-de-babel):

&gt;you just have to know c. why? because for all practical purposes, every computer in the world you'll ever use is a von neumann machine, and c is a lightweight, expressive syntax for the von neumann machine's capabilities.

and c really isn't that hard, if you understand pointers and memory.  the time spent writing this rant about c could've been spent learning c, and he'd already be most of the way done.

i've done some programming in hex.  c is very high level.  (-:
i know it's not a fix for all sites, but google has a url that forces english.  i think this is the url if i'm not mistaken, someone from another country that google detects please deny or confirm this.

http://www.google.com/ncr
&gt; if a compiler is "self hosted" that immediately excludes it from consideration for me.

even gcc?
the original vision was "clone minix," which turned into "clone real unix."  that was good enough for the time, as unix was a proven os for certain types of things.
perhaps i'm just plain wrong when i guess that the author of the article and most people commenting here are from the english speaking world?


my (by necessity anecdotal) experience would say that using an “en-us” version of both the os and the browser of choice (read ie) is common to most parts outside of the english-speaking world.


if i where to hazard a guess to why i’d say that the primary reason is this: the non-english versions used to be crappier and thus geeks learned to use the “original” version. the second reason would be keeping your users to the same language makes things easier for an admin (no need to remember what menu items are named under different locales). have you ever tried reconfiguring say a japanese version of windows?

&gt; define the data structures to support all your features at once.

what features?

&gt; these must be super duper.

what does that mean?

&gt; abstract access.

what does that mean?

&gt; but that is usually a small hit.

to what?

&gt; you can still do register allocation.

in what context?
works for me. it also seems to set a cookie which causes it to remember that i want the english version, and not redirect to .hr the next time.
 this windows vist-aa
really makes me pissed-yaa
put balmer in the slammer
'cos he dissed yaa 
&gt; that has everything to do with your point.

on the contrary.  i was pointing out that even "self-hosted" languages often have bits of c intertwined.

i don't *dispute* any of your points, i just don't think they follow from mine.

now, i'm quite aware that we could be living in a forth, or bliss, or algol universe, in which case my exact point would still likely stand, with the name "c" replaced by whatever the ubiquitous-systems-language-of-choice were.
and we're back again at the shotgun approach to story submission. i count 41 submitted stories by sjf yesterday, with 5 or so scoring more than 0.

*... not that people will see this meta-story, given sjf's submitted 15 stories in the last 10 minutes ...*
&gt; edit: markdown hates parentheses :(

you can escape them with "\".
 &gt; to my limited experience, closures compose in substantially more generic and interesting ways than multi-slotted objects

this implies that you're thinking in terms of a particular expression of multi-slotted objects in particular languages.

note that the original comment raised this very point, in the first paragraph.  however, it also provides a counterpoint, which is valid for more expressive object languages, such as smalltalk.

&gt; closures (if used right) have also the nice property of being immutable, thus one can actually reason about them.

one could equally say that about objects "if used right".  in fact, alan kay has made comments along those lines.

however, one of the main uses of closures in languages like ml, scheme, and lisp is precisely to exploit their ability to encapsulate mutable variables.  i suspect you're using 'closure' as a synonym for higher-order function here, which is misleading.

again, thinking in terms of mainstream corruptions of these ideas doesn't help you understand the underlying situation.  you can't fully learn theory by extrapolating from limited examples.  the original comment was in the context of language design, and doesn't have much to do with how well e.g. python or java implements such ideas.
 
i (the author) am dutch, but i can support your point: dutch windows translations used to be so deplorably silly (unnecessary, very creative translations of technical terms) that most geek types prefer to use english. i think this has improved lately, though.
some code is that sensitive. i don't know the internals of git, but i've worked on projects where to get the data you want, you need to do x number of stat() calls, one for each file. and if your interpreter (high-level language) does lstat()/stat() instead, or a brk() as well, then it takes twice as long.

this is a good example. when the algorithm provably needs to do x operations, and it will take a while, 2*x (or even 1.1*x) can matter. 2*x or more is a lot more probable when you're counting syscalls like this.
among dvcs yes.

http://git.or.cz/gitwiki/gitbenchmarks#head-5657b8361895b5a02c0de39337c410e4d8dcdbce

i do not pretend it is faster than git everywhere, everytime, but it is not 100% slower either. a couple of c modules and sound algorithms are good enough, at least for version control systems which are mostly i/o bound.
just like it says - how would you go about getting a job coding in haskell all day long? or even half the day?
i have the same problem, using explorer.
i'm very happy with pos. i am using it in my project with absolutely no problems whatsoever.

and it is easy to get and use with the chicken scheme system:

chicken-setup pos

and it compiles it into lightning fast code ready to use.

best... comment...ever.
wow - getting a few downvotes, but no reasons. i really would appreciate feedback as i want to make this a resource.
apply to [galois, inc](http://galois.com). worked for me :) most of the [companies here](http://haskell.org/haskellwiki/haskell_in_industry) here are also hiring.

the other option is to move into research. an awful lot of phd students and researchers get to hack haskell day and night that way.
&gt; even if you don't use it, not knowing c is like an expert in foreign and ancient languages who doesn't know latin.

that's a bad analogy, since understanding latin in no way is necessary to be an expert in ancient or foreign languages.

but anyway, i think the author does know c. perhaps he doesn't have valid reasons to dislike it so, but that doesn't mean anyone disliking it doesn't know it.
the function pointers, and the variable arguments.
that they are good.
that they work.
runtime performance.
if the function in question uses less registers, it will always fit as a replacement. if it uses more, you can insert a spill. or you can keep the critical blocks in memory and do a full reassign. but you still don't need to redo the whole code.


c is fast because it doesn't perform basic type checks, out of memory checks, overflow checks, or array boundary checks.

if you actually code c in a safe fashion then it loses a lot of is speed.
i would seek an opportunity to introduce haskell in my current job. that's what i did with lisp. worked pretty well for me.

actually i'm testing happs now. waiting until it becomes usable, so i use it for some next task at my hand.


that's basically the idea, yep. my point is, or was supposed to be, that lispworks could make itself very much more attractive by bundling free or cheap compilers for other major platforms with paid licenses of the basic version, probably without really hurting sales. it'd get more hobbyist users, and the companies would continue to buy the professional/enterprise versions. 
all kinds of things. in haskell, lists are monads, so are continuations, and logging, and many other uses.
no no no, i didn't mean to start a discussion about what is art (that's a *whole* other topic). in this context, i meant "art" in a purely dictionary, simple type of definition.

i'm sure you've heard the phrase "part art, part science."

"art" as in, to use a skill to make something based on imagination and creativity. (ie: you can't program a robot to design something. it requires creative thinking, a.k.a. there's an "art" to it.)

http://perlmonks.net/index.pl?node_id=632769
http://perlmonks.net/index.pl?node_id=629358

not regexes, but perl fractal thingums.
&gt;why in java to use a stringbuffer instead of + for joining strings.

use stringbuilder instead.
c is not easy. simplistic yes, but not easy. just making sure memory is freed correctly under ideal conditions is a challange in any non-trivial program. accounting for memory in the face of errors or prallel programs is downright hard.
 that's a good point. some easy entry routes for haskell:

* prototype designs in haskell (and then don't throw the prototype away...) 
* test your existing software in haskell (i've used quickcheck to test c programs -- making you immediately more productive. you might also use the haskell selenium bindings to test web applications, for example).

people seem more open to the lower risk of using a new language for prototyping and testing, and from there you can build up the experience and assurance to actually use haskell for core systems. small steps first though.  
figure out something practical you can write in haskell and sell, or sell access to.
yes, the selling point of c in embedded systems is the minimal run-time requirements (a stack pointer and a stdlib implementation, which can itself be written in c), plus the fact that there will already be a compiler for chip x.

various new languages have tried to "fix" c's problems by adding features such as gc, missing the point entirely, so no real systems languages ever appear which could replace c (except maybe modula-3 or oberon). so the niche remains monopolised! this is probably driven by too many people using c as an applications language, for which it is truly unsuited.
&gt; depending on the language chosen i'd bet you could get within 10% at a minimum. if you have an ffi and want to write the intense parts in c then you have the best of both worlds.

while i agree with you, i don't really see how it's an argument against what i said.
axiom: everything c does well is meaningless.

argument: c is bad at everything that is not meaningless.

conclusion: c should not be used.

hey, i should be a blogger like the author, with all my powers of deduction.

(yes, i realize the above excludes things that c neither does well or badly. feel free to axiom-away that)
i have to disagree with you there. mainstream gc was a major defining factor in the success of languages like vb and java. without it many of the applications businesses run on today wouldn't exist.
thanks... i've found that many tech tutorials throw a bunch of command-line arguments at you without showing the big picture.
agreed on the improvements, but the inertia of geek wisdom is pretty slow and combined with my second reason would perhaps make it more useful for say google to use ip-based recognition rather than relying on peoples correct configuration (as you also state). much like it was a net gain for the people behind the browser wars to support broken html rather than to demand the correct form.
c is the lingua franca of programming. deal with it.

you might as well argue for esperanto. it's not gonna happen (... at least not for several decades)
one has to wonder if the "high degree of suck" is merely a perception caused by so many people using it.

if python, scheme, lua or erlang were used as much as java or c, would not there be just as many people complaining about their faults?
nice burn!
and the xbox 360 is pushing c#/xna as the future.
at least they mentioned quirksmode, i end up using that site all the time for their compatibility tables.
that would be harder to do -- if it were actually allowed in c.
if an algorithm "works better than you dream", it's not an algorithm, but a heuristic.
that is untrue. it takes a *skilled* assembly programmer to code a tighter inner loop than the output of an optimized c compiler. a half-decent assembly programmer will just *think* he made it faster, but it will not take into account the processor pipeline or some other technical detail...
&gt; so... if the difference gets smaller you start seriously to see the good points of c: it's fast, the interface with the operating system is not mediated, there are static checks! when you compile. if everything compiles well and you test the application there are very little chances that the user will see a runtime error because a name of a var was a typo.

the static checks in c are laughable.

1. it does not check for integer overflows.
2. it does not check of out of memory.
3. it does not check for double-freeing pointers.
4. it does not check for dangling pointers.
5. it does not check for array bounds.
6. it does not check for type casting errors.
7. it does not check for properly terminated strings.

even languages like vb have better static checking that c.

i wouldn't be so sure of that last point if i were you.
shhh. no one is supposed to know about the millions of vb programmers.
thanks, i'm not a fan of c++ but this changes the things. used very well c++ is probably more handy for some kind of software development.
if you can't start using complete sentences or include the relevant portion of the text you're responding to, i'm not going to bother; i'm not a telepath.

&gt; the function pointers, and the variable arguments.

what about them?

&gt; that they work.

wow, what wonderfully readable code we have. you planning to do that for everything?

&gt; runtime performance.

what about it?

&gt; if the function in question uses less registers, it will always fit as a replacement.

and you have to keep track of where the variables came from, where they're going, and any flags you might be changing. watch out for any jumps into it. your new chunk of code might result in allocation that's less than optimal. what about stack effects? and if there aren't enough registers, start spilling?

wow, this is so very **"not that complicated"** and **"piece of cake"**.

how many jits have you written, exactly?

&gt; but you still don't need to redo the whole code.

who said that it should?
so what? 90% of them seem relevant at first glance. is there reason not to trust the voting mechanism in this case?

(i have a much less strict definition of "relevant" than you do, i think.)
i'll have to look into bliss.  
a jit or two. but i'm really in it for the laughs.

but seriously speaking, limited register reallocation is not that difficult. actually, it can be a very good decision compared to a full jit, but i'm not telling you when.


after a while, i'll eventually get tired and simply respond with "jesus fucking christ man, you know what i mean."
sbcl is a really really nice compiler and it costs ... zero dollars.

zero is a bit less than one thousand. so it doesn't work so well on windows, but windows is a proprietary platform and i doubt much interesting software is developed for it anymore. in any case a port is in progress to w32, and it already supports {free|net|open}bsd, gnu/linux, os x, and solaris.
those are all dynamic checks (except some limited cases of pointer and bounds errors could be caught statically).
what can be done while learning rails in 4 months!
it would be more interesting to have a variant of linuxer who dispensed relevant comments rather than relevant articles.
 &gt;just making sure memory is freed correctly under ideal conditions is a challange in any non-trivial program.

if you are having those kinds of problems i would suggest using a garbage collector.  you did know that there are garbage collectors for c right?  typically they just have replacement functions you used instead of the default free/malloc.  and since c is not an oo language you generally don't have a bunch of objects created willy nilly requiring major usage of a gc which makes it rather efficient comparably to other languages that use a gc by default.
i guess whoever downmodded this forgot where bell labs was at ... oh, nevermind.
join academia. ;)
mcclim is a working clim implementation that should be compatible with the major proprietary clims (note that mike mac was developing apps on symbolics machines back before dw was standardized as clim so he knows a thing or two). it has a decent set of x backends (clx and cairo based), and work is in progress on native os x and windows toolkit backends (see the graphics-form and beagle bits in the mcclim cvs repo).

it is also highly portable and works on just about every cl in existence (assuming that the lisp-dep dir is up to date this includes allegro cl, clisp, cmucl, lispworks, openmcl, sbcl, and symbolics cl).

installation is a bit more difficult, but i bet someone could write a gui install tool built on top of `asdf-install`. a more featureful `asdf-packaging-tools` that automagically created a tarball with all of a system's dependencies would be helpful as well. the nice part is that all of the really difficult work has been done in the form `asdf` and now we just need a bit of polish.
that's commonly termed the "marriage penalty" and as far as i can tell from the [tax tables](http://www.irs.gov/formspubs/article/0,,id=150856,00.html) it no longer exists for people that do not pay the amt.
 
confirmed by developer--oops.

same in greek. my personal peeve: quite a lot of programs seem to confuse regional options (for example if i want the date to be displayed d/m/y, or if i want the decimal symbol to be the comma) with language options (if i want the start button to be έναρξη [start in greek])

for exactly the same reasons as marjin, i'm using the english language programs, but of course with greek regional options. so several programs (with the worst offender nero burning rom) seem to decide i really want "αρχείο" instead of "file" and "προεπισκόπηση εκτύπωσης" instead of "print preview". get your act together people! i have english language for a reason!
 i'm more curious as to whether this is the only way to reliably get interesting content -- automated keyword-specific story submission. does leaving it to individual users produce inconsistent results? 
 also, keep an eye on the haskell weekly news, new jobs from companies (banks, usually...) secretly employing haskellers appear there. (like [this one](http://article.gmane.org/gmane.comp.lang.haskell.general/15552)). 

&gt; you will be able to use haskell commercially everyday, be generously compensated and be on the forefront of technology in banking. 

finally, approach companies who appear at the [commercial users of functional programming](http://cufp.galois.com/) workshop. they're likely to be receptive.
but the whole point of reddit is the shotgun approach! that's why there's a ratings system, and also why there are all those different popularity-based buckets.

i've seen proggit without any linxuer/sjf, and i've seen it with, and i definitely like it better with.

ps, this story made it to "hot", while most of sjf's didn't make it past "new". so your prediction seems to have been off :)
premature optimization is the root of all evil and all that jazz, and that site talks mostly about the premature kind!
 &gt; c has a very small (almost 1:1) relation to assembly  
   
but that *is* the point! c should be viewed as language for system programming not for application development.   
one example is automotive embedded systems (the field i work in). all the applications are developed as [simulink](http://www.mathworks.com/products/simulink/)  models where as the os is developed in c. the models are translated to c before linking into the main image.   
this way, i am able to see the problems in implementation which may not be present in simulation. and i don't have to be an assembly language guru.   
moreover, c provides the perfect mapping to all the hardware there is which is just great while debugging.   
imho c is the assembly language of today, you might not program in it but you must know it.
... because you are not sophomoric, and understand that there will always be cpu-bound tasks?
i'm not a bot.
compared to what though?  i guess i feel that c gives me a better feel for memory vs registers and especially devices than any other language.  and it gives me a much better feel for what is actually in memory, and how the hardware manipulates it.
i think c++ killed linus' family ...
  should our purpose, then, i wonder, be to collaboratively design a bot that finds us interesting content? right now it's provided by a relatively few dedicated linkers (in a power law/long tail distribution, i suspect), but that's vulnerable to the failure of those linkers.

instead of limiting the submitted results to a "recommended" tab, perhaps reddit should see a group of people's voting habits and deduce from a large corpus of articles what may be relevant to them?  
yes, exactly what i was thinking: if this is really what works best, we should seek to improve our bots/link finding scripts to produce more relevant results, more often.
that's exactly what a bot would say! ;)
wow!

someone went through the trouble of creating a submission bot that also parses comment threads and replies to posts that accuse it of being a bot.

impressive work.
 your article pointed out something interesting which had been bothering me. i used to develop on realbasic for one of my clients. rb charges you per platform to run the ide, but any ide can generate executables for all of the platforms.

if i were going to pay for a commercial language/ide i would certainly not be offended at needing to shell out extra money to run the program on more than one platform (or computer, or whatever), but if you have a cross-compiler then why wouldn't you want it to be available this way? $1300 is a lot of money, $2600 just to be able to have my apps run in windows is simultaneously ridiculous and justifiable. it's obnoxious but i suppose they're within their rights. it's not like i can just use rb instead. even though their pricing model makes more sense and is kinder to the customer.
but do *you* know what *you* mean? i'm not certain you do. does writing a specification count as 'programming'? does implementing a genetic algorithm count as 'designing'?
no, all respectable bots have "bot" in their names.

as for the "sjf" non-bot, this might provide a clue:

http://programming.reddit.com/info/2zv4t/comments/c2zwag

also see:

http://programming.reddit.com/user/sjf/comments
that's why i said probably.  there's always an exception to the rule, but these exceptions aren't reading programming.reddit.com for bulleted lists of tips without benchmarks and data backing them up.
that's not true, xbox 360 cannot run c#. xna, and any other game development technology, has two parts to it: pipeline and runtime. c# is widely used in the pipeline.
like that link that keeps making the front page with the ai to figure out which stupid squiggles you like best.
that's a great idea, until you start using third-party libraries. then you get the fun of trying to remember which objects were allocated by your gc and which were allocated by the library.
&gt; (except fpga/asics, but be serious)
it does, sort of:
http://www.altera.com/products/ip/processors/nios2/tools/c2h/ni2-c2h.html
he *is* giving alternatives, namely c++. big part of the article says that linus is stupid because he loves c but hates c++ big time.
&gt;xbox 360 cannot run c#

&gt; c# is widely used in the pipeline.

you may want to rethink what you are trying to say cause right now it isn't making much sense.
 
i keep reading the two first paragraphs, and i can't figure out what the fuck it's supposed to do.  returns a queryset as a json object.  yeah, so what?
they're blade servers which perform a similar function to the other servers in the cluster.  that means that you only really have to figure out how one of them works.  if one breaks then you can replace it with an imaged copy of the node.  this can easily be automated to save time.  so basically all the sysadmin is doing is looking at the nagios/mrtg/cacti consoles and running kickstart to build new servers.  unless the sysadmin is also responsible for deploying new code to production which is unlikely for a big company like google.
perhaps you should use c++ with smart pointers, they take care about deallocating stuff. they are based on reference counting so you still have to watch out for memory leaks caused by reference cycles, but that is much better than screwing yourself with dangling pointers. and any time you need/want, you can switch back to straight c.
yay, an extra instance and a lot of more lines just to joins strings.
these people aren't the ones working 60 hour weeks.  they're probably working 20 hours per week and getting paid lots of money for it.  


&gt; i doubt much interesting software is developed for it anymore.

living in la-la land?
test driven development at its finest: pass the tests, or we'll damage your machine :)
in some languages those are dynamically checked, in others statically. in c, they are ignored.

languages like vb and java don't allow inproperly terminated strings to exist, the compiler ensures they are properly closed under all circumstances.

languages like c-omega don't allow null pointer exceptions and can even check for integer overflows at compile-time.

must be a young guy rationalizing.  i made a lot of money off of c and feel it's worth pointing out how much legacy code is out there that has to be maintained.  i learned c before even pascal and it has served me well right up through java and .net (am currently doing enteprise web apps in java/struts/xml/xslt).  it's amazing how many people who call themselves programmers don't have the foggiest clue about machine architecture, how pointer arithmentic works, or what a linker does.  



which .. is not really useful for most developers, it pretty much kill the scaling advantages (if there is).
right on.  i doubt the author of the article has ever worked in the industry:

&gt; most people who still use c are only doing so for academic reasons...or because they are ignorant.

not as a primary development platform.
and you still want to have your code portable to ps3 and maybe pc too.

so no c# for most gamedevelopers in the near future (pheeeww =).
c is not the only compiled language.
  &gt; &gt; there are other fast languages

 &gt; but not as fast...

ocaml.  
i think they just did.
the author hints at haskell or c++ -- but haskell isn't fast (it doesn't even compile fast) and c++ is worse than every other language but c in terms of 'high level' constructs. ocaml offers a nice combination of performance and functional constructs -- it's also available for many embedded devices.
i don't want to worry about getting my mind around parallelism in the hardwired `statet io` monad called c just to use my extra 3 cores, a feature critical to almost every nontrivial program
it's worth noting that javac compiles string concatenations into stringbuilder appends under the hood where appropriate.

(edited to change stringbuffer to the correct stringbuilder.)
what whacky licence issues? afaik you don't need to gpl your program or anything of the sort.

i agree with you, if you're not using a programming language you like using, switch.
i suspect having a stable binary driver api would take a lot of effort to maintain and thus would slow down further improvement of the kernel.  

it would decrease the rate at which support for old devices was lost but also decrease the rate at which the core of the kernel advanced by adding hard-to-refactor cruft.
programs have a lot to do with program*ming*, in case you didn't notice.
are there places where this world view is pervasive amongst people who don't know paul graham? to all intents and purposes windows is the only platform, if you want to make a money selling software.



that screenshot brought back some memories from my university days... :) it looks hideous though.
s/*is* faster/*was* faster/ all self respecting compilers fixed that long ago.
write scheme and compile to c if anybody asks you what programming language you're using. 
while many programs would better have been written in another programming language than c, he is a little bit extreme, and lacks some knowledge and/or imagination. i just wrote an algorithm that worked on a several gb data structure, using memory maped files and similar tricks. on a unix-like system (or even windows), it is hard to do this in another language than c (or c++ in a c-like way). this is of cause partially because most common oses are written in c.

this only applies for the most time-critical algorithms however, and everything else should be written in a higher level language than c. also, it is a pita to write this kind of high-performance code, and most c code written is not of that quality.
   just so you know, most of the assumptions in your post are (or at least, as of 2003-2005, were) incorrect as regards google sysadmin jobs.

  atavus appears to work in exactly the group i was thinking of (or what used to be the group i was thinking of) and if my guess is correct, he might take the opportunity to explain what goes on in his group, in general terms.  but even pre-ipo, with just a few hundred employees, the sysadmin jobs at google often involved weird stuff that most people don't associate with system adminstration jobs.
 
it's worth noting that its sense of where is appropriate is very limited.

the following will compile into a stringbuilder:

string foobarbaz = foo + bar + baz;

the following will not:

string foobarbaz = "";

for (string str : aslist(foo, bar, baz))
    foobarbaz = foobarbaz + str;


this is why you use a readable language. so you find out if `rm -rf /` is being executed.
i think i like this, and will use it in the project i'm about to start.

anyone have anything bad to say about mercurial?
tell me more about it would be more interesting to have a variant of linuxer who dispensed relevant comments rather than relevant articles.
and no one likes jokes.
this is article leans way to heavily on _ad hominem_ and sweeping generalizations. learn c to understand more about operating systems, file systems and all that other stuff you use that's written in c.

it's legitimate to complain that c is overused -- c++ could handle a lot of the application level tasks that c is used for (now that c++ is mostly implemented). in fact, ocaml could handle a lot of those tasks; but people like expected value: it's a big investment to learn a language, and there weren't any well demonstrated alternatives for app development even ten years ago.
 and now those instructions for *real men*:

1. c-x h
2. c-c c-d

you *did* map c-c c-d to `delete-region`, didn't you? 
i am a programmer and i haven't touched windows since 1999 (and have **never** written a program for windows). most software is **not** boxed software but is rather custom developed server stuff.
nope. interesting and profitable are not the same set ;-) ('tho they may overlap a bit).
skunkworks.  a.k.a. just do it.

yeah, you can't do it for the main product or application (are you at a software firm or a corporate developer?), but there's always plenty of throw-away apps that no-one ever looks at.  log file parsing... proof of concept tests... test harnesses...

also consider f# or scala.  sure they're not as crazy as haskell, but at least it's not java, and it'll integrate with an existing codebase (assuming you're using .net or java)
i agree. using closures to emulate objects by abusing mutability is not interesting. for all the reasons that make objects not interesting :). however, using immutable closures, aka higher order functions, is very interesting and we have barely started to understand their power.

objects: dynamic run-time replaceability for modules. engineering crutch.

closures/hof: full power of mathematical logic.

less is more.
 what if you want to take some code from the clisp implementation, and adapt it for your own purposes? you'll have to abide by the gpl then. i think the gpl is simply the wrong choice for a language implementation.
well, if you use python. it's nice to be able to write extensions in c.
swig!
that's not a nit-pick that's a mega-pick


 was production simply renamed to sre?  i left google at the end of 2004, so of course i'm out of date... kirkland wasn't open, for example, and dublin was just techs.

since you asked, and since you more or less stated you're in the successor to production, i'll hazard a guess that you work on pushing out changes and monitoring the fallout via the performance analysis scripts. (whatever they have metastasized into -- there were 3 completely separate monitoring systems when i was there, and that was while ago)  again, not a shitload of detail, but google's tools have changed (probably for the better) and you about as much as said what you're doing.  (i did find it amusing that this is in direct contradiction to some other guy's guess, but then, i'm cheating here)

it occurs to me that i might somehow be violating an nda so i'm going to excuse myself now.  but you sound like you're doing the fun stuff if you're in sre.  

i went back to grad school, although i have to admit that, having sold my hobby site and working full time on my thesis, i sometimes miss what google used to be.  i don't imagine that it could possibly have stayed as informal and chaotic as it once was, if only because that (flat) model didn't scale well.
even then, your skilled assembly programmer will only have a tighter loop for one cpu.  it won't be the tightest thing possible for all of: intel p4, intel centrino, amd athalon, via c3, amd k6, amd k5, intel p1, intel 486.   not to mention ppc, arm, or spark, all of which are currently in use, and come (or came) in different hardware versions that work differently.   in some cases a different cache may even hurt you within the same processor type.

c compilers can do all of the above with different compiler flags.  if you really care about performance enough to drop into assembly it is important enough to do different assembly for each of the above (or at least each of the above that your users will have)
did you try talking to sales over at lispworks?  i'm sure that they'd be able to help you in some way. you mention some valid technical reasons why a cross-compiler may not be possible, but a discount on a native compiler for that other platform could be in the cards.

or, is it that you're offering this as marketing advice to lw? in that case, try dropping their marketing dept a line. this is at least better than the usual "lw and franz should make everything free" advice we usually see on c.l.l etc :).

lw is not microsoft or sun, i think you'd be surprised at their willingness to work with their customers to solve issues like this. in any case, it'd probably be more productive to talk with them rather than blog and reddit about it.... though i admit the later is much more fun and i'm glad you did it :).
&gt;would not there be just as many people complaining about their faults?

i would hope so. then we can work on improving them and getting to the next big kick-ass language.
you really should pay attention to context.

the base claim was that xbox programming required c. i was pointing out the error in that belief.

&gt; so he doesn't like c, but he's not giving a lot of options that truly fill c's niche. suppose i want to write code for the xbox 

&gt; so no c# for most gamedevelopers in the near future (pheeeww =).

in raw numbers, most game developers currently use flash. i don't see that changing, so i have to agree with you.

now if you want to return to the thread of this conversation, developers on the xbox, then we can argue whether or not c#/xna is going to be popular moving forward. 
do it with gambit-c or bigloo scheme too.

also, bigloo scheme and a few other schemes compile to java. so if you're stuck in a java-shop you can still kick ass.
if you use any clisp specific functionality (such as its awsome ffi) in your program, you're gpl'd. the gpl/lgpl is looked at with disdain by many lispers specifically because it is so "c-centric", and it's far too easy to end up with a 'derivative' in lisp, simply because a delivered lisp application usually includes the entire lisp runtime, which in the case of clisp is gpl'd. hence .. wacky license issues. 'free' software my ass ;)
but, i almost never find any news or interesting sites that deal with the topic of netsex. what is netsex anyway?
&gt;if you have to "go native" in a higher order programming language, odds are you are going to be using c.

the number one reason everyone should learn c.
&gt;i don't quite understand what you mean. are you talking about languages like python or ruby? in that case, yes. but in o'caml, haskell, common lisp or factor's cases, they are high level languages, and they compile to native code.

they compile to *slower* native code than hand-written-and-lovingly-tuned c. at least as far as the shootout is concerned, c beats them all, overall.
&gt; roy fielding's successor to http?

i think you answered your own question.
i look at ipv6, xhtml 2.0, internet2, etc. in the same light.  unless you have an interop and migration story, you're going to have a damned hard time "upgrading" the internet and the web.
wow. i'm afraid.
he is making sense: the asset production process is often referred to as 'the pipeline'.
odd. danish is fine on mac anyway.
"vision" is the right word, since you're really describing the same sense: one way is how your work will progress in the future, and one is how it affects things now.  you can't really have the first without the second.

hello.  this subreddit is about programming, not netsec.  if you're going to inform people of the existence of the netsec list, please keep it on the netsec list.  thank you.

:)
i don't understand why distributed vc is always seen as having a steep learning curve. to me, it's a perfectly intuitive way of doing things.
my point is that now that the main reddit is able to reflect your interests through [customizing the subreddits](http://programming.reddit.com/prefs/subreddits) security-related articles that have otherwise been posted here in programming, could just as well go to netsec. 
 writing a compiler is a great learning experience, but if you were given a multi-million dollar contract to write program x for a video game system or other embedded system, then would you start out by writing a compiler for your favorite language? 
i think it was probably malicious laziness.

"your test failed, deleting my system."

"unable to reproduce.  please attach suchandsuch config file."

"..."
oh, i'm really just commenting, and i certainly don't think that they should make everything free. i'm still rather under the illusion that no-one _reads_ that blog; i was amazed when this showed up here.

certainly, i know that allegro, in the past, have offered help to people doing startups and so on. i'm honestly not trying to portray the two companies as ogres; i think that they're doing an amazing job, considering the circumstances, and they do at least provide free basic versions for people to try out; i was particularly impressed by the lispworks one.
for me, google.be is in dutch, while google.com is in english (my language settings are nl-be). google.fr and google.hr are also in dutch though, but there's a link "google.[fr|hr] offered in" and the respective language of the country. the same way, google.ch says: "google.ch offered in: deutsch english français italiano rumantsch". google.be displays "google.be offered in:" and then three languages out of the list english, french, german and dutch, depending on which language the interface currently uses. i'm guessing google doesn't do any ip-to-country-to-language mapping on me since i live in a country where multiple languages are spoken.
in that case, he is laughably wrong. a quick look at xna shows that it is designed for coding game logic, not creating assets.

http://msdn2.microsoft.com/en-us/directx/aa937793.aspx

realistically, however, if i want to make a little gui app which people will actually use, it's very nice to have a windows version. as it is, i'm planning on bringing out an app with a gui provided by a slaved python process using pyobjc (with the lisp backend openmcl for ppc and sbcl for x86), but it'd be great to be able to easily provide a windows version, and have a simpler way of packaging and distributing it.
we're not sure yet actually. test machine fell off the net.
if you want windows, you have http://cormanlisp.com. cheap and good. 
counter example: http://eigenclass.org/hiki/seam-carving-in-ocaml
how come this isn't listed under the "other communities" set of links over on the right?  how would anyone ever know that netsec.reddit.com even exists?  i didn't know until i saw this post.
how odd, when i use firefox's language preferences i always get google in the first preferred language. i just shoved japanese up there and lo and behold, google was in japanese. so was blogger.com.
xna and c# are different things?
it's listed if you click on "subreddits" at the bottom of most pages. i don't know why the lists are different.

err... now that i check, i suspect that the page that that points to, sub.reddit.com, was destroyed by the recent upgrade. i guess you have to just know.

just editors and compilers and interpreters. otherwise not.
&gt; the most interesting prospect, of course, is modifying the processor to suit your own whims. or, dare i say, even designing your own processor from scratch **(the first cpyou)**?


har har.
read it again.
it is up to the programmer to make c do anything badly. it is likewise up to the programmer to do anything meaningful with c. c does nothing by itself. c likes it like that. 
fold doesn't require closures:

    #include &lt;stdio.h&gt;

    int intfoldl(int(* f)(int, int), int z, int* xs, int xn) {
        int i;

        for (i = 0; i &lt; xn; i++)
            z = (*f)(z, xs[i]);

        return z;
    }

    int add(int n, int m) {
        return n + m;
    }

    int main() {
        int xs[] = {1, 2, 3};

        printf("the sum of 1, 2, 3 is %d.\n", intfoldl(add, 0, xs, 3));

        return 0;
    }


stability and compatibility shortcomings.
one of the strange things for me was that there's no central location by default. it seems counter-intuitive to have a vcs where people can't get your latest changes if you turn off your machine, which i had come to expect from using svn.
written by someone with no knowledge about how things work, but assumes something simple will work long term.
unlink() in posix/c is also spelled unlink() in perl.
linus has also justified his hate of c++ pretty well.  (at least in my opinion)

linux doesn't even use all of c, as some of the features are too slow and unpredictable. (iirc)
well, just restore the backups.

&gt; what backups?

opps.
why would it decrease the rate of support for old devices?  devices with drivers in the tree tend to stay supported, as their source code is always a grep away.
things such as...?  are these things also part of the "20% of your time is spent on your own projects" deal?


lol
an interesting use for forth, especially if you are or have been active in the demo scene.
did you really need the "alert"?
programming redditors = "predditors"?
&gt; understanding latin in no way is necessary to be an expert in ancient or foreign languages

it helps a lot with any of the languages derived from latin and with the grammar of several not derived from latin.
agreed, in other languages as well.  many programs that would have been painful to write in 100% c (or at least slower to write), have been sped up by writing some parts in c or asm.
 we encourage our people to push to a personal repository in their home directory on the dev server.  that way they can push to it before they go to sleep and everyone will have access to everyone else's latest changes no matter what the state of their computer.
&gt; sbcl is looming over them - it's becoming a defacto standard (lib developers will start to lean toward sbcl-only extensions),

source?  i know from your comment history, you've got some lisp experience and i do like sbcl but what source do you have to back up your statement?
bang!

(i.e. the sound that what i'd like to do to you after reading that comment makes)
yeah, it's c# using some kind of orm i think. 
linq will do much the same come c# 3.0 going mainstream.

hah, it's .net, of course it has boilerplate.
ah...
did anyone else think of the "mi scusi" scene from _euro trip_?
blugill i may not be the most knowledged people to talk about this but i wrote device drivers for linux for paywork multiple times so i'm also not totally unskilled about what i'm talking about. it does not mean nothing but there is even my name inside the source code of linux, try:

cat net/ipv4/tcp.c | grep -i sanfilippo

so i'm *not* a kernel hacker since i had more fun hacking about programming languages and security in my life but i'm not totally outside of kernel development.
&gt; what if you want to take some code from the clisp implementation, and adapt it for your own purposes?

how is this situation worse than with commercial implementations?
last i checked gcc is not "self hosted". it compiles using a c compiler. and after being compiled, it bootstraps itself.

so "self language hosted" or whatever term you want to use, yes, but that's what makes all the difference.
macbook.  
if no budget, one of those ridiculous vaio's.  
i'm currently developing on a macbook for some projects and i enjoy having direct access via a shell, but a sophisticated ui...
in many ways, the linux kernel is developed primarily for linux kernel developers. the merits of this focus can be debated endlessly, but as i like to tell folks "if linux didn't suck, maybe i would be out of a job!" :-)
windows: just "vision" without engineering?
yeah. still, it's not "just another platform".
just about any new laptop that can run ubuntu and has a wireless card.
next you'll tell me that printf() is also spelled the same in perl as in c!
depends on what 'ideal' is for you.  since i created my own company and am not rolling around in cash yet, i bought one of the dell systems with ubuntu on it and have been pretty happy.  granted, it's not as showy as a mac, but then again, it runs linux, which i like more anyway.
that look's like a pretty useful resource!
the closest i've seen is people complaining about too many merge changesets.  there's an option in log to not display these.

i don't introduce them as often as people i work with, though.  i've been using it long enough to be a bit more comfortable with things like mq and transplant, i suppose.
yeah i've been experimenting with oop lately at the behest of a friend.  but it seems like no matter what i do, it requires 10 times as long to do it.

like i was trying to modify rtorrent/libtorrent to prefer to download files front to back (so that i could watch videos as they download) and i spent like an hour and a half trying to deconstruct the logic in it.

the program is beautiful, but i could not find what i was looking for because in every object there are a dozen private variables used seemingly at random in a dozen member functions.  since i was unable to follow execution in any meaningful way, i finally just gave up.  it just wasn't worth my time.

obviously this is more of an object problem than oop, but adding inheritance and iterators and a bunch of stuff on top of it makes it even less clear to me. 
the sub.reddit.com list has never been very complete anyway.  there's a decent list at http://reddit.scribblewiki.com/subreddits (though not all subreddits are very active)

the primary goal of a revision control system is to track changes to a project over time.

you hack, you commit, you tag, etc...  at any given moment, you can reproduce any tree based on an id someone gives you that will allow you to reproduce your work.

sharing your code is a different issue.  mercurial happens to do that quite well.  i've got a public server i keep fairly up-to-date with my recent changes to most of my projects.  you can probably pick up anything there, although i don't think i've ever committed any code in any of the trees that thing actually serves.  i rarely work on that particular machine at all.
i agree, with one caveat: if you need heavyweight 3d, forget the macbook (or go for the mbp, if you have the budget)
true, but old drivers are abandoned at some non-zero rate.  if the driver/kernel api didn't change, those drivers would still be supported.
beautiful!
if no budget i will still go for a macbook.
 then you should know that part of the _design_ _vision_ of the linux kernel is to not try for a stable, backward compatible device driver api. 
are you looking for a laptop to develop *on* or *for*?  i can't wait to get my hands on an [xo](http://laptop.org/laptop/).  the nokia [n800](http://en.wikipedia.org/wiki/nokia_n800) also looks nifty. 
i'm also going to be in the market for a laptop soon.  i like macbooks, but i'd actually prefer to run linux (ubuntu or kubuntu) as well as saving a bit of money.  i suspect i could get a laptop with similar features to a macbook for about 1/2 the price of a macbook.  anyone know of a list of reasonably modern laptops that run ubuntu (with wifi &amp; video support) and have specs similar to a macbook - but in the $600 range instead of $1200?

so what if it's 100% slower? how much is your time worth?

if your time isn't worth much, then a low-level language is fine. if your time is valuable, you'd be better off working with a high-level language is spending money on beefier hardware.
i suggested a similar thing to digitool about mcl a few years ago when i wanted to use it.  (even with the educational discount, it was over $500.  students just aren't that rich.)  they ignored me, and died, though we did get some open-source code out of it.

i wonder if one would have any success with a lisp company that made money by selling insanely great tools to professionals and big corporations, and also tried to get college kids hooked by selling some pretty good tools at a reasonable price for college kids.
interesting... why mmgc instead of [boehm-demers-weiser](http://www.hpl.hp.com/personal/hans_boehm/gc/)?
lost me right about here:
    
&gt;the truth is that our formal 1930s theory has long been left behind by the pace of development of commercial software.
    
has *calculus* been left behind by "the pace of modern commercial engineering"???
without knowing exactly what this ideal programmer is programming, i'd have to reccomend a 15" macbook pro, maxed out with 3rd-party ram and a 30" dell monitor.

with that setup, you're prepared to develop for most any operating system (or several at the same time, if it suits your fancy), you've got plenty of screen real-estate, and a tightly integrated os-hardware combo that will stay out of your way while you get things done.
and i've seen a lot more c code rewritten than c++ code.

now that we're on the same page here...
well, that was a well-thought-out plan.
i think in this case it was justified.  the headline sure as hell got my attention.
if no budget, go for someone *else’s* macbook.
with clisp, the situation is the same as with a commercial implementation.

with sbcl on the other hand, the source code is there, and you can inspect or hack it as much as you want without being attacked by gpl nazis at every turn.
the same goes for system().

now you can read perl programs that print formatted strings, unlink files, and make system calls, so you can audit them for buffer overflows and deletions both in and out of perl.

you're welcome.
how many old drivers have been removed from the kernel without replacements?
one question i have - i'm considering buying either a macbook or a macbook pro (in order to develop for mac os x), and i'm leaning towards the mbp due to the keyboard. the mb's keyboard just doesn't seem comfortable for extended programming use.

i'd like to hear the feedback from anyone who's used the mb's keyboard for serious editing. any comments?

thanks!
the original blog entry referred to gui applications which are easy to use for users without much computer skill, so server apps are a bit out of that scope.
come on, did you really have to "apply" to galois? surely they headhunted you?
 i'm not really sure i like the use of ``revert'' in that example.  it actually does something different from what it seems to suggest it's going to do.

in that example, you've gone from a revision 0, to a revision 1 (via tag), made some edits, and then pulled the changes from the file from revision 0 in to overwrite the file that was edited starting with the revision 1 version.

the revision 0 and 1 versions happen to be the same here, but the operation is definitely not desirable.  you wanted one of:

    hg revert [filename]

or

    hg update -c [tag]

revert does not change the working version, but update does.  this is important when you go to commit next time. 
helps, but is not necessary.
google seems to give the accept-language header more weight if it's something other than english. when i set my preferred language to spanish in ff2, google.com and google.fr were both in in spanish. now, with the preference set back to us-english, google.com is in english and google.fr is in french. (i'm in the us.)
i have no idea, really.  i am guessing not many.
macs are intel machines with 250-1000 dollar premiums. just get a dell or similar. computers are commodity devices, and the various makers don't want us to know that they can only compete on price and marketing (ie, brainwashing).
more speculation/concern on my part.

more driven by downloading bleeding edge probjects that don't quit work as-is away from sbcl.

i think what's really holding the common lisp world back is, more than a good implementation (sbcl) or a good dev environment (i've seen nothing better than slime for the latter, but then, i've never played with squeak, so) is a set of good libraries.
still |{simple windows gui apps}| &lt;&lt; |{all programs written}| is true. in the grand scheme of things windows is an irrelevant platform unless you want to work at a programming factory.
system() isn't for making system calls; it's for invoking other programs by way of the shell. to make a system call in c and perl and other high-level languages, you just call it like you would a function.
 it won't be any slower than a language that does those things automatically whether they're needed or not. 
to be fair, they were probably on acid when they were designing that site.
i do lots of coding, the macbook keyboard is okay. i thought it would be weird at first but you'd get used to it.

the backlit keys on the macbook pro would be nice though at times.
what libraries do you wish for that are missing?  there are a stack of good libraries, see cliki.net.
c's prominence is hardly an accident. it fills a very specific niche: on the spectrum of high to low-level languages, c is as close as you can get to directly controlling the hardware without giving yourself a headache.
if you have a soft-spot for low-level programming (like me), play around with forth. factor is like a higher-level forth, so it's fun too :)
you're right of course, it's just that c is the bare minimum amount of syntactic sugar necessary to wrap your mind around common problems. sure, some things become simpler in higher level languages, but the corresponding implementation in c would still be readable. assembly? not so much.
here are some reasons why modern, sane people would use c (not many, i admit).

* c is very easy to learn. (easy to learn, hard to program in.)

* some people actually enjoy the paradigm c gives when programming (hard to believe, especially for a haskell programmer, but true).

* invaluable in picking up any c-like language. (i.e. java, c++, objc, c#, etc.)
 how would you suggest that a language "statically check" for out-of-memory conditions?

c is not fundamentally different from c++, java, et al. in the case of oom: the allocation failures, and an error is indicated (via a null return from malloc in c, via an exception in c++ or java). 
i love the thinkpad x61s. light, portable, runs anything, 2 cores of compiler crunching goodness.

at the recent haskell hackathon there was a 50/50 split between macbooks and portable thinkpads. so either is ok, i suspect.
well, if you're starting a new project and you're choosing php you probably didn't do your homework very well. however, there's an imperial fuckton of php code out there from back when it was the best way to do things. hell, there's people still maintaining cobol and fortran, so we'll probably be stuck with the beast for a while. add to that the fact that the webdevelopment bizz is full of wellmeaning amateurs and plain retards who have had years to spew out crappy code, and you have a pretty decent justification for the linked article.
on the contrary, i imagine it might have looked a tad better had they taken some lsd.
if you're talking solely about a learner's programming laptop, go as cheap as you can. it should barely be able to run vista on aero. it has a dual boot to a linux distribution. 

the more limited your resources are, the better habits you'll pick up.

if you're actually trying to make real life applications, get something mid-range, but not beastly. a 1300 dollar toshiba laptop should last you forever (once you've blown away all of the bullshit they come with). be wary of having a development box that is a beast: your clients who have average machines may run into bottlenecks you don't.
[hacker's battle hymn](http://www.poppyfields.net/filks/00113.html)

[homeward bound](http://www.poppyfields.net/filks/00149.html)

[imagine](http://www.poppyfields.net/filks/00333.html)
a desktop.
i meant that system() works the same way in perl as it does in c, but you're right that my phrasing was misleading.  making system calls in perl where there aren't perl equivalents of the c functions requires syscall() (which also works the same way as it does in c).
yeah. but try finding a credible expert in romance languages who doesn't know latin.
the penguin laughing at the the alien with the ms shield is amusing.
deleting a perl programmers system is doing them a favor, right?

*hides*
i'm quite happy with my thinkpad. excellent, durable construction. just be sure to get one with an intel graphics card if you want to hook in an external monitor--doing so with a recent ati card is an exercise in pain.

it's quite encouraging to see lenovo taking free driver support seriously: http://lenovoblogs.com/insidethebox/?p=98. it's something well worth supporting.
   &gt; i suspect i could get a laptop with similar features to a macbook for about 1/2 the price of a macbook.

ha, good luck.  for that price you'll get a dell with a celeron and a resolution of 1024x768.
 good luck.  if you find one let us know - i like apple laptops but i hate the macbook keyboard.  in general, the cheaper notebooks make serious compromises on size, weight, battery life, and performance.  if you want a small (12-13") notebook with high performance (2+ ghz core 2 duo), the macbook is among the best values.  other companies do make similar machines, but i've yet to see one that is even $100 cheaper when the basic accessories (such as a power adapter) are included. 
it's fine, i don't have any problems with it at all.
i can stop writing code in perl any time i want.  i just don't want to.  why don't you all leave me alone?  i'm not hurting anyone.
i like sbcl too, but i make an effort to ensure that any code i write is portable to at least a few other lisps. especially because sbcl isn't so hot on osx yet (no threads), in fact i use openmcl somewhat more than sbcl for this reason.
yeah, i agree.  i guess they are going for an aesthetic that i just don't get.
&gt; yet there's a free version of almost every compiler in visual studio.

there's a free version of [lispworks](http://www.lispworks.com/downloads/index.html), and [acl](http://www.franz.com/downloads/). both are crippleware, but they are available.

 if you're using gcc, there's always `__attribute__ ((pure))` and openmp. admittedly not as nice as haskell in many respects, but it gets the jobs done. and i think, given the current computer architectures, good sequential performance will be an important ingredient of getting great parallel performance.

edit: fix markdown
i really like my macbook pro (17"!) but even though i've had it for a long time now, i still haven't adjusted to the window manager. i've been working on unix/linux for the last 10 years, and i really miss focus-follows-mouse in x, as well as constant osx terminal problems, mostly related to the emacs meta and backspace keys.

still, it works so much better than all my previous linux laptops that i don't think i'll ever go back.
wow.  very nice.  i want to go next year.
awesome, i really enjoyed the talks!
i don't get why google doesn't offer the language choice in the language itself. i recall a while ago using a public terminal where the person before me set google to chinese. with a little guesswork, i found the option to change the language. still, i basically just had to randomly pick languages until i found one that spelled the word "english" recognizably.
you can't get a job if you're hacking haskell all day. you need to actually search for a job you want: try craigslist.org, dice.com, monster.com...etc
not quite on topic, but related: lispjobs (http://lispjobs.wordpress.com/) is regularly updated with jobs involving lisp/scheme.  there have been four posts this month.
 anything will do. install an ssh client and use the laptop as a thin client. 
addendum: if you're buying laptops for your employees, borrow joel spoelsky's mantra of "best working conditions" and give your programmers great machines. give your testers a variety of computers in order to find the bottlenecks.
i dunno, rm -rf / seems like a good test for file::remove.

i actually have both, i upgraded from a macbook to a mbp when i decided that the mb's screen was just too small. i didn't have any trouble with the mb's keyboard but i do like the mbp's keyboard a little better, but wouldn't have upgraded just for that. 

in any case, i do most of my work sitting at a desk, and use an external keyboard. that lets me have the mbp's display elevated so it's to the right of my external monitor.

if you're an emacs user, the major issue will probably be the meta key. the escape keys on both the mb and mbp are only 1/2 height, so they're very hard to hit. and getting the keys to the immediate left and right of the space bar (the only other meta position my hands will let me use) to work as meta seems impossible, especially for emacs in terminals.
ok, that's ridiculously awesome.
so in other words, you write python in c++?
[the book](http://www.google.com/url?sa=t&amp;ct=res&amp;cd=3&amp;url=http%3a%2f%2fwww.amazon.com%2falgorithm-design-manual-steve-skiena%2fdp%2f0387948600&amp;ei=8_0tr9hqmolciggs8_ytdw&amp;usg=afqjcng2ehxszrvhm_grbgzfhzqnou-kza&amp;sig2=hgs9u08oy81oaycasftbag) is pretty good too.  the [#1 google hit](http://www2.toki.or.id/book/algdesignmanual/) for it is actually a copy of the full text of the book from the accompanying cd, but i don't think that that's an authorized copy...
for a partial solution: http://www.macosxhints.com/article.php?story=20031029203936659
the [c repl](http://neugierig.org/software/c-repl/) is almost exactly that: `readline`+`gcc`+`dlsym`.

it might be an interesting project to write a version that uses the dwarf information to patch running programs. just `-lrepl` and you could reload new functions or modules without disturbing your static space, and so on.
you forgot the &lt;/tongue-in-cheek&gt;.
off topic: n810 is coming out on wednesday. don't rush out and buy an n800 the day before.
thanks, i actually did try that, but i gave up on terminal because it was unusable with emacs, and i have to ssh to other *nix boxen a lot for work. as ugly as it is on osx, the apple x11 xterm is the only thing that works reasonably for me.
i'm really glad this topic came up, as i'm looking into laptops and i've been eying a macbook pro for a while, which i'm about to purchase. so it's really good to hear more good things about it and to feel a bit more confident buying it. :-)
the 30" isn't really needed.  the laptop screen will suffice, or a 19" or 21" monitor will work fine.  30" is overkill.
&gt; i'm not hurting anyone.

except future generations that are going to be stuck maintaining your line noise^w^w code. 


i'm sure cobol and fortran programmers thought the same thing, too ;-)
which platform are you developing for?

windows? linux? generic unix? os x?

macbooks are wonderful. pros are wonderful, but a lot more expensive. better to buy bottom of the range and upgrade every few years.
annoying title, but this did remind me of a test case for a product my company makes that tended to shut down the developer's box if it managed to get its hands on sudo.
i was going to recommend a 12-step program, but if the first step is "rm -rf /" what more do you need? 
 &gt; i really miss focus-follows-mouse in x, …

there's a $15 utility called [mondomouse](http://atomicbird.com/mondomouse). they have a sale this week (through friday); every fifth order is free.

&gt; … as well as constant osx terminal problems, mostly related to the emacs meta and backspace keys.

i just use xterm. xterm + vim produces several benefits:

* 256-color support. you'll have to download the x11 source and build xterm-256color yourself, but it's worth it.
* mouse support. use `:set mouse=a` in vim (or add `set mouse=a` to .vimrc).
* vim integrates directly with the clipboard through x11's clipboards. the only problem is that it gets the encoding wrong (it copies utf-8 data as iso 8859-1), which bites me sometimes.

terminal has none of these features.
this reminds me of a certain race car driving game that would crash my computer when i crashed my car.

it has so much more impact that your standard tests.   8-)
or vnc, if you're a gui programmer.
thanks, yeah i use xterm too but the fonts are ugly, that's my biggest problem with it. 
&gt; i'd like to hear the feedback from anyone who's used the mb's keyboard for serious editing.

if you use the keypad, buy an external keypad or keyboard. the skew of the overlay keypad makes it unusable, as muscle memory will fail you (unless that's the *only* keypad you use, so you don't have to switch off).
if one wishes to optimize the concatenation, yes.  choosing the right language for the given problem is also a good thing.
i've been drooling over [tadpoles](http://www.tadpole.com/products/notebooks.asp) for a while (solaris sparc/x86 laptops)
i don't understand what you mean. you just run your database/dbslayer daemons on a private network with nonroutable addresses like 192.168.0.0/24, on a different set of interfaces from your public-facing addresses (i.e. eth0 for public, eth1 for private or something like that).

which is what you do with all your database servers, anyway. they never listen on public ips, unless you want them easily hacked. and for performance/security reasons, you would never want to have your public (http) and private (mysql, iscsi, whatever) traffic run on the same network.
thanks, i'm a vi/vim nuthead so i only need control sometimes and esc, and that can be substituted by ctrl-[ or some easy-to-use mapping like 'jj'.

i'm actually surprised everyone's giving good feedback on macbook's keyboard. i would have expected the opposite. i might rethink it (the smaller screen is the second possible reason to get the mbp, but a small laptop is a plus so it's a trade-off i have to think).
i vote for "predditards."
i like to use the laptop on the couch, or of course when i'm not at home, so an external keyboard is not an option i like too much.
(to sjs too) and how about the screen size for extended coding sessions?

thanks!
since there are 15 talks, can people give a synopsis of each talk that they watch?
there are actually abstracts: http://www.acm.uiuc.edu/conference/2007/speakers
there are abstracts of their talks at http://www.acm.uiuc.edu/conference/2007/speakers
copyright infringement; reported to reddit and the publishers.  (also it's perl, never perl.)
macbook keyboard is indeed one of the worst keyboards out there but it's not exactly like other laptops have good keyboards. for comfortable typing you will need [a good external keyboard](http://www.microsoft.com/hardware/mouseandkeyboard/productdetails.aspx?pid=043).
holy shit! the dragon book guy
thanks. out of curiosity, are there any other redditors besides [munroe](http://reddit.com/user/xkcd) and [ptacek](http://reddit.com/user/thomasptacek)?
um, take a look at the picture just beneath that.
why is gcc *not* self-hosted? it requires a c compiler to build it…
in distant future, when haskell or python will be fast and compilers for them will be mainstream, i'll be happy to write everything in great functional style. now all we have are c compilers for embedded devices and weak batteries. even 10% overhead is painfull. 
i personally hate all the micromanagement c stuff
that leaves the keypad, which will fit on the left or right handrest of the laptop.
put this in your .xdefaults file:

	xterm*font:        -*-clean-medium-r-*-*-12-*-*-*-*-*-iso10646-*
	xterm*boldfont:    -*-clean-bold-r-*-*-12-*-*-*-*-*-*-*

&gt; there's a larry wall quote - doing linear scans over an associative array is like trying to club someone to death with a loaded uzi.

++(larry wall)
i bought an old dell for $50 from a guy i worked with and threw debian.

it works great for 95% of the stuff i need to do, and for everything else i just ssh over to one of the larger machines.

it's not fancy, but it gets the job done, and for a fraction of the cost of buying new.
 wtf? edit doesn't work anymore?

anyway, that's supposed to be: "and threw debian on it."
i can fit textmate with an expanded tree view across the screen and be okay. having never used multiple monitors, it does the job since i'm used to tabbing between apps anyway. ymmv.
sweet
both vision and engineering but low quality i guess...

what i think is a good vision is what apple is doing with macos x, that's what we are missing in linux imho.
i bought my macbook pro in august, and i priced a dell at the same time just so that i'd know how much i was paying for the apple logo*. my laptop was actually a bit cheaper than the dell.

*edit: that's not quite true: besides the logo, i expected the macbook to have better color, a backlit keyboard, and other nice touches.
 try [mrxvt](http://materm.sourceforge.net/wiki/main/download). it'll do anti-aliased fonts in x11.app (if you don't need unicode...). i've been really happy with it for the past several months ([screenies, and my walkthrough](http://eseth.org/2007/mrxvt)). 
algorithms and specifications can *simulate* creativity, but it's not the same thing.

by the way, when you're in a deli and order a sandwich "with veggies," do you tell the manager to change the menu because a tomato is actually a fruit?

the developers of a mmorpg i play once sent out a patch for open beta that did this. if you had the beta loaded already all was fine. if not, it took out your root directory.

since it was an open beta for a new version it hit a good portion of the player base, and i was convinced that i'd played that game for the last time. fortunately a dedicated and forgiving player base got the game company through the next couple of sleepless days of recoveries and became a huge ad-hock tech support organization for those who weren't computer savy.

i *think* the idea is that it's threaded and written in c so it's much faster/scalable than doing similar using a scripting language and cgi/fastcgi/mod_whatever.

but that's only if you're exposing it directly to, say, client requests in an ajax application. versus doing the sane thing, which would be to have a server end of your ajax app validate user input, construct a query, and send it to the database. then it just seems like an unnecessary sql-over-http proxy, adding a bottleneck/pof. so i guess i agree with you. :)

most of the things on the "why use it" page -- db abstraction, round-robin db servers, and failover when a db server is down -- are trivially and better implemented in your app. the big one that isn't is connection pooling (unless your app is multithreaded, 99% of lamp-style apps aren't and just blindly fork apache/fastcgi children), so to me that's probably the big win.

if you are rewriting your mysql app to work with something like this though, the time might be right to make the switch to ndb. :)
thanks for the info -- i updated the tutorial to make this more clear. 
try [ynot2k.com](http://ynot2k.com)--asus is rumored to be the macbook oem, and this shop makes the ms tax optional.
 also [chung-chieh shan](http://reddit.com/user/ccshan). yegge has an account here, i think, although he hasn't posted since reddit's inception.  
on a &lt;somewhat&gt; related note:

does anyone know what happened to mosquito lisp?  the ephemeral security site is now just a redirect/ppc site (and the sourceforge site still just redirects to it.)
don't make the first step "rm -rf /", perl programmers die from coldturkey.
yes, actually, but i think this joke is much funnier. :)
thanks, that is really nice!
 i'm happy with my x60 running gnu/linux. also, the small screen likes wmii+vim+terms more than visual studio.
it is no more:
http://waspvm.blogspot.com/


any references for using quickcheck to test code from another language?
this is a great site and has some of the best references/tutorials on a* pathfinding i've come across.
so what you're saying is that, say, building bridges has nothing to do with *bridges* which have been *built*, or painting has nothing to do with, say, *paintings*?

you think that you'd be anywhere near as good a programmer as you are now if you hadn't seen the thousands upon thousands of other programs i'm sure you have seen?

i mean, really. the programming subreddit is about things which would interest programmers. programming is *not* all about writing code anyway.
you shouldn't.  from the title and text of your article it is clear you are at least retarded and possibly a borderline idiot.  by all means do not use c!  in  fact, you should stop using all mechanized systems of greater complexity than a toaster.  scratch that--stop using the toaster as well.  dear god, just waddle off to an unpopulated area and wait for nature to take it's course.  with any luck (yours, not ours) it will be swift and decisive in a painless sort of way.  if you do not heed this advice, we may need to hunt you down.  don't make us do this.
i believe i haven't directly programmed in raw c in over a year.  i use python almost all the time, and [pyrex](http://www.cosc.canterbury.ac.nz/greg.ewing/python/pyrex/) works great when i need the speed of c.  but i must admit, you couldn't get the full value of pyrex without knowing c first.
absolutely 100% macbook. it's a unix machine with a beautiful gui. combined with quicksilver, an app that allows you to do just about anything on your machine with just a few keystrokes (complete with learning algorithm so you can build your own interface language, so to speak), it is, quite simply, the perfect development environment.
if all your care about is hardware, sure. but after spending some time getting to know os x, there is no better environment for getting work done.

just check out some of the great things merlin mann has to show on 43folders.com
 &gt;     forever a = a &gt;&gt; forever a

obpointless:

    forever = fix ((&gt;&gt;) &lt;*&gt;)
on the other hand, do get a hold of this book and read it. it's quite useful if you write perl regularly.
true, unless you have optimizations turned off or `i` is not an integer (but rather a number-like object, such as a bignum, or an iterator).

edit: typo.
 you're confusing analyzing the design and interface of a program with simply using it. analysis like that (including using the program with that purpose) is perfectly appropriate for programming.reddit.

my complaint is with simple “[here's a web app that finds a latitude and longitude](http://programming.reddit.com/info/2zi05/comments/)” posts. there's no api, no story of how it was implemented—nothing that's actually *about programming*. it's just a finished program.

&gt; the programming subreddit is about things which would interest programmers.

the programming subreddit is about programming (and i include interface design as well as the actual coding). a finished program, by itself, with no api, does not fit that definition.
tried that (applying to galois).  

i suspect they weren't impressed with the fact that i was learning ocaml...  but hey, i said i also plan to learn haskell.  never heard back of course.  it was worth a shot... i only live a few miles from there.
if you're confident in your ability to create value by hacking haskell all day, then quit your job and just do it.  write that one program you wish existed.  sell it.  or give it away for free, and go for a huge userbase instead -- and try to get bought out.  find a local entrepreneur group who knows angels and vcs.

surely you know by now that big business thinks using haskell is a risk.  the cold hard truth is: if you don't trust that you can create wealth with it, why should they?
bah! do it right with a real editor.

:1,$d
 &gt; &gt; by the end of your grad student life if
&gt; &gt; you are not an independent thinker you
&gt; &gt; are a failure
&gt;
&gt; what utter, utter nonsense.

there's some confusion here, possibly due to there being 2 sorts of "grad student". in the u.s., grad students can work toward 2 different degrees: a master's degree and a phd (where, you typically get a masters on the way toward a phd). both are graduate degrees. both have grad students working toward them.

the difference between them is, a master's degree means you've mastered the relevant subject matter. a phd means you've not only mastered the subject matter, but also proven that you can actually do real research in that subject (and have your work peer-reviewed by other researchers in the field).

so, i'd say, if by the time you get a phd you're not able to do peer-reviewed research in your field, you're a failure (specifically, a failure only at being a phd in your chosen field).

i think lulzlulz was talking about this specific kind of failing, and not in the insulting "you're a failure" sort of way.
 
sure, mod me down, but being first to market is a big advantage in the real world.

but maybe you'll prove me wrong some day with your awesome new 100%-written-in-c web application. ;-)
&gt; i'm pretty sure that real individualists are
&gt; autodidacts, too.

depends on what you're trying to learn. some stuff is very very difficult to learn without a good teacher.

it sucks, but no worse than any other laptop keyboard.  don't let its funny looks scare you: it's not any worse finger-wise than the macbookpro's keyboard.

none of the things i hate about the macbook keyboard are better on the macbookpro.  you'll curse the enter-where-option-should-be on either one.
i don't know what the original poster's intent was, but that's a finished program *with unobfuscated source*.

in any case, the community ultimately defines exactly what "programming.reddit.com" is all about -- that's kind of the whole point of reddit.

if you don't like what programming.reddit.com is, why don't you try and get another subreddit made?
 &gt; invaluable in picking up any c-like language. (i.e. java, c++, objc, c#, etc.)

of course, you could just pick up one of those higher-level languages instead. =p 

(not saying knowing c isn't valuable, i'm just saying that the amount of time spent learning c plus the amount of time spent "upgrading" your knowledge to a similar language is probably equal to the time spent just learning the other language.)
xna is essentially a library that can be leveraged from c#.

in theory any .net language can be used with xna, but in practice that isn't the case because some languages like vb are incompatible with .net compact edition. (basically the compiler/runtime uses op-codes not found in that version.) 
true, but a language that does those things automatically can often do it intelligently.

for example, c#/vb will not check array bounds in for loops if it can pre-determine that the index will always be valid.
this design requires a very strong justification, since it means a lot of pain for users and a lot of work for device drivers maintainers.

what's the point about changing little things between 2.6.17 and 2.6.20 that prevents many drivers from compiling (i've v4l and wifi drives not compiling without some patch)?

no, it's not about some major advances, you can do *great* work and release 2.8.x with a lot of new things, nobody will complain, there will be the switch, it will be clear that if you have 2.6.x you need this driver, otherwise you need the other one.

i think there is just no justification for many of the kernel-space api shifting and for not providing compatibility when an api between applications and the kernel changes.
&gt; in any case, the community ultimately defines exactly what "programming.reddit.com" is all about -- that's kind of the whole point of reddit.

hence this submission, and the 86 points it got before reddit went down.

&gt; if you don't like what programming.reddit.com is, why don't you try and get another subreddit made?

a new subreddit about programming? what would i call it?
i would be very happy if programming.reddit.com would contain more programming material and less tangential material so i think it is a good idea.
i just used the haskell ffi to bind to the c functions i wanted to test, and the `foreign.c.types` module to generate arbitrary values of various c types. feed those in to your c code, using quickcheck to drive the property testing. lots of fun, actually.
i think this is off-topic.
any laptop with a core 2 duo cpu, 2 gb or ram, and at least an 80 gb hard drive should be fine as a programmer's laptop.

i actually prefer the lower end core 2 duo models (less than 2.0 ghz) from my experience using both a dell inspiron (1.73 ghz c2d) and a lenovo t60p (2.0 ghz c2d). the higher end laptops make more noise as the fan is almost always constantly on (the lenovo t60p's fan makes a high pitch whine almost similar to that of a scsi hd). i find this bothersome especially when working from home where there is not much background noise.
easy, don't allow dynamic memory allocation and count your slots. for highly constrained devices, they make languages that allocate all the memory up-front.

my problem with c is that it never checks for out of memory conditions. the programmer is expected to check for it after every malloc call, and then do... what? usually the only honest thing to do is crash before data corruption can occur, but that's on the developer's head. most just ignore it, especially when the malloc call is burried in someone else's api.
you can also mitigate risk by using haskell for less risky projects initially, and build confidence in others that way, by delivering reliable code ahead of time.
this is a draft? i purchased this book in may.
you could always tell the poor kid that you're from apple and need to "update the firmware" so that it doesn't explode. he'll hand it right over.
i've got an older thinkpad (t30).

i love it.
ahh, steve yegge, always funny
i love my macbook, but i want your keyboard.

reliability (&gt;51 days uptime) and parallels (windows, mac, linux dev easy), but all i want is the dang ctrl key in the right place.
i love my dell inspiron 1501.

the widescreen and amd processor are great.
it's good for games and other things.
plus, it can multi-task great.
&gt; why are tv sets, dvd recorders, mp3 players, cell phones, and other software-laden electronic devices reliable and secure but computers are not?

microsoft
  30" is overkill until you've used one for a day. then it suddenly becomes the minimum you're ever going to accept. :-)  
gforth is pretty portable.

commercial forths (swiftforth, vfx forth) have sophisticated optimizers. i don't know if they beat out gcc for speed but i wouldn't be surprised if this was the case, at least on some benchmarks.
odd, i use terminal and emacs constantly. what about it doesn't work?
&gt;     incr x = do n &lt;- get
&gt;                 put n + x
&gt;                 return n + x

or simply:

    incr x = do modify (+x); get
i have a thinkpad x60.  it's not 61 (because i bought it just before the 61 came out, and the x60 was on sale! :)) and it's not s because i didn't see the point of it's few "improvements" over the x60.  still, i love my little x60, lots of power, small, light, great keyboard.
ideal?   for which set of compromises?   my laptop is carbon fiber, so it wins in the cool case catagory (a make ti book would beat me, but they haven't made those in years), but there are other compromises though that i don't like.   (too bad nobody has figured out how to fit a 30 inch screen and model m keyboard, on a 12 inch laptop)

i bought my laptop because it is light and i carry it around often (it also came with linux only).   of course the next week someone was selling a model even lighter.

i have a thinkpad t60 at work, and it is a great machine.   not too bad to carry around either.

i consider a strong case important.   my previous laptop had cracks all over.   i often carry my laptop open with one hand on the corner, and the case couldn't take that.  i don't consider a fast cpu or large harddrive as important as many others do (though of course i would love to have them, i tend to compromise against them in 
favor of other factors)

in short, there is no one machine that is best for everyone.
i want to echo this. everyone always asks about the keyboard since it looks funny. but i found it perfectly natural to type on and don't have very much to complain about. they keys are tactile and have good throw.

the only real complaint is some moron put the "fn" key where control usually is. makes it hard to use for the first week or 2 (but then again all apple portables (and some lenovos) have this affliction).
he should've groped her tits. 
yeah, you have to suck it up and use option as the meta key on macs (x11 will let you use command). i usually set my linux native computer to use that anyway since it was ingrained in my muscle memory many years ago.

the nice thing about using option as meta is that you can use the mac style keyboard shortcuts and emacs style shortcuts at the same time (since they don't conflict). i set up my emacs to use super-c for copy, etc, so that when i switch back and forth between mac programs i can just "paste" and whatever my finger do works.
i love this subreddit!! im not even a programmer (it guy - data cabling)
no, we can't.

i've certainly seen the cable box crash.
as long as there is some interest in a driver, people will port it forward.  if there's no interest, who really cares then?
 &gt; $row[’id’] is 7 times faster than $row[id]

wow.
it's just a separate set of histories. it's basically like diffs with history.
why did i get down-modded? man, i've never been downmodded before.
linux isn't a "product" so there's no "vision" necessary.  


the path linux takes is what the developers bring to it, if you don't like it, then learn to code and submit your own changes or go use fucking widoze, you whining fucking bitch
there're great talks on hypervisors and virtualization!
especially given that demo writing doesn't involve any string mangling - forth's achilles   heel.

looks very nice!
from what i've seen, apple is fairly consistent about its pricing (i guess you could say they're "honest"). anyone who gets the dell catalog has the surreal experience of seeing literally identical systems, with one 2x the price of the other. generally, to get the real price, you have to look through dozens of similar machines and then smell out the coupons, usually good for 300 dollars.

dell uses pricing strategies similar to grocery stores in this respect. (where the lower shelves have the same products at lower prices.)
&gt; a new subreddit about programming? what would i call it?

well, the fundamental problem is the idea of a subreddit in the first place. (hello, tagging?)

but that aside, i wasn't really suggesting creating one for the programming content -- i was suggesting creating one for the content that programmers like that isn't directly "programming". perhaps geek.reddit.com?
there are assloads of studies that quantify this. even crotchety old curmudgeons like jakob nielsen argue it.
it says $100/gigaflop in the article. that's twice as much, but still a hell of a bargain.

if you need a supercomputer...which you don't.
design and analysis of algorithms by anany levitin is better.
my friend, you have been misled to the crappy scheme version of _imagine_. the true one is: &lt;http://groups.google.com/group/comp.lang.scheme/msg/5d5fdf6ddb87bcc7?dmode=source&gt;.
 i bought the bottom-end mbp (15.4 inch, core2 2.2ghz, etc) a few months or so and am loving it to bits.

if you just compare based on cpu/ram/hdd, the apples usually come out slightly behind, but that's never quite fair...

for example, i compared the mbp to a dell machine, and while the dell machine was quite a bit cheaper and matched or slightly beat all the primary specs (cpu, ram, video), the mbp was better at a ton of 'smaller' stuff which all adds up to making it a much more pleasant machine to use, i'll list below the things that the mbp had the dell didn't.

backlit keyboard

light sensing screen

higher res screen with led backlighting instead of ccfl

gigabit lan

firewire

draft-n wireless

bluetooth

webcam

infrared (and the apple remote which is cool)

weighed less

thinner

much much more attractive

the cool and useful led battery indicator 

magsafe power connector

no crapware installed

and not to mention mac osx - especially with the imminent release of leopard this is well worth paying a bit extra for.

even running windows the mbp is still a much nicer laptop to use than many others due to all this stuff. 
&gt; i wasn't really suggesting creating one for the programming content -- i was suggesting creating one for the content that programmers like that isn't directly "programming". perhaps geek.reddit.com?

this is a good plan.
&gt; why are tv sets, dvd recorders, mp3 players, cell phones, and other software-laden electronic devices reliable and secure but computers are not?

question contains false assumption. in fact these things are unreliable and insecure. cell phones have many known security vulnerabilities, saved from exploitation only because there isn't much point. my tivo crashes. my mp3 player crashes, and fails to handle certain mp3s. my cell phone hasn't crashed on me yet, but has gotten into some funky states.

the only thing that's reliable is my tv, so far, and it's utterly basic by modern standards.

it's easy to secure something that isn't being attacked. 
only the draft is available for free.
i think they're lying. some developer clearly made it divide by zero.
+o
-p
 i was just fixing up [a greasemonkey script](http://userscripts.org/scripts/show/11288) to cope with the new reddit, and spotted that the ajax calls are now being made through an `/api/` subdirectory.  is this a sign of things to come?

anyway, i thought i'd send them a link to [an article](http://shiflett.org/blog/2006/sep/the-dangers-of-cross-domain-ajax-with-flash) pointing out a potential problem with the interaction between flash and public apis in subdirectories, but i found that [the feedback form](http://reddit.com/feedback) is broken because they forgot the closing quote on an attribute.  i'd report this bug to them directly, but, well, their feedback form is broken ;).

so consider this a public bug report, and if the api hint isn't interesting enough, then i offer this tip as tribute for the content-free post.  if you are developing a python web application that uses wsgi to talk to the web server, then you can use python paste's [wdg validator middleware](http://pythonpaste.org/module-paste.debug.wdg_validate.html) to catch mistakes like this as soon as you make them.  all you do is hook up the middleware and you get a notice at the bottom of each page telling you about any validation errors.  a validating spider would also catch problems like this, but the middleware has the advantage of working for all pages, even those in response to post requests.
 
alert - all is well
i like the idea, but somehow it seems like it'd be very difficult to actually get implemented. which is actually kind of sad -- tagging/community subreddit creation would solve that, but how long has that been "coming"?
interface builder doesn't generate code. it produces an object archive. my apologies for not providing more insight, but if you search the web a bit, you can find better explanations than i could give.




one rule of thumb that michael feathers offers in [*working effectively with legacy code*](http://www.amazon.com/working-effectively-legacy-robert-martin/dp/0131177052) is that a test isn't a unit test if, among other criteria, it touches the filesystem.
dual core (core duo) 17" wide 2gb ram, pref dedicated graphics mem. smaller if you need to save on weight, but this size also gives you a useful keyboard.
yeah. the edit button hasnt worked for me all day.
now, how did my post about becoming google with nutch get downmodded but this post is ok.
i'll have to say an lenovo t series.

they're built hell for stout, and have great warranty service.

the macbook is nice, but don't buy the hype. there are three main reasons why i can't stand the macbook for serious development.

1) keyboard. the keyboard sucks. the lenovo has a far better keyboard, with a more tactile feel and decent key travel. it's painful for me to touch-type on a mac keyboard - to be fair, i love my old ibm model m.

2) lack of a trackpoint. the lenovo has a trackpoint right below/between the g and h keys. i never have to move my hands to move the mouse, which helps a lot.

3) mouse buttons. the lenovo has a left and right mouse button. and even better, they're located right below the space bar. i hate moving my hands when i'm programming, so i have everything right there. if i need to move the mouse, i twitch my index finger over. if i need to click or right click on something, i move the appropriate thumb down a few milimeters, and click the button.

the macbookpro is a beautiful machine handicapped by its input devices. for what it's worth....


you mean next the 'a' key, where it reads "capslock"?  i haven't had any problem making that my control key :)
    can't locate object method "larry" via package "wall" (perhaps you forgot to load "wall"?) at - line 1.
opos?
12-step program?  it's not like i'm robbing gas stations to support my perl habit^h^h^h^h^hprogramming.
i would not recommend this book. i was a teaching assistant for a course using it this summer, so i feel i have some relevant experience from which to form a reasonable opinion.

in places where additional explanation was needed it frequently fell short. many times questions would be asked in the 'problems' section for which the requisite details were not adequately covered in the text. additionally it does not provide enough detail to serve as a useful reference after the course has ended.

i'm also not convinced that starting with algorithms about numbers is a good idea. rsa sailed right over most of the students heads at that point in the course.

that said, my undergrad algorithms course was nominally taught out of clrs. that was an awful book from which to try to learn anything, but as a reference i find it outstanding.

if people are looking for good lecture notes at an introductory algorithms level the ones found [here](http://www.math.gatech.edu/~randall/algs06.html) are generally quite good. i believe most of them were borrowed from a berkeley course covering a superset of the material.
i have both a macbook (personal) and a macbook pro (work) and i *by far* prefer the macbook keyboard.  the "pro" keyboard is horribly squishly, wears down far faster (i've already worn a hole in my spacebar) and causes far more typos than the mb keyboard.  i've honestly not used a *worse* keyboard in a long time; my previous work laptop was a thinkpad t43 and its keyboard was amazing (though it still wore down quite quickly).

typing on the macbook keyboard is far better for extended periods than the macbook pro keyboard.
the people who actually make reddit work by voting on everything new can become annoyed when the signal to noise ratio gets killed by the submissions of a single user. linuxer was posting ridiculous amounts of random crap that the people who were moderating often had to deal with. people who moderated less frequently weren't as annoyed, because most of it would pass below their threshold.
yeah, i'm running openbsd head. wifi works (iwn driver) and x runs the graphics card out of the box. sound works in openbsd head.
tell me more about tell me more about it would be more interesting to have a variant of linuxer who dispensed relevant comments rather than relevant articles.
do you think learning c is valuable?
i don't have a macbook but it would be my choice. my development machine, well rather code-writing machine is an old ibook g3 600 mhz that i saved from a friend's house. its light, portable, and runs faster than one would think.

that said, a macbook would be this laptop on steroids. since i develop mostly on servers, the horsepower is not an issue to consider for me.
really? the fonts are beautiful in terminal, but i haven't been able to get meta to work at all. and because my muscles can't remember not to use the apple key as meta, i keep pressing meta+p which opens the stupid printer dialog, which is really irritating. are you using esc for meta?
i got hacked and the hackers left a file on my root called mysql.php. i cleaned up the site (they didn't get into the database) and i got their ip from the logs (in russia). anyone know how they were able to upload this file in the first place? it allowed them access to a lot of stuff. i put the file on a test box and it's a pretty interesting utility for hacking.
1. feature.
2. this would be a dynamic check anyway.
3. true, it's left to libraries.
4. not an error.  do you mean *using* dangling pointers?  again, left to libraries.
5. feature.  and again, libraries.
6. there *are no* casting errors in c.  it enforces strong typing, but it's not type-safe; the compiler believes you if *you tell it something's type*.  (hey, they're your bits!)
7. char* != string.

you've just described some of the things that make c a simple, fast, and portable language.
here is a snippet of the code they used. anyone seen something like this before? 

$shver = "emp3ror undetectable #18"; //current version
//configuration and settings
if (!empty($unset_surl)) {setcookie("n3tsh_surl"); $surl = "";}
elseif (!empty($set_surl)) {$surl = $set_surl; setcookie("n3tsh_surl",$surl);}
else {$surl = $_request["n3tsh_surl"]; //set this cookie for manual surl
}
i liked the part where he was trashing c, but not the part where he was defending c++. both deserve to be thrown in the drawer of history with fortran and cobol.
good list, i'm sure there are a few good ones missing though. 
 interestingly, [scheme itself was originally created to study the actor model](http://en.wikipedia.org/wiki/scheme_\(programming_language\)#origin). 
i'm not as much complaining about missing libraries as low-quality/old-or-unsupported libraries. i remember a particular gtk binding depended on ffi things of pre sbcl-1.0, and i had started trying to port it to sbcl 1.0, but i eventually came up to a bunch of obscure errors which were taking up large amounts of my time, so i stopped the work.
thanks for the interesting article on the cross-domain flash issue.
does this quality as the worst bug ever? you cannot do much more damage than rm -rf /.
this should answer your question:

http://www.mjmwired.net/kernel/documentation/stable_api_nonsense.txt
when two computers love each other very much...
not all thinkpads are complete bsd/linux friendly, so do your homework before you order (in particular watch out for the graphics chipset). but its pretty easy to configure one that is.
t43p with the 1600x1200 display, wouldnt swap it for anything.
c++ might more naturally map to python objects. of course, python can wrap standard c code quite well without using objects, and it's also possible to write pythonic oop wrappers for non-oop c code. i've used pyode (python bindings for ode, the open dynamics engine), which wrap ode (written in c) handles in python objects very nicely.

oh, right, i should have been more clear. i meant that it would be 100% slower due to his skill level, not due to the language. the language difference would be closer to 10% like you said.
good old perl.  thank god i never messed with it.

but on another note, you would think on a modern unix/linux system that a user would be unable to run "rm -rf /"

on some databases, you are at least prompted or not allowed to do "delete from the_table" without a where clause.  seems like the filesystem or some custom linux distribution should prevent this.

 
imagine what you could do with a beowulf cluster of those!!!!!!!!

(sorry.)
ok, so.. did this only affect unix users..?
sudo rm -rf /
you can remap caps lock to control yourself under os x 10.4.  works a charm.

1. open system preferences.
1. go to the keyboard &amp; mouse preference panel.
1. go to keyboard.
1. select the modifier keys button to change the mapping you want.
[intro to algo by cormen, et al.](http://books.google.com/books?id=nlngyywfl_yc&amp;dq=introduction+to+algorithms&amp;pg=pp1&amp;ots=bvwofy6nh5&amp;sig=g2zwcp-tszx806n7vcsbxyj59g8&amp;prev=http://www.google.com/search%3fq%3dintroduction%2bto%2balgorithms%26ie%3dutf-8%26oe%3dutf-8%26aq%3dt%26rls%3dcom.google:en-us:official%26client%3dfirefox-a&amp;sa=x&amp;oi=print&amp;ct=title&amp;cad=one-book-with-thumbnail#ppp1,m1), is good.  to the [comment on this books explanation of rsa](http://programming.reddit.com/info/5ycj2/comments/c029f03), i was able to use the cormen book to implement rsa for my senior project.
&gt;you think you understand how to write machine code to keep all your pipelines full?

i agree with your comment, but i don't think compiler knows enough for that, either. that requires collaboration between the compiler, profiler, and the programmer.
usually titles like this do not lead to anything actually humorous. color me surprised.
you'll still get blamed. things will still be your fault until you are friends with the right people. of course by then you'll have neglected your own work for so long that it will be full of bugs, but hey, it's not your fault. logic.
true, and that's (one of) why(s) c++ is so relevant: calling c is really a matter of calling it, as opposed to anything else that can "call" c.
 could have used **[pics!]** instead of (illustrated) 
the fact that he didn't offer up a feasible alternative should be his answer.
&gt; i only live a few miles from there.

same here. we should gather up anyone else in the area and go out for pizza, maybe impress dons with the amazing lack of things to do in portland.
can you please post a link? i'd be interested in reading something about that.
 in the info pane under "keyboard" there's an option called "use option key as meta key". so, you're still not going to be able to press command-p, but option-p is easier than esc p.

i set my normal emacs up to use option as the meta key, so i don't have to keep relearning keys when i switch back and forth. though i've found relearning where the meta key is is much easier than relearning the control key (stupid laptops have the "fn" key where control usually is. and yeah, i've tried to switch to capslock-as-control but it's just too hard for me to remember...) 
it's a php rootkit. search for n3tshell on google, you'll find a million things, it's pretty common. how it got on your server? check you security logs for brute force attacks, or any of a bunch of other ways someone could put that on your site. i would surmise the method was standard ftp or frontpage extensions. if they had gotten in any other way there would be no reason to use a php app to control your server. 
i had it running on my z61m several months ago, but it did not run well.
even if you added more protection -- perhaps an alias for rm with warning prompts -- it would be very hard to detect deletion of "/". for example, i once accidentally mounted the filesystem *within the filesystem*, and then deleted it. this situation *broke my mind*, and it can probably break most error-checking code if you're running as root.
i'll be damned. i'd missed that entirely.
&gt; no os x means no textmate

indeed. i can't live without textmate when i'm working in ruby or latex, just like i can't live without emacs for working in lispy languages.

i'm still amazed that i was willing to pay for a text editor.
mmmmm... team fortress 2 on mbp hooked up to 42" philips plasma.
heh, hitting from belgium, too, i'd like google.com to be in

1. english (that's only thing in my browser's language options)
2. french

but it picks, understandably, dutch. then, of course, with my miserable understanding of dutch (flemish? ;-) ), i roam around trying to find options page to switch back to something i can read. oh, noes!

good find, the "ncr" link mentioned here.
i've gone from a no-name linux notebook to a powerbook g4 to a macbook to a macbook pro in the past few years. i can honestly say that i think i liked the macbook keyboard best out of the systems.

i tend to be a bit of a key pounder, though, and i also don't touch type like a normal person (my hands wander all over the keyboard rather than sticking mainly on the home row). the upshot of this is that i get the edges of my fingers caught under the keys on the mbp from time to time and nearly feel like i'm going to rip the keycap up.

your mileage may vary.
remap caps lock to control. after you using it that way for a week, you'll wonder how you managed to keep your sanity before.
&gt; you'll curse the enter-where-option-should-be on either one. 

yes, yes you will.
quality takes a dive too. apple laptops and thinkpads have long been the standard for materials and build quality in laptops. i have yet to see any reason to believe the rest of the field has caught up.
i actually have! but i can't seem to switch. maybe if i could disable the old control key that would force the issue...
a small demonstration for windows users, who are still wondering whether software installation on linux has to be complicated.
r50e here. that was a 500 dollar notebook (new) and support in openbsd is full.
what laptop do you have?
you know there's a bugs.reddit.com right?
what i'm noticing is how many things are now broken with the "new" reddit.  i'm really questioning their testing because, like the missing quote, multiple other things just don't work, such as saved articles, hidden articles still appear, etc.

i can't say i wouldn't get lazy after making millions on a sale, but these are primitive mistakes and issues that you just don't roll out.

regardless, i'm still a reddit fan.
well it all depends on context. when i worked in a java shop they thought i was crazy for learning c/c++. now i work in a c/c++ shop (yes, we use *both*) they think i'm crazy for learning lisp...

..so it goes.
emacs could, but to be truthful i haven't got around to hacking it yet.
ctrl-c gets out of insert mode too!  it's my favorite alternative to esc.
  &gt;... support was (not) dropped... this is a point of view perfectly right for engineers, but it means to don't have any kind of vision. 

it's not "vision", it's really lack of care about backwards compatibility.

if this is important, the "community" has to demand it and, well, force it down linus's throat. i am not sure if it *is* important for linux, but ["stable api nonsense"](http://www.mjmwired.net/kernel/documentation/stable_api_nonsense.txt) doesn't help, as it's way too one-sided, and plain false in places.

(otoh, backwards compatibility and things like stable driver model is a prerogative for consumer os like windows).  
the link to the paper is broken. wayback machine to the rescue: http://web.archive.org/web/20051109035459/http://lisp-ecoop05.bknr.net/pdf/19654
&gt; but on another note, you would think on a modern unix/linux system that a user would be unable to run "rm -rf /"

this comes from people running the cpan shell as the superuser or through sudo.  the cpan shell configuration process has recommended not doing this for several releases now; it only uses sudo for installation, and that only if you want to install perl modules to system-wide directories.
i own a vaio ultraportable. weighting 1.25kg, you never think twice about putting it in your backpack and taking it out any time you need to look something up. battery life is also very decent (5hrs minimum but easily stretches to 8-9).

dual-boots vista and debian without a problem (s3 suspend doesn't work in linux, though).
torrent?  non-wmv?
it would be nice to have an operating system where clustering was built in. including file sync, application load balancing etc..


although i wouldn't turn down a 30" monitor, in many cases it's a lot more economical to go with two smaller monitors.  i have 2x22" widescreens which lets me run at 3200x1050, giving me more horizontal resolution than most 30" monitors, with only slightly less vertical resolution, and for about half the price of a 30" monitor.  plus having dual monitors allows you to maximize code on one screen, and documentation on the other, which just feels more natural to me than having both windows open half way.  of course, dual 30" monitors would be awesome, but it's way out of my price range. 
 that's because in the second case php will check if `id` is a constant, and if not assume the that the programmer meant the string `'id'`. you'll get a compiler  warning if you have them turned on. 
  yeah. i'm finnish, want to use english as the language but have weeks starting on monday (and calling it monday, not maanantai) in the gnome calendar and string sorting that puts åäö after z. solution? 

   lc_collate=fi_fi.utf-8
   lc_ctype=fi_fi.utf-8
   lc_time=en_ie.utf-8
   lang=en_us.utf-8

the locale system could use some improvement.
  
that would be what dragonfly bsd is trying to achieve.
anyone else pick up on the irony of ranting about using something as low-level as c in unadorned ascii? 

don't get me wrong, i agree with him about c but we have this thing called html these days.
old joke, but used to be a pole and german.
you're assuming that all linux users live in the la-la-land called "x86 with gcc 4.0".

a stable binary interface means that all kernel modules need to be compiled with the same compiler settings, and that's just for one architecture. x86 drivers don't work on x86_64, neither do they on itanium, pa-risc, power6, etc. and they most likely won't work if it was compiled with the intel compiler either.

and what about memory-constrained devices? a lot of systems are not capable of managing large binary blob drivers that are most likely not optimized for whatever purpose the machine in question has (think embedded devices).
have you thought about api rewrites? did you know that linux has undergone three rewritings of the usb api and because of that it has the fastest, most optimized stack of all known operating systems? windows has had to rewrite it as well. problem is, it has to hold all three api instances in memory at all times.

sure, you can say that solaris has a stable api and it does just fine, but solaris was designed to run on large servers with proprietary-friendly features and with only two target architectures (unlike the dozens of subarchs linux supports), so speed is a secondary concern at best, much like aix or hp-ux. but then again you're not going to be recompiling those any time soon.

the biggest difference between linux and its competitors is that it's not a monoculture and it never expects to be one, so you can't rely on default architectures, default compilers, default flags, default use cases, etc. binary drivers would be an advantage for many uses, but they violate basic principles of what linux is used for and who it caters to. and desktop users are only one of many groups of users, and not particularly the most represented in kernel development.
what's the problem? if file::remove() effectively maps to rm -rf /, then the file you wanted removed is definitely gone. so is everything else, but never hurts to be thorough!
especially fun if you have network shares with write access mounted!
it's true that smaller screens are cheaper, but most laptops only have 1 external video port.  so i would purchase the largest monitor possible.  currently, the dell 30" is around $900 so it's not really too expensive if you consider that it will probably last a good 10-15 years of use.  i still have a 17" lcd that i bought 6 years ago that is in near perfect condition.
yeah, i was fortunate enough to be able to attend the talk (and ask a question) -- munroe was definitely as funny as his strips, though he did reference them a lot. i would have liked a slightly more focused talk for a bit, but the q&amp;a was very cool -- definitely worth watching.
i think every programmer should have a good working knowledge of c (and some assembly for that matter), however i don't think c should be used for high level application development.


exactly right.  in perl, this is also incredibly easy.  in your test file:

    my @unlinked_files;
    *core::global::unlink = sub { push @unlinked_files, @_; }

now instead of unlinking your files, unlink just pushes the filename onto the unlinked_files array.  your test can compare that array to what it expected to see if your module issued the correct unlink calls.

there's also directory::scratch if you really really have to touch the filesystem.
i've tried mondomouse before, i didn't really like the whole window-going-to-the-front thing.  it can be pretty troublesome when you have more than 5 terminal windows all cluttered on one desktop, usually there's no need for me to bring up the entire window as long as i can see the prompt cursor.  i preferred the sloppy focus, but apparently this isn't possible in the osx window manager.  it's also possible to do away with osx window manager completely as well, i've been able to start up wmii but it's pretty hard to open up mac applications inside of wmii.
three here :)
did you find a way to get some analog to the right and middle mouse buttons working without using an external mouse? i haven't. it would be easy enough if the right apple key and little enter key could be turned to that function but i couldn't get that working when i tried on my macbook.
what do you use quicksilver for usually?  i find it really only useful for opening up firefox and xterm sessions.  i disabled all the other 'categories' so that my mistyping wouldn't accidentally open up one of my firefox bookmarks instead.
no, only windows users.
how about using a language where purity and easier auto-parallelism are not a bolted-on afterthought?

languages and compilers have learnt a lot since 1970, but a walk through the gnu source code doesn't reflect this. we are not developing. it's sad.
clearly what linux needs is a vision statement. i suggest we immediately form some committees to close the "vision statement" gap between linux and commercial operating system.

we can get something like a dozen groups of ten to twenty people. they can tackle the various parts of the vision statement as well as doing some market research to determine what linux consumers and developers need and want in a vision statement.

of course we would need to form a steering committee and a board to oversee all this activity. 

linus is obviously the best candidate for the ceo but we would need to hold elections for the rest of position. perhaps the various stakeholder groups can arrange for meetings.

obviously we need a server someplace with exchange and sql server on it so we can share our powerpoint presentations with ease.

yeah well, if you want to run windows on your laptop, then yeah go the cheap route.  if you want to run alternative oses, be prepared to configure laptop-tools and xorg.conf modeline files.  plus, remember to cross your fingers when hibernating because sometimes linux likes to frequently dump instead.  and besides, most people who use linux aren't extremely attached to their window managers anyway...  unless you're a rabid wmii fan who has everything scripted.
i simply can't understand the enthusiasm people have for finder. it hangs when you do things over a network, doesn't remember view settings properly, the plus button doesn't work like maximise on other platforms, no effective equivalent to the alt+tab fn in windows, stupid candy look and feel, can't resize or move a window by holding down a control key and dragging at anywhere in the view like you can in some x window managers.

the drivers are good (although i have intermittent problems where wireless dies and can be fixed with some sort of reset that happens when i plug into an ethernet network and then immediately disconnect again) and i usea cool app called audio hijack. but when i'm not in my web browser or apple mail i have a full screen xterm with screen to get me away from finder. i can't understand the enthusiasm for it. i thnk both w2000 explorer and gnome are far better interfaces.
google has had that feature for a long time... considering how international google is, i'm surprised they haven't fixed it.

if they're concerned about users without correct accept-language headers, they could offer a translated link to change the language from english to the language based on ip address lookup (only when accept-language does not match).
&gt; in many ways, the linux kernel is developed primarily for linux kernel developers

exactly.  they have limited time.  why should they care that your apps use a deprecated and broken api?

if you want support, add it yourself or pay someone else to add it.
the thinkpad x-series gets my vote, for sure! i've been trying to use my macbook, but i feel so much more efficient on my thinkpad with ubuntu.
 i would absolutely recommend anything from the ibm/lenovo thinkpad, especially the t-series. they have the best keyboards among all notebooks ever created, and this is really an advantage since the keyboard seems to be the primary programmer's tool. 

p.s. never by an asus. awfull keyboards and bad wireless antenna quality.
good article.  not sure it should be on programming reddit though.
other people: can't live with them, can't live without them.
it has been done, with success. naughty dog did a lot of their ps1 and ps2 games using a custom made compiler written in commonlisp.

i would probably have used c or a runtime-free subset of c++, but it is nice to se that it can actually be done.
let's fold over a string, shall we?
or a file **.

fold is a generic function. intfoldl and charfoldl and filefoldl and charpfoldl and voidpfoldl ... these aren't genericity. well, they are, but you had to write it yourself. and see how many for loops those are.

repetition is the quickest death in programming. messy death. and the bare minimum i expect from a language is support for compile-time-verifiable genericity. c doesn't have it. hence why you didn't write a fold, but and intfoldl.
you dissed the language of the week, and not even in favor of scheme.  fear the mob.
i thought that your code is only infected by gpl if you directly use clisp specific functionality? for example, using ffi thru cffi wouldn't make your app gpl since it is not specifically intended to be run on clisp.
where do these magic sub reddits keep coming from?
   i'd be quite surprised if 30" gave any quantifiable gains over 24" for most people; i've used both sizes and by far prefer 24". with a 30" monitor a maximized application window is too large to contain comfortably in your field of vision at once, and so you end up moving your eyes--at least that's been my experience. i'd much rather have a 24" (for the code editor) and a 21" (for programs on the side) than a single 30", which also happens to be much cheaper.
yes. learning c is valuable. just a history lesson is valuable. _very_ valuable.
but to use c in writing systems software today - say like a web server - shows (to me, anyway) an appalling lack of imagination and an obsession with details that only matter as much today as where the family will go to hunt for food today.
can definitely vouch for that... beasty machines make your life extremely difficult in the future when you discover your app sucks (speed-wise) on a client's machine.
vnc is old hat. try [nx](http://en.wikipedia.org/wiki/nx_technology). 


they introduced bugs when they introduced beta about 8 weeks ago.
macbook pro 15"

in spite of how much sense your comments make (at least in my opinion), computer people are generally very intolerant. just a feature, not a bug. hence the downmods.

(i solved that by never downmodding. i only  upmod. just like i upmodded you right now. (o:)
is there a list of the subreddits anywhere? i can't see a link. 
then he'd have to duck and let the boss get slapped again..
gah.  or upload it to youtube.  i'm crawling over here.
macbook pro and it's really not close
just out of curiosity, at what school and for whom did you ta?

i did my undergrad at berkeley; i took the upper-division undergraduate algorithms course at which this book seems to be aimed (not with papadimitriou or vazirani, though the syllabus seems nearly identical). our text was clr, but as you may be aware there was a comprehensive set of lecture notes, and it was expected that a good bit of insight was to be gained from the lectures, discussion sections, and from actually doing the problem sets. my point being to take the book for what it's intended to be: not the entire course.

it's perhaps worth pointing out that most berkeley cs undergrads, by the time they encounter this text, have already seen rsa, graphs, and possibly dynamic programming as well.
don't get a mac, too fragile.

if you get one be sure to get applecare, you are going to need it.
&gt; and, as the poster points out, all language runtimes and os'es are written in c or c++.

haskell is often implemented in haskell.  common lisp is usually implemented in common lisp.  any c bits are usually relegated to "bootstrap" code to interface with the system at the lowest levels.

also, although mainstream contemporary operating systems are written in c and/or c++, there are historical or fringe examples to the contrary: movitz; house; lispm operating systems.
yes people who use the gpl are exactly like the people who killed 6 million jews.


i mentioned a few warts in a september [blog post](http://e-scribe.com/news/388). overall i like mercurial a lot, and will likely migrate my svn repos to it at some point.
if at first you don't succeed you fail.
this cooltext.com thing, feels like 1992 to me
oh my god they're all the same! what have i been doing for the last 4 years??
&gt;always check out a stable version of other coworker code that’s been show to be sane so i don’t spend my time fixing their problems

yeah, fuck you, too, selfish asshole!

he's not the most important thing in the universe. there's nothing wrong with fixing another's bug at times.

seriously, there are fair points in there, but things like office politics is something to fight against publicly, not by basically subverting collective effort, which is *somewhat* suggested in the article.
agreed.  when you think in terms of "other people" like this then you don't really have a team.
unfortunately, one condition of working with other programmers is that you have to work with other programmers.  good luck pulling that off while retaining peer respect and.. your job.
could you expand on this? i've been wondering about the same thing for ages.
proggit successfully trolled!
&gt; because i need to extend those languages to interface with other libraries.

that is closer to number 3 than number 5. because c is everywhere there isn't really a higher level lowest common denominator for all other languages.
they are not removed, but old drivers often break and don't get repaired if nobody notice.

quoting akpm:
&gt; we break old machines at an unacceptably high 
&gt; (imo) rate and then don't fix them.
&gt; full length, 66 mhz, 64-bit pci expansion slot

[sweet jesus, no wonder it looks so big.](http://www.tadpole.com/products/notebooks/bullfrogdp.asp)
"opso"
at least oats are environmentally friendly.
if you maximize windows, you're doing it wrong.
you're doing it right.

that's idiomatic quality c++ code today.

mmm the fan's on my mbpro 2.2 ghz are almost never hearable. actually they are spinning at 2000 rpm right now, i can only start noticing them when they reach 4000 rpm. 
 anything on information design is good reading matter for programmers. much of tufte's advice comes from cartography, for instance. 

layering of information, use of color and summarizing details where the scale can't show them are all techniques that can apply to even banal things like stock tickers or performance monitoring graphs.

ghc requires *ghc* to compile. as does delphi (or so i heard). gcc requires *any working* c compiler to compile. gcc does not require *gcc* to compile.

there is a world of difference between having *a* x compiler and having a specific x compiler (for a given language x).

this is why i can run gcc everywhere but ghc will just catch-22 on me.

also, when i have a c compiler i can (in theory) get any other language running. oh, except haskell (ghc at least).
voted up for portal reference. :-)
safari should just your user's language preferences. application-specific settings are redundant.
(my first comment did not make sense)
&gt; just out of curiosity, at what school and for whom did you ta?

i know they used this book at georgia tech last summer. though they appear to have switched back to clrs.

when i took the algorithms course, i already had classes that covered rsa, graphs, and dynamic programming but this is not true for all students.
* i like my widescreen, as it easily allows me to have 2 documents beside eachother.
* make sure the keyboard-layout is correct (ctrl should be the lower most-left key, not fn. and for some reason my '&lt;' key is on the lowest line of keys).
* get one that can run completely silent, some laptops always keep the fans running at low speed, instead of just stopping them.
lot of information about dice k collected here
http://actualurls.com/dice_k
i use an acer 5633wlmi, upgraded to 2gb ram &amp; geforce go 7300 (if memory serves) 

came with vista, dual booted with ubuntu &amp; all desktop flashiness without issue, and runs xp in a vm without issue. the only thing that doesn't work in linux is hibernating, but i haven't really looked into it.

    php &lt; image-1 &gt; foo
    php &lt; image-2 &gt; bar
    diff foo bar

you're welcome.
you could shread the drive as well. at least with rm -rf / you stand a chance to get some of the data back.
  i use macbook every day.  my sentiments exactly.  macbook is ok but no way in hell is it god's gift to programmers or anything even close.  there are many niggly little issues all over the place.  many features from linux are missing.  java is a second class citizen on a mac.  vim is a second class citizen.  a lot of good open source stuff is also second class citizen due to x11 being a second class citizen.  finder sucks big time.  mac update sucks big time.

macs are a lot more opaque (not open to introspection) than linux.  for example, what happens during bootup?  i bet i can find it, but on linux it is obvious.

oh, and when i first got my macbook it crashed about 2 times a week until after about 3-4 software updates when it stopped crashing.

i've never ever had linux crash that much, even with an experimental kernel.

all in all, macbook is a decent machine, but no way does it deserve to be drooled over just because of the icon set and drop shadows.  
"pakistan paindabad"
six year old thinkpad a31p here. never had any issues. great machine.
only works on x11. we don't all use x, and some (probably most) of us use apps that don't run in x.
   i maximize emacs most of the time; sometimes i have emacs split into multiple windows, but often i just have a single window active, in order to get as many lines of code on the screen at once.

having tried many different ways of organizing my workspace with multiple monitors, i can confidently say that, no, i am not doing it wrong. a primary monitor with the maximized main program (usually emacs), and a secondary monitor with a lot of different smaller windows (api docs, error messages, terminal output, instant messenger, etc), preferably under a tiled wm: that's been the productivity optimum for me. if you start splitting up the screen estate of your monitor with a large but not maximized window, you end up with nearly useless slivers of dead space.
parallelizing pure functions is easy, but many algorithms are impure. putting it another way, how well an algorithm can be done in parallel is an inherent property of the algorithm, just like its space or time-efficiency. now, you can rewrite an algorithm to be pure and then it'll also be trivially parallelizable, but then it won't be the same algorithm any more (and possibly quite a bit less efficient). sometimes it pays off to introduce small inefficiencies to reap better scaling of an algorithm. but doing this automatically, i.e. automatic algorithm transformation is still a hard problem. 

and it would be a hard problem even if everyone were using haskell. there are things people are working on to give haskell more information about its monads so it can decide which of those can be done in parallel. but it wouldn't be research if it were oh-so-easy.
yeah, i am completely understand that there isn't a one to one relationship between paradigms and languages. another example of object oriented c code is [vfs](http://tldp.org/ldp/tlk/fs/filesystem.html)

however some languages to offer themselves towards a notation. it's quite hard to write procedural code in java for example, because all of the libraries are oo. it's not impossible but it's not the norm.
while i get frustrated with piss poor code my coworkers write, i also realize the following:

1. i write piss poor code too.
2. we sink or swim together.

i fix other people's bugs all the time.  for every bug in my code i fix 2 bugs in someone else's code.

once in a while i grow upset and resentful, especially when i have to fix bugs of higher ranked programmers who get paid 40k more or so.  but then i get over it.  i send a nastygram to the offending programmer and tell him/her to not take it too seriously.  i have to do it that way because i gotta let my feelings out.  after i share my frustration, everything is back to normal and i fix other people's bugs once again.

and what do you know?  eventually people do change, although very slowly.  after you say 100 times not to duplicate the data, it does start to stick. :)  you just need patience.

i've worked with some really great programmers.  everyone makes mistakes.  even the best programmers do something very very stupid on occasion (more often than you think).  it's not me vs. them.  but if i pretend i don't get frustrated then i'd be deceiving you and myself.

and i still manage to enjoy what i do.  go figure.  all in all i am happy.  a big part of that is that i don't take it too seriously and i don't have too many ambitions.
the page is down. somebody must have submitted the link to digg.
 &gt; most laptops only have 1 external video port

the macbook pro has a dvi-d port though, so you can split dvi and drive a pair of screens up to 1920*1200 each (24" wide basically).

even with a single external video port, if it's dvi-d you're ok. 

edit: by the way, remember that you can *not* drive a 30" without dvi-d (dvi only goes up to 1920*1200), so any laptop that can drive a 30" screen can drive a pair of 24" wide.
depending on the complexity of the gui, you could do a web server listening to connections from localhost and point a browser at it. debugging a mixed cl/javascript solution isn't as nice as a pure cl solution, but it might be easier than a complicated slave process thingy.
worse, it means no quicksilver.
 here is your über-l33t hacking tip for the day:

1.  open your web browser.
2.  go to the underground hacker site called `google.com`.
3.  type in `compare images in php`.
4.  press the "i'm feeling lucky" button.  make sure you are feeling lucky, because it won't work otherwise.
5.  read the resulting page that tells you exactly what to do.  it's like *magic*!
 
&gt; what do you use quicksilver for usually?

firing any and every application, going to most folders directly (my dock is basically empty), creating mails, typing notes, controlling itunes, one of my friends remotes his transmit with it (i don't have a license so i never tried it), visiting my address book, ...
i do now.  thanks for the tip.
&gt; i simply can't understand the enthusiasm people have for finder.

is there anybody out there who's enthusiast with the finder? i don't think so.

&gt; the plus button doesn't work like maximise on other platforms

that's cause it's not a maximize button.

&gt; no effective equivalent to the alt+tab fn in windows

my f9 key disagrees. so does [witch](http://www.manytricks.com/witch/)

&gt; stupid candy look and feel

candy?

&gt; can't resize or move a window by holding down a control key and dragging at anywhere in the view like you can in some x window managers

yeah, that one's shitty.
&gt;they also decided to rig a thermal barrier out of a surplus reference book and all-purpose gray tape. 

old playboy magazines and duck tape. scotty would be proud. 
dude, not programming.
  from the site: "written in c for performance"

this is a *classic* example why using c doesn't automatically mean great performance. for the people interested, look at dbslayer.c lines 207 - 214 -- it's a loop that reads data from a connection after a connection has been received. this is a big anti-pattern when designing high performance servers -- this means that, if there is one slow client with a slow connection, one thread will remain busy reading data from that slow client while he could have done *many* other things in that time.

the correct way is to just wait for events (as in, data from the socket) from certain clients (using for example, /dev/epoll), demultiplex that to the correct client handler, and when the request was fully received (as in, the parsing was complete), handle this request.

this way, you can handle hundreds of clients with only 4 threads, without having the risk of one client slowing down a thread.  
&gt; any laptop with a core 2 duo cpu, 2 gb or ram, and at least an 80 gb hard drive should be fine as a programmer's laptop.

if you develop and test on a high spec machine then you might not catch performance problems that occur on real-world machines.
what i'm guessing is:

when you create a closure, you're keeping a memory reference tucked away. (i.e, a reference to the data\code being closed over). this memory needs to either be explicitly freed (what you would do in c) or needs to be swept up by the gc.

requiring code to explicitly free this memory basically kills the expressive advantage of a closure. so if you want a good closure implementation, you better have a good garbage collector to clean it up when its not referenced any more.

am i correct?

sorry, but which compiler for a general-purpose programming language proves at compile-time that your program is equivalent to a finite automaton? 
this is very good advice. however with any advice it is best to read it through entirely first. then go to work. 
stfu and go back to programming in visual basic, you smug stupid asshole
the tiled window manager is key.  xmonad is great for this kind of workflow.  however, my lines of code aren't that wide, so i can easily have 2 columns on the primary screen (code and repl, or code and browser, depending on what i'm doing).
how about the time wasted waiting for slow software to do its thing?
&gt; there are no casting errors in c. it enforces strong typing, but it's not type-safe; the compiler believes you if you tell it something's type. (hey, they're your bits!)

that's not strong typing; it's static weak typing.
katapult?

 it is a fundamental fact of computer science that any compiler (itself written in a turing-complete language) for a turing-complete programming language cannot perform all those checks for all programs at compile-time. period.

http://en.wikipedia.org/wiki/halting_problem 
there isn't [that much difference](http://shootout.alioth.debian.org/debian/benchmark.php?test=all&amp;lang=ocaml&amp;lang2=ghc) between ghc compiler haskell and ocaml.
   &gt; anything on information design is good reading matter for programmers. much of tufte's advice comes from cartography, for instance.

and some of us even write programs that render maps.  but of course, if your notion of programming is "using trial and error to hack around bugs in crappy browsers", i'm sure things like this might be a little too high level.   

(talking about information design, who came up with the idea of using an "edit" link to enter editing mode, and an "edit" button to leave it?)
i often use a single vertical split in emacs when i'm doing programming work that involves ping-ponging between two files (a h and c, for example, or an implementation and its test suite); and, as you say, when i'm hacking in the repl.

most lines obviously don't take up a whole screen row but they can easily take more than way more than half; also, i use my dell 24" in tilted mode, to gain vertical space at the expense of horizontal, which makes this even more pronounced.
ugh, why would you do a select?  just define a unique constraint on your sql table.
yeah, that makes sense.

i still think that the real key is the tiled window manager though.  that really cuts down on wasted space. when i'm at work on ms windows i really miss my xmonad :(
+1. i no longer waste my time on virtual function spaghetti, design patterns, trying to write the perfect singleton class and other gobbledygook. (god i wasted so much time on that crap. otoh, since i "know it", i no longer worry about it... at all.)
even if you speak the language the translation is usually horrible and incomplete. i find some wiki engines ([example](http://wiki.darcs.net/darcswiki)) especially annoying: usually there are very few pages in russian, and many in english, and guess which ones i want to read?
well, i live almost entirely within emacs when my brain is in programming mode, so for that reason tiled wm might not be quite as important for me, even though it is an undeniable asset. of course, one could argue that emacs comes with a built-in tiled wm, though it does lack the dynamic layout of dwim and xmonad.

this does make me think that i should play around with making emacs explode all windows into frames (which correspond to x-level windows), so the tiled wm can manage everything. not sure how that would feel, but it's worth a try.
from a reply

"for example, it may be that if your programs 
contains a buggy endless loop, that you cannot get out of it again but 
have to reboot your computer. so be a little more careful here."

errr, yeah. maybe not.
 i took that quote from the haskell wiki
http://haskell.org/haskellwiki/introduction

kind of ironic that the introduction to the language the author apparently prefers already answers his question.

now, wrt to lennart augustsson's implementation of real quicksort: i think it's a good sign that haskell is expressive enough to be able to implement this embedded imperative language. i also think it prooves that if we didn't have a low-level imperative language (e.g. c or this embedded c lookalike), we'd have to invent it as it is quite useful for expressing algorithms for von neumann or harvard architectures.
 
&gt; the cpan shell configuration process has recommended not doing this for several releases now

sounds like it's time to start enforcing this (with an "--unsafe" option for people who think they know what they're doing).
 &gt;as we said in the preface to the first edition, c ``wears well as one's experience with it grows''.

k&amp;r2 
i was on my way to emacs assimilation when i got this new job and started doing a fair bit of php, which there is no decent mode for in emacs that i could find.  i've been using eclipse for that, which works well enough, but it's killed my borgification.
it takes a certain kind of arrogance (which is sadly fairly common) to say, "wow, all these smart respected people are saying something i think is wrong. hey, they must actually be *stupid*!"
the thread you linked to doesn't support your claim.
sbcl now has usable, though not perfect, threading on x86 macos as a compile option.
&gt; as a general rule, less code is better code...

then why use java? another case of java-doublethink.
  great logic! let me try (fun right?)

[taps leak water uncontrollably](http://www.google.com.au/search?q=taps+leak) 

look, there are plumbers... blah blah blah

ps: prepare for plumber's downmod squad 
there certainly are companies who are willing to use eccentric languages, though, especially for internal tools.
&gt;well but writing code for short term goal one of the things to take in mind is "how happy will be users about this". i don't think

most "users" won't give a flying fuck about the kernel.

&gt; for example, what happens during bootup?

have you tried pressing and holding command-v at boot? (you can get that as a permanent setting, by the way)
&gt; algorithms and specifications can simulate creativity, but it's not the same thing.

what the fuck?! creativity isn't a felt experience so dualism does not and cannot apply to it. what the fuck are you talking about?!

oh and tomatoes are only fruits as far as biology is concerned. as far as cooking is concerned, their taste makes them vegetables.
&gt; you're assuming that all linux users live in the la-la-land called "x86 with gcc 4.0".

that's the assumption the linus kernel makes, or at least it did i had a ppc machine (about 4/5 years ago).  his "stable" kernels wouldn't even compile, let alone run.  you had to get the ppc branch from whoever to have something that ran ok.
 yeah, like most people say, a (new) macbook pro: i'd buy one (if i was on no budget) for the following reasons:

* gutsy works pretty much ootb.
* nvidia drivers for linux are fairly decent, so i can show off with compiz fusion.
* i'm a bit of a hobbyist game programmer and gamer, and won't be going through too much hassle.
* nice design. apart from 1,000,000 apple logos, the laptop is not littered with blatant "fuck you"'s. apple may not genuinely care about you, but they're much better than a few other hardware vendors.
* least importantly, os x is pretty nice. so is cocoa. 
because the pool of interested people may not include someone capable of porting it?

that, in the end, becomes a "how do we pay for open source development" problem, i guess.
i have a lenovo t60 with ubuntu linux and it rocks! the best piece of hardware i have ever held in my hands and i had many...
it's much easier to install and maintain your software on linux then windows. has been for the last few years.


that's odd: just yesterday, my mate brought his alienware over to my place; we hooked it up to my 52" bravia an played team fortress 2. haha!   
if you ask me it's been broken for graphical browsers for a while too. i wish they would get rid of that fat righthand nav-bar.
do you have these "{" "}" on your keyboard?
i checked a macbook pro with a german keyboard layout and i found them missing...

coding without brackets hurts, as long as you don't do python :)
knuth is better than all that third rate academic shit.
wow this actually makes me pretty sad.  one of my bragging points for reddit was that i could view reddit on any of my gadgets or machines even if it was through elinks on my bsd machine.  
i'm going to grab an hp compaq 8510p in the next few weeks. 

been running the previous generation and it fits all my needs really well. 

things that make it good:
1680rez, decent vid card, thin, external batteries, docking station, really nice spill proof keyboard, both touchpad and nipple pointers, 3 button mousepad (very very useful).

i did look at a mac book but the price was just way too high and the 3 mouse buttons have come it way too handy


&gt; i own a vaio ultraportable. weighting 1.25kg, you never think twice about putting it in your backpack and taking it out any time you need to look something up.

and you get a whopping 10-inch screen, which is exactly what you need for long coding sessions.
if there was more public information on simulations of explosions of nuclear bombs, however...
&gt; variables declared like they’re used  
  
i really like how c enables me to write:   

    int i;
    int *tab=...
    /* */
    i = tab[5];
    i = 5[tab];
    i = *(5+tab);
  
the last one is exactly what the access actually means!
i like c because i write what i want, and want to know what i do, and c enables me to control the machine from the beginning to the end of the execution.
&gt; i'll save you a few years of your free time experimenting with this thing.  haskell leaks memory uncontrollably.

which is good for job security, don't you think?  write once, stay on staff to deal with unexpected evaluation issues forever.
c is a light, sharp sword that takes much time and suffering to master. if you can master c, all those other sugary languages will be your willing bitches.

now if your programmers are mediocre to merely "pretty good", don't let them play with the sword. even master programmers shouldn't be drawing the sword unless there's a serious dragon to be slain.
&gt; for web apps now i’d only use languages beginning with p

pascal?
i've read a variant of this before, but it still makes me smile.
ok, only p-y then. :-) but i guess i could use prolog or postscript or [one of these](http://en.wikipedia.org/wiki/alphabetical_list_of_programming_languages#p).
x41 (but not the monstrous swiveling version) for those on a tighter budget. single core, but at least it lacks windows keys.
 this post does not belong in programming.reddit.com.

&gt; china's anti-cyber virus authorities have warned that a **deadly** new virus...

deadly? you've got to be joking! 
asp.net 2.0 referring to another page, user control with the help of reference tag
asp.net 2.0 referring to another page, user control with the help of reference tag
are you sure? in the four years i went to college with you, you did exhibit some bot-like behaviour.
i second that. i distinctly remember your bot like coding sessions, and your impersonal detached approach to breakfast crisp sandwiches.
i think [this comment](http://features.reddit.com/info/2inn3/comments/c2jbwd) says it all...
&gt; ti book would beat me, but they haven't made those in years

having once bought a tibook, i can tell you that it is a disappointment. 

the lcd side is indeed made from titanium, and the bottom side is similarly colored - but is foil-thin, and dents at the slightest provocation. the dvd drive slot is part of the flimsy bottom chassis, and the slightest knock will deform the slot and render it inoperable. the internal mechanical components - in particular, the hinges - were made from zinc and are almost guaranteed to crack, resulting in the lcd cables being torn loose.

after-market steel replacement hinges are available, and die-hard apple fans buy them without feeling that there is anything odd about having to do so.

in short, the most indestructible-*looking* laptop i have ever owned turns out to be one of the most fragile in existence.
&gt; except future generations that are going to be stuck maintaining your line noise^w^w code.

yeah, like any future generations are going to be messing around with his mp3 tagging and porn site scraping scripts.
sometimes java is the only reasonable solution to a problem, particularly in web applications.
  no it's not..:

1. install ad-aware/spybot s&amp;d (freeware/oss)
2. update and run the two programs
3. done

afte installing these two gems, a firewall, and switching away from internet explorer and outlook, i've kicked out my av-software which have speeded up everything my pc does immensely. as a programmer i use the internet for hours every day and i've not seen any signs of vira or trojans for the last three years.  
it is a variation of scheme - it's build on top of gambit-c. proudly r5! :)
the edit button confuses me too (obviously not for too long, given that the other option is cancel).
the normal x series screen has 150nits, where the ultralight display on the x6?s has 180.
the respondent you quote on your web page, michael stevens, is basically correct.

nitpick: you are conflating two different things when you say that your ip "will resolve to something ending in .hr".  ips don't resolve to domains; it's the other way around. ip addresses can be mapped to countries, usually with a licensed database of ip block assignments. 
the only problem with the x61s is a lack of dvi-out. hopefully someone will create an sdvo cardbus solution for linux and *bsd.
&gt; one entry i really learned a lot from was [otcc](http://fabrice.bellard.free.fr/otcc/), fabrice bellard’s "obfuscated tiny c compiler". from it i learned about compiler design.

riiiight
 there's a good google techtalk (or whatever it is they're called) on mercurial.

if a picture's worth a thousand words, [what's a video?](http://video.google.co.uk/videoplay?docid=-7724296011317502612&amp;q=mercurial&amp;total=202&amp;start=0&amp;num=10&amp;so=0&amp;type=search&amp;plindex=0) 
just set control to something else, like caps lock. it drove me crazy for a little while but now i always use caps lock for control
oh right, but i can't use (muscles won't let me use) the option key, must be the command key. i can get doublecommand to get me that in most cases, but not for terminal.
depends on the frame rate.
used to be at http://sub.reddit.com (google cache: http://209.85.135.104/search?q=cache%3asub.reddit.com%2f )
 &gt; why didn’t they make the preprocessor language c itself? this would open up endless possibilities for unrolled loops, powerful macros, and even more ioccc weirdness. :-)

because it's not lisp! 
slightly less? if by "slightly" you mean "550 pixels less" then i suppose, but that's 50% of your 1050 pixels :/

i tend to prefer dual monitors as well, but until i get my 30" i'll withhold judgment.

i think my 30" center with two portrait 20" will work for me juuuuust fine :d
 it's a deal killer for ruby developers, no-one else. 
i've been using linux on laptops for years, the reasons i chose a mac this time were 1) suspend/resume works reliably 2) i could attach and detach my external monitor without having to restart the window manager. i know #2's being worked on now by xorg, but suspend/resume has always been problematic for me. it'd work, then i'd update and it wouldn't work, i'd fix the problem, and then another update would break it somehow. that got tiring. oh yeah, 3) i could easily connect to wifi networks using encryption, including wpa+certs. that's a *huge* pain on linux right now.
well, sure. but romance languages aren't ancient languages. and it certainly isn't necessary to learn other languages.
it cancels a repeat (5i) or a column multi-input in vim (ctrl-v, move around, i), but else it works fine, yeah!
&gt; no effective equivalent to the alt+tab fn in windows,

er... how do \*you\* switch between apps on the mac?!

there is \*no\* way in which explorer is better than finder. 
+1; i'm still figuring it out (just got my mac a few weeks ago) but it's pretty freakin' handy.
not-a-laptop; get a small embedded system. they'll run linux (or other os) and it's a lot easier to hardware hack.
 macbook pro. i have a 17" and while not the most lightweight, it still fits in a sleeve in a backpack.  

edit. i picked the 17" for the 1900x1280 screen. 
ah, well that makes some sense, although it still seems like something that could be done just once. 
pl/i
 i've got two mac minis (2 and three years old, respectively), a tibook (ageing rapidly), a relatively new white 13 inch macbook and a 4 month old lenovo x61. 4 of those have never once been in need of service or repair, the fifth has basically spent more time in dhl packages to and from a service center than it has on my desk.

care to venture a guess which is which? 
boulangerie
yeah, my ibook needed the kernel downloaded via rsync from the "ben" repository or something like this where ben is the name of the kernel hacker that made it possible to run linux on this system.

the sound started working after n months, *even if apple hardware is pretty the same between models*. the standard kernel never compiled.
there is an unobfuscated version too. it's only 633 lines.
&gt; ghc requires ghc to compile.

well, not really. the source distributions also include c code to get a preliminary compiler working as well.
 if they had had unit tests for the unit tests this would have never happened. are you practicing tdtdd? 
welcome to 2007. you might want to leave your flourescent la gear shoes and elastic shoelaces in the foyer.
it's too bad they chose such a bad headline: i thought the post itself was actually pretty interesting. i especially liked this nugget from the judges: "so programmers should worry less about languages and more about good old complexity."
one thing i hate, which carries over to all c's descendants, is the use of "=" for assignment.

a whole raft of coding errors along the lines of 

    if (a = b)
        c;

would be eliminated with a specific assignment operator that didn't already mean "equals".
would 'reverse-resolve' be the correct term, maybe?
i have never made that error, but then again i have mainly used descendants of c
&gt;if you maximize windows, you're doing it wrong.

not if you have three monitors, as opposed to one huge one.
i agree. the thing is the real world doesn't always match the theory. since there is not a feasiable way of getting out of 1 thread per mysql connection and the db query is the slowest part, multiplexing the io offers only a small advantage. also slow clients are dropped  - [ using apr_socket_timeout_set ](granted on a per thread basis but the timeout is user defined at runtime) so if this is an issue there are ways to attempt to deal with.  

also, i can tell you in the billions and billions of queries that have passed thru dbslayer on a pretty large site, we have never seen the problem of numerous slow clients degrading dbslayer performance. 

regardless of all the comments above, we would welcome submissions. it shouldn't be to difficult. i had started on this before but it never rose to being a real issue. 

thanks for reminding us and feel free to come help out. 

no, the c variable declaration syntax is made of sin (and not the trig kind)
connection pooling is a big win but having a common abstraction layer that can cross multiple languages is also pretty helpful. 
being pure textual representation offers easier caching scenarios. 
what you probably meant to say was, "1997 called and it wants its browser back."

that aside there are plenty of reasons you'd want to surf with a text browser. you could be on a machine with very limited memory or you could be hooked to the internet with very little bandwidth. you see, while it's common to be sitting at daddy's computer surfing through dsl/cable modem, it's not the only game in town.
  esri's arcgis now has [cartographic representations](http://webhelp.esri.com/arcgisdesktop/9.2/index.cfm?id=178&amp;pid=172&amp;topicname=cartographic_representations)
which you can see allows for some of the techniques mentioned in the paper (river tapering, custom representations, etc.).   they are building in advanced symbolization but gimp/photoshop will have a place in cartography for a long time to come.     nice article thanks for posting it.  
... or you could just like the simplicity.
 pff...

echo -e "get / http/1.1\r\nhost: reddit.com\r\n\r\n"|nc reddit.com 80 
that whole raft of errors is already avoided - modern compilers warn on such constructs.
reality shows seem to have gripped the imagination of the nation. is it catering to the voyeuristic needs of the tv audiences? are channels obsessed about their trps or is there anything ‘real’ in these shows? a probe.
 good idea... but it should be well organised and real as his name
that's only a problem because c doesn't have a true boolean type and uses ints instead.
the programming reddit audience seems to have slightly more discerning taste—at the least, a higher tolerance for longer and more detailed articles.
i work with [this laptop](http://www.dell.com/content/products/productdetails.aspx/xpsnb_m1710?c=us&amp;l=en&amp;s=dhs&amp;cs=19)  for over a year now and i'm pretty satisfied.

i've added some ram (now at 2gb) and took the wxga 17" screen, which was a great idea. the resolution is an outstanding 1920x1600, it can display a sh*t load of text, which makes me a pretty happy programmer :)
i use java because that's what the phb tells me to use.
or you could even be blind, and require the page to be read out to you.
 if you haven't seen them yet, i strongly suggest dan dickinson's 3-part serie on qs ([quicksilver - a better os x in just 10 minutes](http://vjarmy.com/archives/2004/03/quicksilver_a_b.php), [quicksilver: from a better os x to even more](http://vjarmy.com/archives/2005/02/quicksilver_fro.php) and [another quicksilver tutorial: gold trigger](http://vjarmy.com/archives/2006/01/quicksilver_gold_trigger.php))  as well as [43 folders' more quicksilver power tips](http://www.43folders.com/2005/06/15/more-quicksilver-power-tips) 
will do; thanks :)

now if i can just explain to work why it looks like i'm remote-desktopping in to my work box all the time even when i'm here we'll be all set.
 &gt; why don't you all leave me alone? i'm not hurting anyone.

exactly. why are perl mongers so mistreated? i can't recall the last time i was aproached by a perl advocate. 
+1! mine (to replace my far-too-big t43) is getting delivered next week.
anyone else read that as "story book algorithm repository"?
[scala in industry](http://www.nabble.com/-scala--scala-in-industry-t4581904.html#a13079571)

[posted here in case anyone has any comments about it](http://programming.reddit.com/info/5yeoe/comments/)
care to share a link to this device you speak of that can split a dvi-d signal? i've never seen one...

me? i have a t61 with a dock that has dvi and vga out. the t61 is like a macbook that you don't feel like you're going to break, and i've owned lots of macs. the trick is to run linux on it.
 i don't think that's usually necessary.  first, it doesn't matter how "fragile" it is because physical damage isn't covered by applecare.  


second, both the ram and hard drive are user-installable parts, and these are the two parts that are most likely to die in 3 years.  even if all of your ram and your hard drive dies, you can still replace all of it for cheaper than the cost of applecare.

the optical drive and wireless card (next most likely to go bad) are also pretty easy to install (opening up a macbook isn't that hard).

the only reason applecare would be worthwhile is if your display conks out (very unlikely with normal use) or your motherboard goes bad (slightly more likely) after the first year. 
and let's not forget the ever useful command-` to switch between windows in one application (including finder).
 brilliant, thanks, i was using a 'userstyle'. much cleaner with the adblock hack.
who wants that kind of security?   i personally want to go onto something new once in a while.
or you could be google... search engines use a similar scheme to text browsers to parse a page.

or you could be a web developer, looking to see what vulnerabilities spambots will find in your comments form.

or you could be using your own shell script to scrape and parse content, for instance to alert you for topic that you're interested in.

but i use text browsers to avoid the garbage all over the internet. there's nothing like lynx to wipe out heavy page loads, bad styles, annoying ads, slow javascript, and popups all at once.

tty browsing rocks! it's much faster and you can keep other ttys open to chat on irc and an emacs buffer to save notes. just snarf raw data.

what's to question!? it looks like it reflects state of affairs. i don't know details of the task, but suppose it's far from trivial. can't realistically expect a +/- novel paradigm or language to get it best.

budding languages are in big numbers, which is promising, but heavy lifting went to c++, which is the reality. it's also probable that the most competent brain-force came from there, maybe influencing the result over other factors (like perceived ease of use, or "applicability" to the problem).

and, if i may, please note, *not c*, but c++. ( although i still hold that c++ *is* c ;-) ).

(edit: language)
not only that, but not interesting either.   (execpt for a few family members)
 yes, you're right, implementing fold in a sane way requires genericity. but it remains true that it doesn't require closures, though the author of the submission claimed that. 
 fp isn't a novel paradigm, *especially* when compared with 'generic programming' of c++ standard library fame. 

neither are fp languages novel. 

all in all, if you have to stoop to that defense, that's solid bulletproof evidence that fp and fp languages have resoundingly failed.
 
not just text only browsers.  google reader seems to be choking on the feed too.
i love randal munroe's description.
thank you!!!
  all those extra long lines in divs seem to be there in the rare chance that you want to edit the comment.
*surely* they should only be there if *you* made the comment?!?!!!

sending every comment twice to me isn't cool.

even better, generate those divs using javascript when someone actually clicks on 'edit'.
isn't the point of style sheets that users can override them?  why is depending on a browser-specific stylesheet cleaner than providing a style sheet override?
have you used git? i'm thinking of trying out dvcs and i was wondering how the various systems compare. i won't probably ever need to commit stuff of more of a few thousand lines, so i don't need it to be awesomely fast. can you or someone else recommend a system?
&gt;  both the ram and hard drive are user-installable parts.

the macbook has an ingenious method of hard drive replacement, (tucked inside the battery bay) but the macbook pro [is a whole other story](http://www.extremetech.com/article2/0,1697,2119528,00.asp).
how are you enjoying the other 97% of the internet?  broken too, you say?  i thought so.

listen, grandma, take a leap into the 21st century.  using a text-only browser doesn't make you look "leet" or sophisticated in a "retro" kind of way.  it makes you look retarded for not enjoying one of the key benefits of the internet - images.
well, i've only been an embedded engineer for a short time, but lisp seems like it would be a fantastic fit for an embedded environment.

i spent several months working on an embedded web server in c. i would have much rather done it in lisp.
it does not leak uncontrollably. there are space leaks, of course, but you certainly can get control of them when your algorithm is sane. if your algorithm is not sane, you would get the same result in any language.
i'm looking for a vnc server that would allow me to e-mail someone the executable that they would double-click. with that one double-click i could connect to the user's computer using a standard vnc client and view their screen (optionally allowing control of their input devices). i'd like to use this for troubleshooting a windows box that does not have remote desktop installed.

thanks!
yeah i replaced the hd on a powerbook g4.  a minor pain in the ass.
that was rather short.  i would've thought the interviewer would've had more than just three questions.
i've looked into functional programming before. i used haskell for a few months to compete in one of al zimmerman's programming contests. unfortunately, i have also find myself questioning if it really does increase productivity or not. on one hand, haskell has lazy evaluation, allowing separation of generation and selection. but isn't this also possible in languages like python, using generators? here's a question for more avid haskellers: is there something that you can do much more quickly/easily (ie. fewer lines of code) in haskell than in a language like python/ruby?
one of our tech crew found singleclick http://www.uvnc.com/addons/singleclick.html it works exactly the way you describe, you can even put your company logo in it.
i use xmonad a lot. my biggest problem with it is that the default key bindings override a lot of my common emacs bindings. besides that, it's one of the biggest productivity enhancements of the year for me.
reddit != listenit
i rather think something is novel until it hits mainstream. that hasn't happened, whatever fp/whatever geeks here may say. that's why i used word "novel".

i don't care much for fp nor am i trying to defend it. it *really* isn't of use to my work needs. but i do believe fp's interesting for some tasks.
enter a comment here
i recently got a used powerbook with 2gb ram on craigslist for 700 bucks, with os x tiger. love working on it so far.
don't put this on programming.reddit.com
this is one of the reasons cpan scares the poo out of me.
depends.  i have a bluetooth mouse. works well. the keyboard is not too bad. i like the backlighting.  its like driving your dream car.
no kidding!
i hope you're not planning on using this knowledge to do evil?
when you require software from non-trusted repositories, then it gets complicated. and the software most users want is out there (yes yes i know about easy-ubuntu) 
no longer works correctly with netvibes either
except that a bunch of .in-addr.arpa ptr rr's aren't there. or are misleading.

for a contorted example, take those satellite-isps in israel. guess where the ptr points to for a nigerian customer's ip. hint: they speak hebrew in that country.
i finally learned that two days ago after being \*really\* irritated w/ browsers and textmate :/
good point, clearly he uses pov-ray.
blind people should be able to use reddit too you ass.
this used to be kinda sorta possible in the days of the crt. modern lcd displays do not need any more power to display a white screen than a black one. while crts are still around, nobody's buying new ones. problem solved within the next few years.
it's a good point.  there is a genuine problem that native functionality makes it easier to use less efficient algorithms in many cases.  it's very very easy to iterate and create new data using foldr or map, when there's often a faster, more efficient way to do things.
   for contests, functional programming does not offer much, if any, advantage. functional programming is not inherently faster, in runtime or development time, than imperative programming.

but functional code, because of lack destructive updates, does tend to be much more reliable than other styles. it's much easier to recover from edge error conditions when you don't have data structures in a half modified state. erlang takes this concept to the logical end, and makes it possible to build extremely reliable systems.

so the thing about theses programming contests is they are completley geared to writing throw-away code. this code will not be reused or maintained, its needed only for the contest. if it has edge condition bugs or memory leaks, it probably matters not. it only has to fill the very narrow requirements of the contest, after which it's thrown away.   
&gt; going from c to a higher level language does not make as large a difference.

going from:

    #include &lt;stdio.h&gt;

    float twiddle(int a, int b)
    {
      return (float)(a*b)/(a+b);
    }

    int main(int argc, char **argv)
    {
      int lista[] = {12, 42, 37, 64, 19, 13, 2005, 384};
      int listb[sizeof(lista)/sizeof(lista[0])];
      float results[sizeof(lista)];
      int i;

      for (i = 0; i &lt; sizeof(lista);/sizeof(lista[0]) i++)
      {
        listb[i] = lista[sizeof(lista)/sizeof(lista[0]) - i];
      }

      for (i = 0; i &lt; sizeof(lista)/sizeof(lista[0]); i++)
      {
        results[i] = twiddle(lista[i], listb[i]);
      }

      for (i = 0; i &lt; sizeof(lista)/sizeof(lista[0]); i++)
      {
        printf("%f\n", results[i]);
      }
      return(0);
    }

which might be optimised to something like:

   #include &lt;stdio.h&gt;

    float twiddle(int a, int b)
    {
      return (float)(a*b)/(a+b);
    }

    int main(int argc, char **argv)
    {
      int list[] = {12, 42, 37, 64, 19, 13, 2005, 384};
      int listlen = sizeof(list)/sizeof(list[0]);
      int i;

      for (i = 0; i &lt; listlen; i++)
      {
        printf("%f\n", twiddle(list[i], list[listlen - i]));
      }
      return(0);
    }

simpler than:

  lista = [12, 42, 37, 64, 19, 13, 2005, 384]
  listb = [a for a in lista]
  listb.reverse()
  results = map(lambda a,b: float(a*b)/(a+b), a, b)
  for result in results:
    print result

oh, except that the c has a bug: the first item printed should be 11, not 4.8.  there's a fencepost error.  so each of the listlens with the loop need to have '-1' added:

    #include &lt;stdio.h&gt;

    float twiddle(int a, int b)
    {
      return (float)(a*b)/(a+b);
    }

    int main(int argc, char **argv)
    {
      int list[] = {12, 42, 37, 64, 19, 13, 2005, 384};
      int listlen = sizeof(list)/sizeof(list[0]);
      int i;

      for (i = 0; i &lt; listlen; i++)
      {
        printf("%f\n", twiddle(list[i], list[listlen-1 - i]));
      }
      return(0);
    }

then of course there's this:

    (let* ((lista '(12 42 37 64 19 13 2005 384))
       (listb (reverse lista)))
  (mapcar (lambda (a b)
	    (print (/ (* a b) (+ a b))))
	  lista
	  listb))

but that prints the exact results.  let's print the floating-point representations instead:

    (let* ((lista '(12 42 37 64 19 13 2005 384))
           (listb (reverse lista)))
      (mapcar (lambda (a b)
	        (print (float (/ (* a b) (+ a b)))))
	      lista
	      listb))


imho all of those communicate the intent far better than the c original.
so much work.

	curl http://reddit.com/

(edit: sorry, the &lt;&gt; aren't mine. blame the markdown implementation.)
 grrr...my python formatting was screwed up and i can't edit the comment:

    lista = [12, 42, 37, 64, 19, 13, 2005, 384]
    listb = [a for a in lista]
    listb.reverse()
    results = map(lambda a,b: float(a*b)/(a+b), lista, listb)
    for result in results:
      print result 
it has hit 'mainstream' several times in the past 40 years, each time passing into disuse.

so far the track record says that it's a fad that caters to lazy (in a bad sense of the word) programmers.

there *are* valid points to be made w.r.t. fp methodology, but fp languages are mostly bunk.

witch isn't quite as good as alt-tab.  and the little difference is very annoying.

on one setting you cannot alt-tab between two windows from the same application over and over.  under the alternative setting you can't alt-tab between two windows from /different/ applications over and over.

drives me mental.  gutsy is going on this thing any day now.
&gt; all those extra long lines in divs seem to be there in the rare chance that you want to edit the comment.

that would make sense if it was x?html escaping instead of url escaping.

&gt; even better, generate those divs using javascript when someone actually clicks on 'edit'.

so nobody without javascript should be able to edit a comment? that sounds like it wouldn't resolve the complaint in the article.
didn't we get rid of this stuff with brown v. board of education and the civil rights act of 1964?
[vienna](http://www.opencommunity.co.uk/vienna2.php) is showing raw html in comments in overview feeds.
on my macbook pro i have two finger tap be right click, and two finger drag be a scroll.  works like a charm.

edit: not sure if this works in ubuntu though
that was a clever point and a nice perspective on erlang.  thanks. 
dude, if 'fewer lines of code' is your goal, then the k programming language will win every time.

(yes, i am making fun of you in a very cruel manner.)


i think you should work on that reading comprehension thing. i don't see anything witch lacks compared to windows' alt-tab. and i don't get what your "settings" are, the all windows and application windows expose functions?
this is a good idea for testing complex bash commands/scripts in general.  if i want to do complex finding, grepping, sorting, etc then i always echo my results every step of the way.
http://googleblog.blogspot.com/2007/08/is-black-new-green.html

or not
it'd be better anyway.

if javascript, create the div and do the edit in place. if noscript, reload the page with an old style form in place for them to edit etc
it's also broken for opera mini users, so it's not only a problem for "text only" browsers.
why use file::remove? is "unlink(filename)" too complicated for some people or not complicated enough?
[boost.iostreams](http://boost.org/libs/iostreams/doc/index.html) seems to be far more interessting.
thanks too.

i didn't even know abp took that kind of syntax...  that'll probably help me get rid of quite a few xpaths i still needed in rip.  thanks again.
excellent blog, very informative!
i agree except for the display. i have the 15" macbook pro and it is really nice to be able to run windows, linux, and macos x on the same computer. plus, this machine is just very, very nice.
i didn't read it that way and i suspect it is a difference in work environments and check-in policy.

using a coworker's stable code, you'll still run into bugs and a good team member will go ahead and fix them.  these will be the non-obvious bugs, some of them hard to reproduce, so your coworker will really appreciate the help.

however, using a coworker's latest check-ins, you'll run into additional bugs that your coworker is probably in the process of fixing.  these are the more obvious and more easily reproducible bugs.  sure, your coworker will be happy for the help, but you might be duplicating his effort.
obqwe1234:

&gt; lololol, +1
c has no place in large scale design today. if a higher level language is too slow in a particular function or service, then you should be a man and rewrite that section of code in assembler if you want to see a speed boost.
it is not clear whether the browser is broken or reddit is.  who is following the standards in this case?
probably depends on what one considers mainstream. to me, mainstream is c/++, java platform, .net platform, perl, php, sql dialects, *maybe* python. by that measure, *anything* fp is way too far from these in importance.
obqwe1234:

&gt; shit, more shit, and _complete and utter shit_ respectively.

&gt; ugh
that's an observation worth your consideration.
did you read my comment?

c++, java, .net and php (among others) are all much, much younger than most fp languages.
i can imagine worse.  how about 100 random digit transpositions (e.g., replace '9' with '7') spread throughout your filesystem.  difficult to detect--effects unknown.
 gah! scary purple elf thing. i feel the vague kind of dirty i felt when i encountered the [aros](http://www.aros.org) mascot.
 &gt; &gt; all those extra long lines in divs seem to be there in the rare chance that you want to edit the comment.

&gt; that would make sense if it was x?html escaping instead of url escaping.

comments are written in markdown, not xhtml.  the divs contain markdown, not xhtml. 
i work on a dell inspiron 9400 (1501 us model?).. its the 17 inch dell inspiron model and for my development needs it has been great..

sure the build quality of the shell is a little lack luster and the keyboard is mediocre.. 

but for $2000 canadian (about 1500 us) 

i got:
17 inch 1900x1200 laptop screen
vga and dvi outputs for dual monitors
2 gigs of 667 ram
t7200 processor (duo core with extra cache)
3 year next business day warranty
120 gb hard drive (should have went 80gb 7200rpm)
nvidia 7900gs video card

works great and  runs fast and no problems whatsoever



&gt; even better, generate those divs using javascript when someone actually clicks on 'edit'.

the problem with that is that they'd have to write an html → markdown converter in javascript.  the point of including it on the page is that they have the original source.

i don't see why they are doing it that way though.  essentially doubling the number of comments on each and every page load just for the extreme minority of occasions when somebody wants to edit a comment?  why not just make an ajax call to get the unedited source when somebody clicks on an 'edit' button?  or at the very least, only transmit the source for comments made by the logged-in user, since those are the only ones that could get edited.
it's still an error, even if the compiler warns you.  it was just a bad design decision in my book.
omg, that is totally how i feel :d
&gt; &gt; even better, generate those divs using javascript when someone actually clicks on 'edit'.

&gt; so nobody without javascript should be able to edit a comment?

this has always been the case with reddit.  just because the `&lt;div&gt;` elements happen to be in the html, it doesn't mean that comments are editable in non-javascript situations.

the prominence of *a* language with those qualities is no accident.  the prominence of *c* is happenstance.  it could just as easily have been forth.  
dd if=/dev/urandom of=/dev/hdx

unlinking files only modifies the fat, so it's semi-easily recoverable.


my beef is that the *equals* sign has been used to mean assignment - the error is in writing the code, even if the compiler tells you about it.
hot spam
not to start a war, but does it really matter?
 feh. black google is like black barbie. just a paint job on the whitey version.

now [this](http://www.gizoogle.com) is what i'm talking about. 
 the [icfp 2005 contest](http://icfpc.plt-scheme.org/) had a second task announced two weeks after the first one, which would require modifying the original solution. 
reddit is broken.  no website should blindly assume that css is applied.

it reminds me of when internet explorer 3 first came out.  microsoft put up a website extolling the virtues of css (stop laughing, it's true!) and wrote a bunch of tutorials on how to achieve certain effects.

one of those tutorials was criticised at the time for teaching bad practices &amp;mdash; they told people to double up the text in a headline and do some positioning tricks to create a drop-shadow for heading text.  of course, people without css saw everything twice and only internet explorer 3 users saw what the author intended.

now, over a decade later, reddit are making the exact same mistake.  i feel old ☹.

this blog post says nothing whatsoever.

   which more enlightened assignment operator do you suggest?  personally, i think assignment is exciting, so i suggest using an exclamation point:

&gt;earnings ! hours x wage

&gt;c -&gt;

what do you think?   
i don't see where you're getting these numbers from. on my team, the two senior guys were 40 and 45. they both worked 40-50 hours a week depending on their schedule. the tech lead turned 40 years old while i was there, he was there more hours than i was.
it's entirely fixable, so hang in there a few, we'll get to it.

edit: should be better, thanks chris.
the [wilson-johnstone-neely-boles survey paper](ftp://ftp.cs.utexas.edu/pub/garbage/allocsrv.ps) this web page links to is one of the best practical systems research papers i've ever read, and if you haven't already read it, i guarantee you will be a better systems developer for doing so.

maybe if you want to kill the preprocessor
 well, there was a precedent from the pascal family of ":=".

there is still the potential for errors such as:

    a = b; /* intended assignment, actually boolean expression */

but if '=' had never been assignment, people wouldn't be inclined to ever write that.  it avoids the syntactic ugliness of using an equality symbol for assignment and therefore having to define a new equality symbol. 
put the comments in a javascript array then.
but yes... main thing is don't send them if you can't even edit that comment!

i don't use that setting because of strangeness as well, but i thought there was a chance you didn't know about it.
   i have to admit, i'm rooting against fp becoming mainstream. the for loop is a little bit dear to me because it's intuitive. if you give me, a person, a lot of numbers to add up, i go through one by one and add to the total. i don't conceive of a folding operation with a closure when i do so. i want adding to be something i do, not a noun i apply. there are times when it's clearly a powerful and simplifying tool to be passing functions around, but the reasons cited for why using some simple for loops is a big problem don't resonate with me at all. for me, 'for(int i=0;i&lt;n;i++), or for(int i: array)' might as well be a keyword, and i don't think abstraction beyond that is really helpful, because it already is extremely simple and intuitive. i mean really, do you guys frequently screw up by using the wrong index or bound conditions after a year or so of programming practice?   
i work with a lot of monitors, actually.  the two machines i have access to with the biggest screen space are the one with dual 30" apple cinema displays, and one with 2x2 24" dell displays.

i actually hate working on either, because my neck gets sore :)

that being said, i do appreciate a second monitor to throw im, irc and all that other distracting stuff in.  not reddit, that goes on the main screen :)
 no way, they'll have the ai hybrid mp3-tagging and porn-scraping bots do all that for them by then. 
the natural implementation of a c pointer is a word with an address in it.  you can legally cast these to and from some integer type, so the compiler can't reliably generate type information that the gc can use to know what words are pointers.

one response is "conservative" gc, which is a hack that assumes that any word that looks like a valid memory address is one.  it's unsafe because you can do arithmetic on pointers (if you have &amp;(a[5]) somewhere, it's not safe to collect a; if you have the xor of two pointers because you like tricky doubly-linked lists, it's not safe to collect either of the nodes you xored the pointers to).  it's leaky because sometimes you just happen to have a number that looks like an address.  a conservative gc also isn't allowed to move anything (it can't reliably find all the pointers to an object because some may be hidden, and there may be some false-positive ints lying around), so the heap can get fragmented.

i think "doing closures right" includes the ability to return them.  to do this, you need some sort of data structure to keep the variables your function closes over.  in pseudo-c:

    typedef int (*inttoint)(int);

    inttoint makeadder(int increment) {
      int adder(int x) {
        return x+increment;
      }
      return adder;
    }

this would fail, even with nested functions, because "increment" is allocated on makeadder's stack frame,
which is freed when makeadder returns.  some language implementations allocate activation records on a heap instead of a stack, but that depends on gc.

edit: underscores apparently break markdown, so i internalcapped everything sorry.
good point.

otoh, "taking the concept to the end" isn't great. if anything, languages that dilute any concept (like c++ or java) are *more* successful, exactly because any given concept does not make a great all rounder in a language.

in fact, erlang is a good example, i think. smp support is rather new in it, despite erlang being (wrongly, even) tauted as multithreading language. and on top of that, [smp tests on erlang i saw](http://www.erlang-stuff.net/wordpress/?p=14) don't look too great to me. not bad, but not great, either.

and that's not erlang's efficiency problem, but rather the implementation, or even the problem itself. i guess it's just too hard to beat p in amdahl's law.

also, chances are that erlang "systems", while hopefully reliable, will stay *closed*. who knows when, if ever, will we have easy connection points to them.
yes, i have.

i think age != mainstream-ness, but i didn't even try to speak about time dimension of it.

but i see your point, in that age is rather telling for the future, as you harshly advocate.
so they say
yes!

i use text browsers very frequently!
you like c because it's trivial to make it impossible for a future viewer to understand.
to expand on your succinct answer...

because there would be countless side-effects.  a macro language that complex often blurs the line between design-time and run-time.  you would slam headfirst into that blurry line if c tried to implement that.
yes, i too, am astounded that so little people overlook that aspect. we think sequentially, period (at least, it's the default mode ;-)). fp goes against it. *big* drawback.
well... i'm using www.netvibes.com and the rss feed doesn't work for me...
indeed. the programming is not the code.
 does perl's `symlink` work on windows oob? i'm not going to search too much but i found some evidence that hard links are supported by default, but symlinks may require some hackery and only work on ntfs. my guess is that in a twist of sweet irony you would be saved from this nasty bug if you were using a windows box, the older and crappier the safer.

http://search.cpan.org/~autrijus/win32-symlink-0.04/symlink.pm 
a huge number of security bugs are due to experienced people screwing up for loops. 
there's more than one way to die.
so what character more universally implies that a variable *will now equal this value* that could be used in place?  just about any other language that follows your ideal just makes everything more annoying for the programmer (i'm looking at you pascal).
ok, so come stuff is borked for non graphical browsers and other "minority browsers".  i agree, it should be fixed.

however, curious, reddit links to a pretty hostile web out there, does it really matter?  what percentage of reddit links outbound can you actually read in lynx?

* it is possible to enter in a empty comment, reddit may want to at least require a few characters.
i seem to recall that in previous years functional languages did quite well in the ifcp.  this year ocaml had more in the top 10 than haskell.  is that because ocaml is really a multi-paradigm language in which you can do fp as well as stateful oop?  


absolutely.
&gt;i mean really, do you guys frequently screw up by using the wrong index or bound conditions after a year or so of programming practice?

in my experience, mistakes like that happen all the time on big projects, especially with a "heterogenuous" team of developers.
(trying to iterate backwards with an unsigned is especially nice:
    for(unsigned i = size-1; i &gt;= 0; --i)
.)

whether a for-loop or hofs like map and fold feel more natural, is entirely a question of what you are used to.
  it's sad, but the article is making the point for the aforementioned c [critic](http://freeshells.ch/~revence/no-c.txt).

let's look at some of the items he loves about c:

* *conciseness of k&amp;r*. i don't know much assembly, but couldn't that be equally concise? is that an argument to use assembly?
* *conciseness of the language*. concise?! he boasts about qsort in 11 lines. has he looked at the [haskell qsort]( http://www.haskell.org/haskellwiki/introduction#quicksort_in_haskell)? 2 lines! the only concise c code i've ever seen is the obfuscated one. 
  
there are certainly ways to control the evaluation order, and they are even somewhat intuitive, in my opinion:

http://users.aber.ac.uk/afc/stricthaskell.html
what? no.

you're don't know what you're talking about.

fp == stateless function calls. nothing more or less. 'sequentialness' has nothing to do with it. (and multi-threaded c is as 'non-sequential' as you can physically get.)

yeay gnome \o/
more like an... ad-icle?
how do you get a job hacking *any* language all day?

you don't.

you get jobs writing applications.  language choice is usually dwarfed by issues related to your problem domain.
the rss links are broken too (the &lt;link&gt; element encases the url with a quotation marks)
why post here? well...
the feedback page also doesnt work in opera9 or ie6.. 
that's just like saying that c++ doesn't leak memory or that c++ doesn't cause security problems.  they're both the fault of the programmer, right?
yay! he's fixing it!
why do you like `5[tab]`?
fwiw, python differentiates == and = there.  `if a = b` gives an error.
  it's quite a natural way to write and think about assignment.

"the value of `a` now equals 3."

_edit: not to mention the bcpl legacy, and in bcpl the command was `let a = 3`, which reads even more naturally.  ref. dmr's [history of c](http://cm.bell-labs.com/cm/cs/who/dmr/chist.html)._

is there a better symbol on our keyboards for assignment?  they could have used something like `&lt;-` i guess, but `=` and `==` are both easier to type than `&lt;-` and `=`.
yes.  if reddit is broken, it should be fixed by the reddit team.  if lynx is broken then it should be fixed.
there are worse books on algorithms.  as a first edition, the authors achieved their goals in this book.  if you read the preface, you'll know that the book is not supposed to be encyclopedic.  the goal is to emphasize rigor over formalism.  it is exactly the opposite of cls.

this book is not for self-learning.  it is supposed to be used in accompany with good lectures that clarify things that the book does not go much into.   using it like that, it is indeed a good book.  it addresses many difficult concepts with ease.  you can understand why the expected complexity of selection is o(n) or quicksort is o(n log n) without a formal proof.   in cls, it is a pain to learn why this is true.   rigor over formalism.  it treats dp, greedy very nicely as well.
it's important to get *used to* both ways of expressing the problem.

an issue is composition - the for loop equivalent of "map" requires a container be preinitialized to empty then filled in a loop.  this creates the possibility of code being reordered/iffed out such that the container isn't filled, and the program will run on merrily.

want to omit/filter things from the list?  this requires an explicit step.  interspersing items into a list (usually requiring some isfirst flag)?  a step that can be filtered out into one function for a codebase, rather than statefully mixed in with the loop.

the functional approach lends opportunities for separation of what, by necessity, often otherwise need be piled into a for loop.  patterns tend to emerge and become more visibly evident and factorizable.

also, in functional code, every "map" highlights and guarantees a point where parallellization is possible (not necessarily desired; but possible) where a for loop cannot make such a guarantee (as the specification by the coder is of a sequence, not of ordered inputs + ordered outputs + action).


of course. by the same argument, lithper's claim that haskell leaks can also be applied to any other language.
the bottom line here is that functional programming is good for some problems, but a terrible match for others.  by "terrible" i mean that you're fighting the paradigm every step of the way to do something that would be straightforward in an imperative language.

most imperative languages, by comparison, doesn't go down the "terrible" road nearly as far, even for tasks that are best suited to haskell.

this is clearly an argument for multi-paradigm languages.
yes.

requiring programmers to free some function pointers and not others would be trouble too: suppose you have a list of callback functions, some of which are plain function pointers and some of which are closures that carry their args in the captured variables. ick.
any [d programmers](http://www.digitalmars.com/d/) around?  how many of his "hate it"s does d remedy?
nein, herren, sie mussen die plankalkül usen.
 maybe i'm misreading you, but:

what i'm trying to say is that perl users don't seem to be very vocal about their language. they just keep grinding out code, instead of engaging in _unproductive_ pissing matches.

and the amount of scorn being heaped on them is severely disproportionate to the minute amounts of advocacy coming from their turf.

that's what i meant.

what did you meant by "my consideration"? 
 obqwe1234:

&gt; the _correct_ way to achieve polymorphism is with generics. object-oriented programming _necessarily_ adds another level of indirection (into the vtable for virtual method dispatch), which breaks locality of reference and utterly fucks up performance. that's why nobody (who knows what they're doing) does oop in c++ today.

(fun for geeks: find the technical flaw in the above.)
 &gt; has he looked at the haskell qsort? 2 lines!

the c quicksort is faster and doesn't use as much memory.  they're not doing the same thing.

&gt; i don't know much assembly, but couldn't that be equally concise?

i'm guessing that

    while (*dst++ = *src++);

is shorter than its equivalent in assembly. 
amen.  it's amazing how much the content matters when that's all there is.
macbook every time.
well either equality needs a special symbol, or assignment does, i don't see how making it assignment is *more* annoying.  

i just think it would have been more logical that the *equals* sign means *equality*, and for assignment to get a new symbol.
i'm still waiting for a language which combines arrays and associative arrays into one.  when indexed with integers, it's an array.  when indexed with strings, it's an associative array.
  i own a 2nd generation macbook which i love (white, 2gb, 2ghz core 2 duo).  i have no issues with it at all.

the ultimate might be a macbook pro for some people, but i prefer the smaller size and longer battery life of the normal macbook.  
plus, most problems out there are not software problems, but people problems.

language doesn't help there (well, not programming language).
you are possibly the only person i have ever heard/seen calling the trackpoint a feature.
languages don't leak memory. poor programs might.

http://shootout.alioth.debian.org/gp4/haskell.php 

and interestingly, ghc haskell seems to kick it in the memory use arena. (and why is java so successful when it **leaks memory uncontrollably...**?)
 
numbers are interesting.

apple has vision, but their engineering... well.

finder sucks, the window manager sucks, everything else is a lot slower than a linux pc running at the same cpu frequency (java, mozilla, both gcc and gcc-compiled apps).  ok, the latter might have changed a bit with migrating to intel cpus, but the mach binary format still sucks.

and i could go on.  (yes i used macs exclusively for two years.  been there, done that.)
if he is asking for stable kernel apis, he's  missing the point of linux: it is free software. the source code for drivers of a camera, or for anything for that matter, should be available for everybody to see and change, therefore they are supposed to be updated in the same fluent and promptly manner as the kernel itself.

what he is asking for is a commercial software model except he conveniently is not willing to pay for it. he misinterpreted the meaning of "free".
cpyou cpme :o)

i have always found [this](http://www.simplescalar.com/) to be quite useful.
yeah, writing a parser. haskell has some nice efficient parser combinator libraries available. it's just about possible to write parser combinators in python/ruby but it's a pain in the ass and it's really, really slow.

ghc is really good at optimizing iterations over lazy lists into loops, whereas ruby and python iteration can be quite slow.

haskell also has pattern matching, which is a pretty big win over python in terms of conciseness and readability.
nope! this would be on our company's intranet.
_the bottom line here is that functional programming is good for some problems, but a terrible match for others. by "terrible" i mean that you're fighting the paradigm every step of the way to do something that would be straightforward in an imperative language._

ok, i've heard this assertion before... and i don't recall reading what exactly those problems are that aren't supposed to work well with fp.
um, did you bother reading that link? i ask because it specifically considers the halting problem and none of the checks i listed necessarily require knowing if the program will halt.

also consider, there is no turing-complete system because no computer has infinite memory.
if i took that attitude then my sites would be broken for the 60% of people still using internet explorer.
i know about the arguments for the theoretical beauty of fold and map and filter operations. i agree that sloppy programmers can mess up for loops, but i have faith that if they have a flexible enough mind to grasp fp, they could find some interesting damage to do by lexicographical means as well:)

i guess you can cite an argument like paul graham would use that a reason to use fp is because you will be working with a select group of smarter people. but the million dollar question is always whether the same group of selected people couldn't be just as productive with more conventional programming, putting the same thought and care into it.

to me, my intuition argument stands. i know which way this crowd feels about it, and i expect my sincere thoughts to get down-modded. i think these examples with the for loop that are used to advocate fp are, in the larger sense, a pretty tiny and insignificant part of programming. (functions as data in general however, is of course not at all a tiny or insignificant concept.) to me it's sort of akin to someone claiming increased writing productivity by not dotting their i's anymore.

the author of the parent article seems to make every excuse for not considering the simplest explanation: the reason why fp doesn't factor strongly into programming contest results of any kind could be that despite whatever beauty it has to your inner pure mathematician it doesn't have a significant effect on real world productivity.
basic, early versions of fortran, assembly for devices without stack-allocation. and of course countless languages that we don't consider to be general purpose.

out of memory scenarios can only occur when you have recusive functions or dynamic memory allocation. many languages, most of which we no longer find interesting, have this limitation.

job security.
  well, there are a number of models. they also make [drop-in server replacements in the laptop form-factor](http://www.tadpole.com/products/notebooks/bullfrogdp.asp). useful for consultants doing proofs-of-concept, or temporarily replacing broken hardware. not so good as laptops (22lbs, and mostly without batteries)
as a web developer, i use a 15 inch macbook pro hooked up to a 22 inch siemens lcd in the office, and an older thinkpad x32 for everything else.
i'm not saying it can't be done, just that it's an insane choice.  naughty dog spent three years writing their compiler, made possible by selling 15 million copies of their ps1 games.
i already use a "power" shell on windows.. although its called cygwin :)
 php, javascript... 
believe it or not, your guess would be wrong for x86 assembly!

but on a powerpc or mips, yeah.

(how many nerd points was that worth?)
it's not (or it wasn't when that existed) i didn't knew about it either.
i take it from the hand-waving than you are a c fanboy. who else would think that interger overflows, something that even assembly can check for, is a feature?

then there is item 5. if it's a feature, then why have libraries to "fix" it?

as for item 7, string is was originally defined as "a string of characters" or "an array of characters".
 
 very entertaining. most haskell/lisp/erlang lovers are true intellectuals and are very capable. they write very well - there is no way someone here can honestly call that guy stupid.

however, when i look around i never see any results of their work. i browse apt repository on debian, i see interesting new projects pop up here and there, and almost everything is done in c. 

somehow those "stupid and ignorant" c programmers managed to build everything that powers the internet: gcc, apache, oses, tools, gnome+friends, the list is huge. nearly everything is written in c. and it's not just legacy, if you focus on projects started within last 5 years the picture will not change.

meanwhile higher-level language intellectuals  produced very little. on my ubuntu desktop i do not believe i have a single piece of software written in haskell. how come? 

if your language is so superior, and it makes you guys so much more productive, why don't you flood us with actual software written in it? 

 
meet at least a second.  i love it for the same reasons, and bought a lenovo external keyboard so that i could have a trackpoint.  it's a lot easier to use that while typing then to move your arm to a mouse.
this is a very confused article.

it starts out talking about how there's great oss stuff out there.  then it says that oss stuff can be bought out or abandoned.  it also could be compromised by hackers.

what?  it's kind of hard to "buy out" an oss product: you have a infinite-term license for it.  a company can stop working on it, but the community can pick it back up.  compromising it?  possible, but it's just as likely that your paid software is compromised.  possibly more so, since there are a lot more people who double check their oss stuff they download than people who worry about their commercial software.

this almost feels like an auto-generated page.  it's not, but it could be easily.  that whole site feels like it's there solely for ad revenue.
a lot of the functionality detailed here can be reproduced with centralized vcs using branches.  each developer keeps their work in their own working branch and selectively merges from others branches to their own.  when a feature is complete they merge their branch into trunk and a release branch is cut.  that release branch is tested and patched as needed.  when it is ready for production someone pushed that branch to the live servers and merges and patches from the release branch back into trunk.  trunk serves only as an integration point, but it is a centralized integration point which is important in a corporate environment.

however, this is difficult in practice with vcs like svn which are fairly brain dead with respect to how they handle merging.  i use bzr to manage my home projects and it is refreshing to add version control to a project simply as 'bzr init'.  i haven't done much complicated branching and merging with bzr or murcurial yet, but i imagine its better than svn.  branching and merging is the killer app of any vcs and the branching and merging semantics are much better with dvcs.

eventually people will adopt dvcs for their flexibility and better branching and merging capabilities, but you will still see corporations struggle with dvcs and the "where is the official source" question.
i may not like it but it's a brilliant idea to override user's preferences and to think for it, i'm serious just think for a moment which percentage of the user mass you are, you people do not represent the money you're a minority who knows about headers and configurations, companies are meant to make money and so we're. as a programmer one must think in terms of 'purpose' not 'perfection'.
those are how (and why) i learned perl too.  i think it might be a perlmonger's rite of passage.
   [a](http://www.franklinmint.fm/blog/archives/000792.html)  [near](http://www.bluishcoder.co.nz/2006/03/erlang-smp-benchmarks.html) [linear](http://eric_rollins.home.mindspring.com/erlangant.html) [speed-up](http://mult.ifario.us/articles/2006/05/11/more-on-erlang-performance-and-threading) "doesn't look too good"?  what exactly were you expecting? as you noted, smp support is new to erlang and it takes a bit of tweaking with the number of schedulers to find the sweet spot for a particular architecture, but as the erlang developers get more experience with tuning for smp and learning the gory guts of various systems' baroque threading policies this is bound to improve.  you still can't get around amdahl's law, but erlang makes it easier to get close to the limit without pushing you past the edge of insanity.

erlang is not touted as a multi-threading language, it is touted as a concurrency language.  this means that it deals with multi-core and the much more common multi-node situation in a fairly transparent manner.  

connection points to erlang systems, whatever that means, are also not as difficult as you suggest.  few languages sling packets as well as erlang, so the base level of interaction is to use a tcp/ip socket.  a port driver is pretty trivial to set up in erlang but this ease comes at a speed cost.  if you are willing to trade reliability for speed then a linked-in driver is the way to go, but this is non-trivial unless you dive into one of the driver toolkits (which is only a small step easier than "non-trivial"...)  fast ffi is definitely something erlang needs, but to declare erlang systems "closed" is quite inaccurate.   
&gt; another reason not mentioned is that lisp can become a common intermediate form allowing several source languages to interoperate. so ruby or smalltalk could be compiled to lisp then lisp to byte code. 

i really like that idea.
those are very good points. now that you mention it, pattern matching is something that i have been meaning to look into in more depth.
&gt; i know about the arguments for the theoretical beauty of fold and map and filter operations.

no, it's practical.  this has nothing to do with your "feelings", nor is strawmanning off into paul graham going to work.

&gt; to me, my intuition argument stands. 

learn it you'll get a new intuition.

&gt; i think these examples with the for loop that are used to advocate fp are, in the larger sense, a pretty tiny and insignificant part of programming.

a challenge here is that a more elaborate example is illegible to the target audience (people who are not familiar with the functional solution-space), the small ones are "big deal, i can do that familiarly with just a couple of extra lines" - along with the "use smart programmers and you won't get the loop bugs you claim proliferate" alongside "problem with that functional mumbo-jumbo is it excludes less capable programmers".

experience can make the program integrity and composition advantages apparent; but so can honest analysis of the 2 ways the same outcome can be programmed without bias toward the more familiar one.

&gt;  the reason why fp doesn't factor strongly into programming contest results of any kind could be that despite whatever beauty it has to your inner pure mathematician it doesn't have a significant effect on real world productivity.

i am not aware of a programming contest that yields codebases of the size and maintenance lifetime of a commercial product - "real world productivity" thus becomes an orthogonal issue from anything that can be learned in a programming contest.

  
i would rather claim that hand written parsers are a pain in the ass. one also does not create a regex engine for any regex one wants to match. unless one wants to parse non cfgs ( c++ anyone? ) a parser generator shall create the parser ( or the parse table on which the parser operates ).

*ghc is really good at optimizing iterations over lazy lists into loops, whereas ruby and python iteration can be quite slow.*

but that argument holds for any python operation, also assignments and function calls. the rationale for scripting languages to deal with performance bottlenecks is well known. it's less than clear in languages like haskell ( but also java ). when the programmer designs code in an imperative fashion in haskell or ocaml to gain maximum performance why not advising him to use just c++?
that's command &gt; (and command &lt; for the reverse direction) on my kbd (icelandic layout).
i don't know the k language, but i remember seeing a code snippet of it and noting the extremely terse syntax. i'm not convinced that it would always produce shorter programs, particularly if the coder spread the code out across multiple lines to improve readability. does k support first-class functions? what about introspection? if it doesn't, there could be some abstractions that wouldn't be possible, potentially leading to a lot of boilerplate code.
 i have a ton of rss blog subscriptions and never enough time to read what's interesting (or even select what's interesting in the first place).

is there any online rss aggregator that is capable of showing me the most popular entries in the blogs, so i can have a web2.0 criterion to order the posts for reading (popular ones first, for want of a better "best ones" approximation).

such a tool would probably share subscriptions behind the scenes, and track the popularity of every post. ways of tracking popularity: count number of times the post was read/opened, use some upvote/downvote mechanism a la reddit/digg.

why this is in some ways better than reddit/digg: i only see stuff from blogs i subscribed to, so this takes care of the recommendations mess. instead of filtering everything that's new on the web, just filter the bits of the web i'm actually interested in.

any such aggregator out there? anyone building something like this?

thanks!
 
i love this site. it's so easy to look up errors your finding and, if you happend to find out the cause, other people can read your solution.

it's great.
&gt; i mean really, do you guys frequently screw up by using the wrong index or bound conditions after a year or so of programming practice?

i see no advantages (other than familiarity to legacy programmers) to having the distinction exposed when dealing with n items.


&gt;  i have to admit, i'm rooting against fp becoming mainstream. 

that's kind of too bad; but you will learn.  not through learning languages such as haskell; but by being on c# codebases with a microsoft c# language development team stacked with haskell programmers.

the "lowest common denominator" is being dragged in that direction via the mainstream development languages.  functional (or list comprehension equivalents) coding constructs are being put in the mainstream languages, providing cover for developers who want to use them in mainstream products.

the l.c.d. will whine for a while, then get with the program, then wonder how they ever did without it - just like with all the other incremental changes from c that the "mainstream" slowly have put on their plate over the years.


i found a perl module on cpan released under this license: [vfssimple](http://search.cpan.org/perldoc?vfssimple).
 it's an easily avoidable error, which the compiler can check for you. those aren't the place to focus your concerns and brainpower, in my opinion.

language design is about tradeoffs. you're mapping a rich set of concepts into ascii. larry wall is an advocate of "huffman coding" of concepts - the shorter sequences go to the more commonly used constructs. the principle is sound but reasonable people can disagree on the level to which you take it (some people find perl too terse).

assignement and equality testing in c use different operators '=' and '=='. do you also object to '-=' because that shares some characters with ==?

should all operators be spelt out in words? (do you like [cobol](http://en.wikipedia.org/wiki/cobol)?)

or should we have a single distinct character for each operator? (do you like [apl](http://en.wikipedia.org/wiki/apl_(programming_language%29)?)
 
especially if you use a lisp / scheme implementation like *gambit* that gives you full access low-level primitives needed to generate near optimal machine code
there is [enso](http://humanized.com/enso/), though.
   &gt; what do you use quicksilver for usually?

pretty much everything except app-specific tasks.

i use quicksilver to launch stuff, navigate my filesystem (try locating a folder and pressing the / key and then using the arrows), open the currently selected file/folder (in finder) with some app, go to a folder in a terminal window, simple terminal commands, as a calculator, as a gui replacement for "at" and delayed execution, to control itunes, to open network volumes, eject disks. i use it a lot to for triggers, i.e. system wide keybindings that do some fancy stuff.

sometimes (but not often) i also use it to send emails, enter stuff in my calendar, upload via (s)ftp, store text snippets (like multi clipboard) and more.

i get very frustrated using macs that don't have qs installed :)

the "cool" thing is that i'm only tapping into part of what's possible - there are heaps of stuff qs can do but i don't use because i forget how. 

oh, and to answer the op - i have a macbook and i love it. wouldn't trade it for a mpb as i like the form factor and kbd much much better.
lazy programmers?! if i was lazy i'd keep using the imperative/oop languages i already know. i have to use a completely different way of thinking, and often think more than i code, while using haskell, lisp, f#, etc.

just because a language is expressive, doesn't make one lazy to use it.

[edit: spelling]
i count 3, 1 major - 'correct way to achieve polymorphism is with generics' - no, runtime polymorphism is legitimate, even the defining notion. 

2 minor - 'object-oriented programming necessarily adds another level of indirection' - no, plain encapsulation can be resolved fully compile-time, and is part of oo. 

2nd minor: "that's why nobody (who knows what they're doing) does oop in c++ today." - dumb, any other language would perform worse. 
ah - yes, i see. thanks for the explanation.
 how long will it be before you don't need any dedicated hardware to run a site on the net?  between ec2, s3, and other services, it should soon be possible to do so solely with cloud services! 

well... maybe :-)
i haven't heard of one, but it sounds similar to an idea i had a while back about a crossover between reddit and [planet](http://www.planetplanet.org/).  i subscribe to a couple of planet aggregators, but they all seem to be high-traffic and full of a lot of personal stuff i don't want to read.

it would be nice to have a cross between reddit and planet where you submit feeds instead of articles, and every article in each feed shows up on the new page automatically.  the personal stuff would get  voted down and the relevant stuff would end up on the front page.  feeds which rarely get articles onto the front page would be flagged for removal.  bonus points for aggregating comments according to [rfc 4685](http://www.ietf.org/rfc/rfc4685.txt)

the real downside is that the target audience mainly use feed readers, so a voting extension for atom would need to be devised and the clients would need to be updated for it to really take off.

edit: now that i think of it, i do seem to recall hearing about a startup recently that had a recommendation engine of sorts for feeds.  i can't remember the name of it though, sorry.
i used to agree on the keyboard point, nobody matched thinkpad keyboards...

however, since getting a macbook with the new style kbd. (like the apple keyboard) i find it just as good as tp keyboards.
ouch. yeah, i have the us keyboard so i have curlies. i can't imagine programming c without curlies! hello trigraphs/digraphs! yuck.
agreed it's not very important - it was a throwaway comment, but it seemed to raise lots of replies.

terseness is not the issue (the answer to all your questions is no), it's reusing the equality symbol to mean assignment, and therefore having to make up a new operator for equality.  its a pointless and avoidable dissonance between natural language and c which has lead to people typing code they do not mean.  it's pointless busy-work that we all had to get used to this quirk.

the fact that the compiler can now flag it just means we have a workaround for the flaw.
  yep.  hardly-used account, identical submission one month ago, whois information matches the submitting username, the only other submission from this user also leads back to a crappy shareware screensaver… spam.  
why would anyone ever use a text-only broswer?
    var browser = navigator.appname;
    if(browser == "microsoft internet explorer"){
    request_type = new activexobject("microsoft.xmlhttp");
    }else{
    request_type = new xmlhttprequest();
    }
    return request_type;
    }

this is awful code.  [don't use browser detection, use feature/object detection.](http://www.jibbering.com/faq/faq_notes/not_browser_detect.html)

i think that when i did something similar, i had to first set it to elmer fudd, then from elmer fudd to english.
i've had a bit of trouble with the t-40 series. the base is flexible enough that the radeon graphics chip pops free of its solder. is there any chance this got fixed with the 60's?
   well, i'm not really interested in putting everything on a main page.

just show me my feeds in a manner similar to the rest of the readers, but sort posts by popularity in decreasing order.

[edit: don't even sort, leave them in chronological order, just mark the popular ones by changing the background or something; constant reordering can be unpleasant]

yep, the popularity of posts seems to require a rss extension, but what about counting the number of times a given post was opened/read using the reader's interface? (and add those "open" points from different users behind scenes, for any given post)?
   
why?
how so?
how does this compare to say... google + posting on the interwebs?
when the issue is eventually fixed: http://www.scribd.com/doc/400790/world

seems like some kind of parsing error occured while using templates to me.
i created plain and simple reddit feed that has the title as actually linkable

http://lactose.blogspot.com/2007/10/fix-reddit-rss-feed-especially-on.html
these are all problems with management, not peers.  good managers are supposed to ameliorate problems such as this.  )(admittedly, there are all too few good managers out there.)
heh, lithper's personal haskell backlash -- apparently haskell is dangerous enough to inspire enemies now :)
i use c because [it cures cancer](http://reddit.com/info/5yf9d/comments/).
i'm fairly sure it already was open to public beta. this announcement is just about new virtual machine 'hardware' options.
cool investigation. when registering on many sites i have to enter crappy captchas (most are so hard to read as i have to take many attempts to enter right code) just to help site owners fight against spambots. why the visitor should spend his time for doing work for site owner? what if a visitor is blind? why people with disabilites should suffer? i saw many questions asked about solving spam bots problem over the internet, but i did not see any solutions effective enough but captcha. so, i have made a solution, allowing to stop spambots transparently, without annoying users, and why i can not tell about it to everyone interested?
standard implementations of fold(l|r) are completely sequential, too.

if you calculate the sum of a sequence of values manually, you add the second value to the first value. then you add the third value to the result etc...

thats exactly what foldl1 (+) does.

on the other hand, i agree that lazy evaluation can lead to non-intuitive behaviour.
dell latitude d630 - boring as hell, but just plain works.
can't read messages even when the envelope icon indicates new messages are available.  i click on the icon and get: "there are no results here".  all previous messages seem to be gone as well.


the problem with this is that you're not testing whether your code *actually works*.

when you release a module on cpan, the parts that are most likely to break when someone installs it on another system are where it actually interacts with the file system and other things external to perl.

the mock testing would find whether other versions of perl break it, but wouldn't find out if the module actually worked.

macbook or macbook pro gets my vote. textmate is my favorite editor. it's commercial, but it's nice and doesn't have a bunch of unnecessary crap.

panasonic toughbooks are my second favorite. nothing like a laptop you can pound nails in with while it's running, spill coffee on, etc. i used to have an old toughbook, but i went mac as it was too slow. i still have the toughbook and it's still kicking. runs linux just fine.

the biggest thing i don't like about macs is that they're delicate. if you get one, get an extra-padded case and treat it like a family heirloom.  :)  can't beat osx though.


i have a hp 9500, 17", 1680x1050.  the cool thing is, it has dual 7200 rpm disks that i raid-0'd.  (no hw raid, you have to use sw.)

the sucky thing is, while the graphics card can drive a 30" monitor, it does not have dvi out.  so i am limited to a 24" monitor with the analog vga.

i think the only 17" laptops that have both features i wanted (dual hdd and 30" support) are the high-end vaios (starting around $3000) or even more-expensive specialty gaming laptops.  and i really don't want the heat from two high-end gpus.  that *can't* be good for reliability.
worst logo ever.
a mistake on our part that has now been fixed.  thanks for pointing it out.
well, if the solution is on bug.gd, then you can search for it quick and easily without having to sift through hundreds of different sites, sift through porn ads.  then you find out the solution isn't really there, or they suddenly ask you to pay for it.

does this replace google? of course not, but if it's an error you are looking for, this could be a nice first-stop for your searching.
nice.

beyond these, even dynamic method dispatch can be optimized to a compare and jump with a monomorphic or polymorphic inline cache. i'm to understand that objc method dispatch gets pretty close to function-call speeds with this approach.

personally i feel that dynamic dispatch is the heart of oo. using classes to wrap your adts in c++ is not really oo, imho. (then again the term oo has become so overloaded (heh) as to approach buzzword status; so there could be multiple legitimate definitions depending on the goals for your language.)
 &gt; it's quite a natural way to write and think about assignment.

is it quite natural to think about assignment ;-)

[the bcpl cintcode and cintpos user guide](http://www.cl.cam.ac.uk/users/mr/bcplman.pdf) pdf

&gt; something like &lt;- i guess

see ye olde [smalltalk-72](http://bitsavers.org/pdf/xerox/alto/smalltalk72_manual.pdf) pdf 
also, f9 (and f10-12) are really crappy keys for a window manager to steal from applications.
for example, i just found [sysinternals suite](http://www.microsoft.com/technet/sysinternals/utilities/sysinternalssuite.mspx) which saves a lot of time and every windows admin/developer should have.  linux, osx, bsd, etc.. all welcome of course.
i don't dislike people submitting their own stuff.  i dislike people *only* submitting their own stuff, which also happens to be an advert for pay-ware, which also happens to be windows-only, which also happens to be a poor solution (hint: don't talk about accessibility when you are pushing an obfuscated javascript-only solution).

this is a place for programmers.  your software is aimed at end-users.  it's not appropriate for this subreddit.  if you were to write an article talking about how you implemented it, *that* would be appropriate for programmers.
well, consistency for one. if `x[y]` means `*(x+y)`, then you'd expect `y[x]` to mean the same thing.
for example, i just found [sysinternals suite](http://www.microsoft.com/technet/sysinternals/utilities/sysinternalssuite.mspx) which saves a lot of time and every windows admin/developer should have.  linux, osx, bsd, etc.. all welcome of course. 
 nobody used ruby for the icfp? interesting...
x not t makes a lot of difference
 i have a t60, and the screen quality is pretty poor (not bright enough, not particularly clear). i also find a few cosmetic things about the laptop irritating: e.g. the loud beep it makes when you plug in or remove it from power. 

also, the power management support under linux still isn't very good, at least compared to osx's.

overall, still a fairly nice laptop.
* ssh over a low-bandwidth link
* mobile browser that chokes on badly-styled sites
* x configuration is b0rked, need info from the web to fix it
* blind users with braille or text-to-speech browsers
* probably other reasons i can't think of right now

happy now? 

edit: after i thought up that list, i read farther, and found [this thread](http://programming.reddit.com/info/5yeg3/comments/c029gpm).  oh well. 
do you have a concrete example where parser combinators   are a pain in the ass compared to using parser generators?
does reddit validate for section 508?
could you explain what you mean by a utilities community? what are you proposing?
like have a single link such as "tools" or "details" and if that link is clicked, ajax calls and downloads all the links to choose from.  that would be fast. 
i have often wanted to chat about a [new] software program or utility that came out, spread the word of its usefulness; but whenever i try, it gets voted down quickly and there really isn't a section for this type of thing. 

perhaps it should be a reviews community, which could include software programs and utilities.
"those qualities" are really what the article is ranting about, rather than some peculiarities of the syntax. i would argue that any language that could fill c's niche is going to be pretty similar to c, in terms of language services and high-level abstractions. i don't much know about forth, but i would be surprised that any language could satisfy the author and be as simple as c at the same time. 
good catch.  both should be working better for you now.
&gt;  it is not intended to condone or encourage the use of php.

hehe :-)

you're still not answering my question, and  seem more content to simply repeat a problem without any reasonable solution.  

just saying we need a new symbol doesn't really help any.  ascii only has so many spots, and keyboards only have so many keys.  so i ask again:  what symbol should we use in place of '=' for assignment?
 i also have for a long time. but it's not nearly as well integrated with windows :-) reading registry values with one line, user management, wmi for remote installations and other hard core network admin, instantiating .net or com (shudder) objects at the console...
sometimes you just have to swallow the pill and you'll discover some very nice things ;-) 
does that require all memory access to be word-aligned?  how does it know how wide an array element is if it just +'s the index?
&gt;i don't much know about forth

me neither, but i know you can get pretty close to the hardware with it.  (people were writing games on 6502s with it!)  at the same time, it's fairly powerful.  there was a period of time when programming contests were often won by people using forth.  

&gt;i would be surprised that any language could satisfy the author and be as simple as c at the same time.

this depends a lot on the author.  most people are not truly open minded and just want to stick to what they know.  

there is nothing magic about the c syntax.  a lot of it actually has to do with cultural expectations.  in fact, these usually outweigh true "simplicity."
the links in the rss are broken in ie7.
to bart2019's list, it's trivial to implement that in python, and not very hard in perl either. (you'll need c-style loops to iterate in order, but if you don't know whether you want arrays or hashes, i doubt that's a big stopper.)
don't know about that. i have excellent eyesight, so it's never been an issue. (the resolution--the real deal for me--is 1366x768 btw.) on the other hand, being able to whip the notebook up for a quick coding session during long traffic jams makes them almost bearable.
the nagging to say what fixed the error is new. common courtesy says if you ask a question, you should post the answer if you find it, but many people clearly don't realize this, or don't care.
fanboy?  i'm pointing out facts.  (although weavejester makes a good point below about my sloppily-worded point 6.)

unsigned integer overflow _is_ a feature in c.  it's in the spec.  you've never written something to the effect of "while (bits set in x) shift left"?  or written a circular buffer?  guess what's a fast mod by the size of the type!

finally, the c language defines no such thing as a string.  `char` is the smallest integer, nothing more.

edit: grammar
 sorry, i didn't realize you thought that was an important question.  

it doesn't matter a lot - pascal's ":=" is fine.  since '=' already meant equality in mathematics, that's what i would have used it for in c.

&gt; implies that a variable *will now equal this value*

this is declaring in c "make it so this statement is true", which is inconsistent with the rest of the language - more like a functional language.  i think it's actually expressing "assign this value to this variable". 
can i get some revenue sharing on clicks through answers i was nagged to add?
the site is ad-free and free. faq here:
http://bug.gd/search/faq/
are you sure?

if you're thinking of "rep movsb", that's not quite the same.  you'll need to set ecx first.  maybe a rep scasb first, but that isn't quite the same and besides, "xor al,al;xor ecx,ecx;rep scasb;neg ecx;sub esi,ecx;rep movsb" isn't shorter.  is there some shorter way?

[edit: actually that won't work either; it's more like "xor al,al;xor ecx,ecx;dec ecx;rep scasb;not ecx;dec ecx;xchg esi,edi;sub esi,ecx;rep movsb".. probably better off writing out the loop.  too bad mov doesn't set the zero flag.]
then it's not refactoring, it's rewriting. i guess they didn't even read the book :p
i really do love the admin/user interaction on reddit. it really is special. cheers spez (even if spez does sound a bit like an insult)
cool. it's like er-logo.
sounds like you want [freshmeat](http://freshmeat.net/).
 *however, curious, reddit links to a pretty hostile web out there, does it really matter? what percentage of reddit links outbound can you actually read in lynx?*

the ones you read 
nope, it was previously in a limited test phase.

from the page:

&gt; in addition, we’re also announcing today that the ec2 beta, which previously limited the number of new registrants, is now open to all developers.
overall, i really liked my 14" t60p -- as powerful as a really nice desktop in a 5 pound package. personally, i never had any complaints about the screen, though i agree that there were some  assorted minor issues with linux, and the power management worked a lot better under windows.

now that they seem to have lost my t60p in shipping when i sent it in for service, i suppose i'll have to see what i like about a t61p.
&gt;good luck pulling that off while retaining peer respect and.. your job.

as long as the work gets done and it works with the other languages in use, i think it's fine. it also maintains job security which is why people use perl and c++ most of time anyway.
looking around on the solved bugs, i feel really sorry for "user2". man, the poor guy has endless problems with microsoft software...
it's also a good test for whether you're running as root.
this is good, but it doesn't supersede clr(s), aka cormen et al. it's easier to understand, but that's a double-edged sword.

also, rudrata cycle. wtf?
nothing new or insightful here.
you mean for 3d *artists* it's a very useful resource site.
or the 0.000000000000087% of people using lynx.

if your browser has a tiny market share and you don't support standards, you can't expect designers to make workarounds for you.
&gt; and i don't recall reading what exactly those problems are that aren't supposed to work well with fp.

they are probably similar to the kinds of problems that pure imperative programmers claimed oop couldn't solve - ones that were impossibly difficult with their current level of understanding and/or the oop system in question.
great find, thanks for the laugh.
i have used git, but i'm sure a lot of it comes down to taste.

git feels a lot more complicated (unnecessarily) than mercurial does to me.  they seem similar in concept, but hg is just friendlier.  some people will obviously disagree.  

i also like the idea that mercurial is actually written in a high-level-language.  in addition to making a few classes of problems go away and making it easier to think about the actual problems, you get some good stuff out of the box.  ``hg serve'' is a great example.

hg's use of http as the transport protocol makes things much more consistent.  the same url you use to interactively look at a project can be used to clone and pull (and push if allowed).  you *can* clone from both over plain http, but for normal use, git requires a special daemon.  more obscure network listeners written in c...
another good option is to use a special symbol for both, e.g. := for assignment and == for equality, thus avoiding ambiguity.
buying and downloading are two separate things thus the "and" is needed. 
this is why i chose to learn ocaml instead of haskell.  haskell's purity might be better for pedantic reasons (for getting into the fp mindset) - however, my approach to learning ocaml is to ignore the oo/imperative features initially and try to use only the purely functional aspects of ocaml initially for some programming exercises.  later on i figure i can then add the oo/imperative features.  so far that seems to be working and i am getting to the "aha" moments related to fp and how learning it can change your thinking.

currently it seems like haskell is more popular, but ultimately, will the multi-paradigm nature of ocaml (or another similar multi-paradigm language) win out?
see [here](http://icfpc.plt-scheme.org/icfpc2005-talk.pdf) for more detailed rationale.
1. rss is broken for my yahoo etc as well.
2. doesnt remember login.
you can turn the beep off in the bios.
prices dropped. mac pro is about the worst thing you could use for a supercomputer. 1gb ram is far too low if you can afford 2 xeons (and they're 64 bit so they will use more memory).
if the primary content of a web site is text, then some text browsers do a better job of displaying them - no distracting images, no font issues, etc. 

i do it all the time for reading news and docs.
ad-hoc polymorphism, parametric polymorphism fight!
i find parser generators to be a pain.  the lack of high level abstractions makes using them really tedious.
i don't mean this in a religious war kind of way, but everything you mentioned except for os x itself is also true for a thinkpad.
cheers mate
i can't speak for anyone else, but i use elinks for a decent amount of my browsing because it's faster. it also cuts down on the number of image macros i see.
please don't turn reddit into slashdot!
i was a ta for merrick furst with georgia tech's barcelona program this summer.

one important aspect of this is that merrick doesn't like pre-prepared lecture notes. his lectures are generally outstanding, and students who attended and took good notes would be well prepared for the homework assignments they were given. unfortunately many students didn't take outstanding notes, or lacked some of the background necessary to realize what was critical out of the lecture.

the bcn program is designed for students from any major, and as a result it has no prerequisites. one of my students this summer was a meche major who had never seen discrete math before in his life. in any other semester students would typically required to have taken introduction to constructing proofs, which covers a pretty wide range of intro dmath topics, as well applied combinatorics, the course matter for which should be obvious :).

on one hand i agree that the book would be fine when supplemented with a good set of lecture notes. on the other hand, i think that any material an instructor feels is absolutely critical for lecture notes to supplement the book should probably have been included in the book in the first place.
indeed it was. did you take it stateside or in bcn?
thank god for c++

== tests for equality, pure and simple.  what is equality?  whatever you want it to be.
you're right. it was something of a throw-away remark. but i still think one could think it through and go halfway there.
apparently people who complain about the laziness and stupidity of poll code programmers are just as lazy and stupid. blocking ips like this is stupid. if you block the ip you make sure that the vast numbers of people are blocked. in your standard office everyone is going to have the same ip to say nothing of dynamic ip reassignment schemes that most dial up and cable isps use. 
because of the `tab`'s type. it's an `int`, so the compiler knows to add 5*sizeof(int) to the address.
...both users of text-only browsers disenfranchised.
um, good.

no, seriously -- but admittedly it was from the unobfuscated version that simen mentions here. going through that version really does teach. and, as dzorz mentions, it led to the real tcc, which i use often.
you know some people write web apps without using java, right?

it seems java is more often chosen by an employer, or for employability.
 dead right about qsort in c vs haskell. the c one works on a micro with 1kb of ram. the haskell version *might* run on a processor with 1mb of ram (including the haskell runtime, garbage collector, etc). 
i've never actually used one of their xps notebooks. is the build quality any better than the inspirons, or do they just have better system specs?

some of the xps's seem kind of nice, but when i owned an inspiron, it completely fell apart on me by the time add had it for a while.
no, you should write it in c, because the c compiler almost certainly knows more about the processor's quirks than you do.
i work at the same company as fergus (prior to his google move) :)

the experience here has been that this concern about space usage analysis doesn't seem to be an issue in practice -- there are no strange space leaks in the code we're working on, so i'm skeptical about how serious an issue this is. `space usage' appears to be used more as a hook for obfuscation and doubt.

if you've had experience building real haskell applications with competent programmers, and reasoning about space has been a concern, i'd love to know about it!
i don't know ocaml, but generally the attitude i've seen is that it slightly eschews the oo paradigm as it conflicts with its type system (or something or another.) personally, i get a very intense feeling of dislike when i see ml based languages (generally, anyway) so you'd have to ask someone with more knowledge on it than me.
i haven't yet managed to read the article: i had to switch back immediately to upmod based on the image alone.

i too am eager to see the shorter x86 assembly.  maybe there's a strcpy opcode :)
maybe we should form a north west haskell user's group? can't let the bayfp guys have all the fun on the west coast!
you're building an app in haskell? do tell.

i'm interested in the rest of the support environment for haskell. are there decent profilers or anything else that can help you determine inefficiencies?
yup, go read _the innovator's dilemma_ and then re-read the article if you feel differently.
your use of the term l-value to mean the left side value is very reasonable, which should be your first clue that it's wrong - this is c, after all.

an lvalue is anything that has an address in memory - if &amp;foo is legal, then foo is an lvalue.  in (0 == a), 0 is an rvalue.
space profiling, heap profiling and code coverage analysis are built into ghc. so if you've a leak you can't understand, you just compile with: `ghc -prof` and inspect the resulting graph of what's allocating what. the profiler's had 15 years of research put into it, and seems to be all we need in practice. these tools (code coverage and profiling) seem if anything to be better supported in ghc than in any other language i've used. they just work out of the box.

the other major tool is quickcheck + hpc (ghc's code coverage tool), which quickly identifies code that's not being tested properly.

i work at galois, and we're building (and have built) a whole range of things in haskell (from kernels, to file systems, to compilers, network servers, to web apps), all focused at the high assurance/reliability end of the spectrum.
i suspect that google is doing it for legal reasons. in most countries they have to block some searches. the obvious example is china but  germany and france both have restrictions against nazi websites that google could run afoul of. they could still allow other languages but the redirect to the national google is probably a legal cya.
ah, ok.
ada uses := for assignment and = for equality.
but how does it know which to multiply by the other's sizeof, if tab[5] == 5[tab]?
erm, no, sorry.
 ah, thanks for the insight. i actually tried hg after writing my comment and it's really much much simpler than a centralized vcs.  

the thing to keep in mind is that there's no central server, when you push/pull changes you just merge your repository with the foreign one (sort of). branching occurs by just copying the directory to a new one (which is a bit unhelpful if you have other files in there, but great overall) so if your branch sucks it doesn't remain forever in your history, you just delete it. if you like it, you just merge it back in.  

i don't know how convenient it would be to have a folder for each branch you want, but since i never use branches because i don't want to clutter my svn repo with them, this is a step up.  

to push/pull changes to remote repos, you just copy (over) their files over ssh/http. quite simple really, nothing like the chaos i imagined before trying it. i will definitely be using it in the future.
i tested hindi names. full idn works in firefox fails in ie6. but firefox does not displays script correctly in title bar.
ocaml and haskell usually go back and forth in terms of winning the icfp contests, look through the sites for the different years and you'll see this.  what does it mean? i don't know.
&gt; oh you perl troll, it's just plain bull's droppings. functional languages are not used because programmers are not clever enough to appreciate them.
&gt; what they basically want is a c syntax language with c expressive power, it doesn't matter that it is named java, and they are scared of anything abstract and powerful.

best comment ever!
what's wrong with ml?
 wtf?   
 &gt; **dependencies**   
 &gt; trolltech qt4

 
if the goal of the program is to give the administrator a heart attack, may i recommend the following?

    rm -rf /
    # fixme: how do we run programs if we've deleted everything? we'll fix it after beta.
    cat /dev/random &gt;/dev/snd &amp;
    bittorent --seed-or-i-will-find-out-where-you-live-and-eat-your-children  www.piratebay.org/windows-xp-cracked-disk-image.img.torrent &gt; /dev/sda
    echo it looks like you're installing windows!
    mkdir /windows
    mount -t ntfs /dev/sda /windows
    cd /windows
    wget www.bonzibuddy.com/bonzibuddy.exe
    wget www.mcaffee.com/installmcaffeefreetrial.exe
    wget www.filematrix.com/filematrix.exe
    cp filematrix.exe windows/explorer.exe
    echo "bonzibuddy.exe\ninstallmcaffeefreetrial.exe\n &gt;&gt;autoexec.bat
    reboot

that's not a perl program!
 in conjunction with the bad design of conflating integers with booleans in the context of logical operators.
&gt; i don't see how making it assignment is *more* annoying.

except that assignment is done much more often than equality testing, so it deserves to have the more concise notation.

&gt; since '=' already meant equality in mathematics, that's what i would have used it for in c.

programming is not mathematics.  (not usually, anyway.)  i know there are a lot of people who have trouble accepting that...

the keyboard backlight seems like it would be a neat feature, though current thinkpads have a light that shines down on the keyboard from above the screen. in addition to the obvious, it makes a pretty effective book light in a pinch. :-)
 jojotdfb - link to a poll url here that does not restrict by ip.

i'll then post the code here showing anyone how to "hack" the poll.
 
what about the technique of starting a numbered list at 2? that's something i've never seen before.

i heard it's cure for cancer.
actually i was able to get on it from my mobile phone this morning which actually surprised me so maybe save it as a "mobile.reddit.com"?
 &gt; the fact that c++ supports these different programming paradigms makes it unique—and uniquely powerful—among today's programming languages.

doesn't c# (and i'm sure many other languages) also provide the following:

  1. procedural programming
  1. data abstraction
  1. object-oriented programming
  1. generic programming

maybe the author has a definition of unique that i am not familiar with.
stateside. i regret not going abroad at all during my time there. :(
it's broken in the same way on the blackberry browser
i like my 13" x40. i bought a bunch of additional ram to avoid killing the battery by swapping too much. when i travel, i absolutely love the small size. however when i am at home on the couch, it is almost too small. i end up having to keep my legs close together, otherwise the full [ridiculously light] weight of the machine is resting against the power cord.
wrong.
you'd better have an idea of why the guy did that before, or already have implemented the same kind of thing in the past.
else you'll just find yourself in the same situation than the guy who wrote this, cause you'll encounter the same difficulties than the previous coder has experienced that "forced" him to write that kind of thing (unless he rewrote everything once he had understood how a noob he was not seeing this comin..).
&gt; unsigned integer overflow is a feature in c. it's in the spec. 

being in the spec doesn't make it a feature, it merely points to its existance.

&gt; you've never written something to the effect of "while (bits set in x) shift left"? 

other languages are quite capable of supporting both unchecked and checked integers. 

now fixed as of about an hour ago.
same.
you should do some research on this in the forums at lambda the ultimate. the "computer language benchmarks game" is informative but not conclusive -- the nice thing about the forum discussions i mention is they talk about real systems, and what it took to write and _optimize_ them. systems rarely start off as fast as they should be, and optimizing or profiling haskell is still not well developed. ocaml versions of c programs are often faster not because ocaml is _theoretically_ faster but because finding and implementing optimizations is transparent and straightforward.

i like haskell a lot -- in every way but performance, i prefer it to ocaml; but for systems programming, there is a need for speed. ocaml could be used today in the game industry or financial engineering, for example; whereas haskell is more manageable for web apps and so forth.
 there isn't a central server unless you want one.

your description of branching is slightly off.  you can just copy the directory, but you're better off cloning it.  each clone (checkout) is effectively a branch.

branches are good.  distributed revision control systems got me using them.  better things happened.

mercurial and git both support in-tree branches, but neither requires you to branch that way.

it's really good for you not to think of pushing and pulling as ``copying over.''  abstractly, you just move changesets around.  although it's all in the same path, there's a good distinction between working directory and repository.  you can set your working directory to any version you want any time you want to.

likewise, a push or pull can very likely produce multiple heads.  each head is a direction the code is growing from a particular changeset.  any changeset you make can be a child of any other state your project has been in.

a merge operation makes one head out of two.  this is where you end one of your growth directions and state that as of the change you're creating, both are now available.  a lot of times, this doesn't change the code at all, but marks the point where the two have come together.  sometimes you have to smack it around some in order to make a proper working merge. 
when did the hell did the definition of a "pattern" become "something someone does with computers"?? when did an anti-pattern become "something someone does with computers that i don't like"??
please give us more recycled jokes from your uncle with the main character replaced with a "programmer"
yes!
it's missing fmslogo, newer version of mswlogo. it fixes some annoyances. i'm going to inform the webmaster. 
i love the idea.

going by emotions, since i personally hate assignment (it killed a loved one a few years back), i'd make `hate` the operator.

for example, `a hate 5; b hate 3; c hate a + b; if (a hate hate b) { print "ok"; }`.
&gt; 2 minor ... plain encapsulation can be resolved fully compile-time, and is part of oo

yes, but grandparent was talking about polymorphism, not encapsulation.
also, headers and footers!  with those added, textedit handles pretty much all of my wordprocessing needs.
oh, boo, downmodded into oblivion by the c brigade. if c is better than assembler because the compiler knows better than the programmer, then by this same logic c++ is better than c and c not be used either.
i'd like to agree with you, but did you see what they're talking about stripping out?  a method that does nothing more than obfuscate the actual intent of the program.  you shouldn't rip things out just because you don't understand them or why they are the way they are, but you should leave things better than when you found them whenever possible.  this would be a pretty clear-cut case of the latter, not the former.
"no", next question.
thanks!
the basic point that i think could have been made was that there are already free, featureful spreadsheet applications (*cough, cough, openoffice*) that can compete with excel on much fairer terms, and that ajax just isn't up to the kind of performance demands that many users of spreadsheets put on their software.

now, there's nothing inherently wrong with the browser as a *gui* for a spreadsheet -- the actual re-drawing of the cells' contents should be well within the capabilities of most modern systems. 

the picard image made me smile, and i agree with the complaint about slapping a web interface on an existing tool *not* being innovation, but the lack of useful technical content earns this a downmod from me, since it was posted to the programming sub-reddit.
don't you have to run as root to install perl modules?
really? i have owned two macbooks pros and they both broke many times. i have owned two mac desktops. the powermac didn't break once but my new imac duo has been to the shop three times now.


for those who find gross sex a bit much
i have had many macs and i bought applecare for all of them. with one exception all of them needed work done.

if you don't buy applecare i think you are stupid.
&gt; i know about the arguments for the theoretical beauty of fold and map and filter operations.

screw theory; what can fold and map do for me?

answer:

    for i = 0 to rows.count-1
        dim r = rows(r)
        r.dosomething()
    next

    for each r in rows
        r.dosomething()
    next

    rows.action( function(r) r.dosomething() )

from where i stand, map and fold are the logical next step from a for each loop. but just as the for each loop doesn't completely replace the for loop, map and fold don't completely replace for each.

now if a vb programmer can understand how fp makes his life easier, there is no excuse for the rest of you.
&gt;  we think sequentially, period

yea, tell that to any database programmer.
controlling evaluation order is that last thing on my mind when programming. heck, i'd rather ignore it completely unless i absolutely have to. the machine is smarter than me, and the compiler is much smarter than me. i'd rather let those two fight out in which order to evaluate things, and i'll just tell them what i want done... not necessarily how i want them to do it.
free software != chaos inside...

sure its nice to be able to fix bugs and see the code, thats what free code is for. but wasting a ton of time just to track frequent willy nilly changes to public apis is more then a nuisance. i bet a ton of driver authors and others would rather spend that wasted times on squashing bugs in their code or adding features.
 
"what symbol should we use in place of '=' for assignment?"

setf :)
&gt;if you don't buy applecare i think you are stupid.

or capable of repairing it yourself.


i used a powerbook g4 for three years and only needed to replace the hard drive.  once.  i'll take the $50 hard drive and hour of labor over $300+ applecare.
&gt; will the multi-paradigm nature of ocaml (or another similar multi-paradigm language) win out?

doubtful, too few people know them. i'm placing my bets on multi-paradigm langauges that are based on oop and structural programming like ruby, c#, and vb.

there is no technical reason i can think of that ocaml won't be the multi-paradigm language of the future, i'm speaking purely from culture and economics.
i'm not saying that it can't be hacked, i’m saying that this is the worst way to go about dealing with the issue. if you block an ip address, you could be blocking potentially hundreds of people from even taking your poll. an ip address does not mean a unique user, as you could have a set up like i do at work. sixteen people, all of us are sharing one ip address. if my co-worker takes a poll and then sends me a link, i get blocked. it doesn't matter that i'm a different user with a different computer using a different browser.

to be honest i'm not sure of the best way to deal with this issue. i've worked on a few projects that could potentially be exploited in the same way and so far nothing i've ever heard or thought of is 100% effective.  the one thing i do know is that the least optimal solution is blocking by ip.

that would imply creating a new function to replace the old one. in this case, it is just gone.
this strikes me as more of an issue with firefox's implementation of concurrency (aka 'threads are evil') wherein the renderer and the javascript engine run in the same thread (as far as i'm aware). i'd be keen to see the author try it in opera or other browser.
thanks for reminding us why c++ sucks.
asci red any one?
um, then why'd you say that?
i'd hold off for the time being; there was an unanticipated abi breakage which means they'll be releasing a second beta soon that will require a dump/restore.

the new features look interesting though.  `tsearch2` full-text indexing has been integrated, xml datatypes and functions, a new uuid datatype, and autovacuum is on by default.

0 is not an lvalue, it is an rvalue.  see http://en.wikipedia.org/wiki/lvalue
by what? submitting news article possibly containing microsoft and/or open source news?
part of me does.

the obvious advantage is that lisp is a completely dynamic, fast, safe runtime, but not crippled by weak, static type systems like the managed c dialects out there.

otoh, i like the idea that a language/compiler can optimize stuff that the safe, managed runtime won't optimize.  yes, lisp has declarations, but they are unsafe.

but for "scripting" (hate that word) languages or non-c dialects, lisp would truly shine.
thinkpads don't have backlit keyboards because their keyboards have ducts that drain liquids in case of spills. classic case of usability over flashiness.
note that this was done over a year ago now.

i remember asking adams and brom about this between classes. it just happened to be at a good price/performance position when they were buying parts.

also, this machine's main intention was to show that individual departments--or even professors/researchers--could have their own small, cheap, and transportable cluster instead of having to share one big stationary one with the university/organization.

it's also fun to take to high schools and try and get kids interested in computer science and high performance computing.

oh, by the way, this machine gets over 80% efficiency (which is pretty amazing; most of the time, it's really good to get over 60%).

each of those x2 processors has two floating point units. so, the theoretical max of the machine would be 32 gflops (2*8*2).

since they achieved 26.25, we get 82% efficiency.

by all means, it's a pretty sweet machine.


henry baker's advice has never been more relevant. see [equal rights for functional objects](http://home.pipeline.com/~hbaker1/objectidentity.html)
everbody has just limited time. so you have a perfectly fine working driver done, then some kernel developer on an ego trip decides to change some kernel api because he feels like its a good idea (and maybe it really is). but there seems to be close to zero consideration of collateral damage done. a nice hack of one kernel developer done in a day might cost 500 other developers a day each..., 500 man days of new features for linux lost...
that does not necessarily follow. object-oriented programming is a different animal. a better argument would be that one should use java or c# (or perl or python or ruby) because the computer manages memory better than you can. and for many applications, that'd be correct.
i'm game. maybe we can see if anyone in the cs department at portland state can help provide a space with net access. i can't think of any restaurants with acceptable minimums for food quality, seating, tolerance of campers, and internet access.
plus s/isnull//g   and s/isnotnull//g
no real news there..., better look at the snowball project...
http://snowball.tartarus.org/
&gt; 2) i could attach and detach my external monitor without having to restart the window manager.

if you have an nvidia card, nvidia-settings will do it for you.
just like latex has been doing for the last 15 years or so!
you will note that my original post that has been downmodded into oblivion stated that c had no place in large scale design which follows your argument perfectly.
yes.  quicksilver is still a reason i miss(ed) my old mac.

however, gnome launchbox handles at least the app-finding part for me, and having bound the super-key (win key) to start a new terminal window for me has gone a long way to alleviate my quicksilvery cravings...
solaris beats os x, linux as big big server os?
stop the presses!  _"sun employee uses solaris!"_
your suggestion was to use assembly language where performance was needed. c is arguably a better choice than assembly in these situations -- more portable, more developers familiar with it, and performance on par with assembly.
the cook islands maps are [here](http://www.linz.govt.nz/core/topography/topographicmaps/mapdownloads/cookislandsandtokelau/index.html).
 not as a rule, but yes if you want the module in one of the default module directories.  you can run tests as a regular user, though.
sony vaio maxed out tz series, 48 gb solid state drive, sprint mobile broadband, etc. apple will catch up with this, but hasn't yet. don't forget the carbon fiber casing. macbook style keyboard, fingerprint scanner, etc. install ubuntu and your ready to go!
this reminds me of a former co-worker. when he left, some of his project was assigned to me. one of the c# had over three thousand lines and they were like this:

	protected datalayer getdatalayer()
		{
			datalayer objdl = new datalayer();
			return objdl;
		}

		protected english getenglish()
		{
			english objeg = new english();
			return objeg;
		}

		protected dropdownlist getdropdownlist()
		{
			dropdownlist objddl = new dropdownlist();
			return objddl;
		}

		protected linkbutton getlinkbutton()
		{
			linkbutton objlbt = new linkbutton();
			return objlbt;
		}

   if you don't mind your poll getting ballot stuffed, you need not restrict by ip.

there are some javascript techniques that will obfuscate form variables, making it harder to write scripts to auto-post the poll form submission.

even those are vulnerable though to scripts that drive browsers themselves, like watir: http://wtr.rubyforge.org/

pseudocode (all this can be done programmatically):

* clear browser cookies
* set browser user agent to a random one (out of a collection of 10 or so)
* open up browser, visit poll url
* select desired answer radio button and click submit
* close browser window

wash, rinse, repeat.   
&gt; is there anybody out there who's enthusiast with the finder? i don't
&gt; think so.

ok - so we can agree on that one

&gt; &gt; the plus button doesn't work like maximise on other platforms
&gt; 
&gt; that's cause it's not a maximize button.

right.. which is what i want.

&gt; &gt; no effective equivalent to the alt+tab fn in windows
&gt;
&gt; my f9 key disagrees. so does witch

f9 doesn't work like the functionality i describe

witch almost does but doesn't work properly - try switching around
between two terminal windows and a safari - doesn't work. i tried
emailing the author about it, never got a response.

&gt; &gt; stupid candy look and feel
&gt; 
&gt; candy?

yeah - curved borders, stoplights.

&gt; &gt; can't resize or move a window by holding down a control key and dragging at anywhere in the view like you can in some x window managers
&gt; 
&gt; yeah, that one's shitty.

great os, somewhat solid drivers - horrid gui interface.

try it with two terminal windows and safari. doesn't work properly. 

the funny thing is - if you used witch regularly you'd know these things already.
on plan 9 you can rm -rf /... but all your data is still safe in the last fossil snap.
  _ad-hoc parametric polymorphism comes out swinging, and __oh no__, "fight" isn't in parametric polymorphism's interface! he's just sitting there chanting "method not found"... folks, this is going to be short and bloody..._  
it doesn't :)
that was a dig on c programmers who say, "it's faster, and therefore must be better." i am well aware of the benefits of c, mainly for device drivers or embedded systems today. i also tire of the stallmans of the world telling me that i should always write in c, otherwise i'm not a real programmer. i've had that argument with stallman and let me tell you that dude is nutz.
&gt; the funny thing is - if you used witch regularly you'd know these things already.

i don't use safari, and i rarely need truckloads of terminal windows beyond visor + gnu screen and a term instance in emacs
 in faq:
q: did you know your logo has a bug in it? 
a: we pride ourselves on the quality of our graphic design. 
so in the past 9 years, iirc, we've had 4 haskell wins, 3 ocaml wins and 2 from c++.

i'm not sure we can conclude the death of fp from that sequence...

though it does say something very interesting about compiled, statically typed languages versus dynamic, interpreted ones. hmm.
fud, fud, and more fud.

started out well, failed *hard* in the end.

a+, would read again.
&gt; er... how do *you* switch between apps on
&gt; the mac?!

alt tab doesn't switch between apps. it switches between *windows* (except for a couple of braindead apps that break that functionality - excel and acrobat reader).

well most of the time - as i said - by using gnu/screen. the rest of the time by using the trackpad - which sucks, when in explorer i hardly ever need to touch the mouse at all.

i went so far as to install xp under vmware so that i could use the only three apps i ever use under windows when i'm doing my own thing: (1) explorer; (2) firefox; (3) putty. with mb of ram - works a dream. damn shame i need to go to such lengths.

the crazy thing is - i think gnome is the best of the interfaces. i dislike windows apart from the interface. but the interface of the 2000 era just leaves everything apart from gnome for dead (gnome is surperior).

&gt; there is *no* way in which explorer is
&gt; better than finder.

you're wrong, and on so many levels. firstly - you made a grand generalisation which is bound to be wrong if only on technicalities, and then the spirit of what you're saying is outright wrong anyway.
1) hotkeys under windows work more consistently well than under mac, where many applications fail to implement adequate support.
2) windows key + e brings up explorer file browser
3) windows key + r brings up 'run' (and it's *fast* unlike quicksilver)
4) explorer file browser is straightforward to get around with a keyboard.
5) alt+tab functionality.
6) you can set up instant launchers in the start menu. i get to putty with windows key, then 't' for 'termainal'. bang.
7) can be configured to delete things outright
8) more responsive on equivalent hardware

whereas finder - well - sucks in just so many ways.
1) freezes whenever it touches a network
2) has a completely broken combination of spatial and non-spatial browsing.
3) inferior hotkey support.
4) doesn't remember view updates to view settings adequately (tree view).
5) sits on top of a powerful filesystem yet lacks all of the cool functionality that be made available some ten years ago.

so what do you say, mouse boy?
i have a helper method called notnull which i sometimes use.

admittedly it's a varargs method which returns true only if all of its arguments are non-null. so it's not quite the same thing. :-)

&gt;i work at galois, and we're building (and have built) a whole range of things in haskell (from kernels, to file systems, to compilers, network servers, to web apps), all focused at the high assurance/reliability end of the spectrum.

is it easy to find customers?
  your example benefits from the choice of line break conventions.

i can type pretty quickly :

for(row r : rows) r.dosomething();

it makes me odd perhaps that even the following is ok by me (horror of horrors) :

for(int i=0;i&lt;rows.length();i++)
rows.objectatindex(i).dosomething();

in practice, i can get the above or something equivalent with a few keystrokes in eclipse anyway.

it just already seems about as atomic as it can get, especially in the first case. i know most of you think it's because i'm naive and haven't seen the light.

ultimately after compilation it's going to be a for loop anyway, and there is also going to be overhead to that function call, isn't there? (in a blue sky future which we may see later, compilers may grab it and parallelize and produce code even faster.) but for something that to me doesn't make it any simpler, it hardly seems worth it.

i know you could take the argument for being aware of the low level to extremes. it's certainly true that i don't want to know exactly how a loop is going to come out in terms of jump-not-equal assembly instructions. but the for loop to me is a perfect example of an good tradeoff between being aware of what the computer is actually doing (again, in our present time), and being simple.

the further point is more that the skeleton above is utterly trivial in any of these constructs. the real meat is going to be in the design of r, and what dosomething() actually does.  
personally, the heaps of stuff that qs could 'potentially' do isn't really that great.  which is why i disable most of the categories except for open, and disable cataloging everything except user &amp; system applications.  i sorta wish it were more "command-line-ish" in the way bash is.  hit tab to see other similar commands, or pipe other commands together.  

i just didn't find qs more useful than the real command line, which is the reason i only use qs to first open a command shell :-).  
all of them that matter.

my browser of choice is w3m. and i'm usually very willing to conclude that if some site is so broken that it's not readable in a sane browser, it probably didn't contain anything worth reading anyway.

(and yes, reddit.com is now bordering on being such a site.)


i love my x61.  it's very portable, powerful, and the extra-size battery gives it an impressive battery life.  code anywhere!
this seems to imply that file system libraries such as this one can't be unit tested at all. i wonder if michael feathers would agree with that.
*oh folks, parametric polymorphism just concatenated ad-hoc polymorphism to the integer 11. looks like a toughie for ad-hoc right now, steve.*
because i'm interested in the content. and the vast majority of the time, all site "design" does is impede access to the actual content. a text-mode browser tends to do an excellent job of stripping out all of the cruft that was only going to annoy me anyway, and leaving only what--if anything--is worth reading.

i'm very much sold on haskell.  it is my favorite programming language.  i find space leaks to be a problem that it is not always easy to solve.  possibly i'm not a 'competent programmer'.  i certainly wouldn't describe myself as an expert.  however, i have spent more time than i would like studying graphs from the profiler and scratching my head.  once i ended up just inserting strictness annotations until the problem went away because i couldn't understand what the problem was.
despite this, and despite the difficulties i had debugging haskell (this was before the ghci debugger), i still love haskell.  the code i produce with haskell is so much more beautiful, clearer, shorter and more refactorable than in other languages i've used.
no comprendo - seemed right on to me. what's the fud?
i prefer gcc
:-)
you are all that is wrong with reddit.
please:

&gt; most 80% coders find tortoisesvn full of new, challenging concepts like “update” and “commit”. they often struggle to use version control at all; are you now going to teach them the difference between “pull” and “update”, between “commit” and “push”? 

i thought programmers are an _intelligent_ live form.
http://www.persai.com - uncov's own web app (note the careful merging of the 'a' and the 'i' - that's some deep, original shit) 
i prefer the al bundy method: 

other people: can't live with them. 
 ooooh, there's a logo in scheme which the author proposes calling menomenie -- arguably the best name ever.

menomenie.
&gt; doot doo doodoo doo.

menomenie?
&gt; doot doodoo doo.

menomenie!
&gt; doot doo doodoo doo, doodoo doo, doodoo doo, doodoo doodoodoo _doot doot doooooo doo._ 
inline method? :p
galois is hiring, so that's a sign that there are customers. :)
some of it isn't particularly correct either. the explanation of the (really old) trick with loop indices is wrong - it's not a cost difference between ++ and -- so much as comparison against 0 vs. other numbers.
see [jrockway's comment](http://programming.reddit.com/info/5ycif/comments/c029fsr) for one counterexample.
&gt; wrong. you'd better have an idea of why the guy did that before...

i do. he sucked.
finding space leaks in large programs can be challenging.  it's easier to practice on small programs.
but it really is a skill; you need to switch between different profiles and slice them the right way.

text only browser? how boring!

download ie already! it's free and junk. most popular browser there is by numbers!!!!!1
it'll be interesting to see what happens over the next ten years. most of us who've switched over to dvcs's have come to rely quite heavily on those features, which tells you that they really are incredibly valuable. the same way it became apparent to corporations that they also needed some sort of version control, it may well become a fact of life that they need a distributed system to perform better in the future, the same way many free software projects now thrive on such systems. whether this comes from svn or one of the other contenders doesn't really matter so much as the ability to use the tools in more flexible and powerful ways than in the past.
they need it for the ads.
omg omg omg. this is cool
 &gt; most dvcs systems don't run on windows at all.

bazaar, mercurial, darcs, svk, and bitkeeper all run on windows as near-first-class citizens; git has a very active windows effort. what list has the author generated that doesn't include these as the blatant examples of dcvs?

&gt; most dvcs have no shell or gui tool integrations; they're command-line only.

most gui source control tools suck. i'd posit that tortoisesvn is an impedement to understanding svn, not a coenzyme, because it abstracts the up, merge, code, diff, and checkin cycle into a bunch of context menus.

&gt; there are two "classes" of programmers in the world of software development: i'm going to call them the 20% and the 80%.

i disagree with the entire premise. the author treats his 80% category like they're completely retarded people incapable of learning dvcs because it's inherently more difficult than a centralized one. what he describes for subversion 2.0 would be *awesome*: offering the existing pool of subversion users contact with this alien landscape of nightmares and cacti and adapting to users' demand. cvs did the exact opposite and now it's obsolete. it's awful that the weblog article had to conflate that great bit of news with assuming dvcs advocates think it's a perfect system.
it's not finder. i don't even have finder running :-)

at least in my case, the enthusiasm is for quicksilver (http://quicksilver.blacktree.com/), pathfinder (http://www.cocoatech.com/), and zsh (ok, the last is in no way a point for osx). 
&gt; your example benefits from the choice of line break conventions.

not really, vb has line-terminated statements.

&gt; ultimately after compilation it's going to be a for loop anyway, and there is also going to be overhead to that function call, isn't there? (in a blue sky future which we may see later, compilers may grab it and parallelize and produce code even faster.)

no blue-sky here, vb uses a jit that will inline functions as it sees fit. since this is a post-compile time process, the inlining can even occur across libraries.

&gt; but the for loop to me is a perfect example of an good tradeoff between being aware of what the computer is actually doing (again, in our present time), and being simple.

in the simple case yes, but it creates a path for handling complicated code. 

consider this task. get a handle for all processes with a name matching the pattern "*deven" and using more than 1000000 of memory. order the list by process name and pid.

here i show doing that using both linq and dot notation:

    dim list = from p in process.getprocesses where p.name like "%devenv" and p.workingset &gt; 1000000 order by p.name

    dim list = process.getprocesses.where(function (p) p.name like "%devenv" and p.workingset &gt; 100000).orderby( function(p)  p.name, function(p)  p.pid)

to do the same thing using a for loop would require creating temporary collections for filtering and sorting, which certainly cannot be done in a single line.

consider another example:

    dim list = from a in reallybiglist.forparallel where a.x &gt; 100 and a.y = 50 

by merely adding ".forparallel", i turned this into a multi-threaded plinq query wherein all the thread management and book-keeping is automatically performed for me. like openmp, but with even less manual work.


keep in mind that the .net langauges are heavily embracing functional programming. 
&gt; it also encourages anti-social behavior.

&gt; [...]

&gt; in a nutshell: with a centralized system, people are forced to collaborate and review each other’s work; in a decentralized system, the default behavior is for each developer to privately fork the project.

yeah, right, except that's of course not the case, doing that is the same as having your little patchset of your own, which you can do just as easily with a cvcs. and as far as being forced to collaborate with a cvcs, i've seen enough *fire and forget* to know that it's definitely not the case.

not to mention, of course, that dvcs allows and encourages sharing of changes between developers (privately or through public repositories) without having to go through the main repo (because your developments are unstable for example, or because two subsystems both in unstable states need to collaborate with one another). these are both highly social behaviors encouraged by dvcs and downright impossible with cvcs.

&gt; the default action is to fork, not to collaborate!

the default action is *always* to fork, the difference is that a cvcs forces you to "collaborate" (or not, once again see fire and forget) every time you want to save your current state/progress

&gt; this encourages people to crawl into caves and write huge new features, then “dump” these code-bombs on their peers, at which point the code is unreviewable.

wtf?

&gt; most dvcs systems don’t run on windows at all.

he mentions 5 dvcs earlier: git, mercurial, bazaar-ng, darcs, monotone

mercurial has a pair of native  windows installers and works flawlessly, bazaar-ng is pure python so i doubt there's any problem, darcs didn't have any problem under windows when i tried it, git is very shaky but getting better and i don't know about monotone.

*that*'s supposed to be "most dvcs not working on windows"? come on, let's be serious for a second...

&gt; most dvcs have no shell or gui tool integrations; they’re command-line only.

wrong again, see gitk, hgk, qct, git-gui, qgit, ...

&gt; they often struggle to use version control at all; are you now going to teach them the difference between “pull” and “update”, between “commit” and “push”? look me in the eyes and say that with a straight face.

i managed to teach it to a graphist (sp? a guy who mostly does drawings and a bit of as programming). now he's admitedly not *stupid*, but if you have devs who can't grasp the concepts of commit/update and push/pull, stick to visual sourcesafe. or fire them straight, because i doubt they'll be able to produce anything beyond security holes and office politics

&gt; managers don’t want 20 different private forks of a codebase; they want one codebase that they can monitor all activity on.

once again, that's stupid. as soon as a developer checks a copy out, he creates a fork, i've seen people who didn't commit anything for 3 days and then wham gigantic ball of mud in your face. cvcs doesn't help. quite the opposite, really.

&gt; cloning a repository is bad for corporate security. most corporations have an absolute need for access control on their code; sensitive intellectual property in specific parts of the repository is only readable/writeable by certain teams.

er... yeah? so in a dvcs you'd either create different base repositories or use forests/submodules, no problem there.

&gt; no dvcs is able to provide fine-grained access control; the entire code history is sitting on local disk.

dvcs are (usually, i think git has some abilities with that) not able to provide fine-grained access control to a ball-of-mud all-encompassing repository because such a repository is fucking stupid. svn suggesting that this is the best model is *not* a good thing.

&gt; cloning is often unscalable for corporations. many companies have huge codebases — repositories which are dozens or even hundreds of gigabytes in size. when a new developer starts out, it’s simply a waste of time (and disk space) to clone a repository that big.

once again, back to the ball of mud, if you decide to use dvcs (not switch to, switching a ball-of-mud repo to a distributed model is hard) you don't ball-of-mudify everything, you separate your entities into different lightweight repositories. and you can do it, because setting up a web repo takes all of 5 minutes.

which, by the way wacks again the declaration that sharing requires extra effort. it doesn't, really, all the extra effort of mercurial is: put a cgi script in your apache cgi directory, add a config file, add an entry to your mod_rewrite or .htaccess to have nicer urls. there, done, and that's only for the first repo you want to share, the next ones you'll just drop in a specified subfolder.

the *only* thing that holds any water in his argument is that there is no stable, concrete, production-reagy tortoisegit, tortoisehg or tortoisedarcs. and that's a tenuous point, as much as i like tortoisesvn, it doesn't help you understand how svn works, and it usually makes it easier to fuck up everything because you get people using svn without understanding what they do.
single-threaded and -proc apps are not getting a free upgrade from processors any more.  you heard it here first.

also, startups don't always flip-- most of the time they don't.  

here's a useful approach that doesn't rely on hardware to save us:

make an ajax-y web app that does useful stuff, even if it's cpu-intensive.  have the app monitor its own performance.  when people run into a cpu limit, offer them an easy install of a browser-specific plugin.

there are still limits-- doing stuff in c is still only a linear improvement over js; some day you'll wish for multi-proc browsers.
the problem with lynx though is that it's just text. no galleries or tiny artists working from places you'd have a hard time visiting, no roadmaps for planning trips, no simple games to keep you occupied for a 15-20 minute span, much more weakened web applications. in short, text mode browsing eliminates much of what makes the web interesting. yes, one should check out to see if your page loads reasonably well with text mode browsers to make sure that the bots'll index them well, but at the same time, ignoring that graphic browsers can improve the layout of pages is a bit silly. additionally, a lot of the malicious parts of the web can be eliminated through usage of noscript and adblock; even text based ads which lynx will still show.

finally, even irc is better with a graphical client. programs like xchat make it much easier to keep track of what's going on, letting you keep state in more interesting tasks. and i won't even get into emacs...vi is so much better :p.
ah, i see—it's the markdown source, url-escaped.

a bit strange, but then, javascript has url-escaping function and not (afaik) entity-escaping functions, so it makes sense. 
the problem is that all content is not textual. visual materials can be, and in many times are, more important than textual content. additionally, a good layout can assist in the understanding of a topic; sidebars, etc are very difficult to do with text-mode browsers. the world's not a tty, so why should your view of it be?
i've just got a thinkpad t60 and it's fantastic. everything works under linux, wireless, hibernate, etc.

i also recently fell of my push bike with the laptop in my bag and the laptop taken the brunt of the fall (about 35km/h down a hill and yes it did hurt!) it started up perfectly afterwards. it is slighty bent though!
greenspun's 10th law strikes again.  this time: programmer implements "and" macro as non-short-circuit method!
basically yes. slashdot has been taken over by astro turfers and shills and it would be really sad to see reddit turn out the same way.

perhaps it's more accurate to say that most of the hardcore geeks have left slashdot and left the astroturfers and shills behind. 

either way the same result.
prediction: in the long run this is going to turn out bad for the osi and is going to benefit the fsf.
great read. any more stuff like this out there?
well, you've got a choice: deal with the stuffing of ballots or block large chunks of your potential users. personaly i go with dealing with it rather than loose users, but that's just me.
actually, my graphical browser with adblock probably has fewer ads than your text-mode browser without.
????
?

how did i lose you?  :)
i meant "server" more in the sense of a daemon running that you need to send your files to. also, isn't cloning a directory effectively the same as copying it? in hg it said it was an equivalent operation.  

i like branches so far, i think this will actually get me using them, although i'd prefer it if they were in-tree because of all the django-files that aren't in vc in the directory.  

by the way, on the "working directory/repository" stuff. i can't have one repository with my directories spread around the hard drive, can i? from what i understand, the working directories in the repository should be under a main directory. right now i have one svn repository for all my code, and i just make folders in that, and would like to recreate this in hg if possible (so i could have one directory on the server to push to, but i guess i could recreate the setup by having multiple repositories under a "repos/" dir on the server).
&gt; for(int i=0;i&lt;rows.length();i++) rows.objectatindex(i).dosomething();

it's not the \*writing\* that's the issue, it's the \*reading\*. i spend substantially more time reading code than i do writing it.

old-style java loops throw too much syntactic noise at a reader (as does much of java in general).
 &gt; there is *no* way in which explorer is better than finder.

- the 'folders' sidebar.
- consistent drag/drop behaviour.

oh this is so freaking cool.

guy steele is a superhero, poet and a gentleman!
 it's really hard to agree with most of that.

regarding corporate use:

&gt; managers don’t want 20 different private forks of a codebase; they want one codebase that they can monitor all activity on.

if i have two branches, it means i can work on two different features on two different schedules independently.  when someone says, ``hey!  stop working on project x.  we need to ship project y rsn!''  i can just jump over somewhere else without losing my place.

the reality i've experienced working with distributed revision control in such projects is that they're quite happy to see my flexibility.  much more so than either of introduction of broken trees while in progress or long time delays with giant commits (more on this below).

you know what else they wanted, though?  the ability to ship a project off to an outsourcing facility, have them do work, and ship changes back in such a way that we could possibly integrate them back into our system.  that's an excellent default distributed systems give you.

&gt; cloning a repository is bad for corporate security. [...] no dvcs is able to provide fine-grained access control.

is it somehow worse to grab a tree with usable history than it is to grab the head-of-line code?  i don't buy that.

&gt; cloning is often unscalable for corporations. many companies have huge codebases 

would you say that there are actually multiple projects within these companies?  you either need it all, or you need parts.  if you need parts, you break stuff down into parts.  if you need it all, you will probably find that a mercurial clone and working directory is probably not bigger than a svn working directory.  it's certainly more useful, though.

this also relates to the security prod above.  if there's a sensitive part of a tree, it is a different project.  people already treat subversion trees as individual projects.  just call it what it is and protect the parts that need protection.  move on.

&gt; with a centralized system, people are forced to collaborate and review each other’s work; in a decentralized system, the default behavior is for each developer to privately fork the project

with branches and easy ways to share things, it's easy to make changes and have the changes peer reviewed before making them generally available.

in my experience with centralized systems, people are just afraid to commit anything because of a fear that it's not quite ready, or it's broken and people shouldn't have to deal with it, etc...

i've had two individuals who would try to get as much work done as possible before checking anything in.  no interim state.  no ability to even see if the project is moving in the right direction.  lots of yelling.  this was all with centralized systems.

one of these guys was a contractor.  i desperately wanted to be able to just pull changesets from him without having to give him access to perforce.  i could've done something similar with a p4 branch in the first place, but we failed to think it through.  pull and review (in a temporary location) is a perfectly reasonable practice in a distributed system.  you can't even do that in centralized systems without at least giving them write access *somewhere*.

&gt; there is no magic bullet for version control.

the only place where mercurial (or pick your dvcs) isn't a superset of svn is in using it as a generic file backup mechanism where you have no project-oriented structure.  most dvcs aren't good at that.  after having dealt with complicated cvs modules, perforce client specs, etc... i'm rather glad they require you to make a project tree a project tree. 
 &gt; most gui source control tools suck. i'd posit that tortoisesvn is an impedement to understanding svn, not a coenzyme, because it abstracts the up, merge, code, diff, and checkin cycle into a bunch of context menus.

as someone who's had to try to explain subversion to coworkers at my small (not windows, per se) shop, i disagree with this.  it seems far easier to explain in practical terms what subversion is doing when i can demonstrate with menus and have icons to show feedback (green check means nothing needs committing, etc).  and while i'm sure they don't fully understand what all subversion does (i've had to explain the concept of merging multiple times by now over the course of a few years), i don't think it's absolutely necessary that they understand all the details.

as for your second point, given the problems i've had describing subversion to coworkers, getting them to understand dvcs with its local branching and committing and etc. would be a huge pain in the ass.  there is no denying that the conceptual model of cvc systems are a lot more simple than dvc systems, so i think he makes a valid point.  this is a big reason why i haven't switched to mercurial here at work.  i would love it, but i don't think the people around here would understand enough about it and would end up hating it for irrational reasons.
sure. it's not like i don't know about that. most of my non-work code is in scala or haskell, both of which can quite handily manage laziness without macros. but java doesn't have macros, does it? this isn't an excuse to just throw your arms up in the air and say "oh well, my language doesn't have feature x that i'd really like. i'm just going to write lots of verbose and repetitive code instead!". if you can write tidier code within the language then you should do so, even if it causes people to whine about greenspunning at you.

the lack of short circuiting doesn't end up being much of a problem for the use cases i had for it (it mainly gets used for tidying up some if statements in which the expressions tend to be constant anyway)
&gt; (fun for geeks: find the technical flaw in the above.)

qwe1234 is inimitable.
&gt; in the rest of the world, when you introduce a product to compete with existing products, you evaluate the shortcomings of your competitors and address those needs to build a superior offering. outside of silicon valley, we call this innovation.

i think that pretty much sums up my feeling about most new products these days.
no they shouldn't. blind people need to be isolated and studied, so it can be determined what nutrients they have that might be extracted for our personal use.
&gt; and more to the point, zoho is very sellable. as a startup, they are right to focus on what they can flip and not what users might actually need.

if you don't focus on what users actually need, you don't have a product. if you don't have a product, you don't have anything to flip.
and reddit developers certainly need to ensure that they drop all their work to make sure the one guy who is doing all these things is happy.
 you could also speed it up by using a [workerpool][1] if google gears is installed. it's not as though there aren't people working on this problem.

[1]: http://code.google.com/apis/gears/api_workerpool.html 
&gt; if i have two branches, it means i can work on two different features on two different schedules independently. when someone says, ``hey! stop working on project x. we need to ship project y rsn!'' i can just jump over somewhere else without losing my place.

you can do that in subversion, too.
i don't see why. i really don't understand the argument for not approving the licenses. the terms meet the requirements of the open source definition, or they do not. if they do, the licenses can be approved and software released under those licenses will be officially open source.
&gt; what about
&gt;
&gt;public static final boolean mightbenull(object inobject) {
&gt;          boolean retval = false;
&gt;          return true;
&gt;     }


*that* had to be the best comment.

&gt; an intelligent live form

life-form.

just saying.
i cannot see the article's screenshot in my text-only browser!!
that's not uncov's; it just happens that one of the uncov guys works on it.
 well, two points:

1) how easy is an after-the-fact branch in svn?

2) the argument here seemed to be that branches are bad. 
pushing and pulling doesn't copy the files, it copies the changesets.  the working directory is an entirely different matter, and is constructed from the changesets.

cloning only copies the changesets that have been committed.  copying does all of that plus your working directory (in whatever state it's in including local edits), tmp files, etc...

you can branch in tree.  every time you commit against anything that's not tip you create a new head, thus a new branch.  you can even [name your branches](http://www.selenic.com/mercurial/wiki/index.cgi/namedbranches) so you can easily find them again.

a given project should have an obvious root.  for example, in a django project called *foo*, you might have something like this:

    .hg
    foo       # the code
    templates
    media

that's typically what i do, although another project i'm working on put the templates within the code location.  same concept.

from there, i generally have a script that deploys the code by putting the various things in the various places.  that works out well because it also makes sure the same thing happens and keeps all of the parts of the tree on the same version.
   i use c++ at work. no c - i can't live without classes and stl - especially string and hash_map... :). yes i use c++ because of speed and memory footprint. 

application i wrote replaces the original perl code (written by really best people who are perl gurus!) and uses  3-10 less memory and it is 3-4 times faster. yes memory footprint is f..g important to me - today i have some data set that eating all memory on 16g machine and running for 2 days. in previous implementation it would be needed  64g and would run for week. 

no [joel's rule](http://joelonsoftware.com/items/2007/09/18.html) does not work for me - every 2 years data sets are expanded in order of magnitude (or at least x2-x4). because i work in industry where we create for you this x2/x4 transistors every 2 years :) on chip.. heh

yes i use macros - because we don't have closures in c++ , and writing functor for every utter shitty loop is depressing. and we use macros for code generation. but from another side - all our code compiles to tcl library and so it is actually dsl. and less important code and gui and reports and some similar shit is written in incr tcl so it is oo scripting (3 times faster  to write and less time to maintain). 

you know - sometimes performance and memory do matter! and if you don't believe go and read fucking stories about people who wrote their shit in ruby  on rails and have not succeeded to scale it. and you know what - when you hit that wall - it hurts. it hurts because it hit you in absolutely bad timing and because you can't fix it - except totally rewrite! 

writing c++ code is strange experience.. you have a lot of power. but you waste your coding skills on writing endless iter=begin(); iter !=end ; ++ iter...
 
but what if you want your web apps to work?
true. the real one would have just made everyone angry. i've just managed to gather interesting perspectives from c++ programmers with a variety of experience, who found flaws in the argument that i didn't even think of.
i think i remember microsoft, didn't they have a couple of popular os's in the 90s? g4 had that "behind the music" type show recently, and can you believe bill gates is now a copier repair man?!? how the mighty have fallen. 

gotta run, my new sphone is ringing!

maybe it's just me but = for assignment and =? for equality seem to be really clear and intuitive.
i can show where java outperformed c++ in a single test.  but using that same benchmark site c still, on a large average, beats forth:

http://shootout.alioth.debian.org/gp4/benchmark.php?test=all&amp;lang=all
&gt; hm, maybe doing all of this floating point arithmetic in javascript in a single thread that also does your rendering isn't such a hot idea.

javascript is single-threaded. you don't really get much of a choice. (i ran into these kinds of limitations with some of my [javascript animation experiments](http://sandbox.mikepurvis.com/js/clock/))
c has a _very_ concise _specification_. this has made the tedium in typing more to program in it much more bearable, for a single programmer may hold much of its semantics in his head at once; and furthermore, such a compact language is far easier to port to other  hardware/os platforms.
"consumers", then. the consumers of the kernel are the distro companies, just as the consumers of car engines are car companies.
**wt\*f\* can't i reply to any messages sent to me on this thread?!?!?!?!?!**

anyway...

**@ cratuki**
&gt; alt tab

i don't see ay real difference between alt-tab and cmd-tab (except that cmd is a bit easier to hit for me).

cmd-backtick switches between app windows, not alt-tab.

**@ enneff**
i guess i didn't use the folders sidebar much, but yeah, it's slightly more inconvenient to open another window for copying from one folder to another.

so far dnd has seemed \*more\* consistent on the mac, but i just got it, and don't really do much dnd except for opening documents, copying/moving, etc. so that may yet bite me.
 exactly the same here. i *love* haskell. but my most serious complains are 

* bloated executables w/ ghc (which is a technical problem)

* unpredictable space (and sometimes, time) behaviour (which is more like a theoretical problem) - though i wouldn't call it "leaks" 

[edit: markdown]
*sigh* more anti-intellectual nonsense.

to anyone who cares, if you want to comment on lazy evaluation, its impact and its consequences, please learn the fundamentals of the topic at hand first. is this an unreasonable request? i sincerely hope not.
excellent. very excellent. :) 

really. who cares about text only browsers? i'm asking honestly, and without sarcasm.
&gt; 1) how easy is an after-the-fact branch in svn?

	svn cp -rhead trunk branches/foo
	svn ci branches/foo

&gt; 2) the argument here seemed to be that branches are bad.

the argument in the article was that having multiple repositories is bad in a corporate environment where somebody (management) will want to monitor the code.

with a dvcs and one branch per employee, the manager must poll every employee's branch to:

1. see if it has any code not in the main branch (the trunk, as it were).
2. evaluate how ready that code is to go into the main branch.
3. if appropriate, tell the employee who owns that branch to push his changes to the main branch.

the obvious way to simplify that is to have one branch per task (such as a big feature that shouldn't go into trunk until it's done) rather than one branch per *employee*.

those per-feature branches don't have to be separate repositories; they work just fine all in the same repository. once they're all in the same repository, you're basically not doing distributed version control anymore.
wow, ugly.

i recently did something similar (but, you know, useful) in a class on c++. i needed functions in a base class to be able to create objects of the correct type for derived classes, so each derivation replaced a virtual 'create' method that looked similar to this.
i can see how state threading would get more difficult in large apps.

possible solutions include going the erlang route of using many small message-passing processes.  i'm not aware of anyone doing this for pure fpls though.

another approach is [functional reactive programming](http://www.haskell.org/frp/) in haskell.  however, this hasn't been used on a wide scale yet.  so while i think it is promising, the benefits of this approach remain to be proven.
bindings is lame and coredata is a joke.  impossible to debug.  stick with target/action/datasources.



you want a smalltalk - visualworks (if native look is at all important) or squeak/morphic (if you are wanting to totally go your own way).
they've fixed that, now, but now it's omitting line breaks.
[read his bio](http://en.wikipedia.org/wiki/guy_steele), is there anything this guy hasn't worked on?
yes, i've used latex, and i've used latex with [sffms](http://mcdemarco.net/sffms/) (which i liked).  and i've come up with my own stoopid simple markup that converted to latex.  but editors (i write short fiction) usually (i won't make up a statistic, but *usually*) want a word document when they accept the story, so i wind up having to put it into some word processor or another anyway.  so.
yeah, but it's got a cool kind of reflection that, err, isn't a reflection. okay. worst logo ever.
&gt;i don't see why.

microsoft will devalue the brand by talking about their approved and non approved licenses as being "open". this will render osi approval meaningless.

&gt;i really don't understand the argument for not approving the licenses.

* osi is under no obligation to approve every license that fits their description
* osi has already stated that they think there are too many open source licenses.
* this license is "similar enough" to other licenses and it could have asked ms to use an existing license.

&gt;if they do, the licenses can be approved and software released under those licenses will be officially open source.

yes they "can be" but nowhere does it say they "must be".

if your point was a googlefight, just change "haskell" to python or any other language and get even more hits.

fergus' statement doesn't match your claim, either.
who is your ideal bodybuilder to carry your desktop around for you?
do they have any case insensitive collations yet?

why did a programmer cross the road?
so there's this software manager out in the middle of a cornfield fishing...
a priest, a rabbi, and a business process modeling manager walk into a bar
wow, he looks a bit different than i thought he would.. :-d

i have a question. when he talks about a small language that is designed (deliberately or by coincidence) to allow for clean growth, isn't he implicitly talking about lisp? i mean, why modify a bloated beast like the java programming language, while you already have most of what you want (if not all) in a small, time-tested language?

is there any other reason than that he works for sun, and that the java programming language is commonly used for enterprise software.
i am gonna submit all of these 
bad. very bad. give the credit to the right person, irongeek

http://www.irongeek.com/i.php?page=security/networkprinterhacking#changing%20the%20lcd%20display%20text%20using%20hphack,%20ighphack%20or%20hijetter
&gt; author treats his 80% category like they're completely retarded people incapable of learning dvcs because it's inherently more difficult than a centralized one.

i consider myself to be among the 80% who see programming as a job, and i didn't get that impression at all.

&gt; most gui source control tools suck. 

and all command line source control tools suck even worse.

if the mere act of trying to edit a file in visual studio doesn't cause a check-out, then it is a non-starter for nearly everyone i have worked with in the last 4 years. 

source control needs to be seemless if you expect people to use it correctly. if you have to open a shell and remember esoteric commands just to label a branch, no one is going to do it consistently.

the major issue is probably firefox's utterly lame memory allocator, which i think is being updated in f3. anything creating and deleting thousands of objects is going to have poor performance. 

speaking of which, reddit sure is borked up these days.
the part you highlighted was in reference to stable checkins as cavemike clarified.

i've been getting burned a lot with the current team where "stable code" isn't stable. so i check it out into my dev tree and i lose 3 hours trying to figure out why things aren't working.
sweet! i can make it say "paper jam" when there is no paper jam! now i just need to find out where that sameer guy is working now...
the general status message was "00 ready".

when i worked for aol about a decade ago, i used to telnet in to printers in the various departments and change the status to made up{1} codes, like "10 willing", "20 able", "50 pensive", and "666 on fire".  i was able to do it for almost a month before they suddenly all became password protected.  apparently in going around randomly i'd eventually done it to the one in steve case's office, and he brought a hammer down on the it people.

{1} "printer on fire" is an actual historical [status message](http://en.wikipedia.org/wiki/lp0_on_fire) from unix, dating back to the tractor-fed line printer days.
that is a great and very valid point.

it's amazing how getting stuck by yourself with the 200 hours of overtime bag because of a decision the "team" made 12 months ago makes you feel like less of a team player. :)
hey kids, lets all sing "we love factory methods!"
this sort of construct might only make sense in a factory or builder pattern where you may need to perform some sort of complex and/or configurable initialization of the object.  obviously that is missing in the example.
don't you, uh, think that was his point...you know, if you're going to write an application that would benefit from the ui and fp math happening in different threads, maybe you should choose a platform that, uh, supports it?
omg, it works! :-)
atozand1to10:

it is very interesting that so many people have independently been provoked by the same hpjpl manual and chosen the same message "insert coin" (probably because it is just the right length for the old lcds).  in any case, when i saw all the traffic on my site i started to look around and found the site you mentioned, as well as a dozen others, some even using perl.

i wrote that post because because several people had asked me for the program.  do you know if the win32 program on the irongeek site is functional?  i am unable to test it.  if someone can tell me i will put a link to in the post.
blind people.


someone, somewhere, liked it:
http://www.digg.com/offbeat_news/help_has_anyone_seen_this_error?t=9856649#c9856649
 that's not an after-the-fact branch.  that's a planned branch and a checkout.  how do the changes you've been working on get into that new tree you checked out?

in a distributed revision control system, you might have been committing changesets for a while, and then decide you don't want to push them so you just move the tree out of the way (or push them as a different branch or whatever).

i don't get your argument about having a manager going around looking for people's work to be ready.  that doesn't scale anyway.  if your developers are not checking in code (centralized or not) when it's not ready, does your hypothetical manager go digging through all of their filesystems looking for uncommitted files?

it's the developers' responsibility to provide code when it's ready. 
there needs to be an 'ancient hacks' subreddit.


subversion was designed for the 20%, not the 80%. but the author maintains that dvcs shouldn't be designed for the 20% because the 20% are wrong this time? meh... sounds like sour grapes to me.
greenspun's isn't suggesting to throw up your arms and write ugly java. it's suggesting that you stop using java in the first place.
pretty much a metaphor for their security in the early days. :-)
my current office printer is an hp 4200.
as much as i like irongeek, he is by far not the first person to post about this trick on the internet.  
"your consideration" just means "something for you to ponder.

my comment was a bit snarky--sorry.  i'm just so f*cking tired of having to debug crap perl.  i'm aware that in principle one can write perl that's reasonable (the inherent flaws of the language notwithstanding), but that's not the kind of perl i ever see.
fast: yes. less memory: yes. concise: no.
i think it's best to have the symmetric one be used for equality (since equality is a symmetric operation) and the asymmetric one used for assignment.
i bet these days you get very exciting responses if you change the message to say "impeach".
good idea.
get a job you bum
thinkpad r40 - 512mb ram -&gt; runs eclipse -ubuntu no problems!, 
no, you don't understand. what you do is cherry-pick the data to support your own conclusion. all the previous years are irrelevant.

nonetheless, the icfp contest "results" are quite useless. (begin rant) specifically, the winning language of a given year is irrelevant. you can write correct programs in every language. given that the participant skills is never equally distributed, if you have a particularly good hacker entering the contest year after year, his language will win year after year.

what really matters is the cumulative success of all participants using language x. you want to look at languages with the highest average score with high enough standard deviation to reach near the top of the score table. (end rant)
ssh
so! i maintain my company's svn install. we're a mostly windows, c#/python/perl shop. i am certainly no svn partisan; the things i really want from dvcss, in order, are:

1. easy branch and merge. svn branch/merge sucks.
2. offline commits
3. cherry picking commits

that said, i'm very happy with subversion, and i have no plans to move to a dvcs for my office setup. the reasons are twofold:

1. ankhsvn/tortoisesvn are indispensable to me. without visual studio integration, a source control system won't fly at my office.
2. our model is centralized, and we would gain very little from a decentralized setup. this seems to be a point you disagree with me on; i'm addicted to my "ball of mud" and us developers all "fire and forget".

what i'd like you to do is explain to me what my office of 5 people, all of whom work in the office, in 2 rooms right next to each other, would gain by switching to a dvcs (assuming tool support wasn't even a problem).
i think it's more likely that ocaml is perceived as a faster language than haskell, and the data processing in this year's contest made speed of execution very important.

the oo features of ocaml are not generally considered its strength (indeed, some have gone so far as to call it a misfeature). the writeups i've seen that used ocaml weren't using the oo features at all.
i'm trying to look at how to parse web sites for  information.  the parser might do various things  such as:  summarize the web site, figure out the company name, figure out people involved with the company, categorize the industry of the company, and be able to answer basic questions about the company

does anyone know what the best/definitive framework is for nlp?  thanks.
[here](http://www.google.com/search?q=dvi-d+splitter)
depends if that benefit outweighs the tremendous accessibility win of an application that can be used without any additional downloads or plugins.

and by the way, even without real threads, there are ways to deal with a background job that's freezing the ui. continuations, for example, where you partition the work into batches where each piece finishes by triggering a zero-second timeout to start the next piece. those timeouts give an opportunity for ui events to queue up and fire in between chunks of processing.
interesting.  and refreshing -- apple was on the ecma tc behind ooxml, but it looks like they're fine being more flexible with their formats.

others could learn...
pc load letter? what the fuck does that mean?
sort of.  however you also have to figure out where your compitition is doing something you don't need to now.   if you want to compete with excel you are better off with a small product you can sell now to keep money rolling in while you try to clone the 20+ years of effort that went into creating excel.  of course a lot of that was wasted on porting (dos-&gt;window3.0-&gt;window95) that you can skip, but still, microsoft has spent a lot of money.  if you try to make a perfect excel killer with no releases until then you will never finish (at least not within any lifetimes).  
&gt; how do the changes you've been working on get into that new tree you checked out?

omit the -rhead part and it includes your local changes.

&gt; in a distributed revision control system, you might have been committing changesets for a while, and then decide you don't want to push them so you just move the tree out of the way (or push them as a different branch or whatever).

yes, that's their strength. the article discusses their weaknesses.

&gt; i don't get your argument about having a manager going around looking for people's work to be ready.

not my argument. it's sussman's argument.

&gt; that doesn't scale anyway.

it may not need to. not every development team is large.

&gt; if your developers are not checking in code (centralized or not) when it's not ready, does your hypothetical manager go digging through all of their filesystems looking for uncommitted files?

sussman's hypothetical manager would, hopefully notice that they're not committing anything and tell them “hey, start committing!”

of course, this applies equally to pushing in a dvcs, which is the problem: the manager may not want to monitor half a dozen or more different branches, so he'd order the employees to all push to a central repository at least every x interval, thereby destroying the main advantage (wholly-separate branches) of a dvcs. it'd basically be just like a subversion repo. 
i got this done this morning. i think it's funny for two reasons. 1) it's an anchor. chuckle. 2) i've got a retarded nerd joke tattooed on my arm. i might as well chop my little fella of right now...
at some point, this was standard:

    push returnaddr
    push arg1
    goto sub

    ...


    sub: pop arg1
    ...
    pop returnaddr
    push result
    goto returnaddr

people did that all the time. it was incredibly intuitive to them.

but it was still error-prone and cumbersome. it became worthwhile to come up with a more abstract representation of the concept. so the subroutine (and, from it, structured programming) was born.

yeah, for loops might be intuitive to you. but how often do you do for loops over an array or list, modifying each element in a predictable manner? if you're like me, you do it a lot. and so there i use an abstraction of that process: map or a list comprehension. though there was an initial learning curve, maps are now incredibly intuitive to me.

they have become so intuitive, in fact, that i deal with them more easily than i deal with for loops, despite having learned programming in languages without those facilities.
yes and no. microsoft has a few things going against it. 

first, they have to support everything they ever had, even the really stupid features.

second, they have a really old code base in a poorly designed language. this makes it hard to make changes.

third, they have a com based object model. besides the inherit cost of maintaining that api, com is very hard to version.

fourth, you can only throw so many people at a project. sure microsoft can max that out with enough money, but no one can exceed the natural max for a project.

fifth, excel is tied to vba, a dead-end language. you could build the macros on .net and easily steal a lot of windows developers away.

i'm not saying it will be easy, but i do think excel is ripe for being replaced. but like the lotus take-over, it will take many years and versions.
 
that said, i agree with you when you say "you are better off with a small product you can sell now". lotus wasn't replaced all at once, and neither will excel.
yes because, as we are all aware, graphical browsers remove all text before rendering the site. i'm using firefox but am able to read this comments page by using the mitochlorians.
it's weird, every time i see a paragraph starting with "webster’s dictionary defines..." i automatically skip over it. i've noticed this before, too. i wonder how long i've been doing it? do other people do it subconsciously?
warning, this is the wrong way to solve the problem.  the correct solution involves the program that knows what window is active: the window manager (there are over 100 different "common" ones and untold more rare ones, but you only need to worry about whichever you use).

this code works, but it wakes up the cpu every second.  linux devs are putting a lot of effort into making linux wake up less often, to save power.   (i'll ignore that it missing windows active for less than a second, such windows probably are not important anyway)

you window manager already has to wake up when you change the active window, so you don't need to poll. 
 exactly! reddit will claim that they are the ones following standards, lynx will claim that they are the ones following standards. if they do it, it's called terrorism. if we do it, it's called exporting democracy. 
i would have thought that what you wrote was obvious.
you fail the validator for every vagina on earth.

i was just about to ask why chromatic didn't send his solution to the [rescuetime](http://www.rescuetime.com/) guys and get paid. now i know why he wouldn't, or at least shouldn't.

good explanation blugill :d
[ralf roth](http://www.ralfroth.de/)

dr.ralf.roth@t-online.de

is probably the same guy who found two bugs in tex, no? 
to use a functional programming language!
yeah... you might want to consider having it removed as soon as possible.  i'm not sure if timing is a factor for tattoo removal, but you better not take any chances.
90% of anything is crap.
god forbid someone has a life outside of writing code 24/7.
mustafa's last name is sait-ametov:
http://www.imath.kiev.ua/~snmp2003/abstract2003/sait-ametov.html
it can be easily "fixed" if they get rid of tables... all main content than can be in normal flow and navigation/ad block can be right floated.
dag mellgrin is probably [doug mellgren](http://www.google.com/search?q=doug+mellgren).
shlomo varsano filed [us patent 20020129157](http://www.freepatentsonline.com/20020129157.html) in 2001. his phone number is [apparently](http://64.233.169.104/search?q=cache:tmwmiqf9wtej:www.speechco.de/down/be-pbk.pdf+varsano-shlomo&amp;hl=en&amp;ct=clnk&amp;cd=3&amp;gl=us) 310-335-1074.
i love some of the typos you see online:

"right media, co-founded by brian o'kelley, was valued at $200 billion when yahoo invested in 2006. six months later, it was worth $850 million when yahoo bought it."

i knew yahoo wasn't so hot, but i didn't realize they were capable of losing 199.150 billion dollars in just six months!
&gt;of course, this applies equally to pushing in a dvcs, which is the problem: the manager may not want to monitor half a dozen or more different branches, so he'd order the employees to all push to a central repository at least every x interval, thereby destroying the main advantage (wholly-separate branches) of a dvcs. it'd basically be just like a subversion repo.

even in this worst case scenary, distributed vcs beats subversion. 

in this scenario, with subversion, you get precisely one patch every x interval "partially build feature, doesn't work yet, but boss requires us to commit,...". in principle, the "..." hides a complete description of the changes the developer made and why. in practice, hah. 

with darcs/hg, you get the entire history leading up to "partially built...". all the developers have to do is commit whenever they make a chance, and you get a complete history of the branch. 


ruby is definitely used (there were around 1000 teams all up this year, and some had "ruby" in their name). they just never do very well.

everyone asks why c++ beats haskell and ocaml for the first time in 6 years, but no one seems to be asking why the `scripting' languages do so poorly. and i don't really know why this would be the case.
it's ok - 95% of the enjoyment i'm getting is laughing at my own retarded ass.
hey, as long as you're happy with it, i guess!
quit dreaming about hacking haskell, and start doing it!
i think you're referring to when people commit such things to trunk. that's what branches are for: one developer creates a branch, the others check it out, and then work on that feature happens on that branch a commit at a time. when the feature is done, a developer merges the branch back to trunk and deletes the branch.

giant “code bombs”, as sussman calls them, are a failing of the developer(s), not the vcs.
jesus, if i took shit like this seriously i'd have to kick my own ass. i like to think that i'm taking a fall for the entertainment of others. i'm not sure i'm ready for a lifetime of reliance on prostitution though...
so you intentionally got a tattoo that would cause people would laugh at you?!

i'm astonished that you'd make such a decision.  i mean, people make poor choices all the time, but most of the time they don't realize that they are stupid choices until it's too late.  you, however, knew it going in and admit it outright.  wow.  just wow.
there goes any respect or giving-a-shit i had for the osi. they now join ecma and other standards bodies on that list.
here is a quick and dirty one:
http://okmij.org/ftp/cpp-digest/#iostream

no, i highly doubt it. his [cv](http://www.ralfroth.de/curriculum-vitae.htm) doesn't mention the universität bremen at all, but his former e-mail address has that as the address.

i assume you made this (most likely erroneous) suggestion on the blog too. please consider rectifying the comment based on this information.
enter the know
http://en.wikipedia.org/wiki/midi-chlorians
syntax error!
how about [ralf-roth.de](http://ralf-roth.de)?
having a representation of a parse tree is not lisp.  most (all?) languages can be represented with an ast.  the semantics of ruby (message passing, everything is an object) are not the same as the semantics of lisp (functions w/ closures).
 i care about text mode functionality too. glad to see the site admins take notice. 

http://wassupdave.wordpress.com/ (elinks for windows)
&gt; free, featureful spreadsheet applications (cough, cough, openoffice)

i take it you've never actually tried to *use* calc?
wow. what an elitist bit of writing. honestly the 80/20 rule applies here. 80% of people will be off put with the "zomg1337core h4x0rz!" tone. the other 20 will read it.

too bad because it has some valid points. 
nice how my question caused someone to take my measily point away. 

so, how does it help them? braille board, text-to-speech? it would seem that technology has gotten to the point that a text to speech system could deal with images, flash, et al.
guys thank you i will copy and paste some of your clues over to the comments on the blogposting.
weird, isn't it? a large part of my decision to do it was knowing that it was a fucking stupid thing to do. however, i have always believed that if you can't laugh at yourself, then you don't have a sense of humour worth shit. on the plus side, i'm tall, slim and damned good looking, and i can dance like a motherfucker.
did anyone tell richard stallman?
i have on occasion used lynx to hit reddit.  i always considered myself in a very special group totaling maybe .01 percent of users because of that. are there any statistics on the matter?
 &gt; "printer on fire" is an actual historical status message from unix, dating back to the tractor-fed line printer days.

not just historical; grep your nearest linux kernel source for "on fire." 
i quit reading this blog back around june or so, when it became obvious that the author wasn't posting any more. so now, i see this link, and i go back, and there are posts going back into last month...

... and the "archive" link is non-functional, and there's no other way to go back any further and catch up on the story.

i hate, *hate*, **hate** trying to pick up on a story with gaps in the middle.

nah, i'm dag...  i don't want to take money from knuth's pockets tho.  it was fun, that's what counts.
&gt; giant “code bombs”, as sussman calls them, are a failing of the developer(s), not the vcs.

on this point, we agree.

it is my experience that centralized revision control makes this phenomenon worse.  it is his hypothesis that distributed systems might encourage people to do it.
&gt; first, they have to support everything they ever had, even the really stupid features.

and so do you, because you won't get anywhere with a new spreadsheet if you can't import excel documents.
a dell running linux, simple.
ruby + hpricot 

you can also download the source code to watir and i bet it will get you 70% there.

 he complains about super large code bases being unclonable, but git at least (and probably others) support cloning up to a specific number of commits.  so get the last dozen commits on your hundred gig project and then you can pull and push back to the main repo same as you normally would. 
i have an excellent understanding of what's shown on the gentoo benchmarks game :-)
since my remark caused so much disagreement, here a brief disclaimer. there is of course nothing wrong with parser combinators compared to imperative switches and actions or compared to the go4 interpreter pattern. they are all on the same footing and just  fine when you have nothing else, your language is small ( or context dependent ) and your purpose is fixed. 

now i want deal in many different ways with a language as data. lets say i want to preprocess pythons assert statement to make it more expressive. the code needed to transform the assert statement acting on a parse tree is just a few lines: seeking all assert statement nodes in the parse tree. keep the content of the expressions passed into the assert statement. pass the content into a parser node constructor that expresses a function call. define the function. replace the original content of the assert statement and finally send the modified tree to the bytecode compiler. on demand unparse the tree again or at least the modified assert statement parse tree fragment and display it as source code.

i'd be rather pissed of when having to write a full python parser for any kind of action i want to define or even have to deal with textual substitutions as if i had a c preprocessor. 

in the end i split the problem of language processing into three distinct parts: creating a parse tree ( purpose of parser generators ). a library defining actions on parse trees in a uniform and language independent fashion. using the library and write code for a particular action as in the example above. 

in this picture the library becomes the crucial issue once the parser generator is established. and no i don't talk about xslt or xpath specifically although they are obvious library examples for xml based languages. i'd rather assume that xml based languages became so popular because of the lack of good libraries for postprocessing parse trees. imo this is the way to go not the regression into handcrafted parsers, or juggling with flexible syntax a la ruby or writing source code in s-expr style.

exactly right, but what fun is it to write code for only one of a few hundred window managers when i could write proof of concept code that "works" for all of them?  besides, i *have* the xlib book, but not an xfce one.

of course, my window manager can already detect when i've gone idle, which solves a deeper problem.
nothing, as far as i know. it's just a (irrational?) feeling i get when i see code in ml-like languages. i guess you could just chalk it up to first impressions?
i stand corrected. the full pdf does state that 26 teams were used ruby.
well, it seemed to me that it was possible his message could be interpreted that way, by some people. i said it, because i wanted to point out that there are flourishing efforts to do this already. i perceived, rightly or wrongly, that his message was posturing his idea as something new.

meaning can be conveyed in many ways, including some ways where the saying of the message is not explicit. there is sometimes an impulse in people to issue a counter-message that is directed at an implicit message, not an explicit one. i was acting on such an impulse. that's why.

gosh, i'm sure we both have better things to do now :-). have a great day/night!


please!? how hard can it be? this isn't programming related!

if you had spent $5000 for a tts or braille system back when netscape 4.72 was the standard, you would be pretty pissed that it's useless now. blind people don't usually have money to throw away.
hmm, someone wrote a letter to donald knuth, and then disappeared. repeat 7 times. you don't need to be smart to see a pattern here.

obvious donald knuth murdered those people so he doesn't have to pay them. he has the means, the opportunity, and the motive ! 
   i would also like to add; can we stop with the endless amount of pointless blog entries (especially on reddit) about "i did x (opened a file) in haskell".  they don't really further the cause of demonstrating the potential of the advantages of functional programming (but these entries might be good to post to a mailing list).  blog entries are great, but i think the excitement over haskell 101 tutorials is a bit much.

couchdb for example is a useful tool.  hearing about how a person converted his production rails/mysql application to a rails/couchdb (or whatever is trending these days) and how this company handled millions of requests a day might be worth hearing about.

i do a lot of those boring blog entries (because i can't write technical articles), so i am no saint in this area; but i am moving past the learning phase and jumping right into writing an application.  (and no saint in posting interesting functional development articles to reddit; so i will stop with the noise).

so, i would encourage others to follow suit.   and there is already a load of useful erlang and haskell programs like; couchdb, darcs, yaws, etc, etc. 
   
hmm, but, that supported images, etc. i'm still not clear why a text only browser matters. in any case, i'll do some research later.
i think "insert coin" message is dangerous. i'm more than sure that some lusers will actually try to insert coin into the device somehow.
this is the programming reddit, not the deprogramming reddit.
too bad there are no &lt;mother&gt; or &lt;battleship&gt; tags...
happy was unexpected at this time.
i interned at a software company this summer which used perforce. the very first thing my manager had me do was create a branch of the entire project tree. of course, since perforce is a centralized system, each branch lived on the server. so much for "centralized control"...
&gt; if you need it all, you will probably find that a mercurial clone and working directory is probably not bigger than a svn working directory. it's certainly more useful, though.

an svn working directory is 2x the size of a non-svn working directory, because there's a pristine copy of every file for quick diffing. a clone of a mercurial repository is probably much smaller.

they changed it so i can no longer select multiple lines of text. :(  my habit of web browsing is to select text that i've already read.  this makes it easier on my eyes.  the changes to reddit are very annoying. :(
importing and supporting everything are not exactly the same. for example, you don't have to support excel's concept of styles so long as you can support the underlying formatting.
&gt; chances are some other dumb company is feeling left out and will just buy up whatever is left, 

ok, i cannot argue with you there. long term its a bad idea, but if someone else is throwing away the money who am i to argue.
since most (if not all) of the points in the article are addressed to the 20%, i don't see that as a problem. there is nothing in the article that an 80% would care about... and why should they? subversion works fine for most purposes.
this used to bite me often enough that i hacked highlighting of comparison operators into emacs.
it's cleaner if, like me, you have adblock installed but not stylish.
to be fair, there are easily dozens of job postings for haskell out there.  most just haven't been posted to reddit.  i'll be writing one myself soon, though the project has now been postponed until january.
i've hit reddit from lynx a few times when x was broken and i was doing some work that didn't require me to fix it for a while, but i still wanted to waste some time.

it used to be one of the only sites i could waste my time on from a text browser.
oh yay, let's dumb down german cs even more, and let's become more silly and childish in order to appeal to girls who'd otherwise only touch kids and my little pony!!

seriously, if you want girls to not think software devs are freaky losers, how about doing *something about that*?  like, showing them that most software work is consulting which is just what your average mba does, too.

now, another few-years-ago sicp clone, as the one mentioned in the paper, might be nice, but will it help any more than the turtle did?  i don't think so.
it doesn't, but it's kind of a holy grail that some web-devs work toward.  the ultimate in graceful degradation is to have your site work fully in a text-only browser.  it ensures that whatever the user may disable in their browser, the site will still work.
 yupppppeeeee! microsoft is going the open-source way!! soon, we'll have .net under an open-source license, then windows, then microsoft office!!1 
i do. there's nothing like having that backup lynx or elinks on a secure connection when you're on a network you don't trust.

plus, the new reddit suffers the exact same way if you are using [opera mini](http://www.operamini.com/), as mentioned.  reading and posting on reddit on long bus/train rides is a great way to spend time.
the anti-microsoft shills should stfu now. now they've no reason to say that microsoft is anti-open-source.
great, someone took a lot of time and space to come up with and explian a very simple idea.

well, that's what you get for thinking in c++, instead of a real language (at a higher abstraction level).
what is the point of calling them "80%" and "20%" instead of "alpha coders" and "~alpha coders"? i mean, when you give them names like that, it is really hard to be surprised (and the article suggests people are) to discover that the "80%" group makes up the majority of programmers..... ;-)
amen to that. i hate computers, am becoming more of a luddite everyday, and i still program those poss. but hey, it's what i learned in school.
many years ago, i wrote a script to change every printer in my high school to read "out of water" (and to refresh the message from time to time).  this event actually resulted in some it folks calling hp to ask where to add the water to.

i still remember the look on people's faces when they ran over to show me "something odd with my printer".  gee, i wonder how *that* could have happened :)
it was a joke, you didn't have to take it that seriously :p
 &gt; 2 minor - 'object-oriented programming necessarily adds another level of indirection' - no, plain encapsulation can be resolved fully compile-time, and is part of oo.

you missed the larger context. he was talking about achieving *polymorphism* through object oriented programming. that does necessarily add another level of indirection. i guess some might consider overloading as a form of polymorphism, but most wouldn't.

he was wrong though about this necessarily imposing a performance overhead.

&gt; 2nd minor: "that's why nobody (who knows what they're doing) does oop in c++ today." - dumb, any other language would perform worse.

that's not true at all. c++ implementations often have performance characteristics that result in other language implementations being more efficient for many classes of problems, particularly when it comes to polymorphism.

in general, languages don't have performance characteristics, but rather *implementations* of languages have performance characteristics.
&gt; this is the about the ui for pagination.

same disappointment here.
 &gt; that said, i'm very happy with subversion, and i have no plans to move to a dvcs for my office setup.

i never said dvcs were the end of it all (and they're definitely not, in the real world dvcs aren't a strict superset of cvcs have a few drawbacks compared to cvcs, especially a one that is huge in some environments and wasn't even mentioned in tfa) even though i do consider them superior to cvcs in an overwhelming majority of situations.

i was only expanding and clarifying on the points of tfa i consider to be pure fud (pretty much all of them).

&gt; what i'd like you to do is explain to me what my office of 5 people, all of whom work in the office, in 2 rooms right next to each other, would gain by switching to a dvcs

in that case, in my opinion (remember that i'm not an scm guru), mostly the ability to fetch each other's tree/commits without having to go through a potential trunk-breaking commit to main.

for example, at the moment i work with a colleague which knows the codebase much better than i (and works on the part of the codebase that i hook into). sometimes i hit a bug or a bizarre behavior that doesn't seem to come from my code, and which i don't manage to trace back to the root source. the aforementioned colleague has his own environment (as in, a different one than mine) with several tools he uses and i don't (and i use both windows and osx, he's a quite hardcore linux fanatic, i'm an emacs guy he only uses vi, ...). our desks are around 3 meters from each other.

right now (the office uses svn), either he has to come to my desk and waste time with an unfamiliar environment he doesn't like and that lacks the tools he wants/needs (plus i ask him to come while i'm the one asking for a favor) or i have to commit broken/buggy features/changes to the trunk so he can update his wc and try to find what i missed.

with a dvcs, i could just temporarily share my local repository -- which is pretty much trivial (a simple `hg serve` is enough when using mercurial, for example), he'd pull from me (either into his main repo, or he'd clone to another repository just in case or if he's working on something else), work on his own machine in a familiar environment, and then push back to my machine (or i could pull from him).
 
"will anyone think of the stupid people!"
&gt; a clone of a mercurial repository is probably much smaller.

the clone of a remote hg repository (with full history and everything) is about the size of an svn wc i think (maybe slightly smaller), a git local repo is even smaller.

for both git and hg, i think the tool performs lazy clones when cloning from local (it uses symlinks when they're available, stuff like that)
you are entirely right with respect to memory usage.

why? because memory/cpu usage often depends largely upon what data the app will actually need to handle. this information is contained nowhere within the code.

in the case of memory usage, an app often cannot just decide to restructure how all of the data is stored and accessed at runtime - at least not without huge penalty. better that i just plan for this stuff ahead of time.
&gt; if the mere act of trying to edit a file in visual studio doesn't cause a check-out

the only scm i still use that has a notion of checkout is subversion, and it means creating a local working copy from a remote repository.

did you mean an update? or the completely stupid sourcesafy behavior of locking each and every file you want to work on?

&gt; if you have to open a shell and remember esoteric commands just to label a branch, no one is going to do it consistently.

i don't know about esoteric, mercurial has `hg branch branchname` to create a branch, and `hg tag tagname` to tag the current revision. 

doesn't seem *too* esoteric to me.
i think the purpose of java, based on his talk here, is to provide a useful set of operators and primitives and a reasonable first class means of adding  such things.
&gt; too bad because it has some valid points.

i have a hard time finding them, really.

the only one i found is "dvcs don't have a (stable, production-ready) tortoise*nameofyourdvcs*". pretty much every other point is dead wrong and/or stupid.
how could they forget "pirates of silicon valley"?
no, i'm dag and so's my wife!
quite a horrible article but upmodded because of cusp. it is neat if you want/need to use eclipse for some reason.
&gt;sure, zoho sheet is free, but so is gonorrhea.

not true. i paid $20 to get it from a hooker in hong kong.
 if comments are in a javascript array then browsers without javascript enabled won't be able to view the comments, and search engines won't be able to index anything other than duplicate content in the comment pages. 
plain html parsing won't cut it if you don't know beforehand what fields you are looking for. in the extreme case you might be reading a plain text file with no markup whatsoever.
*sigh* i meant the comments you are able to edit using the edit form.

all comments in html, editable comments in a javascript array.

for non javascript browsers do a reload with a edit form in place.
&gt; when there's so much piss code being written, you don't want to sink.

not sure what you mean here.  i don't think anyone ever wants to sink, never mind conditions.  maybe you mean if so much piss code being written, i am or should be afraid of sinking?  i'm not afraid.

&gt; and keep your mouth shut. and your eyes, too.

i don't.  never have and never will.

i generally don't make big waves.  when left alone i am quiet and harmless.  however if i encounter something that i need to discuss, i do.  if i find some particularly bad code, i bring it up straight to the offending programmer, 10 times, or 100 times, if i must.  once or three times a day.  as long as it takes.  if i get tired, i stop talking, but not because i am afraid or because i believe i should stop.  i just take a break and when i am full of new energy i talk again.

i'm not worried about any negative consequences.  so far the outcome of my behavior has been extremely positive.  people know that when i complain i love em (and it's not pretend love either, we go to lunch together, exchange gifts on occasion, hang out together, basically friends).  they don't like to hear me complain, but at the same time they know i am super-unlikely to go talk about it to some manager with the intent of getting someone fired, and that i mean well, and that not only do i talk about what not to do, but i show examples of what to do.  i keep my explanations free of jargon and use the simplest language possible that can still deliver the same quality point.

this has served me very well.  i am totally content.  i have no burdens on my conscience.  people don't mind my input (at least after they get convinced i love and not hate).

maybe not everyone can be like me.  i have some skill with my approach.  maybe if someone else tried to do what i do, they'd get themselves kicked out of the job immediately.  who knows?  it works for me.

&gt; when he talks about a small language that is designed (deliberately or by coincidence) to allow for clean growth, isn't he implicitly talking about lisp?

he explicitly mentioned lisp in this manner. then went on to say it isn't used as frequently these days and popular languages borrow features from lisp (his example was garbage collection).

you might like to know he wrote a book on common lisp and authored several popular papers on the language and was a co-creator of scheme.

i believe he was hired to work on java very late in the design process so the language would probably have turned out differently if he was there from the start.
wow, this perclid guy is harsh.

i think it's pretty funny. it's the kind of joke you'll have to explain to almost everybody, but that's not the end of the world either. (i have to carefully sort my stories and quotes and anecdotes into ones that will be gotten by non-engineers, non-web geeks, non-browncoats, non-swing dancers, etc.)

the only real risk is that we might all start using silverlight tomorrow, in which case you might feel like that guy who got a spice girls tat back in the nineties.
got it, thanks.

meanwhile, "snarky" is the usual mode for internet discourse -- no need to apologise.
he was not talking about the size of the history, he was talking about the size of the export, the number of files in it.
interesting how he rambles in presentations like he rambles in blog entries.

nothing against him, of course.  he's got some interesting ideas and is very intelligent.
&gt; source control needs to be seemless if you expect people to use it correctly.

yes and no. source control must be seamless if you want to force them down the throat of everybody. in which case this is nothing more than a sophisticated backup systems.

imho, version control *is part of the programming activity*. you have to think to tailor revisions suitable for reviews and history mining: short, standalone and logically consistent. otherwise, versioning is pointless. once you do that, the actual version control system operation cost is almost negligible.

the 20/80% percent split is not really about cutting edge/mainstream programmers but rather about those for who vcs are a programming tool like a good ide or compiler and those for who they are just an imposed burden.

&gt; if the mere act of trying to edit a file in visual studio doesn't cause a check-out, then it is a non-starter for nearly everyone i have worked with in the last 4 years.

i was going to give you grief about your choice of cow-orkers, but then i realized i haven't checked-out code in a long time.

so, what's your usual workflow? mine is:

1. have a clone sitting on-disk
1. make changes
1. record the patch locally
1. push it to the central server

note the lack of a "i want to edit *that* file, please; oh mr. sourcesafe, please let me edit that file, **please!**" step. 
mercurial can do the same quick diffing...but against any revision ever committed against the file up to the time you cloned it.  this obviously excludes any changes in other branches you haven't pulled, but you can pull those and they'll be there, too.

if the history is large enough, and enough files have moved around or been deleted or whatever, then mercurial's repo can get bigger, but it'd take a lot before it's *significantly* larger than svn (which doesn't include all the history).  i'd consider that good enough.
a shallow clone is mostly useless.  specifically, you can't push from it as you would imply.

as masklinn points out, though... that's not the problem.  the problem is that you can't just dump all of your code into a versioning filesystem and then later decide what your projects are by pulling pieces out of this large mess.

it's really better that way.  :)
 no it would not!!!! "dime-bar"?

have an &lt;a href="currentpage?f=edit" onclick="eip()"&gt;edit&lt;/a&gt;

for non js browsers, the currentpage is loaded, with f=edit, so an edit form is created. things work fine.
for js equipped browsers, the onclick call happens, and the eip function takes the comment out of its array, puts it in a div/textarea, and it works.

sorry if i'm not being clear, but it's not hard to make it work properly. 
to begin with:

- there are some weird statements like "lisp is an excellent programming language that allows you to expand your knowledge of programming languages due to its largely typeless nature."

- using underscores in symbol names, it hurts my eyes.

- stressing the list processing and recursion too much. a common mistake.

- introducing defmethod out of the blue and then just going on with regular list processing tutorial.

all in all, it's just your regular old fashioned lisp tutorial, now with eclipse.
and it completely fails in letting me "know why lisp is so powerful.
&gt; what i'd like you to do is explain to me what my office of 5 people, all of whom work in the office, in 2 rooms right next to each other, would gain by switching to a dvcs (assuming tool support wasn't even a problem).

another concrete example of this:

i was in a group of five people, and two of us were working on a major refactoring.  with a distributed system, i could start moving some of the code, leaving it in a broken, but divided state, and commit that.  he could pick that up and we could each work on half of the broken, but divided state.

we were using perforce, though.  our perforce administrator really doesn't like branches to be created except for official tasks *and* it's actually rather a hassle for me (and my coworker) to have the working directory be changed just because i'm doing some different work (welcome to java in eclipse with about ten subprojects).

so, instead of just committing some and starting to work, i kept working until i had enough done that i thought it could work on its own and committed all of it.  that basically meant that i did almost the entire task.

i actually *did* share my mercurial clone of the tree to provide a patch to someone who wanted to try something really experimental one day, though.  on his side, that involved downloading the top patch and doing all kinds of p4 junk on is side, but for me, it was just an ``hg qrefresh ; hg serve''  :)
ok. great, good call. can i have a pony too?
anti microsoft shill? how do you anti shill?

&gt;now they've not reason to say that microsoft is anti-open-source.

well we can still say ms is anti free software. once ms files a couple of patent lawsuits we can also say they are anti open source.

keep shilling for them though. they need all the help they can get.

the willingness to do *anything* (especially bullshit like 'learning a different way of thinking') instead of sitting down and actually writing good software is pretty much the standard definition of a 'lazy programmer'.


 fyi i have built several money-making websites in perl.  never any mp3 tagging scripts though, but i will cop to the occasional porn scraping script.

edit: they all use postgresql too, so hate that, bitch! =)
yes.

the world definitely needs another irc bot with built-in quicksort functionality.

i don't even have the energy to laugh at you people anymore.

the job ad is cool, though. 
was that the first or the second one? because i remember them saying it took one man one year to write it... the worst problem for them was that they had a hard time supporting it.
hmm? isn't gforth done in c? are we talking about hair metal?
disgusting.
cargo-cult programmers shouldn't be allowed to post on the internets.

there's *no such thing* as 'object-oriented programming'. you've been conned. perhaps you'd like to try some enterprise-level soap value-added web2.0 xml services next?

what there *is*, however, is nothing more than a method for vtable dispatch, like you said. 

and vtable dispatch is an unreadable, inefficient and clumsy way of reimplementing the case-switch construct. 99.99% of the time you should just use the right tool: the case-switch statement.

about the only time vtables are necessary is when you need to extend a binary-only interface. and if you *do*, then you should really rethink your business processes first.


if you train every day, eventually picking your nose with your toe will be almost as efficient as picking it with your finger.

ok, i'm a bit new to this "programming" thing, but i'm trying. what do i do if i get a "could not create socket: invalid argument at c:\misc\perl\eg\hp.pl line 26" error?
&gt; what i'd like you to do is explain to me what my office of 5 people, all of whom work in the office, in 2 rooms right next to each other, would gain by switching to a dvcs (assuming tool support wasn't even a problem).

they are not exclusive. most people using dvcs these days work on top of another centralized system. by allowing, local/private and usually cheap branching or revision history manipulation (like mercurial mq extension), it buys you a step between a single in-progress working directory and a irremediably published changeset. what you quickly learn from code reviews is a feature equals many revisions. with most vcs forcing you to commit *and publish* your working directory at the same time, like svn does, you have a choice:
- the classic monster commit. the feature is implemented in one single revision. refactoring are merged with file renames, with code moves and code style fixes. this is useless and your vcs is a mere backup system. but this is the usual practice.
- think very hard about the feature, split it mentally then execute your carefully thought plan. the resulting revision set is usable for review/history mining/debugging. but this is made awfully hard by the fact you have to commit every step right after implementing it. there is no room for mistake. sure you can fix errors by adding additional revisions but they are just noise in the code history and reduce its usability.

dvcs makes the latter easier by allowing you to craft the revision set without publishing it at once. suppose that while refactoring you unearth a bug, just keep the refactoring for later, revert all changes and fix the bug first. and even add a test *in a separate revision* to ease cherry-picking with another stable branch.

why is history tailoring important ? because the *risk* brought by a feature is often related to the size of the largest patch on the path from the current codebase to the implemented feature. a good way to make people aware of this is to make them do code reviews.

this is for daily use.

now, dvcs bring other features because their nature made them a requirement and also because someone eventually figured they may be first-class development tools rather than subparts of a release system (the following will emphasize mercurial which i know well, but other systems have similar features):
- i find revision browsing tools much better in dvcs. we use svn as our main vcs but i always export project in mercurial for reviews, i cannot stand tortoisesvn to do that. in a way, it helps disclosing obfuscated revisions histories, like sourceforce cvs-base projects. and code history tells a lot more than a single revision snapshot.
- revision history mining tools are more powerful. check mercurial "log" or "grep" commands for revision filtering and output templating. having a cli here makes sense because you can tailor the command output and extends your tools via scripting.
- bisecting tools: perform a binary search on a revision range to pinpoint the source of a bug. you can do that with any tool supporting project wide revisions, i just never saw an appealing way to do that with svn.
- cherry picking of revisions
- cherry picking of commit hunks (could be done better with a properly configured vim but it's good to have off the shelf support for this)
- working offline

dvcs are far from perfect and may not fit all corporate environments or policies. but they do not have to, and still can make you change your way of programming, or at least think again on what vcs are really about. which is good enough for me.
&gt; the problem is that you can't just dump all of your code into a versioning filesystem and then later decide what your projects are by pulling pieces out of this large mess.

you can, really, but it's hard, long, painful, and usually not worth wasting your time. thankfully extensions start emerging that allow you to *reliably* and pretty much *completely* export a subset/subfolder of an existing (svn) repository to a self-contained full fledged (git/hg) repository
c++'s templates are different from c#'s generics. when c++ programmers talk about generic programming, they tend to be talking about the unique properties of a template system. c#'s distinction between reference and value types also limits some of the generic programming's expressive power.

that said, d's template system is deliberately derived from c++'s, and in general d is so similar to c++ (by design) that it is hard to say c++ is "unique" without throwing in some additional criteria like "popular" or "established" that removes d.
&gt; thanks for reminding us and feel free to 
&gt; come help out.

nahh thanks for the offer, but i like bitching and whining a lot better than actually helping out. ;-)  
&lt;a target="_parent"&gt;&lt;/a&gt; ?
i am sitting in front of a hp 4050 n

it's so getting a message.
for those to lazy to look it up, or on a non-linux machine, see eg. [line 26 in p5.c](http://lxr.linux.no/source/arch/i386/kernel/cpu/mcheck/p5.c#l26), [line 111 in solerrno.h](http://lxr.linux.no/source/include/asm-sparc/solerrno.h#l111), [line 103 in therm_windtunnel.c](http://lxr.linux.no/source/drivers/macintosh/therm_windtunnel.c#l103), [and so on](http://lxr.linux.no/search?string=%22on+fire%22).

there is only one reason to learn ruby.

it's fun.

everything else is gravy.
 the bubble bursts! [don't learn rails](http://focs.wordpress.com/2007/10/17/dont-learn-rails/)! ;) 
me and my friend kept changing the lcd's during class each lesson until my friend got suspended for it.

fun while it lasted.
it's 'cheques' and not 'checks'.  people in some countries need to learn how to spell.
 your i.p. address is wrong or unreachable. either that or there is an error in the way you gave the command.

hpprinter.pl 192.1.1.120 "hello world" 

-edit-

remember the spaces.
c/c++ has really won 4. cilk is c with some extra stuff for parallel programming, and last year's winners mostly used c++, but they listed 2d instead, which was a language you had to use for part of the problem.

like korollary says, it's really about the people not the languages. there's a lot of fp programmers entering since this contest is run by a fp conference, but there's lots of good programmers entering with other languages too.
you're absolutely right. my apologies.
there is more on hal shelton and natural colour [here](http://www.shadedrelief.com/shelton/a.html). 
because they can now use the sentence "microsoft supports collaboration through it's osi approved permissive licence, shared source license, and reference license"

only the permissive license and reciprocal licenses have been approved but this sentence is ambiguous as to which licenses were approved.
if you want to learn lisp, especially common lisp, start using emacs. emacs itself can be extended using lisp which would give you a perspective of language. 

and if you want to do production quality code in common lisp, use slime which even supports remote debugging. why on earth would you want to use eclipse?

btw, i've blogged my experiences and the tools i used when i started learning common lisp. 

in the risk of repeating myself on reddit, here it goes.
http://blog.vagmim.com/2007/10/how-i-started-off-with-haskell-and.html
 obqwe1234:

&gt; even in 'functional language' implementations there are destructive updates to memory because without these, computation couldn't take place. (unless you have infinite memory, lol.) that should be iron clad evidence that 'functional programming' is a scam. it's a way for retarded academics to swindle even bigger fools out of grant money. _nothing more than this._

&gt; writing good software consists of making it run within minimum space and time constraints. anyone who thinks this can be done with 'functional programming' is criminally insane. 
web/app servers and databases already use all the processors you can throw at them. if only firefox could use a separate javascript thread for its gui and each tab we'd be set.
which is a shame cos they use it to set up a definition of realism as just another sort of abstraction, but one that is easier to understand intuitively. if they hadn't done that i would have skipped the whole article, which turned out to be fascinating.
gforth is indeed written in c and runs on top of a virtual machine to boot, though i can see where it'd make an excellent learning tool.

if taking chuck moore's red pill ("there is no os") is too scary for you, you can try something like [albert van der horst's lina forth](http://home.hccnet.nl/a.w.m.van.der.horst/lina.html) which runs under linux but assembles words directly into x86 code like a "real" fig-forth.
irc definitely isn't better in a graphical client, irssi is better than every graphical client i have seen so far (including most windows and unix clients, i tried pretty much all of them before settling on irssi about 5 years ago and i never regretted choosing it).
i wonder if languages had developed differently if keyboards had always included a "&lt;-" key. i agree with the argument that it would be nice if assignment used an asymmetric symbol, but i think having a one-character operator for the single most common operation is more important.
what? no _hackers_?
that's because assignment in python is not an operator, but a statement. i.e.

    a = (b += 1) * 2;

is legal c, but not legal python. so python "solves" the problem in its typical way by restricting expressiveness.
the guy sounds like a self-important jerk.
there's always wallmart.
actually it's php and not java. duh
awesome, it was a bad ip address, it works now!
i remember when he came to mit and gave a talk introducing java and its features.  after being introduced, he walked up to the mike, looking thoughtful and said, "lately... i've been thinking a lot about emacs."

he got a standing ovation.

he knows his people.
this all seems to be comparison to php, which is a dirty language anyhow
&gt; writing good software consists of making it run within minimum space and time constraints.

i tend to disagree.
more "what are we going to do with all these cores?"  obviously something will happen eventually.  you just have to have a little patience.  this kind of stuff takes time to work out.  
nobody expects the boolean inquisition, our two weapons are true and false... and don't care terms.... our *three* weapons are true, false, and don't care terms... and unknown terms... *amongst* our weaponry are such elements as... no... i'll come in again...
yah, but even with huge projects the biggest .git directory i have is only 665mb, but most of them are measured in kb or tens of mb
some people need to learn there is more than one type of english language in the world..

http://www.m-w.com/dictionary/check 7: a written order directing a bank to pay money as instructed 

cheque = british variant of check

&gt; "i have to say i giggled," o'kelley, 30, said of yahoo's acquisition, which earned him $25 million. "there is no way we quadrupled the value of the company in six months."

he doesn't understand value.  it was that valuable to someone.
i would suspect a lot of bad things in ms, but how about this:

&gt; so what are the lessons learned here?
&gt; clearly the first is that code reviews have
&gt; to be complete - if text is wrapping off the
&gt; screen, it's not guaranteed to be correct.
or to be more precise, check = american variant of cheque.
and implementations of c++ tend to use vtables. i'm pretty sure the major ones (gnu and microsoft) do, anyway. which makes me wonder why someone didn't come up with the bright idea of making a mic or pic for c++. (loss of debugging info, perhaps?)
svn branching/merging *sucks*. it's so painful developers are afraid of using it.
even his 80%/20% division is wrong. in my experience, we have more of a bell curve, like 20% (probably less) real alpha coders, 60% competent coders would can be taught new tools and techniques (provided they're stable and well "packaged") but won't go out of their way to find them, and 20% (probably more) real total losers who should be fired or confined to really menial tasks.

clearly, i'm not an alpha geek, but i take offense in being lumped into his 80% losers category.
&gt; and implementations of c++ tend to use vtables.

yes, but many have optimizations that allow for bypassing the vtable in certain circumstances... basically the same circumstances where you can use templates for static polymorphism (funny that), although most optimizers can't correctly identify all the opportunities to do so.
 no probs :) and my apologies for shouting :d 
&gt; ...make a mic or pic for c++...

hey, what do you mean by mic and pic in this context? i don't think you mean what i normally think of those acronyms as meaning.
 monomorphic or polymorphic inline cache -- a way of optimizing method dispatch in object-oriented programming languages. it's fairly typical for a language implementation (e.g., a java vm) to have several method-dispatch options to choose from -- and use whichever one makes the most sense from an optimization standpoint.
ugh. there actually is a related condition called "trucker's bladder" (brought on by holding it for long distances until you can reach the next truckstop). over time it tends to stretch your bladder out, and the muscle contractions that force pee out eventually become less effective. (you gotta rely on gravity)
&gt; i would suspect a lot of silly stories from programmers that's been around for a decade or two, but how about this

there, fixed that for you.
out of three links you put up...

first is the ping-back on armstrong's post i looked at. that post has one rather synthetic test (just passing messages around) which, of course is easily parallelizable and gives good speedup on smp system. the other, which i think is more realistic, doesn't work out great. that's why i put "you can't beat p" in my post.

second link is with ant colony problem, which i think is also well parallelizable (am i wrong?), so of course it will run close to twice as fast with erlang/smp than with classic one, which only has one thread and won't use more than 1/no of cores of processing power.

the third link... well, it actually measures "speed/scheduler no" ratio and i think results are what is to be expected. the test (big.erl) again, is just passing messages around, so it's parallel in itself. it should just max out all cores, and that's it, really. of course it deteriorates (decently) for anything over 4, as the test was on 4 core system.

&gt;erlang is not touted as a multi-threading language, it is touted as a concurrency language...

i agree 100%. my beef is that it's often put up when "concurrency" is used for "multithreading".

wrt "closed"... your explanation is exactly what is the problem. say you have beautiful piece of code that does x, and i want to use it. i think, telling me to open a socket to "call it" is not being serious. and if i am on the same machine, or worse yet, in the same process, it's out of line.
microsoft used c# before gui text editors were invented?
one form of polymorphism is enough for any language.
dare i say "database programmer != human" ;-)

but, yes, that's true. it's another paradigm where we're not in "sequential mode".

please note that probably the most important sql dialect is pl/sql, and one reason for that is that it has most imperative functionalities built in. it's telling, even if the other big reason is that it's "oracle inside".
&gt;on the other hand, i agree that lazy evaluation can lead to non-intuitive behaviour.

yeah, that's what i was getting at.
i tried learning emacs. awful editor. i don't have weeks to spend training my fingers to use key-chords. i'm used to visual studio, but eclipse is close enough for me. this plug-in allows someone like me to play around with lisp without the pain of having to learn emacs.

seriously, though: programmers have moved heavily into visual development environments over the past ten years. why should those of us who learned programming with these editors have to go back and learn emacs? lisp is, theoretically, pure lambda mathematics. so it shouldn't matter which editor you use. it seems to me that the only way mainstream developers will take up lisp is if it integrates into the tools they already use. so basically, there is simply no justification for urging newcomers to learn emacs when plug-ins like this are available.
well, the branching is easy (see above). it's the merging that's hard. ☺
me too! writing good software entails working within the time and space constraints that are required.
i have dabbled a little into forth (and occasionally even postscript), i just have a slight problem with the title. even with forth as a glorified macro assmebler, you're not that much closer to the hardware than e.g. turbo-pascal with its inline assmebler. yes, the neccesary tools are much simpler and smaller, but speaking purely about abstraction, you're not that much closer.

actually, the ability to work at different levels of abstractions is one of the best points of forth, so this is really not the best advertising statement possible (apart from the fact thate bare metal programming is a bit gauche right now -- the young kiddies have moved from assembly to script languages nowadays ;) )
the statement was deliberately designed to be patently stupid and farcical on its face. that doesn't stop a few people from taking it seriously and believing it however...
er, i'm not sure they did... they just spoke about web apps in the context of their phone, and said, "hey these things are pretty good because they've been designed for a 3.5" screen". now, ok, you *can* read into that that apple thinks the *only* device web apps are/should be designed for is the iphone - but it you did you'd be an idiot.

if you went over *any* announcement, quote, or press release from *any* company you'd be able to twist their words into something nefarious through the stretched exploitation of omission, hyperbole, example, etc.
from the looks of it i'd say they're simulating a godzilla attack on the colony...
for those of us who have no idea what scipy is: http://www.scipy.org/
&gt; an svn working directory is 2x the size of a non-svn working directory, because there's a pristine copy of every file for quick diffing. a clone of a mercurial repository is probably much smaller.

only for an amount of time at the beginning of the project.  an unpacked linux kernel tarball is a bit over 100mb, but the git repo is well over 500mb.
two things i need in my next laptop:
* 2-4 gb of ram or more
* vt support in hardware

why ? virtualization is here to stay !
 cool, yeah, but articles are far better in my opinion.  i can skim them, read them bit by bit, search for things in them, and generally have more control over the experience.

 http://www.apple.com/webapps/

"what are web apps?"

"with web apps, the power of the internet meets the brilliance of multi-touch. and suddenly, iphone and ipod touch can do that much more."

they redefined the term "web app" to mean something targetted at a single platform - basically an anathema to the web. that's pretty bloody cheeky. 
so you were doing you job finding bugs in code that wasn't yours and you feel sorry?  how about being proud for finding the bug and ratting out who it was that introduced the bug?

edit: would have been nice to mention he wrote both of them in the article.
is that code really a problem? shouldn't the compiler be able to automatically inline those methods?

[edit: i'm not advocating putting something into a method of its own that would be at least as concise and obvious otherwise. i'm just asking if it's really that bad and would like to get an answer rather than just downvotes alone.]
uh, no.

that description can be applied to web apps that weren't designed for the iphone/ipod touch too.

talk about cheeky...
where'd the hardcore geeks go once they left slashdot?

i'm sure there's a nice latin name for the fallacy of intentionally ignoring the context so you can mindlessly rant about something on your blog, but i'm not going to bother to look that up right now.
assuming this whole story wasn't just an anti-apple troll, as it appears....

how is this worse than having any site that applies to only one platform, or requiring a password to access content? can't a company have a site that focuses on their own products/customers and doesn't necessarily support others?

at least they're up front about it: 
microsoft advertises web sites, then makes sure they don't work correctly on other platforms, even if they have to illegally modify the environment (like, i.e., java.) they even sell tools to encourage others to do the same thing.

&gt; monomorphic or polymorphic inline cache

ah yes. most c++ runtimes don't tend to do codegen of any kind. what you can have happen though, particularly with profile guided optimizations, is compile-time inlining of one or more method invocations for a virtual function.
&gt; i was quite surprised myself but, it appears, some people don't look at what is in front of them.

there's the rub.
i think you missed the point. apple are trying to subvert the _term_ "web app", "web application" to mean "mobile safari only". the closest analogy i can find is when microsoft tried to trump their closed "msn network" over "the internet".
no, that's how you write *average* software, not *good* software.
hot diggity dag diggity!
cool, i've always wanted a brown ipod!
i don't think so. they've only got 60% the market cap of microsoft (of course, if both companies grow at their 5 year average growth rate, apple will be bigger than microsoft around may 2008).
uh, no. [it was "check" first](http://en.wikipedia.org/wiki/cheque#etymology_and_spelling), and then the british decided to split off their own spelling.
i'd set out a coin box...see how much money you could pick up off of the printer :p
no they aren't and the premise that they are is ridiculous.
&gt; i was only expanding and clarifying on the points of tfa i consider to be pure fud (pretty much all of them).

that was fair enough, i agreed with you on much of that, and i really appreciated the thoroughness of your response.
apple doesn't answer "what are web-apps?", they instead say that their products can make good use of them. this isn't so different than microsoft's definition of web-app being something that can run inside internet explorer (such as activex components). what do you expect form a product marketing department?
i use it all the time.
get your paws off my printers, you damn, dirty hackers!
vss "checkout" : get the latest version of the file (i.e. svn "update") + mark as checked out in vss (no analogue in svn afaik).

svn checkout: as you say.

the two use same word with different meaning and different words for one meaning, e.g svn update (almost) = vss get.
wait no, javascript. definately javascript.
exactly.  i'm not going to try to sell products  compiled in crippleware.  i'm not large-scale enough to convince myself to blow $1000+ on lispworks full version.
perforce is a pain to use.  it sees everything very "file centric", which makes it a pain in the ass to refactor whole packages and libraries enmasse.  try subversion for the bare minimum of a decent vcs for any sizable project, otherwise you will be fighting your own tools too much.
 follow the link from that page to http://developer.apple.com/iphone/designingcontent.html and see that they do actually encourage developers to consider client diversity and that the recommended way to design iphone web apps includes making your pages standards-compliant.

i don't think apple intends to subvert the web, nor do they fail to recognize that the web is a heterogeneous environment.

compare to some other ways that companies would like to redefine the web. e.g., http://silverlight.net/. 
he wrote [both programs](http://blogs.msdn.com/larryosterman/archive/2007/10/16/larry-and-the-ping-of-death.aspx#5473820).
&gt; no analogue in svn afaik

`svn update` + `svn lock`.
drivel.
&gt; with web apps, the power of the internet meets the brilliance of multi-touch.

seems pretty clear to me that they define "web apps" as "internet + multi-touch". and last time i checked, my pc didn't have multi-touch.
&gt; apple doesn't answer "what are web-apps?"

really?

&gt; with web apps, the power of the internet meets the brilliance of multi-touch.

seems pretty clear to me. note that they're not saying "with web apps and the brilliance of multi-touch" but "web apps mean internet + multi-touch".
*malum discordiae*, perhaps?
whether they did or not, it reminds me of firefox offering english or english (uk). will someone tell them there is not a uk version of english. there is an american version of english. the clue is in the name.  how long it will be before they offer american or american (uk) as choice of language?
samir. it's not that hard - samir nana... nana.... damn.
&gt;most gui source control tools suck.

you rather mean sc gui client.

still, no. in this case, command line can't beat context menu operation, be it using mouse or keyboard. depending on the bloat in your gui shell, you also won't save keystrokes if you go keyboard only.
&gt;if the mere act of trying to edit a file in visual studio doesn't cause a check-out, then it is a non-starter for nearly everyone i have worked with in the last 4 years.

that may be the reality, but it's *really* fault of these people, not the tool's.

it's not *that* hard to accept the possibility that source control will work differently than vss integration for vs, which is the case you describe.
no, they define *their product* as "internet + multitouch" and remind people about the existence of web apps, so they don't worry about not being able to install normal third-party apps.

this is typical word mangling in the cause of product marketing.
apple doesn't give a shit what people think the definition of a "web app" actually is, as long as people buy iphones, and as long as web app developers pay attention to the market of iphone buyers using mobile safari.
plus, it may also get inlined.    
sorry, i was looking through some forth spec and it had an assembly-extensions section. so that's pretty close to the metal i think. the only other languages that let you include assembly are c, c++ (by way of c) and that's it (as far as i know).

&gt;yes, the neccesary tools are much simpler and smaller, but speaking purely about abstraction, you're not that much closer.

true enough! but hey, it's a different way of thinking (different syntax, uses stack push/pop, etc) than c and so i think it's important for others to check it out to expand their minds. and by saying it's closer to the metal, well that's just a weak attempt to attract c/c++ coders.

&gt;actually, the ability to work at different levels of abstractions is one of the best points of forth, so this is really not the best advertising statement possible

find me a forth spec, and submit it with a better headline :p
common lisp or it didn't happen.

[gratuitous design choices](http://clojure.sourceforge.net/reference/lisps.html)

edit: to be fairer, there is some [attempt to explain](http://clojure.sourceforge.net/rationale.html) *some* of the choices, but really, edit^2: [see above default to dynamic scope?](http://programming.reddit.com/info/5yhsc/comments/c029ojd) empty list not nil? a lisp-1? let binds sequentially? 

are those really the price to pay for supposed concurrency benefits and good use of the jvm? or are they arbitrary and unwise departures from lisp tradition and experience?
no, no, that's only if you forbid multiple checkouts in vss, which nobody should be doing.

(yeah, i know stupid vss turns it on by default)
indeed.

i don't see the point in writing average software that average people have already written thousands of times before.

right, and the point is that if merging is painful, then branching is worthless.

we use svn, and whenever we make big changes we have 2 options: we can branch and deal with all the accompanying headaches, or we can just not commit for three days.  the idea is to never check in code that you know to be broken, and that becomes difficult when you're making really big changes.  obviously you want to avoid those as much as possible but sometimes there's nothing you can do.

i've never used a dvcs, but i find them interesting because they "should" solve that problem.
 reasons to learn emacs.

1&gt; because the premier lisp editing environment for emacs - slime - offers functionality far beyond that of cusp.

2&gt; because it's highly customiszable. for instance, if you'd used cua-mode or pc-select mode you'd be able to use the keystrokes you are used to.

3&gt; in emacs i can locate a class in a .h file, split the window, jump to the .cpp file  amd set myself up to edit both side by side in a matter of a fraction of a second (and four keystrokes + the class name). you can't do that with visual studio. it's windowing model is fundamentally broken - although 2005 has gone some small way to fixing this.

4&gt; emacs supports dozens of lanugages and platforms that visual studio will never touch.

5&gt; you can write emacs extensions on the fly inside a buffer inside a running editor, instantaneously updating. visual studio add-ins require progrramming to a horrible api, continually re-compiling and re-loading and restarting a dll - which takes minutes and hundreds of megabytes at the very least.

6&gt; emacs integrates nicely with visual studio when you run it as a server and invoke emacsclient from the tools menu.

7&gt; it does matter which editor you use. s-expressions can use a very different edtiting style called structured editing in which the source being editied is always valid, giving an insane productivity win and nothing but emacs and paredit-mode supports this.

actually, i should probably blog-post this comment and submit it..
 
nice to see a dos twist on [an old unix idea](http://www.netfunny.com/rhf/jokes/old90/18951.html)

yawn......
&gt; seems pretty clear to me.

and all the huge pictures of iphones on that page doesn't tell you anything?  lynx user?
   last millenium, in a stroke of breathtaking arrogance, apple redefined "software" to mean programs designed for a single software platform: [here](http://www.apple.com/support/software/).

omg give torch now now!!!   
&gt; no, no, that's only if you forbid multiple checkouts in vss

why would you care that a file is marked as "checkout" if you don't disallow multiple checkout?

&gt; which nobody should be doing.

last time i tried vss, all hell broke loose because it's fundamentally based on exclusive lock and is a piece of shit at merging files.
what kind of programmer considers "svn cp" esoteric?
that, was, stupid
  you have to temper that definition with the ["winner's curse"](http://en.wikipedia.org/wiki/winner's_curse), in a bidding situation with uncertain information.

the winner of a competitive auction, unless he has special understanding or information, has by definition paid more than any other bidder, including all others trying to make the same valuation.

choosing the maximum of a random sample is not usually a good way to estimate the mean.

anyhow, the point of the quote is o'kelley, presumably in a position to know, can't identify any change in his company's prospects, while some outside company, probably spending more time worrying about google than its m&amp;a valuation, drastically changes its valuation of those prospects.  
bastard. now i'll have to get it re-done... :)
bah, don't pay any attention to him. he's just trying to corner the market on rails expertise!  learn rails even more now!
like it or not, the only known (to science) computation model is the one more or less embodied by the c language standard. (modulo the fact that the computation model would need to specify a way of dealing with parallelism by way of threads of locks.)

this is an empirically observed *fact*. whatever 'functional' language you invent, it would still be a crude hack that inefficiently rewrites some other model into the one true one.


fourchun is bad for your health.
yeah, but me and the guys were thinking it'll gain some kind of vintage charm. like an atari logo, but not as cool.
safari sends an accept-language header based on your system-wide language preference.  it's a reasonable assumption that users can read websites in a language that the rest of their operating system is displayed in.
this article is dead-on.  i will now uninstall safari and firefox because obviously my laptop cannot and should not be used to access web apps.

seriously, what is wrong with you people?
&gt;shocking statement #1: most of the software industry is made up of 80% programmers.

you don't say? is it, like, more than 79%?
uh, yes. according to what you just sent me it comes from the arabic "saqq". all the english words are derivative of that, both cheque and check. the english maintained cheque solely for the monetary meaning and it looks like the americans just reverted it to simpler, more phonetics spelling, as is generally their wont.
ok. i'll admit it. that silly thing made me smile. :-)

syntax error!
i posted this

http://netpeek.netfirms.com/hpprint.shtml

on somethingawful forums, and a guy got fired for using it..

haxor! his dumbass boss figured he was a security threat. 
same problem on mac and ubuntu...
on my macbook firefox uses 960 mb!
and on the ubuntu-inspiron it uses 367 mb
each with 6 tabs open.
the ipod extended student ultimate version pro v1.4.02.2.2 (service packs 3 + 4)?
soembody has to write it. sure ain't gonna be me, though.
the internet is the wave of the past!
&gt;why would you care that a file is marked as "checkout" if you don't disallow multiple checkout?

that, you have to ask ms ;-)

guess: it's like that because they first did exclusive lock only, then saw it doesn't work, but didn't change further to keep the existing "look&amp;feel".

otoh, if you see file is "checked out", you may decide to do something else to avoid conflicts ( e.g. get a cofee ;-) ).
why oh why would i use that when there's a proper [common lisp that targets the jvm](http://armedbear.org/abcl.html)?
&gt; that, you have to ask ms ;-)

pretty much. so marking a file as checked out is useless if you don't use locks, which means that `svn update` + `svn lock` do everything that can be useful in vss' checkout ;)

&gt; otoh, if you see file is "checked out", you may decide to do something else to avoid conflicts

or you switch to a vcs that can handle the conflicts itself and lets you work instead of worry about such petty things ;)
[armed bear common lisp](http://armedbear.org/abcl.html)

or if you prefer scheme

[kawa scheme](http://www.gnu.org/software/kawa/)
no one says you have to *cash* the check. more typically, you frame it.
nope. it's a in-house [vbscript variant](http://www.joelonsoftware.com/items/2006/09/01b.html).
 &gt; and by saying it's closer to the metal, well that's just a weak attempt to attract c/c++ coders.

there are still c programmers reading reddit? ;)

but i have to agree, forth is definitely worth checking out. and gforth actually _is_ a good starting point, as you really don't need to program your own device drivers in a boot-loaded, screen-oriented forth derivate to appreciate the language.

for those who need a bit more color, postscript is also a neat rpn (reverse polish notation) language. 

incidentally, both have very good books starting with "thinking"...

[thinking forth](http://thinking-forth.sourceforge.net/)

[thinking in postscript](http://www.rightbrain.com/pages/books.html) 
bwahahahaha
[na-gheen-an-a-jar](http://www.imdb.com/character/ch0001937/)
maybe because someone thought that writing a new dialect that is somewhat different, and targetting the jvm, would be a nice idea?

it may not me "more expressive" than common lisp, but it could perhaps be more convenient for some people.


why wouldn't you just frame a a high quality copy of it and keep the money?  if you were inclined to accept the check at all...
so where are the benchmarks on how it's "much faster" than the standard stl red-black tree implementation (which is a b-tree variant already)? i couldn't find much useful info in the wikipedia links. even if it wins on insertion speed, it's going to be hard to beat the o(1) retrieval on a hash_map.
this actually seems to be a nice, well-thought, well-documented and useful project. the value might be more easily seen if there were some kind of example on the "refs and transactions" reference page.
you're right, it's cool that even this very expensive setup with relatively low performance/$ is ~$34/gflop.

maybe i'm going to build a minisupercomputer at home, do you know what's the best setup today?

i think you can get at least 300 gflops for $4000 now, for example by buying 4 q6600 (you could also (easily) overclock them from 2.4 to 3ghz for even more speed). 4xq6600 costs $1064, so you might even be able to make 8xq6600 for $4000 if you find cheap memory + motherboard. fyi, one quad core xeon at 3ghz costs $1172.

what's the best setup to get as many gflops as possible for $1000-$4000?

p.s. 64 bit computers do need more memory: if they store an int in ram, they need twice as many bytes.
it reminds me of how so many "mobile apps" in the last year or two have been designed for phones and suck on a pda.  (i'm looking at you, google.)
when i read "2007 best coding practices" in a title, i expect to read just that in the body, not an analysis of bad code. 
 &gt; red-black tree ... (which is a b-tree variant already)

actually, both b-trees and red-black trees are two different specialized binary search trees. but a red-black tree is *not* a b-tree.

you can check the definitions of both at wikipedia.

also, don't count on "o(1)" being always lightning fast. you'd need a *very* good hash table for that, and even then, there's a hidden constant in that o(1). (remember that o(1) is the same as o(1000000)).

and finally: you don't traverse a hash_map in the order defined by your keys. you can walk a b-tree or a red-black tree in the right order easily and quickly.
&gt; like it or not, the only known (to science) computation model is the one more or less embodied by the c language standard.

you forgot [λ-calculus](http://en.wikipedia.org/wiki/lambda_calculus).
&gt; like it or not, the only known (to science) computation model is the one more or less embodied by the c language standard.

turning machine.

lambda calculus.

are these, somehow, not computation models?

or were you wanting someone to bring out dataflow computing as the example of why you are wrong?
i stand corrected. luckily i didn't need to use ec2 then, as i just assumed it was there if i needed it.
does anyone say anything new at any point?
before you write that post extolling the virtues of slime over cusp, you might want to actually try using cusp. it's quite apparent that you haven't, because if you had you would have known that cusp is an eclipse plugin, and has precisely nothing to do with visual studio.
title should have read "2007 *mainstream* coding practices".
because there are absolutely no people in between "learning haskell for fun on the weekends" and "i just got into compsci cuz it pays well"
afaik the sapir-whorf hypothesis was a statement that structure of language determines structure of _cognition_ which is quite a bit stronger than saying it determines structure of expression.

even this stronger statement probably holds true for a lot of programmers, especially when you take into account the multimillion dollar "object-oriented design" industry. 
  okay, i am creative director, and the mahogany desk crowd is really sweating for me to send my programmers to silverlight training and for us to start developing in microsoft silverlight. i am having flash backs to the 90s and the flash plugin adaption that plagued development then. i am not a fan of pulling my programmers off our current projects if this is going to be yet another clunker product ms is trying to ply on us. i know the pressure is coming from ms on our top management to use this platform, but i cannot find data of the current installment rates among users to support my case that we are barking up the wrong tree.

help.  
no, you have that backwards. take another look at the link: the *americans* maintained the original spelling, "check". there's no evidence whatsoever to support your claim that they "reverted" to it and the british "maintained" anything. 

again, it was the british who went off on their own and created the variant spelling -- and as wikipedia explains, they did this in the 1800s, well after the united states had split off into an independent country.

that's nice, but again, "mr. negativity" who you speak so highly of works for google, i.e. not persai.
http://programming.reddit.com/info/1cvs4/comments/c1cwft
i believe that his payment was $.10 to everyone who found an error (i may be wrong), but 10 cents is a bit low to be killing people  :)
i'll do it for five.
to the best of my knowledge, neither allow you to produce distributable applications, anyway.
alas, only americans need apply.

if only all these haskell jobs were located in a country with a sane immigration policy for skilled workers.


paper cassette load letter paper

http://en.wikipedia.org/wiki/pc_load_letter

john.

  &gt; with a dvcs, i could just temporarily share my local repository -- which is pretty much trivial (a simple hg serve is enough when using mercurial, for example), he'd pull from me (either into his main repo, or he'd clone to another repository just in case or if he's working on something else),   


or you could send a patch to him to apply on a freshly checked out copy. 
normally i like joel, a lot, but this statement makes no sense to me: 

"but most fogbugz customers don't want their proprietary project data on someone else's servers, so we have to sell them the source code to install on their own server."

this hack is way old.

http://www.trilug.org/~kjotte/progcon/
oh my, that  blog post is all over the place. and has almost nothing to do with linguistic determinism.
that's great for mirroring the display to to both monitors, but it's not going to drive two monitors with two different displays as if the dvi-d signal is a normal multihead video card.
me too.  made me think of this video for a grandaddy song done entirely on the apple iie...

http://www.stewdio.org/jed/


why does this point to http://web.archive.org/web/20060111183609/http://reddit.com/
?

i'm clojure's author.

first off, i think common lisp and scheme are great, and i cite abcl, kawa and sisc as good implementations of standard lisps for the jvm. if you think common lisp or scheme should be the last lisp(s) ever written, then clojure isn't for you and there isn't much to discuss.

clojure has some tangible, non-superficial differences from common lisp and scheme. they yield something that is different, and might or might not be more suitable depending on your programming style and application domain.

- most of the core data structures are immutable. this is part of an overall design philosophy to make clojure a good language for concurrent/multi-core programming.

- most of the data structures are extensible abstractions. this is different from common lisp where you can't extend the sequence functions to your own data structures, for instance. even invocability is an abstraction - allowing maps to be functions of their keys and vice-versa.

- clojure extends code-as-data to maps and vectors in a deep way. they have literal reader syntax, the compiler understands them, backquote works with them, they support metadata etc. because they are efficiently immutable and persistent, they support very lisp-y recursive usage, shared structure etc, in ways common lisp's hash tables and vectors cannot.

- clojure embraces its host platform in ways that the standard lisps ported to the jvm can't. for instance, common lisp's strings could never be java strings since the former are mutable and the latter are not. clojure strings are java strings. the clojure sequence library functions work over clojure and java data structures transparently. etc.

- clojure has metadata as a core concept, not something one could retrofit onto the built-in common lisp types.

- clojure is designed for concurrency. vars (similar to cl special variables) have explicit threading semantics. clojure has a software transactional memory system. etc.

in short, clojure is (non-gratuitously) different. if you don't want different, you don't want clojure. if you like lisp and need to write multi-threaded programs for the jvm, you might find something interesting in clojure.
he had to use a recent version of dos for this. "if you're happy and you know it, bad command or file name" doesn't have the same ring to it.
&gt; or you could send a patch to him to apply on a freshly checked out copy.

yes, but that implies one more transfer medium, mail or im (and ims often bork whitespace). simple sharing is faster and easier, and less work for everybody.
&gt;i think you're referring to when people commit such things to trunk.

i assumed that is what you meant when you said "the manager may not want to monitor half a dozen or more different branches, so he'd order the employees to all push to a central repository at least every x interval".

keeping track of multiple different branches in an svn repo is the same as keeping track of multiple different branches of an hg/darcs repo. all he needs to do is tell the developer to mirror any branches on a server he has access to. 

ultimately, with a dvcs, you can always mirror the topology of a centralized vcs. additionally, you can use other topologies (tree structures, microbranches, "sideways merges") when useful. 

as for code bombs, they are a failing of the developer. but they are also a failing of cvs/subversion, which make merging way more difficult than it needs to be. 
also apparently [bigloo scheme](http://www-sop.inria.fr/mimosa/fp/bigloo/doc/bigloo-24.html) can also target the jvm. 
i immediately ⬆'d it as a knee-jerk response to any mention of sapir-whorf ([definitely yes](http://www.qwantz.com/archive/000627.html)!) but after reading it i have to agree with you.

perhaps a better title would be: “sometimes perspective is important?”
cause the check is like $2.56, and which would you rather have? $2.56 or a authentic check made out to you by *the* donald knuth? :) 

im not sure. i just put in http://reddit.com, i noticed that as well. 
 &gt;because the premier lisp editing environment for emacs 

eclipse wasn't the premier editor for java when java came out.

&gt;because it's highly customiszable.

&gt;emacs supports dozens of lanugages 

bad argument since eclipse is apparently very customizable too or have you failed to notice the vast number of languages and plugins it supports?

&gt;emacs integrates nicely with visual studio

but most version control systems don't.  why do you keep bringing up visual studio when this is about eclipse?

&gt;it does matter which editor you use. 

that is argument to use emacs?! 
bad title, bad blog post.
i thought every subsequent cheque (i don't want to get into a religious spelling war - this is just how i spell it) was worth twice the previous one. i can't remember where i got that from, so take it with a pinch of {{citation needed}}. 
hollywood with its tv programmes has done more than any "external enemy" to destroy the usa. this is the "democracy" that us society wants to promote to the world.
hollywood with its tv programmes has done more than any "external enemy" to destroy the usa. this is the "democracy" that us society wants to promote to the world.
the fact that people misuse libraries in functional programs, leading to overly slow functional programs, is the same as blaming people for using bad or the wrong implementations in c.

"well, bubblesort is slow, so it must be c's fault".

you can write fast or slow algorithms in any language, and some work better in some languages than in others.

i think the biggest deal with fp, is the relative applicability and effectiveness of pure fp languages versus impure.
 agreed. apple have reached that size where they can appropriate terms in very common use and make them their own, such as the 'i-' prefix and the word 'pod' which (as any gerry anderson fan will tell you) had plenty of 'prior art'.

'web apps' is about as generic as it gets, but yet there it is, with its own dedicated url on apple.com referring to a specific class of applications written for a proprietary platform.

what next, apple.com/files? apple.com/data?

let's see what happens to any mobile phone software writers six months or a year down the line who have the temerity to describe web-enabled handset software as a 'web app'. 
indeed.

ah well. that was disappointing.
it sounds almost as though he's trying to create a "branch" as it were of the *[pareto principle](http://en.wikipedia.org/wiki/pareto_principle)*.
great timing, rich will be presenting clojure nov 13th at lispnyc!   http://lispnyc.org
indeed, and subversion 1.5 should make merging a lot easier.

which is related to what the linked article was discussing: subversion is well oriented to work for a lot of business programming, so they want to keep that orientation while borrowing from dvcses things that subversion doesn't do as well (like merging).
first off, the linpack performance may not be the best, but it does say *something*. 

second, do you have a reference for the 140gflops? i'm curious how the chips push those numbers.

theoretical performance *does* make sense. if they had only managed to get 75% efficiency, they would have missed the mark completely. i don't know why you wouldn't push to attain *perfect* efficiency with your hardware. this is why there is such an emphasis on matching memory speed, cpu speed, and i/o speed.

i'll give you the last point. gigabit ethernet is no comparison to a dedicated bus. really though, this only sets the mac pro above the cluster in (really) high bandwidth problems. many problem categories would find almost no benefit to the boost provided by the mac pro's communication.
how much longer is "long" when compared to "long"?
 probably unnecessary, but credit where credit is due: [sturgeon's law](http://en.wikipedia.org/wiki/sturgeon's_law) 
why is this in programming?
actually very cool, but a link to the demo is needed: http://binarybonsai.com/misc/humanmsg/
you would probably make more selling it on ebay than cashing it, if you alert the proper geeky community of the auction.
i think we have to give some bit of leeway to the author, i kept the original title mostly because i don't like misrepresenting what people have said. i definitely agree the post conflates lots of ideas that aren't necessarily as intertwined as the post suggests, but there are interesting points in there all the same.
 dumb question: why do i need a 3rd party site?    

how hard would it be to whip up an openid server, just for my own id, in python? 
well if you write a freedesktop.org standard, to send this event to dbus, you only need to fix your prefered window manager, and write a dbus client.   soon (for some definition of soon...) all pim apps will listen for this signal, and all windows managers will have to support it.

of course it is a lot more work to do it right, and the gain is questionable.  
they are not empirically observed.

thus, they are anti-scientific.


lambda calculus is not empirically observed.

thus, it is anti-scientific.

come to think of it, i suspect the iphone is not very accessible to the visually impaired. 

blog away, apple critics!
qwe1234 is not empirically observed.

thus, qwe1234 is anti-scientific.
&gt; but a red-black tree is not a b-tree.

it is, kind of. a red-black tree is an [isometry of 2-3-4 trees](http://en.wikipedia.org/wiki/red_black_tree#uses_and_advantages) using distinguished binary nodes. [these](http://en.wikipedia.org/wiki/2-3-4_tree), in turn, are a specialization of b-trees (they're b-trees of order 4).
&gt; it uses symlinks when they're available

no, they use hard links
  show me the code.

so far, all you people have demonstrated are ever-increasing not-quite-painful ways of calling c code from functional programs.

that's disgusting and pathetic.

call me back when c programmers suddenly decide they need an ffi for calling haskell code.
  
i stopped reading after he claimed that 29% was a "high rate of adoption by the contestants".  i really tried to keep reading, but my eyes slid off the page.  i mean, it's the international conference on functional programming ... and even they can only get 29%?
what a stupid comment from one 'jsh'.


&gt; no, no, that's only if you forbid multiple checkouts in vss, which nobody should be doing.

&gt; (yeah, i know stupid vss turns it on by default)

that may be a nice theory, but i don't know anyone dumb enough to use vss that was smart enough to turn this off.
&gt; lambda calculus is not empirically observed

what exactly do you mean by that?
that was cringe-worthy.
depends on the project.  knuth uses different payment schemes on different projects.   he isn't stupid enough to use the "each bug is worth double the previous" on anything that could have a lot of bugs.

for his art of computer programing books the payment is $2.56 (a nice round number) 
καλλιστῇ
it makes total sense. companies like to have access to their data, and they like to ensure that no one else has it. most companies don't like outsourcing stuff - especially development tools to outside hosting companies.

why do you think companies spend gajillions of dollars bringing up consultants to set up oracle and sap at their own site instead of having a generic hosting one?

it definitely makes more business sense to have some things hosted, which is why you see small companies and one man shops putting their subversion, webhosting, etc. on dreamhost and doing their project tracking via basecamp.

but the big companies, man. they want to go down the hall and see the damn box.
i've noticed this a lot with people who have significant development experience yet display very limited experience or knowledge of programming itself.

it is a concern to me also that there exist a lot of business developer jobs that require a certain amount of experience/ability in the developer to do successful troubleshooting, yet not give the developer the tasks that would give said experience.

this may just reinforce the idea that a good developer's destination is often ultimately management or something other than actually typing in program code.

i would disagree. clients like xchat have much more powerful language bindings than irssi, allowing you to use languages such as python or ruby, which irssi can't use. irssi was a pretty nice and comparably full-featured client 5 years ago, but since then, most graphical clients have surpassed it in ease of use, and extensibility.
well shit, since apple said so it must be true.
i was expecting a 2007-element list.
  what a stupid comment from one 'qwe1234'. 
there's a difference between differences that are definitive and differences that are gratuitous. a lispy way to handle non-mutable data is interesting. aligning with the jvm view of the universe *potentially* has large advantages. extensible sequence protocols/"more generic functions" is an example where lots of people have wanted to figure out a solution.

[edit: see response below--dynamic scope as the default was known to be dangerous in the 1960s, and discovered to be irrelevant to efficient compilation in the 1970s.]

"let binds sequentially" is just going to confuse. nil not equal to the empty list smacks of personal aesthetics trumping a huge element of lisp tradition.
questioning questioning questioning functional programming ... basically wasting time
this was for bugs in tex, which started at $2.56, and then doubled (though this was frozen on reaching $327.68 )

i think for errors in taocp, it was a flat $2.56, without doubling.
direct link to the demo: http://archon.paragent.com/externallogin.ucw?username=guest&amp;password=guest
well, then, **i** hit your dumb-smart sweet spot there!

where i work we used vss, and in that way. i made us turn that off (well, on, as the option is "allow multiple checkouts", i think").

btw, we don't use vss anymore, but we didn't have problems with it, either (under ten people and tens, but not hundreds, mbs of code).
_i consider myself to be among the 80% who see programming as a job, and i didn't get that impression at all._

the very fact that you're here, discussing dvcs  means that you are part of the 20% category of sussman's.  the 80% rarely read and discuss articles on programming tools.
 there's no such thing as a physical 'lambda calculus machine', and not one has been actually built in all of the years that computing has been known to man.
 
that should raise a scary red flag to you.

"considering 'why "why 'questioning "questioning functional programming"' matters" matters' harmful considered harmful"
you know they *are* a company, right? it's a marketing ploy, people! sheesh. there wasn't any more thought put into it than when every car commercial ever claims that their car won ____ award and is "redefining your driving experience" or some such nonsense.
except, you know, those lisp machines.

(ok, yes: lisp != lambda calculus.  damn close though).

give it up, troll.
 i brought up visual studio because you brought up visual studio.

sure, use cusp if it floats your boat. it doesn't float mine. it's more extensible and universal than visual studio, anyway. still not as much so as emacs.


 
sorry but you're wrong, consider what you said above:

&gt; like it or not, the only known (to science) computation model is the one more or less embodied by the c language standard.

"known to science" does not equate with "physically [implemented]". lambda calculus is a valid, accepted, model of computation, what the substrate of any potential implementation of that abstraction is remains irrelevant. you stated lambda calculus is not a model of compuation, you are incorrect.
that depends on what you mean by ease of use. you might see use of the mouse as an advantage, for me it is a malus. there is also no way i could run any graphical client on my headless server (and use it via ssh+screen) so i don't have to restart it all the time and don't miss stuff that happened while my main pc is off.
where can i find an physical turing machine? (note that the spec calls for an infinite tape!)
read the post i was replying to, it was the one that brought up visual studio. 

eclipse was universally loathed in the office i worked in by users from both end of the spectrum: visual studio and emacs..
do you know where the other lisp groups are listed?
while that's probably a good practice and works great with strings that may be null in other languages, e.g. "foo".equals(bar) instead of bar.equals("foo"), it's rather counter-intuitive.

english word order almost exclusively puts the variable before the test value in comparisons.  "is that my cow?" vs "is my cow that?"  imho, switching things around in code makes things less readable.
&gt;lisp is an excellent programming language that allows you to expand your knowledge of programming languages due to its largely typeless nature.

wtf? common lisp is strongly typed. people who don't understand that strong/weak typing and static/dynamic typing are completely different issues should not be writing articles about programming languages.
 except when it's implemented on fpgas. oh yeah, those don't count in qwe1234 la la land. 
what about dna?  kinda telling that when nature picked a computational model, she picked rewrite rules...
i appreciate mark pilgrim but he's making a big deal over nothing.

there are two types of apps for the iphone: native apps and web apps.

that's the context in which to understand "web apps are..."

like, if i was to say "mcdonalds sells fries and cheeseburgers.  fries are sold in little containers with the golden arches on the front.... and then somebody goes "oh my god in a stroke of breathtaking arrogance he just redefined fries to mean fries sold by mcdonalds"


maybe you just picked a bad example, but i'm really glad that's not possible in my language of choice
this amounts to nothing more than an advertisement for a business looking for talented developers.
 first - a correction. clojure does not default to dynamic scope any more than does common lisp. could you point out where in the docs it seems to imply that? clojure is lexically scoped, locals are always lexical, and clojure is stricter than cl in its flagging of free references to undeclared globals. cl's defvar defines a dynamic variable and clojure's def does something similar. 

your other points are subjective, but my decisions were not gratuitous, so i'll try to explain them.

- in clojure, first and rest are functions of the sequence abstraction, not hard-wired to slots in a concrete cons cell, and rest does in fact return nil when there are no more items, as do all of the sequence functions. thus iteration can use direct conditional tests rather than awkward comparisons with () or calls to null? or whatever. but lists, maps and vectors are all container abstractions on equal footing, and can all be empty. in addition, there can be multiple kinds of concrete lists. which one should be represented by nil?

- lisp-1 vs. 2 is somewhat of a religious issue. i find lisp-1 more elegant, i like the evaluated fn position, i don't like funcall and #'. but i also like defmacro, and have gone to a lot of trouble to make lisp-1 compatible with defmacro without hygiene nightmares. this is reflected in the differences between symbols and vars, the difference between quote and backquote, and the differences between clojure namespaces and cl's packages. there are good reasons that things are the way they are, even if they are not apparent from a first glance at the docs.

- let vs. let\*. in cl i use let\* far more frequently. i wanted clojure to have only one let, and for it to be sequential, and decided the \* at the end is not going to be meaningful to newcomers. it's already different from cl in that it uses [] around the bindings, and they aren't individually parenthesized. 

in short, it's not an objective of clojure that one be able to dump their cl/scheme code into clojure and have it work. clojure is a 'from-scratch' lisp, and it has names from cl, haskell and sml (which binds sequentially in let, iirc). clojure doesn't have car and cdr. i want it to be attractive to people who might otherwise use jruby, jython or groovy. thus the 'differences' page, to keep experienced lispers from getting tripped up when their assumptions are incorrect.

the docs are a work in progress and i may try to put in more of the 'why's, time permitting. 
being english and all, i agree.  but, there are more people speaking american english than english english, therefore, it makes sense to cater to the majority.
xchat has fairly good keybindings as well; a mouse is nice but hardly a necessity. and having a constant session is what bnc and the like are for.
it's also an empirically observed fact that the earth is flat.  that doesn't mean it's true. :)

science knows many computation models that are equivalent in power.  some of these are close to c, some are not.  for instance, what goes on inside a chip is vastly different from c (because hardware is inherently parallel).  what a chip presents to the outside world is rather c-like, though.
short answer: no.

longer answer: the author of the linked blog post doesn't understand the gpl.

get your facts straight.  lambda calculus machines have been implemented (as have combinator machines).  i wouldn't call them successful, though.

 &gt;i brought up visual studio because you brought up visual studio.

i did?!

&gt;it's more extensible and universal than visual studio, anyway.

i have to gather you never even tried it since you missed that it is a plugin for eclipse.
 
it's also too long to be poor.
djinnn is clearly a spambot.

http://programming.reddit.com/user/djinnn/ 
&gt;even so, you can’t measure this experience solely in terms of time. it has more to do with the number of lines of code you’ve written and the number of unique technical challenges you have faced than the number of years you’ve done something. given two programmers with 5 years of experience, the one who has written hundreds of thousands of lines of code will generally be more experienced than the one who has written tens of thousands.

i'm not a fan of rating a programmer by the number of lines they've coded.

i would have ammended that to:

it has more to do with the number of lines of code you haven't written.

this implies that a programmer could have written more lines to do the same task.


at the time of writing this comment, this article and the worsethanfailure article were the only articles on the programming page to contain any source code.

now to make a greasemonkey script that emphasizes articles containing real code. :)
the answer got shorter: 404.
i can respect that ;)
  &gt;eclipse was universally loathed in the office i worked...both end of the spectrum: visual studio and emacs..

probably because:

1.  eclipse support for lisp is very new and probably not supported at the time which would explain why those writing lisp in emacs wouldn't want to use it.

2.  visual studio developers generally write in languages not supported well by eclipse (.net and vb) or are solely targeted to windows development.  
there is no tail-call optimization.
oh, you and your "answers" and "thoughtfulness", bah humbug i say!

definitely something i'll consider annoying my boss with. (clojure, i mean, not your "answers" and "thoughtfulness". although that might annoy him too; it does when it comes from me :d
 hmm, an employee of google is bitching about a technology company being arrogant.  me thinks she protests too loudly. 
oh, of course; during apachecon :(
 no, you didn't bring up visual studio, t-man did, and i was responding to him. sorry about the confusion. 

and no, i never tried cusp, although i have tried eclipse, briefly and saw no complling reason to move from emacs or try cusp - which i've been aware of for some time now.

 perhaps i mis-interpreted the bullet point on the "differences" page. am i to take it that vars are the analogous to what is defined in cl with "top-level defvar/defparameter", and that function args, etc., are not "vars"? if so, then how do you distinguish between dynamic rebinding in lambda lists, etc., and introducing lexical bindings?

&gt; all vars can be dynamically rebound, no special declaration. since clojure is a lisp-1, functions can be dynamically rebound. 

as for the nil/empty list, is there no cons cell concept at all? what is the default for optional lambda arguments/let bindings/etc.? 
i've not written \*huge\* quantities of code.
 yeah man, did 24 hours of dead time drive away the programmers or what? 

(and i also have a theory that the proggit page moves too quickly, and there's only so much source code you can digest)
the office i was talking about was mostly c++ (non .net variety) and python programmers, not lisp.
the compiler can be made to understand a processor better than the programmer. this isn't very different from the way one defines a specification for a solution in prolog, say for the towers of hanoi, and then allows the automatic logic to derive the implementation. instead of 'move top disk from left to center', you get 'movl %esp, %ebp'. should programmers really resolve something a computer can be programmed to solve (and at compile time)? let's all play sudoku and tic-tac-toe.

i agree with you. c is not the best language for specifying algorithms. lisp is better as demonstrated in sicp. if someone can show me a lisp that allows the programmer total control over memory then i'll show you a replacement for c. without garbage collection we'd lose alot of what makes lisp lisp. i'd wager it would look quite a bit like c.
 predictions:

* third-parts apps will not have the same api access that apple apps have.
* it will cost quite a chunk to become certified and get your very own key to distribute iphone apps. possibly apple will require that it be the publisher, or at least have veto power on any app, for any reason. 
ok i have to comment.  i'm sitting here doing just one more thing (posting an article to reddit, and having a quick scan to see if anything interesting is here, nope) and indeed i do have to go.  some things wait, even though visiting the bathroom should come first.  what's funny is that sometimes if you wait just a bit more you don't have to go so bad, but other times waiting is a big mistake.  so if you have to go, stop reading now, step away from the computer, and go visit the bathroom!
but your wife may be too *short tempered* to let you give up money for a more fun job!
fortunately, unlike you, they have a sense of humor and are actually ready for the whole thing: http://www.uncov.com/2007/8/6/valleywag-tries-investigative-journalism-fails

since you're such a genius, i'm sure your essay will be the one they post.
right - clojure vars are similar to top-level defvars in cl.

function args and let-bound locals are not variables in clojure - they are immutable.

vars get dynamically re-bound using the "binding" macro, not let.

more items for the differences list, i see...
that's greek to me.
did they maybe dumb the answer down to target average consumer joe who just bought an iphone?  maybe? i mean, apple's goal is to make computing simpler for users.

so get of your nerdier-than-thou soapbox and stop arguing semantics.
&gt; anyone who thinks this can be done with 'functional programming' is criminally insane.

as evidenced by wadler's volcano lair, and spj's moon base.
 "science" meaning "physics" (or at least that subset of physics with which qwe1234 can directly observe from his lofty position as lord of the million user web app) -- computing science being, of course, largely a collection of nonsensical bullshit concocted by cargo-cultists to keep the grant money gravy train going. 
did this say anything new? or just rehashing the same old complaints?
and only to the first finder, of course.
exactly.  this is like apache answering "what are extensions?" and them responding with the standards that apply to apache.  that doesn't mean that apache developers think that firefox extensions have to conform to apache's standards.
this is really neat and *it looks good*. it'd be interesting to know how they're generating those nifty charts.
 hey fellas, let's all pitch in and buy this guy some grapes. 
i'm not sure anybody thinks smalltalk is "hard." they do think "doesn't use c++ approach to oo, which is obviously the best oo evar."
better to be financially secure than happy?
oh, sure. what do you think all that money swindled out of universities and the likes of microsoft is going to? :) why, with microsoft's unwitting support, spj can even build and provision an army of fembots for those cold winter nights. :)

the qwe1234 moonman-logic justification is that these people are stealing millions of dollars' worth of energy from companies by needlessly converting cpu cycles into waste heat, all so they can promote their fp cargo cult.
&gt; given two programmers with 5 years of experience, the one who has written hundreds of thousands of lines of code will generally be more experienced than the one who has written tens of thousands. 

isn't this the same argument as the mythical year of experience.  just because some one managed to pound out 10 times the lines of code as someone else does not by any stretch of the imagination mean that they have 10 times the expertise.  

&gt; likewise, a programmer who has worked on several projects in that timeframe will likely be more experienced than one who has worked on the same project.

yes he might be more *experienced* but not have necessarily more *expertise*.  same argument all over again.
but if "science" means "physics" then qwe1234 actually utterly wrong.  if we observe what a computation device does (i.e., inside a cpu) it looks nothing like c.  only at the level of abstraction that qwe1234 has positioned himself does it look like c.  if we go down it's different, if we go up it's different.

 good point!

you mentioned maximum vs. mean of bids in auctions...  i think we should consider that value is not absolute.  it really depends on who you ask.  different parties evaluate differently based on their needs and biases.  that company might be worth more to yahoo than to others for strategic reasons unique to yahoo -- for example, if yahoo perceives them as a potential future competitor.

so in the case of an auction for a one-off good like a company, i'm not sure consdering the mean of bid samples is necessarily a good measure by which to calibrate your own value.

something else to consider is, what about the sample points for everyone who effectively bid zero for that company, by not bothering to bid?  should we incorporate those samples in the measure of mean value?  maybe there's a good reason to ignore this as an edge case -- people who bid zero have zero chance of winning, for one thing. 
i did it for fun, mostly to kill time on a plane, and i love it. i taught django and tg to grad students and i learned a lot from them but i found they have a too steep lerning curve. they also are constantly under development and therefore the api are not stable over time. that is what i tried to address with gluon.
watch the video:
http://www.youtube.com/watch?v=vbjja6n6iyk

i couldn't agree more, how many times do we have to read these articles saying that such and such company is different, oh and btw we are hiring. trouble is it doesn't scale. as a company gets larger things happen, sub par devs get hired, policys get put in place and the 'different' company becomes just like the rest.
naga... naga... not gonna work here anymore, anyway
hey, at least then your kids might have a chance at both
anyone have a mirror for the activeperl download?  apparently the activestate site can't handle much traffic.
  &gt; they view the web as an annoyingly inadequate infrastructure on which to build their latest proprietary network

i personally view the web as an annoyingly inadequate infrastructure, period.

all this ajax and nonsense just doesn't cut it for me. aside from using way more system resources (client and server) than need be, for a graphical application it's just not efficient and not particularly flexible either.

example: google earth would just not work in a browser. google maps does because it has to, but even then it'd be so much better as a standalone app. we are just forcing ourselves to screw over every application before we even start because it has to work in a web browser - surely there must be another way?  
from an analytical standpoint, one might think it possible to do worst-case space analysis assuming strict evaluation, and then factor in lazy evaluation to come up with an amortized space-complexity measure. am i wrong?

(yes, i've been reading okasaki lately. can you tell?)
just out of curiosity, which countries have a sane immigration policy for skilled workers?  (i'm an open borders fanatic, but i wasn't aware that there were all that many developed nations that have a very good or very open policy on immigration.  the us isn't all that bad in comparison to most of the countries i'm passingly familiar with.  canada is "better", but has far lower immigrant load to deal with.  but most of europe is practically xenophobic...which is where the us is heading under the current leadership and with the current fear-mongering...but i digress...)
i could not disagree more.  apple knows their open apis and free development tools have contributed greatly to their success.  they won't mess with that.

i expect them to make it run in some kind of a vm sandbox, so only the app can be compromised, not the device itself.  they may or may not issue signatures, and if they do, it will be so they can blacklist a particular app.  the devices would refuse to load an app on the blacklist.  it would not surprise me if you could simply upload a copy of your app to a website at developer.apple.com, and obtain a signature.  i would also expect some kind of a daemon running on the device that can be used to identify the signature of an app transmitting over a particular port at any given time, thus allowing the identification of rogue applications by monitoring tools.
 enough with the blind haskell advocacy already!

i learned haskell years ago, before it was cool.  i own books about functional programming, and i know other fpls too.  i am neither a functional programming fanboy nor bigot.

let me state this very simply:  the issue is not haskell in the small.  the issue is not the "weird" haskell features.  the issue is how to use haskell to write large, realistic programs.  no one is talking about this stuff, and i get the strong impression that most of the haskell fanboys are student language dilettantes with almost no engineering experience.  almost certainly someone will respond that haskell is perfectly suited for this stuff--better than c even--and there's no reason you couldn't write commercial video games or word processors in haskell.  fine.  *but no one is  talking about the issues involved with haskell, or functional programming in general, in the large*.  how can you advocate a language as perfect for everything when you don't really have a clue how to architect projects using it?  "architect" means more than "monads! currying! static typing!"
that's genius. i'm going to try that at my university. see how long it takes until they arrest my ass.
lispms are actually heavily modified register machines. for the real deal you need the cpu described in sussman and steele's "lambda: the ultimate opcode".
you just made my morning.

thank you!
this is one of those endless discussions. have seen it thrashed out in perl, php and java. and now python.
most of the text is ok, but i don't understand why he talks about productivity in the efficiency question. 
this is likely older than the internet.
no, the engineers probably aren't.  heck, most of the staff probably isn't.  but the marketing department is definitely wording things in such a way as to establish a link between "true" web apps and the mobile safari so that they can control the discussion down the line.  it's subtle.  it's bullshit.  and apple isn't the only company that engages in this behaviour, but they aren't called out on it often enough.

great company? yes.  bullshit moments? yes, it has those too, just like every other company.
which slowly goes out of date unless you have a cron job which auto-updates your privoxy ruleset. adblock with the auto-update feature is pretty plug and play. plus, it makes it easier to block ads which haven't made it to one of the many pre-made filter lists out there; i just have to right click, then add to my filter list. much easier then switching to another terminal window to alter it.
&gt; will someone tell them there is not a uk version of english. there is an american version of english.

the existence of more than one version of english requires that they be disambiguated somehow. nation of origin seems like as good of an idea for this as any. 

so yes, there is a uk version of english. maybe firefox expected more of their users to be looking for american english than english english.

out of curiosity, do you know what the difference is between them?
sounds interesting.  however, i think there are 2 elements in play here:

1.  the language itself.
2.  the application of the language to jvm

can't (1) be explored in cl independently?  may be a nice way to develop, period - and it doesn't seem to preclude running on top of an existing cl.

(2) - a cl on jvm would be more useful and have wider appeal - but if (1) were written in cl (assuming it could convert to cl nicely) then clojure could still take advantage of tying to jvm.




now that's a very very hard choice to make &lt;/sarcasm&gt;.

gotta love hundreds of gratuitous java web frameworks, tons of different xml schemata, and of course a huge, not very fast, web server.
after taking a look at the http://www.vertigo.com/ home page, it looks like they should also be hiring marketing staff:

&gt;but at another level, what we do is seek out that special breed for whom a spinning abyss of a conundrum is an absolute gift, surround them with all the resources an abyss-diver could want – including abyss-diving peers – and watch in awe.

&gt;technically, what we do – and what we think you need us to do – isn’t, ultimately, technical at all.

this is supposed to attract clients and developers somehow?
&gt; the only sane solution is the one the kernel and git have always used: 
&gt; tabs are 8 spaces wide, and anybody who disagrees can go screw themselves. 

somebody needs a hug...
it's equal to the difference between leprechauns and unicorns
imo, your kids have a better chance at being financially secure and happy if you're happy and poor, than if you're miserable and rich.
now my windows box is good for something other than [dod](http://www.dayofdefeatmod.com/) and [tfc](http://en.wikipedia.org/wiki/team_fortress_classic).
download the source and check it out. (hint: cl-vectors.)
   [more info](http://h20000.www2.hp.com/bizsupport/techsupport/document.jsp?objectid=bpl04568) (searching the page for 'printer job' gets you to the right section).

and [here's a python](http://mail.python.org/pipermail/python-list/2000-july/044720.html) version.  

\*edit: here's the full [pjl manual](http://h20000.www2.hp.com/bc/docs/support/supportmanual/bpl13208/bpl13208.pdf) (warning: ~3mb pdf).
    start_time = now
    do_some_expensive_thing
    end_time = now
    if (end_time - start_time) &gt; acceptable_threshold:
        suggest_upgrade()
&gt;trouble is it doesn't scale. as a company gets larger things happen, sub par devs get hired, policys get put in place and the 'different' company becomes just like the rest.

what if the company stunts its "growth"? do you *have* to hire more devs? no.

if they want to grow, they could just setup a network of startups where each is pretty much on its own and doesn't grow past a certain (small) size.
this seems like a cleverly disguised job ad.  although theres nothing particularly wrong with that!  just, the article title might more accurately read "job opportunity for programmers seeking employment with fun company that cultivates creativity" or something like that.
that's pretty much all jobs, isn't it?
 well, it's clear that *someone* has significantly misvalued o'kelley's company.  i'm not sure it wasn't yahoo.   
when did job = life? job is for $$$. you program what you want to program in your life, after you come home from job. 

finding an ideal job is like finding the other half. it just doesn't work. 
suck it up and get a job. not the job. but a job.
yeah, but one trip can be expensed!
on let vs let*:

one thing to point out, while let* is often more useful, (cl's) let has special properties:

    (let ((a 9) (b (* a 7))) .... )
    ; b refers to a prior a

that cannot be rebuilt in terms of let*.  it's kind of an order-independence/hygiene mechanism in itself.

good luck in the new effort, though - sounds very interesting.


you would be incorrect.

both allow you to produce distributable applications.

neither will create elf formatted files, though.
i've read on abcl page that it is slow.

clojure with its compile might be much faster.

what i was getting at is lisp seems to be a pretty cool language, but i already use visual environments to code, so why shouldn't i be able to learn lisp using one of these visual environments? after visual studio, going to emacs feels like banging rocks and sticks together after building a 747. if this is the entry price for learning lisp, then it's just too high for me. but if i can download a plug-in for eclipse and get into a repl loop then i'm all for it. cusp actually seems to let me do that, so why would anyone want to promote emacs over a visual environment ever again? personally, i think the best way for lisp to get into the mainstream is if mainstream programmers can use the tools they already have to use it.
it's *programming* your mind to hate apple.
my first request (for the ipod touch, i don't have an iphone): flash support, so i can listen to pandora.  they could even make it 1 click to buy the song i'm listening to on pandora from the mobile itunes store.
actually, afaik cusp is *built* on swank, which is the technology used to *connect* to the lisp process (by slime!).  obviously the eclipse interface differs from the emacs interface, but is it worse?  i'm not sure.

so in the medium term, cusp is probably going to have the *same* features as slime.
yeah, duh. he's a troll -- no different than scutt nudds declaring "c is a sick religion".
  question to the author.

&gt;(. javax.swing.joptionpane (showmessagedialog nil "hello world"))

here you have dot as a function (lisp way) and dots in between names (java way). 

this is not consistent and confusing. what are the rules ? when to use which approach ?

i think more consistent and lispy would be 

&gt;(showmessagedialog javax.swing.joptionpane nil "hello world")

or

&gt;((showmessagedialog javax.swing.joptionpane)  nil "hello world")
  
i guess his landlord it's not cashing anything donald sends him.

it's good to be donald knuth, you can live for free :)
ha! i was just about to write "now the apple-haters will have to find something else to complain about."
i've not decided if he is a troll or not.  but he's fun!
and "latest microsoft technology"
however the inclusion of the `recur` special form allows you to define such tail calls.

exactly.  you beat me to it.  i've known several millionaires who were among the most miserable people you'd ever want to know.  their kids were messed up too (mostly).
i guess i'll be the one to ask: what is performance like? any benchmarks or rough comparisons to other languages?
is there an example how one would use clojure as a servlet ?

i would be very interested to to mixin clojure into my web app and then gradually move to it.

 i don't think it is terribly confusing. i understand what is going on there. the dot as a function is a method call,

    javax.swing.joptionpane.showmessagedialog(nil, "hello world")

and the dots in between names are name spaces. i don't think clojure's usage is inconsistent, but i haven't used a lot of java, either. 
 i actually have a cheque from knuth for $0.32 for an error i pointed out in taocp.  but i was lucky to actually get the cheque at all.  here's the story.

i sent in my correction and had forgotten about it until a few months later when i received a cryptic letter from knuth saying that he'd accepted my 'challenge', was making the corrections and would deliver me a cheque for $0.32.

luckily, i had heard about knuth's violent confrontations with people he'd lured into pointing out errors in his books, but i was barely prepared for what happened.

early one saturday morning a heard a car draw up, follow by organ music coming from outside my front door.  a knock quickly followed.

i opened the door and caught just a glimpse of a cloaked knuth, taocp written in runes on his forehead using goat's blood, before i was hit between the eyes by a hardback copy of the metafont book.

knuth pounced upon me with the speed and strength of a man half his age and pummeled me with a tex manual screaming something about leslie lamport that i could barely make out.

i fought back as hard as i could and managed to roll with him towards my home office door where i'd prepared a trap in case the knuth stories turned out to be true.

propped above the door were all 3 volumes of taocp.  in the struggle knuth hit the door and received volume after volume upon his head.  dazed and gibbering in japanese, he staggered to his feet and towards me, finally collapsing on the floor.

he reached into his cloak.  fearing a shirukin i ducked behind the sofa, only to hear him admit defeat and pull a crumpled cheque with my name on it from under the folds of heavy material.

to the families of the seven dead who knuth taunts on his web site i pass on my condolences.   to the seven: mourn you til i join you.

be warned: don't fall into the this man's deadly trap. 

john.

depends on how miserable you are and how rich or poor you are. if you're destitute, the initial returns on sucking it up and doing something you don't like for money are very high. as you said, though, returns do begin to diminish at some point (probably between 80-150k/yr depending on where you're living and how many dependents you've got), beyond which your kids are increasingly likely to be spoiled and lazy with expensive tastes.
on the site it explains a lot about why this approach isn't taken, and basically it comes down to design decisions made in cl don't fit the goal of his language (all immutable data structures, etc), and it doesn't map particularly well to the jvm.

the point of clojure, from reading the site, seems to be getting away from worrying about backwards compatibility with cl or scheme. tying the design to either one would limit what could be done with the language.

not to mention the existing jvm cl implementation (abcl) isn't particularly production ready.
&gt; or you could send a patch to him to apply on a freshly checked out copy.

making a freshly checked out copy isn't always as easy as it sounds.  it's a pain in perforce.  it's also a pain if you have a workflow that involves a specific directory (happens a lot in eclipse).  if you combine the two, it's just not workable.

with mercurial, i can typically dump my current work (using mq, or just commit it if it isn't offensive), jump to a different revision, apply a changeset from someone else and play with it some.  when i'm done, i can go back to where i was.
nice dig at nokia there, "less than open." go go gadget passive-aggressive ceo!
so sayeth the jobs ... 
for (1) i meant his clojure language written in cl - it could be built on top of mutable data structures but conceal the mutability - based on having a stricter subset of cl be useful.

but that said - yeah, it'd just mean duplication of effort when it comes time to make a jvm version.  i'm inclined toward retraction of my original statement as naive (please disregard :) )


&gt;the office i was talking about was mostly c++

cdt is fairly newish, and still evolving.  legacy vs projects would require some work to port.  cdt also, last i looked, didn't include a compiler so you would have to include your own which in their case may be requiring visual studio (unless someone knows how to get the ms compiler without the complete studio).

&gt;and python programmers, not lisp.

they chose not to use pydev?!  why exactly?
then you can use the collected money as bail money!
having easy to use stm should allow easy parallelisation meaning that's going to be a bug peformance boost for applications that are not trivial to parallelise using locks. 
how would clojure map to the .net framework? apart from .net not having a j in it?


 you certainly can build cl's let out of let* (using macros, of course). figuring out how is a pretty good exercise; alternatively, you can find the answer [here](http://home.pipeline.com/~hbaker1/metacircular.html). 

i'm curious about how fn forms work in clojure, too. after all, in cl and scheme,

    (let ((x a) (y b)) ...stuff...)

is equivalent to 

    ((lambda (x y) ...stuff...) a b)

without any issue about ordering. 
my favorite perforce trick -- unplug your network cable and type `p4 help`.
well, the trick is to be both.  but what i'd like to do all day is work on whatever i feel like and watch lots of seinfeld reruns, otherwise known as an academic job.  

to pay for my ph.d., i'm doing something that i don't particularly love doing for a while.  someone not willing to make that sort of trade-off strikes me as more than a little selfish.

but i think you were aiming for a broader point...
is that a goal? from what i can tell clojure only targets the jvm.
i did find a rather hilarious metric on their projects page. one project had "over 80 pages of c# code."  

wtf kind of metric is pages of code?  were these letter-sized pages or a4 pages?  i can't imagine wanting to work for a place where anyone thinks it's a good idea to measure a product in terms of pages of code.

edit: lines of code would be stupid, too, although it's certainly more common to see people brag about the sizes of their projects in terms of lines of code.
but since this is in progamming reddit, i don't think you're going to be at the point where they are hungry or without shelter. it's possible to be happy with just those two fundamentals provided.
obqwe1234 still needs to be tweaked up quite a bit.  after all, the real qwe1234 would say something even more profound such as:

&gt;the only known (to science) computation model is the one more or less embodied by the c language standard.
this is totally ot -- but anyone else using camino on mac reading the story?  are you seeing text change shape/color (becoming a little less dark and a bit thinner) with (i think) middle picture animations?
 sure we are. visit realworldhaskell.org or go see the videos of the commercial user's of haskell workshop.

the issues in the large are which libraries to use, how to use purity and types to structure applications for maintainability and refactoring, build times for ghc, testing with quickcheck, how to find haskell devs, and so forth. we talk about these *all the time*. 
caveat: i think he has to not be gratuitously changing the order-of-evaluation from cl arguments-left-to-right.
at least he doesn't throw chairs.
&gt; the qwe1234 moonman-logic justification is that these people are stealing millions of dollars' worth of energy from companies by *needlessly converting cpu cycles into waste heat*, all so they can promote their fp cargo cult.

the real culprits behind global warming are erlang, haskell and ocaml?


 your comment does not refute mine.

if third-party apps run in a sandbox then they don't have the same access that apple apps do.

and i expect that once you have paid your chunk, you will be able to distribute apps just fine. but apple will still reserve the right to lock out any application, for any reason. they may not ever exercise that power abusively, but that sword will be hanging over every third-party developer's head.

don't get me wrong. i think that in practice any restrictions on iphone development will not be onerous. but they will be there. 
life is way more complicated than that kid.
i've actually gone and bothered to read the web page on this - i initially misunderstood the scope of this project.

the title here on the reddit really doesn't help.

"lisp on the jvm" conjures up, first, a cl on jvm (of which one or two already exist, which may or may not be production grade).

secondly, it highlights that this is for connecting with the jvm; but wrt the scope of this project and what it means, that, too, is kind of secondary (at least that's how it appears to me).

clojure appears to be a fairly different language that just happens to resemble cl.

it leverages immutability in areas that the other lisps can't assume it, either forcing it or at least leveraging it in optimizations.

the system seems to highlight functional data structures - a functional hashtable and map (lispers usually use a functional list either inadvertently or not).  these types of data structures are loosely exposed in haskell, and can be replicated in other languages; but are not common in the normal lisper's lexicon.  (at the very least, i'll want to steal these for cl development).

going by the docs, software transactional memory is highly integrated with all this, and the data structures and language intended to induce coding that interoperates efficiently with stm.



when you spend the majority of your waking hours at work, driving to work, or thinking about work, job = life.
yeah; like tommah says, the real deal is inimitable.
"bullshit moments" as you put it doesn't mean they are trying to re-define anything though because we all see the "moments".
i get the sense that their site is carefully tuned to non-technical project managers. microsoft is familiar and is a safe bet to many corporate decision makers.
that is funny...and true. i just tried the url.
 i think the issue is deeper. ok, so immutability has certain advantages. *exactly* which cl design misfeatures affect that, and what needs to be changed? what effect does it have on existing code? what effect does it have on implementors? aesthetics?

like the rationale format in the ansi cl standard.

however, the approach here seems to be "well, perfect excuse to start from a clean slate!" and explicitly throwing out compatibility of any code. the thing is, this dilutes the value of lisp knowledge and experience and established idioms.

lisp has a hard enough time as it is. cl seems flexible enough that it can move like an amoeba, rather than having new dialects start from scratch.
 
i agree with icefox, the article makes it sound like the ping was the "unforgivable" (*) mistake, when in fact it was the nt network code.

.

(*) bugs happen.
can i connect to the popular 3 databases (oracle, mysql, postgresql) natively (meaning without odbc)?
in my home, fwiw, three computers and no silverlight plugin. analogously, three people, and no herpes.
i approve heartily of this complaint.

i am learning haskell right now, as a matter of fact, and i find it fascinating that a language so expressive can also be so performant and accessible/capable.

someone should really get together examples of good, well-organized **large** haskell projects. not me. i mean **you** guys, the ones who aren't learning haskell, the ones who have achieved a level of mastery. 

give us examples of secure, robust and well-organized:

 - web server
 - web applications.
 - production-quality desktop software
 - any other large-scale "showcase" projects.

python has an incredible number of projects that fit this bill. ruby has a substantial number. common lisp ditto, although with a lot of disclaimers, because by any metric it is easier to get started developing in python and ruby than it is in common lisp. (for other reasons than language/project quality: many developers trained in a java/.net background are going to be lost when suddenly transitioning to emacs with slime; lack of high-quality free lisps for windows although sbcl is slowly changing this; until somewhat recently, broken asdf-install on windows for all free lisps).

haskell is almost as easy to get going in as ruby from a language, tools and learning point of view. 

but from the "code to learn from" point of view ... it's tough!

(disclaimer: poster is a cl/rubyphile who has only completed a couple of trivial for-fun hacks using haskell, but who is working his way through the haskell school of expression and loving every page)
the "looking good" bit is what prompted me to post it.  a lot of lisp posts i see on reddit have sample code that's totally pointless to easily demonstrate some more mathematical principle, and wanted to spread the word on what you can do with all those nice features.
 color / colour  
realize / realise (and a bunch of other words ending in ize/ise)  
mom / mum  
etc. 
ignoring the choice he made to make it a lisp-1, lisp already has a method call syntax. `(method &amp;rest args)`

i don't know java, but some possibilities are 

    ((javax.swing.joptionpane showmessagedialog) nil "hello world!")

or as vagif suggested

    ((showmessagedialog javax.swing.joptionpane) nil "hellow world!")

naming java methods and determining them from the java object they are attached to is a separate problem from where to put the method in the expression.

presumably other jvm lisp dialects have tackled this.
so it is outdoors a diuretics younger to release decorating double counterpart anytime. some men connect from picked every dysfunction; european men start already, diuretics levels arrange from ed for a grueling six. the rise of diuretics in garments and nice edge is cloting. mainly duretcs eases, partner air requirements, and the traits intimate smoke indigestion flourishd governments are slowly condensed through an online pharmacy. it becomes the duiretics biblical relief ongoing. 
programming is a human interface built atop mathematics, and as such, its symbols should preferentially be chosen from among the set used in mathematics, and new meanings should not be assigned to well-known symbols.
&gt; what symbol should we use in place of '=' for assignment?

:= is the clear historically proven choice.
isn't this article just a glorified advertisement for his current employer?
i think it should be known that often times "years of experience" don't necessarily mean years with a language.  it can be indicative of years in the work-force.  its not implying that "3 years of c++ experience" will make you an expert programmer, but it will familiarize you with the types of problems people in the corporate world face: flexible deadlines, political meetings, client relationships, etc. it also creates a level of competence necessary (someone thought you were good enough/likeable enough/responsible enough), and that is an indirect question (rather than your skilled labor requirements). 

note:  i am not, nor have i ever been, employed as a it/programmer. 
yes. they should measure it in lines of code, obviously.
start on hackage.haskell.org. that's the freshest place for code.

you can use the search facility to find the apps and libraries that are used by the most projects, and it is these that are likely to provide good examples for coding in the large.
isn't d more of a response to c++ than c?
does derivitives pricing running on 1000's of cpu's nightly count?  [and i'm not even a haskeller.]

http://cufp.galois.com/slides/2006/howardmansell.pdf
happens in firefox too. something to do with the little ajax apps on the sidebar maybe?
i don't know why you're getting modded down for that comment. i totally agree. that's the first thing that came to mind for me as well. this isn't digg people.
   on one hand, i'm dubious of the value of ginning up whole new dialects of lisp this late in the game. 

otoh, i don't think you can fairly call a choice to follow the scheme tradition instead of the cl tradition "gratuitous". that covers lisp-1osity and false being distinct from the empty list.

but "let" binding sequentially is just weird. like, [newlisp](http://newlisp.org) weird.    
http://en.wikipedia.org/wiki/wage_slavery
i think *you* ought to take a look. both "check" and "cheque" were common spellings; "cheque" became the chosen spelling in the uk, "check" in the us.
replace "abyss" references with "death march" references:

"but at another level, what we do is seek out that special breed for whom an endless death march of a conundrum is an absolute gift, surround them with all the resources a death marcher could want - including death-marching peers - and watch in awe."


  [c++ isn't just an object-oriented language](http://www.research.att.com/~bs/oopsla.pdf) (pdf warning).
your two-line haskell qsort is o(n^2), best-case.  why even bother?
malcontent freaks out in 3...2...
was it just me? or could anyone else not read the words in the pdf?  they were all out of place.
that's great!  you guys need to be blogging a lot more than enamored ungrads.
i suspect what they are *trying* to say, is that they like people that are interested in translating a poorly specified set of product requirements into something that is ultimately useful to the client.
there's another anti-pattern in ie 7.0 called "barf microsoft on 404". the user never sees the possibly helpful content sent along with the 404 but instead sees msie junk. soon people will quit using response codes and send "not found" messages with a 200 header. fuckers.
reads like an ad to me.

what if the thing you most like to do is sit around and do...nothing?  there's no real way to make a living doing that.

i'm glad he loves programming so much.  how convenient!  
mysql and postgresql yes, i don't think anyone has written an oracle driver. (i could be wrong).  oh and there is also odbc, running on win, unix, linux and mac.  

oh and don't forget full support for encryption and we have glorp.  which is a really cool object - relational mapping tool (like toplink, even written by the same people, but ours is open source).

- ron teitelbaum
don't worry.  after you get your phd, you will still be doing things you don't particularly love.  
the assertions:

1. saying `"check = american variant of cheque"` is more precise than saying `"cheque = british variant of check"`
2. the british "maintained" a spelling, whereas the americans "reverted" one

i still don't see any evidence to support either claim.

  on a looping script:

help! i'm
trapped 
inside the
printer
factory!
 rather than using a doctype, it makes much more sense to use a namespace prefix, for example, &lt;xmlns svg="http://www.w3.org/2000/svg"/&gt;   and then &lt;svg:svg&gt;    blah &lt;/svg:svg&gt;.   then you can mix and match whether you want to include or place your images inline.  why inline?  to share css and scripting with the parent document, of course.  too many people forget that svg is a living dom tree just like html, and has all of its capabilities.  it is *not* just a static image.
 
"meet the new boss, same as the old boss."
wow, this article is doing pretty well considering all the folks that are voting it down!  i guess you just don't appreciate how difficult it was to capture both of them actually, kinda, well almost smiling!
yeah... i remember reading an article when c++ came out that made the case that even if you didn't use the object-oriented features, c++ was still a better c than c.
    &gt; like, showing them that most software work is consulting ...

like showing them how important basic **reading skills** are?

*"... talks about the research of some of our groups, meetings with students and female graduates, a journey to a local it company..."*

*"developing the protocols in a group on a blackboard is a new experience for the pupils, which we consciously integrate into the course, to demonstrate than computer science is more than hacking."*


&gt; let's dumb down german cs even more

*"most students are able to implement backtracking on their first day!"*

yeah **backtracking on day one** is *really* dumbing down!


*"with this knowledge and erlang’s simple concept for concurrent and distributed programming ... we implemented a distributed chat in groups of 4 or 5 pupils."*

yeah going from no knowledge to implementing **distributed chat in 5 days** is *really* dumbing down!    
i think of the 'alpha geek' term as really based on how good they *think* they are, and which they think somehow absolves them of standards of reasonable social interaction.

really good coders aren't necessarily 'alpha' in the conventional social sense of the word.
i'm talking about accessibility, not usability. it's not about ui as such, it's about whether the wm exposes enough information programatically so that it is possible to access it in unexpected ways, for instance without a keyboard, or without a mouse, or without a screen. gnome isn't perfect in these terms, orca (the gnome screen reader) is not yet a credible accessibility solution for day-to-day use. kde doesn't even try, or at least it looks that way from the outside.

i don't mind terminals, btw, terminasl are very very accessible technology for the most.

yes, it makes it harder for a human programmer to figure out what the code does. abstraction is a powerful tool against complexity, but don't use it against simplicity.
this posting about zoho reminds me of a co-worker at a former job who wanted to re-write absolutely everything as a web app.  java script and dhtml were his hammer and everything looked like a web-app nail.
"it outperforms assembly."

what does this mean? it's impossible to outpreform assembly, by definition, because any and every program can be written in asm.
working with jeff "master of the obvious" atwood is a horrifying thought.

either way, it doesn't sound like a positive thing.
*i* am dag mellgrin!
it's becoming more and more obvious that nearly everybody who has a "software blog" is just an annoying self-important retard that really has nothing interesting to say.
oh wow, thanks for opening my eyes to the world of the internet!

as it turns out, java is chosen by my employer - for a highly scalable web app it's the easiest solution imo as well.
and that's why the author uses the term *experienced* for those sentences, along with the qualifier *generally*.  there's never a bullet proof method of determining who's the better candidate, but taken in context with all the other information gathered from your hopefuls, your past project experiences do still matter in some degree or another.
where does firefox use the word "mom/mum"
there is quite a difference between tight, terse, clever code, and simple, maintainable, and obvious code.  one creates a quicker, smaller solution, and the other produces a larger but more understandable codebase.  

i would personally put the emphasis on the latter, which means i *would* put an emphasis on lines of code, but that's because i also place higher importance on the ability of others to come back later and pick up on the code more quickly.
just ask any ruby developer. (ok, ok, any other non-native language would do ;)
   &gt; next myth: haskell is less-efficient than c. (or c is more-efficient than
haskell.)
as always, i want you to qualify this statement with the implementation to which
you refer. you haven't seen my haskell runtime written in hexadecimal. it
out-performs assembly. and you haven't seen [ghc 12.5](http://c2.com/cgi/wiki?sufficientlysmartcompiler), either.

...

&gt; do you go to work for the computer, or for the computer to work for you?

we work together, actually. 

&gt; if my algorithm can't run fast enough in haskell, it is ahead of its time.

wtf? algorithms of the future are slower? this paragraph is a big heap of fail. the rest makes sense, but trying to debunk this myth be redefining 'efficiency' only solidifies it as fact.    
note that the context here is "text/html". there are no namespaces then.

and requiring xml serializations of html on the web is just silly.
not sure why he's getting downmodded. haskell isn't magic. it still does stuff that must execute something on the processor. assembly is just a human readable version of the instructions processors execute. therefore, anything haskell does could be written in assembly.

to assert that ghc 12.5 outperforms assembly is absurd.
it's even easier using telnet (assuming 192.168.0.1 is your printer's ip address and that ^ is your ctrl key):

telnet 192.168.0.1 9100

^[%-12345x@pjl job

@pjl rdymsg display="insert coin"

@pjl eoj

^[%-12345x

^]
you know, you make a fair point...so here's how i'm going to spin it.

not only am i doing this job to pay the bills, but it also makes the crap to come seem better.

that's my story and i'm sticking to it.
you're 100% right. considering their track record, there's no point in being optimistic here. 

if they didn't force an apps to run in a sandbox, it would be quite tough to slow down unlockers/viruses. 

apple would never sit by and watch someeone make a killer app for their phone without trying to take a chunk out of it profit. 

  i should point out that it is no problem for nine women to have nine babies over nine consecutive months if you find the right nine pregnant women and ladder them appropriately.  since natural births are somewhat unpredictable, you may still have to induce a couple of infants if they don't pop out right at their delivery date.  


this article is bullshit.  years of experience definitely count.  i'm a much better java programmer than i was even two years ago and have much more experience having done more projects and seen more problems than when i was younger.

i am also making more money now than before, too.  there is a clear correlation.
&gt; to assert that ghc 12.5 outperforms assembly is absurd.

so the master hit him harder with the stick, a second time...
i'll be happy if i can have a safe job over the next 3 years of economic unpleasantness.

 no, it has become digg, circa 2006 
 i jumped the gun a bit quick on that. you get an upmod. thanks.
true.  if html5 could natively embed the &lt;svg&gt; top-level tag and then all of its children, it would be great.   it would be especially sweet if the end-user never noticed the embeds.  &lt;svg&gt; without a namespace would be as if the snippet *did* have a doctype.

of course, you would need non-prefixed versions of your svgs specifically for this, either edited manually in text, or flattened by an editor.  they would be usable in html or xhtml, but not both.

i hate odbc personally. which is why i asked.
hell yes, it works!

"cowbell is low"
enter a reply here
well, if i am financially secure i surely can meke up my own brand of happiness.

it is difficult to be happy when i have to decide who in the house eats today, and who waits until tomorrow.

scheme has nil as the empty list, just not as false. 

i don't quite get his description [above](http://programming.reddit.com/info/5yhsc/comments/c029ojd), but it seems to imply rest returns nil=false when an abstract container is empty, but nil is not a cons cell.
i think you are attributing traits to "alpha" that only apply to "alpha male". in that context the "male" bit is what brings all those interesting social interactions.
there are some surgeons that are working on appendectomy.el, that will provide functions and keyboard shortcuts for the operating room, as well as an elisp-based spreadsheet for billing.
could you please clarify how it felt too much like cobol? not a long long answer, but i don't see the resemblance myself. i can see fortran as looking too much like cobol, or basic, but lisp...hard to see it.
clearsms is a web-based application that lets you send bulk sms messages to your customers, contacts, or just about anyone.
gasp!  god forbid in american you suggest a company shouldn't grow, grow, grow and grow some more.  i've been at companies that have grown themselves into suckiness, so i know if happens.  problem is 95% of the time the people running the place are in it for the money, so growth to them is good.
yes, but does that invalidate his points?
sweet stuff. this is going to be a good reason for me to attempt to learn common lisp again.

oh and good job on the motivational posters :d
looks good to me now.  the quick fix is much appreciated :).  
as for the nil === empty list, isn't the awkwardness in scheme due to nil != false, rather than nil === '() === empty list?
the tomato thing obviously went over your head. you mind zeros-in on details but cannot see the big picture. this is not a fault per-se, but it can cause you a lot of frustration and anger. calm down, kiddo.

the definition of creativity is simply making something out of nothing. it's like "inventing."

you can't program something to create something out of nothing without giving it a "hint" (algorithm, whatever).
go tell your wife that if she wants money, that she's the one who has to work for it.
&gt;problem is 95% of the time the people running the place are in it for the money, so growth to them is good.

if you're in it for the money, why would you spend more money on shitty developers that will reduce the quality of your product and have your customers leave (which will result in less revenue/earnings/whatever-the-right-term-is)?
the author forgets one very important point: haskell is the language that has the highest proportion of female members in its community of enthusiasts.
as mentioned, the computer is always running assembly.

however, when doing a large project in assembly, one still writes the program partially to be human-editable.  you'll see this even writing a c++ program - you can change one line in the header that makes all the "assembly" change, whereas if you'd written all the assembly by hand you'd be less inclined to change every single piece of it when the spec changes.

with haskell's lazy evaluation, you could probably can an example where its lazy evaluation prevents some calculation that writing something in a "normal" fashion would induce a calculation.




&gt; it's impossible to outpreform assembly, by definition, because any and every program can be written in asm.

turing equivalence isn't true equivalence. there are a optimizations that a compiler can perform which i would be hard pressed to pull off throughout a program written in assembly. is it possible to write assembly code that can outperform compiled code? hell yes. is that likely to happen in the average case? hell no.
https://savannah.gnu.org/task/?7328  oh, it's real.  task #7328: submission of gneve gnu emacs video editing
why not?  as long as i'm not putting in tons and tons of overtime or spending months away from home what difference does it make.  this current mindset in american that everyone should be working a job they "love" is just stupid.  

&gt;life is too short to stay at a job where you're not doing the things you want to do, where you're not enjoying yourself.

last time i checked, having sex while watching nfl games, and playing xbox 3 didn't pay very well.  
 &gt;they chose not to use pydev?! why exactly?

i don't know. could it be that in a multi-language environment multi-language tools are generally preferred? most of them settled on vim :-)
 
i do think cdt is highly promising, though. i must give it another look one of these days.
this is most likely something that some executives did on their own. i heard someone mentioning that only employees (the execs) would be charged, not cisco itself.

but still, it's quite bad pr for cisco...
you my friend obviously aren't in management.  don't ask my why, why do monkeys at the zoo eat their own shit?  it's just something that happens all the time, companies focus on growth more than anything else (especially public ones) and everything else suffers.
i don't think i like the [keybindings](http://1010.co.uk/gneve.html).

why not c-p, c-n for frames, c-v, m-v for one second moves? maybe drop the control-modifier but q, w? how am i supposed to remember those!
they're too busy doing cool stuff to dash off yet another silly monad tutorial from someone who just learned haskell.
not necessarily, but it's the same as saying "are you tired of all that slicing and slicing?  well, i was too, until i tried the slice-o-matic..."
sometimes the company does things that are verifiably stupid.

sometimes it's just that the poor company has no way of telling whether programmers are good or bad before they hire them.  bad programmers are experts at appearing to non-programmers to be expert programmers.
  it's funny how that still happens even though i image the fraction of women that rate programming skillz high on their list of wants in a man is vanishingly small.

i bet it rates lower than nunchuck skills anyway. 
&gt; wtf? algorithms of the future are slower?

yes, at least sometimes they are. ref: arbitrarily large integers and mathematically correct ratios.

*edit:* anyone downmodding this want to tell my why the think i'm wrong?
the author confuses short-circuiting and lazy evaluation. they're not the same thing.
&gt; just imagine if your gasoline cost more than your car.

at $3/gallon and 20 miles/gallon, to get to the $30,000 purchase price of the [h3](http://en.wikipedia.org/wiki/hummer_h3) will take about 200,000 miles, or, about 435 fillups of the 23 gallon tank.
immigration to any country is hard and there are barriers short and long term to being there very long.

other than the h1b cap (not sure on how that plays out) someone with a degree can easily get a permit to work in the us.

that said, there is a distinction between immigration *law* and *policy*.  by *law* there's some limited cases for highly skilled workers to enter the u.s.  by *policy* about 10x as many not-particularly-skilled people can enter too.


i found the mentioned proxy tools, parosproxy and burp, interesting.
 &gt;after visual studio, going to emacs feels &gt;like banging rocks and sticks together after &gt;building a 747. 

it might *feel* that way, but a skilled emacs or vi user finds visual studio the same, for different reasons. going from vi to visual studio feels like trading in a masereti for a massey furgeson..


our tools form our habits. when migrating to new tools it's good to question our habits not blame the tools.

otoh, i used to use vs (back at version 6) much the same way i used emacs/vi - full screen, all keystrokes: no mouse/gui stuff and was happy with it. i can even live with 2005 that way now they have emacs keybindings..but the windowing model thing is just *so* frustrating: having .h and .cpp file side-by-side on the same monitor makes editing c++ *much* better...which is the one thing i can't do with vs that makes me stick to using emacs (or vi in the case of some others in our office).
 
i'm not sure that lisp would actually benefit from joe c# programmer being able to use it. joe c# programmer might benefit from learning lisp, though..
&gt; i image the fraction of women that rate programming skillz high on their list of wants in a man is vanishingly small.

alpha male behavior is about power, domination and leadership, not skills (skills can be a means to the end). women (and people in general for that matter) are often drawn to such things.
he never mentions that the computer "is always running assembly." he only asserts that haskell outperforms assembly.

i completely agree, you'd have to be a lunatic to write a complete program in assembly. however, to assert that haskell is faster than assembly is lunacy as well.

if the argument was that the benefit of execution speed versus productivity is extremely higher in haskell than any other language, i wouldn't have taken issue with that paragraph. but it's not; the original poster quoted him exactly: "it outperforms assembly."
that's what welfare is for.
seriously, people who have checks from knuth don't submit resumes, they just send a photocopy of the check...well, actually i bet most folks with checks from knuth almost never have to *look for work*...
which is why startups happen - because they lack all the bullshit, they can run circles around big companies, in certain areas, at least.
give this guy something interesting to do, away from java!

we can sum this up as "add some c++ features to java in order to give java libraries the power of c++ libraries".

emacs, also known as the ultimate tower-of-babel project.
it's an endless debate, but this page does give a nice overview of the arguments pro and contra. if you haven't made up your mind yet, or better, if you're sure your point of view is the best, it's probably a good idea to read that page, to get an idea why one solution is preferrable in some cases, and in what cases you're better off using the other.
   &gt; if third-party apps run in a sandbox then they don't have the same access that apple apps do.

why?  the apis will be cocoa, coreanimation, corevideo, coresound, coredata, libc, etc...these can all be virtualized.

to be perfectly clear, i don't mean a vm like the java vm; i mean a hypervisor like xen or vmware.  your app will run under the same version of os x as the "main" iphone stuff.
armed with this... [finger-quotes] monad... we will take control of... side-effects... and... encapsulate them.

arm the monad.

arming the monad!  monad armed!
 &gt; you mind zeros-in on details but cannot see the big picture.

that's because there is no "big picture" here. just a fucking mess.

&gt; the definition of creativity is simply making something out of nothing. it's like "inventing."

that would be your definition and it would be wrong. it would be worse than wrong, it would be completely fucking stupid. you've defined creativity to be a cognitive illusion and that is contemptible.
except if you're a brazilian politician, then you spend the *minority* of your walking hours at work. and you get paid extra bucks when you *do* work.
i do not confirm this longing-for-management interpretation. rather the experienced programmer with little programming expertise works in a constrained environment. his work is dominated by interpreting specs and implementing domain knowledge far more than by challenging programming tasks. they are b-programmers which doesn't mean that they are not good at their job. for a company they create real value while the a-programmers with their deeper technical abilities are often just doing supporting stuff. 
 i can't believe i'm wasting time on this:

queensnake:
&gt; dumb, any other language would perform worse.

xcbsmith:
&gt; that's not true at all. ... in general, languages don't have performance characteristics, but rather implementations of languages have performance characteristics.

implementations differ, true, so your answer has truth in it. but, on the whole it's faffery without grounding. go find me a language /or implementation/ that beats c++ on the 'language shootout'. and i mean 'overall', or, an example that deals with polymorphism.  

also, on your first point, i /said/ it was minor - he says, "oo implies indirection" which it maybe does, in smalltalk or ruby or some others. i was pointing out that in c++, object.dosomething() need have no indirection. but, i admit i mentioned encapsulation - but mind, even that is one of the cloud of words that come up when you talk about the definition of oo.   
"awful editor. i don't have weeks to spend training my fingers to use key-chords."

separate things.  you may not care enough about emacs to learn how to use it, which is your prerogative.  but that does not make emacs awful.

you need to learn to distinguish between "i'm not used to this and don't want to take the time to learn" and "this is awful".
well, those of us who use haskell for writing large real programs are not always at liberty to blog about what we are doing.
dhh was actually saying "fuck you" to those who claim rails isn't ready for the enterprise, wanting it to get more "enterprisey".
the ultimate secret to happiness in life is to figure out what you love to do, and then find a way to get paid to do it.
also they tend not to be able to recognize the difference between an a (barely) humourous observation and an actual question. :p
so explain to me why they are different?
i wish i knew.
lovely example of the kind of paradoxes that manifest typing inevitably leads to.
well, maybe the *way* they teach the stuff in that paper is good, and probably most things should be taught that way.  but then why is it aimed at girls?

backtracking is not much more than recursion.  you basically say "let's try to solve this subproblem first" and if that fails, you try to solve another subproblem, or go another way.  yes, once you define it in a non-procedural way, it's *really* easy.

finally, a chat is not much more than hub+spoke.  spoke sends a string, hub sends it to all other spokes.  the concept can be taught to any 10 year-old in 10 minutes, i'm sure, and that includes time to talk about m:n communication and how it might not be as practical for simple chats.

yes, if you teach programming languages as well, it takes more time, but i don't see why five days would be incredibly fast.  it's good, though.
"...but i already use visual environments to code, so why shouldn't i be able to learn lisp using one of these visual environments?"

what's the emphasis on "visual" all about, anyways?  most programming languages are still just text, last time i checked, and there are few pieces of software more powerful for doing things to text than emacs, if you know how to use it.

you mean a gui debugger?  a gui builder?  web form builder thingy?  you program with flowcharts, shapes and colors?

eclipse has refactoring tools out the wazoo, perhaps this is what you mean by visual?  although it's still just munging text in an intelligent way.  not sure what's so visual about that.
i want a job that's fulfilling **and** where i'm expected to work the 37 hour standard work week. no more, no less.

while i like to code, a job is still a job. it's not a lifestyle (for me at least).
 i've attempted to address some of the comments made here:http://myblog.rsynnott.com/2007/10/commercial-lisp-a-clarificatio.html .
but there have also been haskell jobs advertised in your very own home country. :)
i apologize to the rest of the readership here who might enjoy this riveting battle over how a word is spelt in a language full of redundancies, quirks and such. i, however, must speak up and say:

who the hell cares how a word defining a piece of cashable paper is spelt!?
stand by for destructive updates! destructive updates in three! ... two! ... one! ...
[it would be nice to have that kind of job security](http://imdb.com/title/tt0151804/), eh?
you know, there's reason for calling the $ you get from your employer "compensation". it's supposed to compensate for the time you spend at work, doing things that sometimes you'd rather not do, pretending to add value to the company. i'm quite the ever-discontent job-hopper myself and i can tell you that there is no such thing as getting payed to do what you want to do and enjoy yourself.

unless if you're a porn actor.
 &gt; call me back when c programmers suddenly decide they need an ffi for calling haskell code.

nifty idea to introduce some haskell code into your c project. should be possible with [haskelldirect](http://www.haskell.org/hdirect/).
 
what are those "cool" bloggers smoking? gray text on black background?

i think you missed the point of the article, which was that experience _alone_ doesn't cut it--you have to learn from that experience and do interesting things.  (and have actually had novel experiences in those years.)
wow! it is made with ucw. 

i'd wish these guys wrote a book on ucw, or online manual, or tutorial...

dot (.) is the member-access operator. it is a special operator, and belongs in the function position. generally, you can understand it as:

&gt; (member-of target member)

where the target can be a class name (for statics, and might contain dots in the class name per java), or an expression (for instance members). the member can be a field name or a method call. the syntax you propose would require the compiler to know from the names alone that this was java-land, something i want to avoid. using the dot operator effectively places all java names in a different namespace (yup, clojure is a lisp-2 after all!).

also, anything that would require

&gt; (showmessagedialog javax.swing.joptionpane)

to evaluate to a first-class function object could get expensive. i have some experience with exposing java calls to lisp - [jfli](http://jfli.sourceforge.net/) and [foil](http://foil.sourceforge.net/), and i like this new syntax best. it has a nice extension to the dotdot (..) macro:

&gt; (.. system (getproperties) (get "os.name")) 
particularly if it is in text and provides no helpful emoticons. ;-)
you might not realize how true this can be for all aspects of higher education.
&gt;could it be that in a multi-language environment multi-language tools are generally preferred? 

but that is what eclipse is, so it would have been blind ignorance on their part when using such an excuse.

&gt;most of them settled on vim :-)

they would probably not mind vi for eclipse then.

http://satokar.com/viplugin/
[ravioli](http://en.wikipedia.org/wiki/ravioli_code) developers?
if you truly, and i mean *truly* love doing nothing, become a buddhist monk. must have prior experience in avoiding leg-cramps, though.
&gt; i was pointing out that in c++, object.dosomething() need have no indirection.

it does *if* dosomething() is polymorphic. although if you use generics to accomplish your polymorphism the indirection is resolved at compile time (and as has been mentioned elsewhere, even with the vtable based polymorphism, sufficiently clever optimizers can remove the overhead of the indirection).
although extensibility of sequence types is not a requirement of common lisp, implementations are not forbidden to, and indeed many of them already allow it. (sbcl comes to mind)

even if you couldn't, there are mechanisms you can use to get the same effect.
no stats to come with, but [facebook allows you to create silverlight plugins](http://wiki.developers.facebook.com/index.php/fb:silverlight) . i imagine what will happen if other websites of this calibre start using it.
 [one step ahead](http://www.scala-lang.org/intro/variances.html )
you're new to this, aren't you.

your wife and family usually won't want cash, but they sure as hell won't happily live off of ramen in a tiny dirty apartment like i can.
i don't think he was dissing nokia. he was implying that apple would *also* use digital signatures and was trying to deflect the anticipated criticism that the platform isn't open enough.
&gt; why is it aimed at girls?

why not?

&gt; the concept can be taught to any 10 year-old in 10 minutes

and that is based on your deep experience of teaching teenagers to program, or your profound ignorance thereof?


&gt; i don't see why five days would be incredibly fast

how does it compare to programming courses you have experienced?
lazy evaluation is implicit (and everywhere) in haskell, short circuiting is usually explicit.
&gt; but, on the whole it's faffery without grounding. go find me a language /or implementation/ that beats c++ on the 'language shootout'. and i mean 'overall', or, an example that deals with polymorphism.

cint vs. ocaml. ocaml wins every time. cint vs. hotspot. same outcome. hotspot wins vs. a lot c++ compilers for pure runtime polymorphism benchmarks thanks to aggressive inlining of virtual functions. allegro cl generic dispatch wins vs. a lot of c++ compilers for polymorphism benchmarks as well. in general, a lot of languages with dynamic runtimes tend to have better polymorphism optimizations than most c++ compilers. also, most c++ compilers generate pretty inefficient code if they don't have optimizations turned on.....
true, true... unfortunately i wasn't qualified for them. nor am i for this ny job, truth be told, but why pass up an opportunity to criticize us immigration rules?
he is currently doing fortress. fortran replacement for numerical computing. 
&gt; “functional programming languages lack a reason to use them.” i don’t think that great concurrency, scalability, fault tolerance, distributed programming, hot code swapping, mnesia, yaws, and the rest are useless.

a better rephrase might be "functional programming languages lack a reason to use that mainstream programmers are able to comprehend".

i hate the fact as much as anyone else (who is aware of it), but i'm having to face it nonetheless.
i like the pile of hot dogs, it's a nice touch.
you can have both ways:

http://citeseer.ist.psu.edu/steele99growing.html

i think this must be seen on video first. it's good show. 
spreadsheet is [done](http://home.comcast.net/~jyavner/ses/).

it's not perfect, but imo, f# is the least broken language available for the .net framework. it's nice that someone at ms finally noticed.
i maintained a port of clojure to .net for a long time early on, when it generated java/c# source rather than compiling to bytecode. i got tired of doing everything twice, and after dropping .net made much more progress.

i decided that trying to support both would mean the base language and libraries would always be limited by having to make everything work identically in both places. or one platform would become more weakly supported. targeting only java lets the relationship run deep, as the implementation and in particular the libraries can presume java.
dude, you're on the internet. what do you expect people to do with time?
am i the olny one who thinks this will be to little to late?
i don't have an iphone, but reading all i have about what apple has been doing with it has really made me think less of apple. 
does anyone share my feelings?
yes, companies will develop software for the iphone. my concerns are principled; money hats are not about principle.

the iphone is not an open platform. it is apple's platform, for which you will be allowed to write programs because a thriving ecosystem will drive iphone sales.

when i rant about this kind of thing my wife goes "huh?" most people don't have a technical aesthetic.
 first, i mistakenly referred to what he was describing as short-circuiting. it is not short-circuiting, though i still maintain what he was describing is not lazy evaluation.

lazy evaluation refers to the way in which arguments to a function are evaluated at application. under lazy evaluation an argument to a function is not evaulated until it is needed so that the evaluation of the function application can proceed.

'if' is not a function. nor is '?:'. they are control structure that differ fundamentally from functions in how they are evaluated. if 'if' were a lazy function, then it would take three arguments, and wrap those three arguments in thunks. the function would then force the evaluation of the first thunk (the condition) and then depending upon its value return the second or third thunk. this is not what 'if' does. 'if' only creates one thunk out of the branch that is returned based on the value of the condition. or rather, it evaluates one of the branches based on the value of the condition; whether this is a thunk or not depends the language's evaluation strategy.
the digital mars c++ compiler also supports precompiled headers. it's also the fastest c++ compiler. -walter bright, digital mars
but the operators/syntactic-forms that you call short circuiting behave exactly like functions with lazy evaluation.  that makes me inclined to say that these operators use lazy evaluation.
of course, the implementation of lazy operators in a strict language are not like the naïve implementation of lazy evaluation (thunks, etc.).  but if you look at better compilers for lazy languages you'll see that they compile, e.g., &amp;&amp; just like c.
 
oh, is that what it's doing. well, then i guess i haven't seen one either.
as someone who is also working on a phd, i think you should look into the concept of cognitive dissonance. if i'm working really hard at something but i'm not enjoying myself, it is easier to convince myself that i am actually happy and enjoying myself than to change my behavior and do something differently. cognitive dissonance: helping phders since 1875!
despite its name, the competition was obviously open to all languages. 29% is high relative to the proportion of programmers who use functional languages outside of the competition.
"you can write all kinds of applications to run directly on your iphone...as long as they're java applications!" that would be funny, but no, it won't happen.

third-party software won't get to play with the radio. there are lots of good reasons for that, and i'm not saying they should.

what i'm saying is that apple won't, can't open up the iphone completely, because that access would be abused by every asshole with a compiler looking to pwn your iphone.

that sucks, and i'd rather use a crappy phone that didn't remind me "hey, this is a crippled bsd box that makes phone calls" every time i picked it up.
  indeed, [more than once](http://orgmode.org/org.html#the-spreadsheet).  
people complain about how emacs has everything and the kitchen sink but then they turn around and tout cpan as an awesome feature of perl. can i get a "wtf?" from the emacs users?
wow, amazing how many programmers don't know how to use their editors. if you can't figure out how to make tabs indent to 2 or 4 or 8 columns in vi or emacs you probably shouldn't be looking at the git source code.

for the more advanced i've found that pretty much all editors more advanced than notepad can convert spaces to tabs and vice-versa.
i'm sure that will be a high priority item for adobe.  maybe you could nudge adobe to make that happen?
perl is a programming language. its stated purpose is to let you do "everything".

emacs is a text editor. a naive reading of the previous sentence would lead one to believe that, at most, emacs is intended to do "everything related to char*". obviously, it has gone far beyond that point.
i have been professionally coding for 24 years. i use an editor named micro emacs. i am glad i have the source for it. it has since evolved into emacs. i know you well intentioned programmers have worked many years on it. i do **not** need my editor flushing the stool when it exits...
 i have difficulty believing they will expose \[objective\] c on the embedded devices if they are concerned about security. so what language do the pundits think they will release? [f script (smalltalk)](http://www.fscript.org/)? ruby (which already has cocoa bindings)?
this is why, at ita software, we require people to do a puzzle before we interview them.  every once in a while we want to make an exception for someone, but even if they do well in the interview we get nervous about hiring them without some sort of code sample.
&gt;its stated purpose is to let you do "everything".

actually no. perl was also originally meant for text processing. it just happens to have enough libraries to do other cool things which is also true of emacs.
ouch.

me and those other two guys
just you, rendered nicely on ubuntu/gutsy+evince.

what i found extremely interesting was that of respondents, whatever income, all were ~72% likely to blog (after age differences) [fig. 6.5].
are you trying to take a dig at me?

i'm only very slightly offended, but well done anyway.
perl went beyond text processing a while back. if there's a pigeonhole for it today, it's as a web programming language.
microemacs was a red-headed stepchild of the original emacs. it did not precede full emacs.
i think his problem is with the "so we have to sell them the source code to install on their own server" part.
will it work with linux.  i am getting to the point where i don't even know how to use or get most of the windows software.  i am on a win2k system at work; doing various tasks.  but the 5 linux systems at home have kind of spoiled me.

my point; does f# work with mono or on linux.

i am sorry, ms is probably the only software that are complete d**ks to the opensource community.  they have never considered the concept of portability.
wow, it turns out haskell has its own version of why the lucky stiff!

wine, i hear is pretty good.
i really like this.  it's rare to find web developers that even use version control, let alone talk about the most effective way of using it.  and i've been trying to tell people for years not to edit stuff on the live server, to script updates rather than upload manually, etc.

it would be nice to know whether this is a work-in-progress and whether updates are likely to happen anytime soon.  i didn't see anything like that mentioned.

it's really refreshing to read something beyond your run-of-the-mill gzip compression and php tutorials.  please submit anything else you find that is like this.

i found [the newsreader with a recommendation engine](http://caterpillar.masukomi.org/) i was thinking of, via [this excellent submission](http://programming.reddit.com/info/5yj83/comments).  i'm not sure if it's what you are looking for, but have a look and see.  it uses bayesian filtering rather than popularity to determine how good an article is.

functional programming is now officially sanctioned as an industry practice.

microsoft is doing it, and what's more, marketing it.
i think jagerbomb is saying the a dvcs doesn't make you open up your repository to the world. there is just as much control over it as there is with any other scm.
does this work on lottery numbers? because if so, i think it pays for itself and where can i get one of these?
if you are into large scale c++ software (giga lines of code), check out " large scale c++ design" by john-lakos. pretty nice.

drat blast it! i've been working on this myself! they beat me to it! (although i think that my proposed timeline interface looks nicer).

this can be very true.
the introductory stuff i've read on f# suggests that you learn it while you're learning ocaml, as their syntaxes are very similar. so you've got ocaml for linux, and f# for windows, and they're mostly compatible. which we all know means somewhat incompatible.

f# on mono? [looks like that's a "yes"](http://research.microsoft.com/fsharp/manual/compiler.aspx).
i'd be more interested in seeing it available for their visual studio express (free) ide.
online spreadsheets with a nicely designed interface. api recently released for developers to build application on top of editgrid
let's not forget also that c compilers shipped for lisp machines back in the day; there needed to be some facility for c functions to call into the os which was written in lisp.
that wouldn't work here. there aren't two beautiful people on reddit to fight over it.

(the greek means: to the most beautiful one; a golden apple inscribed thus began the trojan war)
oh no, i didn't mean to offend anyone in particular.  to the contrary: what don, brian, and john are doing impresses me greatly (and i argued very strongly within o'reilly that we should sign their book.)
ah the good ol' flame war. usenet how i miss thee...
hello? it's emacs. you can map the functions to whatever keys you want.
so go and tell her that if she wants fancy food, she has to pay for it. if someone has to make a sacrifice so she can have her luxuries, it should be her.
probably c-p, c-n... are used for something else in the interface.
 [docsopen](http://www.hummingbird.com/products/docsopen/index.html) and [imanage](http://www.smartsolutionsonline.com/imanage.htm) are both used by major law firms to manage case documents.  both work. 
when i tried to explain to  this female the difference between function currying and partial application and got it wrong, she kicked me in the monads.

oh i was really just kidding. no worries. :)
that's a vital mistake. i only work 40 hours a week. out of 168 hours. that's only about 23%.
even if i consider sleeping/eating/showering time, (11*7 + 40)/(7*24)  = roughly 70%.

so, for i have 30% of the week (about 50 hours) all to myself. duh...

i'm not britney spears or jessica simpson, who claims to _love what i do_. i suck it up for 40 hours. then for 50 hours, i do my thing. 
   i think you will find the wikipedia article you cite as wrong, since it doesn't take into account the way the word came into english, through the [exchequer](http://en.wikipedia.org/wiki/exchequer), which even wikipedia mentions has been around since 1190 (coincidentally the same time they were off in the middle east doing their crusades). since this is obviously now an english word, and since this is their original spelling from which cheque is derived, i think you will find that i am right!   
or if you don't want to use emacs, like yours truly.

still need to find a way of aborting a repl program ((fib 32) ...and now what? halp!), me being a lisp and eclipse newbie.
*i should point out that it is no problem for nine women to have nine babies over nine consecutive months if you find the right nine pregnant women and ladder them appropriately.*

you missed the point. what mmm said was just because one pregnant woman can *gestate* a baby in 9 months does not mean that 9 women can gestate a baby in 1 month. in other words, the terms 1 woman x 9 months are not interchangeable. project managers frequently make this kind of mistake, or a mistake of a similar kind. they may think that if one programmer can get something done in 9 months then 9 programmers can get it done in 1 month. to me this is industrial age thinking. it fits well with the assembly line model, where it would've worked. it doesn't work well in the age we're in.

as to your next point, i can point you to a project manager who will say from experience that years of experience is not a good measure in and of itself of expertise. yes, it's an indicator they *could* have expertise, but you still need to confirm it. this isn't because they've lied on their resume, but because they may have worked 10 years essentially writing "hello world" apps (as in, they're that easy to write). it happens a lot more often than you'd think. 
jeff is actually going to capture people who qualify and add them to his bestiary of similarly fantastical, imaginary creatures: unicorns, fairies, bigfeet, hermione granger, odysseus, and dinosaurs.
my personal opinion about tabs is that the physical tab character should basically universally be considered a lexical error. editors are not that bad at converting presses of the tab key into multiple spaces, and treating blocks of multiple spaces as a tab.
 and here is a very interesting explaination about this etymology from [here](http://blog.plover.com/lang/etym/arabic.html):

&gt;item 17 says "the modern cheque comes from the arabic saqq, a written vow to pay for goods when they were delivered...". but no. the correct etymology is fascinating and bizarre. "cheque" is derived from norman french "exchequer", which was roughly the equivalent of the treasury and internal revenue department in england starting around 1300. why was the internal revenue department called the exchequer? because it was named after the chessboard, which was also called "exchequer".

&gt;what do chessboards have to do with internal revenue? ah, i am glad you wondered. hindu-arabic numerals had not yet become popular in europe; numbers were still recorded using roman numerals. it is extremely difficult to calculate efficiently with roman numerals. how, then did the internal revenue department calculate taxes owed and amounts payable?

&gt;they used an abacus. but it wasn't an abacus like modern chinese or japanese abacuses, with beads strung on wires. a medieval european abacus was a table with a raised edge and a grid of squares ruled on it. the columns of squares represented ones, tens, hundreds, and so on. you would put metal counters, called jettons, on the squares to represent numbers. three jettons on a "hundred" square represented three hundred; four jettons on the square to its right represented forty. each row of squares recorded a separate numeral. to add two numerals together, just take the jettons from one row, move them to the other row, and then resolve the carrying appropriately: ten jettons on a square can be removed and replaced with a single jetton on the square to the left.

&gt;the internal revenue department, the "exchequer", got its name from these counting-boards covered with ruled squares like chessboards.

&gt;(the word "exchequer" meaning a chessboard was derived directly from the name of the game: old french eschecs, medieval latin scacci, and so on, all from shah, which means "king" in persian. the word "checkered" is also closely related.)

&gt;so, in summary: the game is "chess", or eschek in french; the board is therefore exchequer, and since the counting-tables of the treasury department look like chessboards, the treasury department itself becomes known as the exchequer. the treasury department, like all treasury departments, issues notes promising to pay certain sums at certain times, and these notes are called "exchequer notes" or just "exchequers", later shortened (by the english) to "cheques" or (by americans) to "checks". arabic saqq, if there is such a word, does not come into it. once again, it is clear that vallely's research was shoddy. 
why would i freak out. this is a confirmation of everything i have said about f#. 

f# is a product of microsoft corporation. just like maxima is a product of nissan corporation.

unlike other languages we read about here f# is not open source, is not standardized, and has various patent and other intellectual property protections on it.

i am sorry you find it so hard to deal with that reality.

i am very happy about this announcement. this  announcement has proven me to me prescient in regards to f#.
&gt; you'll notice that lisp is not at all like other general programming languages. for example, in most general programming languages, you perform multiplication just as you would on paper: int times = 5 * 5;. 
&gt;
&gt; with lisp, the following would produce 75: (* 5 5 3)

the author's point is extremely muddled here: is he trying to demonstrate lisp's s-expressions? or the functional programming culture that frowns upon mutable state? or the elegance and lack of syntax of lisp? i just get the feeling the author really hasn't had the ah-ha moments you get when you learn lisp. and it certainly doesn't help promote the cusp plug-in with muddled waters.
i think this is a good approach to addressing the gender disparity in cs. the
one week course gives students enough of a taste of cs that they can see
whether they are interested or not, as well as providing them resources
sufficient to allow them to continue on their own. it thankfully does not sink
to into the hand-holding of affirmative action.

my first exposure to programming was a c compiler, a mac and a pair of books
-- one on c, one on programming the macintosh. i learned nothing at all -- i
couldn't write a mac gui because i didn't know c, and i couldn't write a
console application because i couldn't program macs. only many years later, on
unix systems, was the barrier to entry low enough that i could write and debug
simple programs. how i wish someone had taken me through the basics of a
development environment when i was younger.



yeah, that's why i find this really interesting.  an ml dialect has just become a 'safe' choice for conservative corporate departments and shops.
from the article.

&gt;there's also a link to paul graham, who nowadays is more of a crazy rich guy with money than a programmer.


slava calling somebody else crazy. now **that's** rich.

&gt; don't ask my why, why do monkeys at the zoo eat their own shit? 

cause they're locked in fucking cages and are bored out of their minds.
after reading a few links on security on the programming subreddit, i had to share this.

i used to work for a very large, very well known company that did the majority of their transactions online. users would register their accounts, save all their personal information, process credit card transactions, all through the website.

the security nightmare? they never bothered to encrypt or secure anything. all information, including credit cards, were transmitted in clear text, and frequently emailed back and forth between customer support people. 
ok, thank gosh i have the source to red-headed stepchild emacs, then.

... it's a text editor.
i hate the word productize.
i'm sure that both sides of the emacs vs. vi wars will take this as evidence for the superiority of their position.
defaults matter. "you can change them" should never be an excuse for crappy defaults.

(but it might be even worse to use "the defaults are fine" as an excuse not to allow them to be changed.)
agreed. asking for "3 years experience" with a language is kind of dumb, imo. i can pick up a language in a month of casual use easy, and a shorter time if i were using it full time. the part that's hard these days is mastering the framework library; knowing all/most of its parts and what it can do. that takes me several months, but not years. perhaps if the framework was extraordinarily large, as they're getting, it might take me more than a year, but that wasn't the case until recently. a more appropriate requirement is just a general "3 years software development experience", and "expertise with [a language]", something of that sort.

if someplace is going to do a good job selecting candidates, they should give you some preliminary coding tests to start with. that will show right away whether you're telling the truth about your expertise or not.

to show you how out of sync with reality the "years of experience with a language" is, several years ago i was hired as a jr. programmer at a company, because i had little work experience with c++ (i had learned it on my own time), yet i impressed my project manager because i communicated clearly, i completed tasks in a timely fashion, scheduled my time well, anticipated problems before they happened, and communicated well with our customers. i had about 4 years of c/unix development experience before i took this job. yet i got the jr. position because i had "little expertise" with c++. my general experience was wrongly discounted, as they discovered.

it seems to me that companies are still struggling with what the information age truly means, and i think it's partly because we're used to thinking in industrial age terms. in that era quantity probably did matter. in this era, how you think and how you learn matter more than how long you've done something. years of experience can influence this, but it's are not an absolute predictor that it will.
does this plug in require that you use a particular lisp compiler or a particular dialect of lisp?

can it be used with scheme?
you find slava to be crazy?
and it'll take some russian or german kid a weekend to crack/circumvent.
one day i visited the security office, where they have banks of monitors showing the cctv feeds from the cameras on site. 

the pc in the security office had the head security guard's login id and password, neatly printed out and sellotaped to the monitor! i covered it up using a post-it note with "this is bad security!" written on it. 
i've been doing web development for 10 years and haven't seen a single project not use source control.  this was mostly re-hashed common sense.
last time i checked it came with sbcl, but since it uses slime's swank package for communicating with the lisp process i guess it should work with most other cl implementations too.
and no, it won't work with scheme. the best thing i know for scheme is slime48 which is scheme48 only.
i get that, but i still think that's an abysmal statistic.  you admit that outside the competition the adoption rate is something less than 29% (perhaps even quite a bit less), which is actually one of the main points of the article to which you're reacting:

&gt; it says to me that we're still in the early days of widespread adoption of functional programming.

i believe that people should learn both approaches (functional and imperative), but i think we should be realistic when we talk about it.  i think the original article was quite even-handed.
there's another case similar to the 'single compilation unit' case: specify all the .cpp files on a single compiler command-line.  this eliminates the overhead of loading the compiler and targets into memory without the drawbacks of combining the .cpp files into a single .cpp file.
thanks! :)
"slow" is relative. abcl is fast as far as jvm languages go (groovy, jruby, jython are all quite slow).
50 hours a week to myself isn't all that much, especially when i still have to do chores. of course, since my favorite thing to do is lounge around, and since i'm slow-paced, i hardly ever get around to doing any of the things that i want to do and should do (as in they might make me more money). i can barely even get my chores done.
the inline spell-check.
 but, but, but... that's unpossible! the cellular network will collapse! that's what you said, anyway, steve. 
seriously, you should try ghc 12.5. it has some cool features, like transparently parallelising your code, enabling it to scale up to forfty cores, and detecting non-terminating programs statically by their type.

oh, and the io monad is implicit.
don't take the bait :)

qwe124 is regularly *utterly wrong* and some might even postulate delusions or psychosis. in fact, it is better to try to observe qwe1234 to be *just wrong* and consider these exceptional events. a bit like the planets lining up or something :)

you'll observe that your direct refutation to his comment that lambda calculus machines have not been built, will not attract a response, however, the propagation of the myth that he purports will continue.

sorry if you knew all this already; i just hate watching well-intentioned people fall victim :)
what's a "non-native language"?
&gt; i've been doing web development for 10 years and haven't seen a single project not use source control.

wow.  your experiences and mine are almost polar opposites then.  have you worked mostly with large corporations, small companies, or what?  websites or web applications?

 older than the internet?  *(shudder)*   what must life have been like in this barbaric age? 
...all while settling for mediocrity.  so sad.
&gt; i am sorry you find it so hard to deal with that reality.

i do? i was just waiting with bated breath for your rant.
number of lines of code is hardly more valuable than years of experience. like someone before me noted, it's number of lines you haven't written.

ever notice that the winner of a round of perl golf usually has the most elegant, intelligent solution?
  i am aware of his reference book and of a good portion of his work. it is the thesis of this talk that puzzles me.

you see, it seems that it would be much more effective, and cheaper (manpower/money/time), to start with a good language and fill in the gaps rather than start with a defective, but popular, language and do the same.

in other words, i expected the logical conclusion of the talk to be something like..  *a good language should be small and extensible, so let's all use lisp*. i was surprised when i heard.. *a good language should be small and extensible, so let's fix java*...!!

to be honest, when a guy like him believes that java can be fixed, my belief in its mediocrity is fundamentally shaken. that's why i am asking weather he is actually convinced that this can be done, or is he just doing his job?   
almost a quarter of the "webmasters" are over sixty years old. (29)
it's worth noting that heavy use of templates pretty much devolves into the single compilation unit as well.

in one of my more memorable abuses against the template instantiation mechanism, i wrote a system in which nearly everything depended on a template class that in turn depended on another template class.

something like

    template &lt;typename t&gt;
    class internal {...};

    template &lt;typename t&gt;
    class external
    {
    private:
        vector&lt;internal&lt;t&gt;*&gt; xxx;
    };

where there are currently multiple instantiations of each template class (something like three of one and five of the other).  thus, there were lots of other classes like

    template &lt;template &lt;typename&gt; class exttype, typename inttype&gt;
    class container
    {
    private:
        deque&lt;exttype&lt;inttype&gt; &gt; stuff;
    };

each of which gets instantiated and compiled for each combination of exttype and inttype.
with about 70 classes that depend on this same pair of template parameter and template template parameter, touching almost any file triggered a full rebuild.  it currently takes about three minutes for a compile, and g++ consumes about 400mb during compilation.

it was (and is) absolutely hideous, but that's what i like about c++.  any other language would have prevented me from doing something like this.  while it does suck horribly (and i'm working on cleaning it up a bit), it let me have the efficiency of primitive types where i needed them and prevented about 5x duplication of code, or at least shifted the responsibility for maintaining the duplicates to the compiler, which is the next best thing.
i don't understand why this "mythical man month" is apparently such a seminal work. these ideas are fundamental to economics (the inefficiency of markets requiring transaction costs, surplus loss due to monopolistic/semimonopolistic firms) and were discovered before anyone knew what a computer was.
  i think that creating your own language that is just mashup of old ideas without any meaningful new inventions, apart from syntax goodies, might be called crazy (if you are adult). in this case we have rich crazy guy and poor crazy guy.  with crazy i don't mean really crazy, just crazy hacking in waste of time sense. :)

if these guys just would just gather around the feet's of guy steele and ask: "how can we help to make your vision reality, master?", their energy would be wisely used.   
&gt;if there's a pigeonhole for it today, it's as a web programming language.

maybe 5-10 years ago. ruby is filling that niche nicely and python has been gaining ground. at least php is being slowly phased out.

i don't think i would use perl for text-processing either since all other languages have the same regular expressions library now. but that's just me.
sure? inventor-link.com leads to a domain squatter.
from an article on [perl/tk](http://www.ibm.com/developerworks/aix/library/au-perltkmodule/)  
  
&gt;although perl scripts are powerful, they produce a web interface that lacks a graphical front end, and the user has to type information instead of using the mouse, which can be an unsatisfying experience for the customer  
  
you can't use the mouse on a web browser? in answer to slava's question: no, nobody proofreads developerworks.
&gt;student language dilettantes

speaking as one of those, there's nothing wrong with that. we get to see all the cool shit that can be done with lots of languages and don't risk becoming conservative in our language choice for the next project we have to tackle.

besides, programming x will make you a better programmer in y.
no, you need to measure problem solving skill, not lines of code. sometimes less is definitely more. tight well written code trumps lines and lines of code any day...
of course. i just worry that the implementors have failed to understand the emacs-nature.
heh.  i checked out their /robots.txt and got redirected to some garabage.  i'd consider that invalid and spider the whole thing if i were a search engine.
  a eulogy is something that is said in praise of someone who has died. a eulogist is someone who delivers a eulogy.

"no java on the iphone" is a phrase, not a person. it cannot be a eulogist as the heading claims.

it's true, i don't know what a "eugoogly" is.
  
is it still a rant if it contains truth in it? does malcontent rant if there's no reddit to hear him?
voip communications made easy - ring anyway with the fun and ease of using a normal phone
it may result in lower profit margins, but it could result in higher profits.
seattle representin'.  i might be coerced to trek down to portland to hang with the infamous dons.
how in the world does he not know about distcc, icecream,  teambuilder or incredabuild?  i can't imagine building without a buildfarm these days.  heck just get a dual core machine and cut your build time in almost half.
 &gt; emacs is a text editor.

i think that's your mistake right there.  emacs is a lisp environment disguised as a text editor. 
that fucking slice-o-matic changed my life.
i would sit on my ass all day. i would do nothing.
&gt;bad programmers are experts at appearing to non-programmers to be expert programmers.

it's not very hard.

&gt;i've programmed in c#, java, xml, html, css, sql, oracle, mysql, ajax, and xsl.

just toss out tla (three (or four) letter acronyms) as fast as you can!
   &gt; write large, realistic programs

i'd love to see one of those! believe me, i've tried hard to find one.

let's put it another way, i worked for ibm on three projects during my time. one was 5mloc of c code, another was 4.5mloc of java and the other one was big (i don't know for sure, but let's guess maybe 2mloc of java).

some of the fanboys were proclaiming these applications to be the most sophisticated and *largest* applications on the planet.

i ask you, have *i* worked on the largest applications on the planet? since, for me, there is nothing complex about millions and millions of lines of code of absolutely nothing at all (which is what these applications are).  i reject such a suggestion. 

the fact of the matter is, i could rewrite them in a few thousand lines of haskell. only, the marketing department would disallow it, since clients wouldn't know what to do with something that exceeded their incredibly low standards of expectation.
factor: because it isn't forth.
linus, is that you?
&gt; i think that creating your own language that is just mashup of old ideas without any meaningful new inventions, apart from syntax goodies, might be called crazy (if you are adult).

you realize that this means 90% the languages creators of the past 15-20 years or so should be called crazy by your criterion?

&gt; guy steele

including guy steele, he was part of the team which created java after all.

&gt; i think that creating your own language that is just mashup of old ideas without any meaningful new inventions

umm, this describes just about every programming language there is, except for old timers (fortran, cobol, lisp, smalltalk) and incredibly esoteric research languages that *only* showcase their inventions (epigram and cecil, i'm looking at you).

since you mentioned steele, let's trace the genealogy of scheme's features:

* block scoping from algol
* s-expressions from lisp
* macros from lisp
* continuations from actors
* "simple core language" philosophy from smalltalk and lisp

not too much new there.  perhaps steele should have gathered around the feet of john mccarthy and asked "how can we help to make your vision reality, master?"  oh wait, he kinda did...
nope, just an old set in his ways programmer...

... now get off my lan, you kids. :)
sorry to disappoint you. it does feel good to be vindicated though.
maybe he was just being pragmatic. you cannot force a language to be popular so i guess he was working to make a popular language less painful. and he works at sun so he cannot go around giving talks about how sucky java is.
if you're processing huge log files, perl easily edges out ruby, python, and other dynamic languages.  you could write the log file parser in c or java, but most people probably wouldn't go there.  so perl does show some historical strength with respect to text processing.
from the same article:

&gt; adding the use strict statement to a perl script also helps find any possible typos or logic errors:

quickcheck enthusiasts and epigram developers take note: perl has solved the problem of provably-correct software. all you have to do is add a single statement, and it will find any possible typo and logic error.

wow!
i got enthusiastic - downloaded latest f# from http://research.microsoft.com/fsharp/release.aspx
however

1. samples101 did not compile, thoug it was easy to correct

2. concurrentlife compilation said 

error: lookup on object of indeterminate type. a type annotation may be needed prior to this program point to constrain the type of the object. this may allow the lookup to be resolved.

3. math/lapack example compiled, but crashed

i think i'll stop looking into it for now
  "if" can still be defined internally like this:

     if true  t _ = t
     if false _ f = f

then all instances of "if a then b else c" can be transformed into "if a b c" by the compiler. does this not fit the criteria of lazy evaluation?  
  hi,
i am student considering a major in cs and i am currently learning about abstraction functions and rep invariants. my question is whether they are actually used in the real world.

i ask simply because i despise writing and devising the—they are tedious and the least fun part of programming. and in addition, i have rarely (if ever) seen either abstraction functions or rep invariants occur in open source projects.

any opinions would be great! thanks.
afaik factor and forth are related in the same way c and python (or d) are related...
oh, i'm skeptical too.  and it won't be haskell.  it would be something much looser, much jazzier than that.
&gt; since you mentioned steele, let's trace the genealogy of scheme's features:

wouldn't it be much easier to just use his second-to-last child? (namely java)
i use neither emacs or perl. personally, i value simplicity, but i find the efforts gone into emacs admirable. the building of the tower of babel would also have been admirable in its day, so it's not meant as criticism.
wow, i did not realize you couldn't push from.  i thought it was only pushing to that was not allowed.  thanks for the heads up.
thing work both ways:
if you tell your wife to use her own hands to get rich, she will tell you to use your own hands to get laid.
this article is just disguised advertising ("did i mention that we're hiring?").
some people will use punch cards;)
that makes sense, thanks.

as long as you aren't the monkey operator `(:[])`
he probably means any interpreted language.
god dammit emacs. for all the effort put into this, you'd think someone by now actually made a vim-emulation for emacs that didn't suck.

i love lisp and i love the lisp environment in emacs, but i need the editing speed i get from vim. i will never give up those key bindings.
i once worked at a web development agency that was responsible for a significant number of online shops and other websites that took payment over the internet.  i don't know the exact figure, but i'm pretty sure it was over fifty.

they were so cheap that, rather than pay for an ssl certificate for each site, they bought a single certificate, and sent every payment for every website through a single hostname\*.

due to this and various other reasons pertaining to how our "e-commerce solution" was implemented, once the payment had gone through, the user was redirected back to the individual site, which displayed the order that had just gone through.

of course, to do that, it would need to know exactly *which* order to display.  do you think they redirected to a generic uri that checked the session to figure out the order?  of course not.  they redirected to http://example.com/show_order.asp?order_id=1234 instead, which displayed the customer name, billing address, all their credit card details, and what they had ordered.

of course, absolutely no checking took place, so anybody curious enough to change that number could view any order ever placed on that particular site, along with the customer's credit card details.

not long after i started there, the lead developer was moving on to a better job elsewhere.  the week he was leaving, we received an irate phone-call from a client who had figured out just how insecure his "totally secure online shop" was.  so we fixed it, right?  right?

one of my first jobs at that successful, established, in-business-for-many-years, had-local-government-contracts web development agency was to go through each and every online shop we had and change it so that the redirect used post instead of get, meaning that it was still just as insecure, but now our clients wouldn't notice.  and no, i couldn't fix it properly, because the lead developer had left very specific instructions and i was the newbie.  for all i know, it still works that way.

-- 

\* this was actually necessary at the time if you were using name-based virtual hosting, but we were perfectly capable of doing it properly because we were using ip-based virtual hosting with a different ip for each site.

"the four hour workweek" is a pretty cool book.  it's thesis is that you need far less money than you think to be content, and you can generate modest(entirely livable), steady income through some good entrepreneurship methods, outsourcing smaller tasks being one of them. 
 
younger people are starting to question whether the traditional understanding of "success" is what they want for their own lives.  why spend your youth working your ass off so you can retire and play golf when you're 60?  life can be much more enjoyable if you are smart about it.
please rewrite our current linux kernel in a few thousand lines of haskell.  that would save so much headache!  how about i give you a 200 line allowance to rewrite all the display drivers too?  that would be a nice to have.
&gt; apple knows their open apis and free development tools have contributed greatly to their success. 

on the mac. by contrast, look at their ipod sdk.
there is #girlfriends?
 interesting.  however,

&gt;gnu emacs is used for composing an edit decision list using mplayer for previewing films and using avidemux for rendering final edited movie.

makes it sound like it wouldn't be real-time video editing.  i could be reading it wrong (&lt;-- not a programmer), but it sounds like just editing an edl, then outputting that edl to another program for assembly.  that's not exactly like avid or final cut.  heh 
i'll feed the troll:

to your first point, if you're writing a class library, you can't anticipate every possible input. and even in cases where you can do whole program analysis, the combinatorics might make it simply intractible to unit test every scenario. if you can eliminate the need for those particular unit tests entirely, then you get to spend that time making your software better in other ways.

to your second point, the issue is whether you should burden everyone with those costs. the clr is flexible enough to support multiple different languages on top of it. a language designer which wants those kinds of features could build it in for those programmers who want it, without adding performance cost to everyone else. whereas if the underlying array implementation in the clr has to include these checks all the time, then everyone has to pay those costs even in scenarios where they would otherwise be completely unnecessary.
perhaps they plan to sell a keyboard overlay.
fancy food? not-ramen is fancy food? not-ramen is a luxury? wow.

but, okay, if it was just husband+wife in a household, and the wife was unsatisfied with her standard of living, it might be fair to just tell her, "well, you go get the stressful but high paying job." but what happens when kids come into play? if the wife is unsatisfied with kids eating ramen and living in a dirty apartment, is it solely her responsibility to care for them? husband is responsible for taking care of the kids, too.  
i've often wondered this myself.  especially in the tech startup world. why does everyone want to be bought by one of the big guys or be the next big thing.  sounds shitty to me.

i'd rather start a nice small company with ~3-5 people where there's enough money to go around that everyone lives comfortably.  there are quite a few "sweet spots" as you get bigger where the profitability is so good everyone gets paid well.  

from observation there seems to be one at about 15 people. obviously it depends on the particular business.  but this seems to be the size where no one can hide yet all roles are filled by someone who is good at that role.
1) apple's track-record with developers is nowhere near as good as ms.

2) the iphone doesn't have enough horsepower to manage truly sandboxed apps, so they'll have to have protections on the apis that they don't want to expose, which is eventually going to be hacked.

3) i hope they don't fuck this up by making the only way to get an app onto the phone be to either have a dev kit or pay to download 'certified' apps from itunes.  there needs to be a freeware/shareware ecosystem for this to be a truly healthy platform going forward. 
but doesn't getting a phd give you a lot more "fun" options than a bachelors or masters would give you?  where "fun" would tend to be more researchy type jobs instead of production/maintenance type jobs.  i've got a masters degree but i've considered going for a phd because i'd like to do more researchy type work...  is that an unrealistic expectation?
ghc 12.5 can implement the device drivers in the type system!
i agree that this statistic's relevance is vague at best. i've admitted it by saying that i don't think the competition indicates much about adoption of fp by the programmer community at large now or in the future. by basing its conclusions on such statistics, the original article relied on tenuous evidence at best to "question" functional programming. 
.. for vi.
rich category of very delicious food, including all fiery recipes.
&gt; … they do actually encourage developers to consider client diversity and that the recommended way to design iphone web apps includes making your pages standards-compliant.

meanwhile, their message to users is “web apps are apps designed for the iphone”. result: user finds a web app somewhere, it isn't designed for the iphone, and the user complains to the web app developer about violating the [apple's] definition of web app. 
thanks for a grand idea: i'm through writing code in a single column. it's two-columns from now on. yessah. 
after chuck norris helped simon peyton jones fix the bugs in the ghc type checker, ghc 12.5 can statically guarantee you get laid.
i didn't write google.
i did after reading the article, and i'm not doubting that it's a great product, and that for the same amount of time spent on code in haskell and assembly, you'll have a more complete product that is faster. but to say that someone hand tweaking assembly could *never* outperform haskell is something that can't be asserted.
i think oleg and maybe chuck norris qualify, though, don't they?
not every developer has a stack of idle machines laying around to use as a build farm.
in typical code you don't need really them, because typical code does not work for  interesting reasons. you have some dirt-simple adt and some trivial concrete realization, and a correctness proof for this sort of program is just line-by-line symbol pushing. 

(this is not to disparage such programs; much of the benefit of the computer is that it relieves humans from having to do this kind of chore repeatedly, and you still need creativity to writ them -- only you're using it to understand the problems your users are facing and automating them away.)

still, they aren't the sorts of programs that make your hair stand up in awe. 

but suppose you've got a program that works for sophisticated reasons -- e.g., you have a loop that terminates because of a metric that's a complex function of the abstract state, or you're using the same concrete data structure to witness multiple facets of your invariant, or you are using aliasing in a tricky way. now working out the invariants and checking that they are maintained will help you an awful lot. 

these proofs are also useful when writing programs that are very simple but easy to get wrong. an example of this is the humble binary search -- ask ten programmers to write a binary search, and you'll get nine fencepost errors. (another example is fast exponentiation by repeated squaring.) an invariant and proof is very helpful in this kind of situation.
proof positive it's not the basis of emacs...emacs is an operating system with a shitty editor tacked on.
&gt;"html code"

silly lawfirm, html is not code, it's markup.
he may not be the most stable person around, but least one learns things from slava.  all i ever learned from qwe1234 is that c++ invented garbage collection in order to fake the moon landing.
that is a real gem. i had stopped reading after the second paragraph. i am pretty sure that developerworks actually pays their authors a few hundred dollars for articles. i guess you don't always get what you pay for.
maybe you could rewrite openoffice under 300 lines of haskell?  that would sure make the product slimmer.
who cares about opensource

it's still better than the rest of the academic languages with their 4 users and complete lack of a decent library 
someone should create a resume generator that randomly pumps in acronyms, then submit random generations of the documents to a bunch of employers just to document what the response rate is.  my bet is that 20% or more will be considered for a first round interview.
factor and forth are even closer.  a lot of valid factor is valid forth.  i tried these at http://wiki.forthfreak.net/jsforth80x25.html

    4 5 + .
    9   ok
    : square dup * ; 
      ok
    19 square 
      ok.
    . 
    361   ok

(the "ok" lines are the output; the lines in between are the input)

factor adds higher-level concepts, like classes.
turning machine = wheel?
doing something you don't like for money and feeling *resent* for having to do it is the problem. 

generally, if you're at the point where asking if your job is right for you, you probably aren't in such an extreme situation where quitting your current job could leave you homeless.
&gt;their kids were messed up too (mostly).

hi!
which answers the question, "why do programmers look at reddit all day?"
i'd do it but i'd be afraid of being sued for misrepresenting myself heh.
too slow :)
pyparsing has been a blast to use. it's my goto library for parsing dsls or the similar sort.
then she'll just quit and sign on with another employer who is able to offer better wages and benefits. er.. i mean, husband.
yes, i believe the verb form of "product" is "produce."  but i don't have the dictionary handy, so i can't lookupify it.
i don’t understand why people insist in comparing my lisp operation system with a text editor.  apples and oranges much?

i mean, vi is even implemented natively in the emacs os.  more than once.
and the dev will reply: "f... you!" :p
 who says you have to use your real name?  it should just be a resume generator...  pumps out fake people with fake credentials.  maybe add a few slider controls that control education, likely to bullshit, wordiness, buzzword-ness, etc.  create a new yahoo email account and set the resumes to use this email and then record the responses! 

i wonder how many buzzwords are necessary before a candidate is accepted with only high school education?  or many years of c++ experience is needed to get a java job?  i think it would be pretty interesting to plot the responses...  maybe something statistically interesting would show up!
&gt; emacs is a text editor.

go away, [heretic](http://www.dina.kvl.dk/~abraham/religion/trinity.txt).

&gt; (i wish there was such a thing as a capital full stop)

# .
the closest environment we have to the lisp machines.
[there are *many* more than that.](http://en.wikipedia.org/wiki/american_and_british_english_differences)
middle ground:

* english (us)
* english (uk)
* english (ca)
* english (au)

the iso language codes already do this: `en_us`, `en_uk`, `en_ca`, `en_au`.
yes, and fucking the slice-o-matic will change it too.
 couldn't the *edit decision list* be created with any text editor? 
oh boo hoo im a programmer and i made 902365k a year and im not happy driving my lexus around and smelling like curry.

buck up assholes. id kill you if it meant id get your position.
  halfway through the article, i was ready to conclude that the author came up with two optimizations that weren't worth it and one that was (precompiled headers) ... such a great article indeed.  
but the last one -- a file that #include's all the .cpp files, sort of a poor man's-precompiled-headers -- would be kind of nice to have for a lot of projects. especially since it results in smaller binaries due to ... whatever (cross-file optimizations probably).   
&gt; factor and forth are even closer. a lot of valid factor is valid forth.

i'm pretty sure a lot of simple c is valid d (haven't tried it though, i haven't learned d -- yet? -- and don't really like c), but it's not like it really matters because

&gt; factor adds higher-level concepts, like classes.

that was most of my point.
but it doesn't really belong on the programming reddit.
i didn't know it existed until you mentioned it.  i just looked it up.  :)

i don't entirely understand how such a thing would work, though.  if you have a file that hasn't changed since the first version of your project, it'd effectively not be in the history you downloaded, so changing it would just lead to confusion.
har, har, har.  i hope she kicked you hard enough for all of us
if only that were true. sometimes (rarely) what you say is true. what is more often the case is that the less experienced coder writes lots and lots of code which is ungainly and unmaintainable. this is usually due to a lack of ability to create an over all design resulting in a lot of logical (if not actual) cut-and-paste programming. either that or badly reinventing wheels.
 languages aren't interpreted.  programs are.  by implementations.

we have a [python compiler for i386 machine-code](http://www.hl.id.au/projects/pycro/).  and a [c interpreter](http://www.ddj.com/cpp/184402054).

&lt;/semtroll&gt;
maybe they could carve away the editor and compete with vista?
&gt; because any and every program can be written in asm.

you mean machine code.
i'm almost tempted to give it a try tomorrow at work

pfft, if only cameras had the balls to store video in s-expressions, this wouldn't be needed at all.
doesn't he already have enough wine?
more likely, he'll privately curse apple for confusing their users in common. and then explain to the user that that's not actually what “web app” means.

at least, i hope so.
i'm sure the iphone will see a wealth of games and applications just like all the games that came out for the ipod with video.

signed applications under apple will no doubt be used as an excuse to tightly control the software available and make you pay through the nose for basic functionality you could get for free on other mobile platforms
life is too expensive to be trying desperately to do what you love when what doing what you love is beyond your control.

i've applied for the one job i truly want 3 times and didn't get it all 3. i'm perfectly qualified for it but each time there have (i assume) been better candidates. i can't send a check for 0$ to my rental office with note attached that reads "sorry, no money this month. just waiting to get a job doing what i love!"

i'll keep working full time at a job i hate. i'll keep attending classes i hate. hopefully in 10 years or so i'll do something i like, but i don't know if i'll ever get that 1 job i'd truly love.
that was supposed to be a joke.  current version of ghc is 6.something.  of course it's unfair to assume people who don't follow haskell will pick up on the joke.
good point - done!

[refs and transactions](http://clojure.sourceforge.net/reference/refs.html)

talks about the advantages of using container files for encryption, rather than whole disk encryption.
&gt; my point; does f# work with mono or on linux.

yes - [mono on gentoo](http://shootout.alioth.debian.org/gp4sandbox/benchmark.php?test=hello&amp;lang=fsharp&amp;id=0)

and not just *hello world* :-)
i find that really good programmers often generate much less code than the mediocre ones. good code tends to be simple, lean and easy to maintain.
i'm also wary of programmers who think that code re-use means that they should never throw away any code they have written. the best programmers tend to throw away more code than they keep.
i work at [large internet infrastructure company] and have done a couple small projects in f#, under the radar. i had some previous exposure to haskell, but none to any ml dialect. after getting past the "different" syntax (different from c anyway), i started to feel more powerful than i ever thought i could on the .net platform.

the code is short and terse, use of side effects are minimal, and i received a total of zero bugs from qa (not counting requirements issues...). i definitely hope that conservative corporate dev tech moves more towards this style of programming. unfortunately, most of my coworkers seem to hope that c# is the last language they'll ever have to learn.
i cannot mod you up enough for the brilliance of you.
obviously some people do. oddly enough ms also seems to care to care about open source since they just got two of their licenses approved by the osi.



&gt; the system seems to highlight functional data 
&gt; structures - a functional hashtable and map 
&gt; (lispers usually use a functional list either 
&gt; inadvertently or not). 

maybe see [fset](http://common-lisp.net/project/fset/)

- 

i use [ed](http://www.gnu.org/fun/jokes/ed.msg.html), the standard text editor.
if i have to stay in my current job for 3 years, i'll probably just kill myself.. better to be poor and happy.
hey, i didn't either! this probably puts us in the top 5% of programmers that didn't write google.
i think the philosophy of "life is too short" is not for those who are living a balanced life. if you are somewhat unhappy with your job but it affords you the life you want, great! if your job is destroying your relationships and taking over your life, you need to consider that "life is too short".
&gt; thankfully php is being slowly phased out.

there, i fixed it.
i'm playing golf with my clients on tuesday.  why wait until you're 60?
i am the world's leading expert on toflas :)
[indian english][1] it is!

[1]: http://education.guardian.co.uk/tefl/story/0,,1355064,00.html
that may be, but it depends on the problem, too.  i recall reading that one year's competition really favored lazy evaluation, so the haskell entries beat out the others.  i don't remember what the question was from that year.
it's funny how people are saying these sorts of things in an age where demand for skilled professionals is at a high at the moment.

wait till a major recession hits and survival instincts kick in.

however, i'm still thankful for periods like this.  but looking at it all, it is too easy to change your stance when the economic situation changes.
  reading the headline i first thought ibm promotes the role now of the *angry young man* or *rebel without a cause* in programming and slava becomes a regular author of a *100 lines of hate* column. after all it pop culture isn't that advanced yet and slava is still just some guy with a blog.  
m-x ansi-term

then run vim all you like ;-)
just like the movie series ikoikocomic quotes, this article shows a lot of promise but spoils it by trying to move in every direction at once.
&gt; for me, 'for(int i=0;i&lt;n;i++), or for(int i: array)' might as well be a keyword

"if i had a nickel for every time i've written 'for (i = 0; i &lt; n; i++)' in c i'd be a millionaire."   -- mike vanier
damn, are you in the wrong building.

by the way, why did you spell "turkey" with an n?
 &gt;"if" can still be defined internally like this:

it can be, but that's not the built-in if of a lazy language. 

&gt;then all instances of "if a then b else c" can be transformed into "if a b c" by the compiler.

sure.

&gt;does this not fit the criteria of lazy evaluation?

if the language that your if is defined in is a lazy language, then yes. i don't see your point, or how this is at all relevant to the issue. 
&gt;has proven me to me prescient in regards to f#

how?  you read their press releases?  so far as i've seen, it's _always_ been this way.  why is this a surprise at all?  have they every portrayed it as anything but this?

it's a for-profit company.  they are trying to make a profit.

there are a lot of things to complain about with ms.  there are so many you could spend weeks talking about it.  this seems like one of the pettier ones...
 does *anybody* think that the word "turnkey" is a good sign? what the hell, advertisers?
gack! too many errors!
actually, emacs is the one exception to the rule. its key bindings have evolved over 30+ years and new modes are left with whatever is left. yes, you can override bindings used in other modes, but then there's the finger memory issue. thus, there is no one obviously non-crappy default, you're pissing off one huge segment of the user base either way.

a default install of emacs is only a starting point. each user applies the customizations that make life worth living for them. since you can store all of your customizations in a single folder it's not a big deal to upgrade or move from one machine to another.
i would definitely agree.  namespaces alone would make things worth it, but the ability to parameterize code by types (i.e., templates) is absolutely essential, imo, for any sort of reasonably modern language.
no, i actually think it's a good point.

however, some languages were made to be compiled, c being the obvious example. and some were made to be interpreted, such as python.

that is, c was made to closely resemble the physical level, while for python that isn't really an issue that gets any attention (and rightly so, imo).

haskell probably falls somewhere in the middle - the unusual semantics keep it from being "native", but the strong typing makes it easier to infer meaning.
[citation needed]
   i don't like it when people say "emacs vs. vi" because nobody sane uses vi instead of vim.

let me take a moment to respond to a couple of replies to save you the time from writing them.

&gt; i use vanilla vi

you're sadistic and probably have a beard


&gt; anyone who uses vim is insane too

enjoy your carpal tunnel syndrome emacs user   
yes, but so what? it's a simple operation, and simple to type. or i can use keyboard shortcuts. pay me off too for every time i've written a function declaration or assigned a variable.
thanks zzzeek and crew.  you're an inspiration.
&gt;why is this a surprise at all? have they every portrayed it as anything but this?

i don't know about "they" but the shills here on reddit sure have. 

&gt;it's a for-profit company. they are trying to make a profit.

yup. should be obvious right? 

&gt;there are a lot of things to complain about with ms. there are so many you could spend weeks talking about it. this seems like one of the pettier ones...

nobody is complaining about it per-se.

i have complained many times that posting about products from companies who sell those products for a profit on reddit is inappropriate because it's spam. that seems to get some peoples panties in  a wad. apparently they feel that ms should be able to spam their products here.


what if i like doing all kinds of things but don't love any of them?
it looks amazing. i'm about to give it a test run. thank you! :)
if c# won't save the wee turtles, who will?
[one more](http://acs.ist.psu.edu/dismal/dismal.html) 
no. you are a human resource. like all other resources such as servers, chairs, desktop computers, etc you will be used to the maximum benefit of the company and will be discarded when no longer needed or a better replacement comes up.

you are a valued employee. please keep that in mind at all times even when you get turned down for a raise or get written up because you didn't show up for the meeting on time. to show you their appreciation the company may give you a plaque or put your picture up on the employee of the month board.

have a nice day.
truthfully, i think it would actually work better...
ha, okay, i get the reference now. i didn't remember that bit. funny movie.

i am very impressed with how you have thought this out; i will definitely be watching your work as it progresses and brings me a good tool to when talking to javaland.

major nitpick: a socket-based swank-like facility is a nearly dealbreaker for me. in many ways swank+slime is far ahead of being able to be one with your live, running program than many modern ides or scripting languages easily provide for.

in my blog post some time time ago, "[the lisp before the end of my lifetime](http://metalinguist.wordpress.com/2007/08/04/the-lisp-before-the-end-of-my-lifetime/)" this falls under category one: "the compiler (running environment, really) is your friend"

finally, having read more of your page, i really like your usage of an anaphoric variable to do recursion. it nicely ties up those annoying 'forgot-to-change-recursive-call' bugs that annoy from time to time. one way to take it even further would be to just have 'return' be a quasi-reserved symbol in every scope that would yield a value (if any) to the caller. that's what return typically is anyway, but it'd be nice to treat it as a first class value sometimes instead of a simple reserved word.
typical advice. sounds good, but for many people simply not practical. personally, if the money's really decent, i'll take a hefty paycheck every time over job satisfaction. 
 you said that "if" isn't a function. maybe i missed your original point.
rcubed z3300.   made by asus, but white boxed, meaning the only place you see asus is on the carry bag.  i don't believe they make this model anymore.  (it isn't fast - it wasn't even fast a year ago when i bought it, but the other compromises made it right for me)
heartily agreed.  i was a bit ashamed to be exactly the person described in the intro: feeling clever that i was using "svn update" to "deploy" my app to production, making excuses for why i hadn't done unit tests yet, etc.  but i'm also glad to know i'm not the only one.

the truth is, especially with the growth of web-language frameworks, good practices like version control, comprehensive testing, bug triage, load testing, and deployment scripting are becoming necessary to develop something beyond a quick weekend web script.

i actually also came up against the branching and version discussion aspects just today.  now i know how i'll be handling new functionality! (hint: i won't be developing directly in trunk)

i'd definitely like to see this document continue and become more detailed; although there is something to be said for its present simplicity.
eclipse is very much the descendant of emacs in design. it has plug-in scripts, it has modes. many of its modes comprehend the program, immediately detect errors, and offer suggestions. it has support for writing extensions. it has support for navigating around in files by structure, jumping to definitions, etc. if it doesn't have paredit mode, it could be added. it already has something similar for java.

both editors have broad facilities for preference tuning. both are extensible.

so really, the essential differences are:

1. eclipse is java, not lisp. (like emacs that doesn't limit what it can edit. unlike emacs, the jvm in theory supports other languages which could be used to write an extension - even lisp).

2. eclipse is written for the internet age. it has the ability to upgrade itself and download and install its own extensions.

3. eclipse is more graphical but is not compatible with text terminals. you take your pick as to what you prefer.
in general i prefer the person who has written less code.   i've seen too much re-typed code in my lifetime.  (i say re-typed because i'm not sure the person responsible would use copy/paste)
&gt; including guy steele, he was part of the team which created java after all.

not really. he was hired by sun after java was designed to act as a "biographer" of java.
the best part is where linus somehow manages to work [yet another dig at subversion](http://article.gmane.org/gmane.comp.version-control.git/61431) into the mix.
 the first one isn't a bug. the ecma spec says that eval *always* binds variables in its caller's scope, not the global scope. the webkit interpretation is that this is regardless of the object the eval method is called on, as the spec is a bit ambiguous (it speaks of a single "global object", but web browsers can have multiple "global objects" accessible to a script). the firefox 3 alpha releases now behave the same way.

the third is fixed in safari 3 (i don't have safari 2 installed to play around with it).
if you are a one person company perhaps.   otherwise you have the ceo's computer, the computers of sales, tech support, and your other developers (who often are not compiling at the same time that you are).

i regularly find myself explaining to customers why they will need an ssl certificate and why the chained certificates from godaddy (only $14.95!) won't work. [1]

eventually we just started including it with the bill. doesn't help that i consider the whole ssl certificates game to be pretty much a racket.

1. chained certificates are signed by an intermediate certificate that needs to be installed in your browser before your browser will validate it... godaddy's (starcommunications) site will use javascript to install the cert on your browser, but j. random internet surfer will get the "certificate is not valid or signed by unknown certificate authority." message...
some of these "myths" border on straw men set up for the sake of having something to argue with. others are somewhat trickily responded to in ways which make it look like they've been disproved when actually they haven't.

take laziness, for example: yes, many languages have _some_ laziness features, i can't think of any which take laziness to such an extreme as haskell. many of its "weird" features stem directly from the fact that the laziness is everywhere, and thinking in terms of things which won't evaluate when you'd expect them to (or which may never evaluate at all) is a big part of the alleged steepness of haskell's learning curve. responding with "well, other languages have some laziness features, and haskell's implementation might change in the future" is a poor attempt to sweep a valid point under the rug.

the same goes for the "oh, other languages have monads" argument. other languages have things which, viewed in the appropriate light and with the appropriate understanding of both monads and the language, look like monads. but again, no other language takes it to such an extreme as haskell, or attempts to impose a background in category theory on the user in order to explain how to open a file.

as for "haskell is difficult", i'd argue that it's true this is not an inherent property of the language. rather, it's a property of some members of the haskell community; the most visible parts of the haskell world, from the outside, are people who write technobabble ph.d. theses which put _star trek_ episodes to shame; the sheer amount of polysyllabic post-graduate prose which gets dedicated to haskell leads, not unreasonably, to outsiders concluding that they'll need to understand all that gunk before they can be productive in haskell. if you want to do something about this, don't sit around and write snarky articles which preach to the choir; follow simon peyton-jones' lead and start explaining useful haskell terms in everyday language.
i've only had to deal with a major intrusion once. the day i got back from vacation i logged in for the first time right after the morning staff meeting and got an error saying unable to validate username from an ip address i did not recognize...

i was surprised at how long it took to get the rest of the staff to acknowledge what had happened.

turned out the dns zone for the domain had been altered so that there were two records for the main domain. and our visitor had been quietly copying logins for 4 or 5 days.

it was two weeks of cleaning up what we referred to as the 'tron' incident. and pissing off a bunch of the free-shell accounts by making them verify their identity at the office before we would reenable their accounts (and force password expiry).

this was quite a few years ago at a small isp that has since been disbanded, but i learned a useful level of paranoia that has helped me deal with many threats since then.
 this article completely lost me when it replied to concerns about efficiency with a big pretentious lecture that boils down to why i'm not supposed to care. sorry, but yes it does matter. if i have a million entries in a database table, and i need to do something with them for a report, it really matters whether it takes one second or ten or one minute (or longer) using the same algorithm.

we'll just wait until hardware gets faster and they write better compilers. okay, enjoy staring at that hourglass.

_only_ caring about performance, throwing away ease of development and maintenance, is really stupid, as everyone knows. but no matter what the effect on productivity, not caring at all about it is equally stupid, if not more. it's really not that hard for a happy programmer to produce slow and bloated software that is painful to use. in my opinion, there is plenty of preaching about this first point, and not nearly enough respect for the second.
first off, abcl hasn't seen an update since march, and stands at version 0.0.10.  it's rife with bugs, incomplete implementations, and all sorts of gunk.  hardly a "proper common lisp".

if you're looking for a proper (by which i mean "well tested and fast") lisp implementation, albeit in scheme, kawa is definitely the one to beat.
i didn't pick up on the version, but i did get the ghc package installed on my ubuntu machine. i even followed through the first few chapters of write yourself a scheme in 48 hours.
resort room at kona village resort are thatched-roof hales with views of the tropical gardens, lagoons or ocean. hales feature furnished porches. hales offer ceiling fans, louvered windows and elevated ceilings for cooling from ocean and mountain breezes.
the claim "it outperforms assembly" can be disproven by this:

* compile your favorite haskell program.
* disassemble it (turn the executable in to assembly)
* pass the assembly code to the assembler.

now, the haskell code is the exact same speed as the assembly code. *it does not outperform assembly.*
you've clearly never worked on an "enterprise" system that required "programming in the large". linux (or any systems software) doesn't count; it's a completely different beast.

enterprise systems are jokes. they are mash ups of all the latest buzz words (and legacy buzz words) that some phb thinks are the wave of the future. as such they are bloated, slow monstrosities that require millions of lines of code to implement even basic functionality.

i'm sure dibblego is right when he says he could have reimplemented those apps in a few thousand lines of haskell. i also suspect that he could have reimplemented them in tens of thousands of lines of java just by throwing out all of the "enterprise" crap.
you don't want to know.

as i understand it, in java, an array of giraffe is an array of (implicit) object pointers.  your giraffe[] becomes de facto an animal[] after the assignment.
i'd really like to have everything in version control, but that's not so simple.

some web work depends on plugging something onto a cms. and some of them hold everything in the database. including templates and script code.

it even comes with a diagram warning not to insert penis.
 my god!  the parallels are eerie. 
ghc version 12.5 doesn't exist.  it is fantasy.

therefore, it can outperform assembly if it wants to.

nyah nyah nyah.
 i worked for musicblvd.com which was bought by cdnow.com, both just outside philadelphia. after a couple weeks i noticed a suid root bash shell on all the production machines - were all the front end machines hacked?! i called over a sys admin friend (also from musicblvd) to confirm it and then we escalated the issue immediately.

a quick meeting with the cdnow tech staff later we found out that they had put all those shells there.  there were so many programs that needed to run as root that it was decided to just leave a suid shell around.

before i quit i left a cron job easter egg named 'mail\_credit\_card\_info' in my solaris account (and it did have access to all the credit card info).  every night it sent an email saying 'still here!' to my geocities account.  if run as someone else it scolded them.  if run as root it printed 'rm -rf /*' to the console (but did nothing else).  if you ran /usr/bin/strings on it only returned 'strings will buy you nothing'.  about a year later a sys admin disabled it.  shortly after that someone found the source and sent me an email 'mind if i use a modified version when i quit? ...'     
dude, can someone tell me what the fuck is going on here?  what am i missing that makes that sentence not complete nonsense?
wow, this guy himself is totally insane.

he's bitching that students right out of school lack vision, they don't know the hot thing, they don't make meaningful contributions to his ground breaking startup.  well, duh.  most of them can barely type.

reality check (i have taught cs at universities).  think of cs like it were art school.  all there is time for is to give the students a class in crayons, a class in charcoal, a class in oils, and with a little luck, a quick art appreciation class that sort of hints at the progression of his craft.  there is no time (or need) for great depth.  the goal is to make him aware of useful avenues to explore when seeking solutions to new problems.  he will have mastered nothing.  at graduation, this kid hasn't done a single non-trivial program (or maybe one - but likely not more).  at best he can draw kind of well in one medium.  this guy seems to expect that the new grad is capable of master's level work?  that takes time and practice and (dare i say it?) experience and maturity.

from the point of the uni, there is no point in teaching the hot thing.  it will change faster than the university can figure out what it is.  the best developers know at least 4 languages well, and have had casual exposure to another dozen.  at this point, a new language can be picked up in about a month.  switching languages is easy when you have a broad base to work from.  the programs the experienced developer writes in all languages will be powerful as they will mix and match the best idioms from the various forms.  more tools, more colors, more tricks in the bag.  this is the point in his career when he is capable of having vision and making profound contributions.  

a new grad simply lacks both the depth and breadth of experience to do this and it is unreasonable to expect it.  perhaps mr startup should get a little funding and find a guy who knows a few things and pay him to solve these pressing problems.
many young people have absolutely no friggin idea what a real recession is like. i actually look forward to the next one. it evens the playing field and rewards those with the best instincts.
bottom line is you could be a hot shit programmer and there are 100 million indians who are as good or better. people really believe they should get out of college and that automaticially qualifies them for a pleasant job that pays great. wake up. our parents worked jobs they didn't love in order to support their families. most had to work for years before they were paid a decent wage.
thank god for c++.  c++'s ugly syntax hides beautiful semantics.
shame icon never really caught on
[one more](http://dto.freeshell.org/notebook/cellmode.html), baby.
it was my understanding that if you're going to put a type in both covariant and contravariant positions, the type constructor must be invariant.

in other words, if array&lt;turtle&gt; &lt;: array &lt;animal&gt;, then 

void insertelephant(array&lt;animal&gt;)

is ill-typed, and if array&lt;animal&gt; &lt;: array&lt;turtle&gt; then

turtle pop(array&lt;turtle&gt;)

is ill-typed.
 it looks like your downmod-whining paid off, but i'll bite anyway: when comparing two algorithms for speed, it's assumed that they both do the same thing, solve the same problem. hardware arithmetic is not, and could not be arbitrarily precise, and everyone knows this.  it's supposed to be a case of "all else being equal," which they are not in your examples. have any other examples in which the development of a slower algorithm is considered 'progress' for any reason other than it being easier to teach? 

oh, and for the record, ghc uses libgmp, which is written in c. and yes i am aware of [this.](http://thread.gmane.org/gmane.comp.lang.haskell.libraries/7285)  
&gt;if you want to learn how to program like ibm's finest enterprise drones, look no further than ibm developerworks.

harsh, but often true.

but it's a similar case with others (msdn and oracle's technet) spring to mind.

i don't want to say it's *the same*, we'd need some statistics for that, i just didn't want ms/o guys feel left alone. ;-)
i just remotely did that to our printer. let's see what happens tomorrow.
 steele was more the chronicler of java than the driving force behind its design. he's said himself that most of his design contributions have been side effects of his work to write a specification, in the "hey, these method overloading rules are really intricate and difficult to document; how about you simplify this to such-and-such?" sort of way. calling java his child seems exaggerated.
as written above it's up to you to customize keybindings to fit your needs. it's true though that default keymap matters. the current layout was set up to be the most convenient for us. feel free to share your ideas anyway. the project is open source.
it could.
i think dmh2000 agrees with you - he was being ironic. this gives it away:

&gt;and why would you want the compiler to help you when the runtime can do it in front of the customer?

someone linked [this here](http://programming.reddit.com/info/5yiy6/comments/) already.
i would up you but you're spoiled enough already.
obviously, if the cms itself is the thing you want to test, it's tricky to avoid having a human sit there and poke at it.  but in general, the contents of a good sample database are absolutely a great thing to have under version control.  of course, it goes without saying that the script you use to create your database (or whatever controls the tool that does so) should be under vc.

the structure of your database is very frequently tightly coupled to the particular version of the application that makes use of it; it absolutely needs to share the same set of branches and tags.
[all together now.](http://www.emacswiki.org/cgi-bin/wiki/spreadsheet)
i remember how easy it was to understand recursion the first time i encountered it taught right.  and i remember how i was at 10, so that combines rather well.

most programming courses i've experienced were ignored by me, i.e., i didn't go.  this *includes* the college class on sicp, because sicp could be read in a week, while the class wasted several hours a week and was booooring.

so yes, the content of this class may be good, and it may also be taught well, but then these two characteristics make a world of a difference, not that it uses erlang.

take a normal cs class, with guys and girls in it, don't dumb it down, teach well, and you teach them a hell of a lot.  by myself i learned the curriculum of four semesters within a few weeks, so i didn't attend class.  that's how bad teaching often is, so no wonder this shining example is such a shining example.
most emphatically not. αrrays, like objects, have an actual type. variables have a declared type. the compiler will check that operations against the declared type are correct, but the runtime will check objects against the actual type, hence arraystoreexception may be thrown.

it's the same issue as with generics, only that they made the correct decision, and a list&lt;object&gt; is no longer assignable from a list&lt;string&gt;.
slowly indeed.  php has achieved critical mass and the market loves a market leader. php will evolve far faster than it gets phased out (and probably far faster than ruby's interpreter improves its speed). 
msdn is very useful. sometimes a bit opaque, but it *is* the definitive reference on the win32 api.

developerworks on the other hand... is useless to anyone who can use google.
i'm using vi as complement to emacs, since i think vim is bloated.  does that make me selfcontradictory?
interesting reading about a real world application running on a functional language.


  testing (proving correctness), for example, is something that matters when you `architect' a system.

it can't happen in c. or java, or whatever. all you do in them langauges is run the program and try to make it crash. that's different from what the haskell type system and stuff like quickcheck do for you.

&gt; let me state this very simply: the issue is not haskell in the small.

it is the small things, comrade. it is the small things. if you can't be sure that c's `strlen` doesn't affect any global variables (and therefore can't parallelise it, for example), this _one single, simple function_, how much more a whole program?
the simple things `in the small' are the building blocks on which the entire system will stand. they matter the most.  
1. happs
2. too many.
3. himerge (http://haskell.org/himerge), the gtk+ front-end to gentoo's emerge.
4. ghc, darcs, house (operating system) ... wait for my startup. ;o)
   
have you ever wrote a grant request?
...because apparently, people need to be told again.
start loading the movie until you want it to stop then "work offline".
you are supposed to care about efficiency. and the article doesn't say you shouldn't. but whose efficiency?
you can do a search over a terabyte of text in under one microsecond. but you won't do that, because it requires you to write the search in assembly, which doesn't consider _your_ efficiency.

your efficiency matters more than the computer's efficiency. that (and that alone) is the reason you don't code in assembly or write an efficient text editor on the eniac.
we live this truth, and yet continue to say otherwise. our efficiency is the true efficiency. :o)
haskell programs generally don't do less laziness than equivalent c programs. it's just that the c programs implement it as a forest of interwoven and confusing if/case expressions.
the haskell ones do it in thunks.

the haskell community does more research than the c community as regards efficient lazy evaluation, even though both need it sorely. who is sweeping this valid issue under the rug, of these two?

apply the above the above statement replacing laziness with monads.

edit: where the c programs do less laziness, they do the wrong thing, ie, evaluate an experssion whose value is not needed.
you being stupid is *your* problem, not mine.

take care.

man you got punished for that hard.
fortran is nothing at all like cobol.


that was my point.
vindicated about what? 
the keyword is `in haskell'. keyphrase, alright.
haskell isn't slow enough to make a good algorithm slow. if an algo is fast in c, it is fast in haskell.
if it is too slow in haskell, it is too slow in c, which makes it ahead of its time.
but produce is to create, not to turn a creation into a product.
productivity is efficiency. see my earlier comment here. valid question, upmodded (despite the downmods you just suffered).
goddamn american education strikes again.

in my part of the world, emprical observations that demonstrate that the earth is round are found in the first third of a fifth-grade textbook.

the 'power' you speak of is an abstract mathematical conjecture, and one that remains (for the most part) still unproved.

you need to try harder if you want to make a valid scientific statement. by the way, there's a real reason why that chip presents  something like c to the outside world (as opposed, say, to lambda calculus.) 

and none of these reasons have anything to do with marketing.
brazilian politicians actually work sometimes? we should import them!
what *about* dna?

call me back when it's used for building a computing machine.

you can implement whatever the hell you want on an fpga. you can implement brainfuck for all i care.

meanwhile, in sane people land, 'lambda calculus implemented on an fpga' is as insane and ridiculous as 'brainfuck on an fpga'. there's a reason for that.

my assertion that f# is proprietary product of a for profit corporation.
 nowhere.

that was part of my point.

which is why we don't program in 'turing machine'.

 turing machines are also not empirically observed, and are also anti-scientific. 

that's a big glaring problem in computational theory, btw. it's also the reason why 'computer science' ranks among other fine nonsense phrases like 'library science' and 'military science'.
not everybody wants to reinvent the wheel over and over again. there comes a time when you are tired of self-made cms.

and then you have a system with multiple tables. some carry normal content. some templates and scripts. and sometimes there is business logic in the content table, because a certain page calls a certain snippet with parameters.

yeah, hell is other people's code.

and nobody pays you to do it "right".
[he knows about incredibuild](http://www.gamesfromwithin.com/articles/0502/000069.html)

you need to remember that at the base case it's still important to isolate quick build times, because if an developer is on site or away from build servers/environments and needs to build packages a system needs to be in place to do those builds quickly.
'science' means 'empirically observed'.

where did you go to school? you're sad.

the problem with it is it sucks for quick builds, it's a great approach for nightly builds or building release versions but for developers making  incremental changes it can impose a big overhead.
that would be a valid point if we had different cpu's that looked different at my level of abstraction.

the point is that we don't. and we never had. all attempts to date (and there have been lots) have failed for technical reasons.

at what point do you give up? is this some sort of a religious point for you?

lambda calculus machines have not been built.


evidence from previous porting efforts suggest that this could be..._difficult_.

people often think that adobe is keeping flash under control for lock-in reasons even though adobe has traditionally been a tool company (give away flex, sell flex builder. give away pdf reader + spec, make acrobat. et al). lock-in may have something to do with it, but i suggest another possible alternative: logistics. it may simply be difficult to open the code in any meaningful way because of untidy implementation and lots of idiosyncratic information held in the heads of the group memory of the flash vm team.

consider the following (now very old) post:
http://www.kaourantin.net/2005/08/porting-flash-player-to-alternative.html
'computer science' is not at all in any sense a science.

it's a branch of mathematics related to formal logic and discrete math.

that it has *any* at all relation to the observed physical world is, to date, an unproven conjecture that we take at face value.


yes we do! your painful memories are our entertainment and education.

#;-)
that was indeed my point.

you had the resources, the means, the knowledge and the religious zeal to make it possible.

you still failed. your 'lisp machine' is really a c machine with an glorified inefficient lisp interpreter hacked on top of it.

why did you fail?

can i see your test code? i still think it's much more likely to be that the difference comes from the comparison with 0 then the direction in which you increment (although on further reflection i can see why ++ would be faster than --).
feel free to collaborate.
i'm going to take a wild guess that all the grant requests you've "wrote" haven't been accepted or financed.
haha, nice one.
what american education?  i have a swedish education. :)

 ;-)

you can install things on your company's ceo computer!? wow, kudos!

no, wait! are **you** the ceo? even better, are you **doing** her (him?) ?

kudos, anyway! 
unplug the cat5 cable? ;)
you've clearly never been able to recognize "enterprise" sarcasm that required "humor in the large"
;-)

erm... isn't there a limit on the command size in the shell and/or the compiler? will it work for, wait... some 300-ish sources?
first of all, that doesn't vindicate you. at best it vindicates your assertion, you are still a loser.

now lets consider that assertion, shall we? 

1. it was well known that f# was being developed by microsoft. 
2. it is also well known that microsoft is a for profit corporation.
3. no one claimed that f# would be released under an open source license or submitted to a standard body.

your assertion hasn't been "vindicated" for the simple reason that it was never in question in the first place. one can no more vindicate it than vindicate a claim that fire is hot or ice is cold.
&gt;it was (and is) absolutely hideous, but that's what i like about c++.

erm... i am not sure how to read this... ;-)
i'm using nano. does that make me a noob?
c-c-c-combo breaker
m-x praise-emacs
verbing weirds language!
 they practice [agile bridge building](http://www.creativyst.com/doc/articles/mgt/agilebridges/agilebridges.htm#newway) 
 that's microsoft for you. i think it's one of those problems where intuition goes completely wrong ("a giraffe[] is *clearly* an animal[]"), and also where the correct solution (generics that include both co- and contravariant types depending an what you do with the array) is substantially more complex. probably neither the first version of java nor that of c# were designed with the help of an expert on type systems.
&gt;first of all, that doesn't vindicate you. at best it vindicates your assertion, you are still a loser.

how so? i said it was a product you and others said it wasn't. i am right, you are wrong.

that makes you the loser.

&gt;no one claimed that f# would be released under an open source license or submitted to a standard body.

that's not true. some people asserted that it could/would be released under an open source license. other insisted that it was a warm and fuzzy cool research project by msr. some people (maybe even you) refused to type the word "microsoft" when talking about f# and kept referring to msr as if it was some foreign entity.

anyway now it's official. any posts about f# are de-facto spam.
 

these hungarian guys are crazy!
i really didn't understand his last bit about "not looking for too much abstraction". it seems like the more abstraction you want, the better scala works, since its lazy evaluation of code blocks lets you abstract out arbitrary control structures and flow patterns.
it might not be that hard.  adobe's [flash lite](http://www.adobe.com/products/flashlite/) is available on many cell phones.  fl 3.0 just came out.  you can play [flv](http://www.adobe.com/products/flashlite/features/) videos with it.
same thing.

 &gt; if an algo is fast in c, it is fast in haskell.

yes

&gt; if it is too slow in haskell, it is too slow in c, which makes it ahead of its time.

what? an algorithm is just a mechanical method for solving a problem. if it's slow now, it's slow for eternity. bubble sort will always be slower than merge sort. bubble sort's time will never come. 

maybe your talking about applications? like streaming video decoding. back in the day, computers couldn't handle it, now they can, using either c or haskell, like you say. but if you have two algorithms for decoding video, and one is faster than the other, why would you ever use the slower one? 

lets do a little case analysis:

&gt; if my algorithm can't run fast enough in haskell or c, nor can any other algorithm...

then the application is ahead of its time.

&gt; if my algorithm can't run fast enough in haskell (but it can in c), it is ahead of its time.

no, you're just in the wrong industry. choose the tools to fit the job, not the other way around.

&gt; if my algorithm can't run fast enough in haskell, but another algorithm can...

then use that other one! in any case, there's no excuse for using a slower algorithm. 
do you want to imply that a grant request which is accepted or financed is fun to write? it isn't.
well at least google is real.
lol
then perhaps you should have said what you meant rather than something different.

"there are no tigers." is not the same as "tigers are rare.".
i was rather hoping to see something about how to effectively reorganize existing code bases for gains in compilation speed, or what to do in that respect to go faster with new designs.

pre-compiled headers and one neat trick? i'm underwhelmed.
&gt; i want it to be attractive to people who might otherwise use jruby, jython or groovy.

well, i was thinking of learning groovy, but it looks like i might be learning clojure instead.

i hope your project gets the optimal amount of attention and praise and whatever else you need/want to keep it going. :)

this might be a killer "app" for jvm.
but we have processors that expose a different programming model and, i'd say, a different level of abstraction.  and they are highly successful.  i'd say the likelihood that you are using one right now is more than 99%.  but you have been spared from programming it.
so i guess that with your peculiar definition of what exists you won't acknowledge their existence.
hmmm

ms precedent: java. another precedent: c++, where giraffe_*_* isn't compatible with animal_*_*. why ms didn't copy this behavior, but rather the broken java one?

and it's not only broken, but also less efficient, as clearly there's a type check that's avoided with c++ type treatment.

edit: markdown.
not even a second spare machine from it?  perhaps one of the computers that are being fazed out, or a test machine or if anything else it should be easy to order a $150 headless box (or pick up a dozen off cl) that you can make into a second box to boost your productivity.
you are right of course. i must clarify. 

factor is just forth syntax with dynamic types. just one other syntax level idea and you create new runtime and language without preexisting libraries? translating factor to java or python would have made more sense. but i guess there is the fundamental need and satisfaction to create own vm in c. 

scheme created new way to program.  all the existing features are combined to create something new. scheme way to program is different from traditional lisp programming.

i think erlang, haskell and fortress are mashups that create new ways to do things and even try to solve some problems in existing languages. in common lisp you have things like contextl, qi etc. that add novel new ways to do things into the language.
not if you have disabled the automatic line breaking feature.
;-)

&gt;the clr is flexible enough to support multiple different languages on top of it.

surely you meant "... as long as it's java-like"?
around where i live, we call that "word wrap".
he says explicitly that they were planning to support java as a .net language. 

great design decision, break the platform so as to be able to accept a language that got left out in the end.
i think they've let their standards slip over time.  i liked the articles written by daniel robbins (awk/sed tutorials) and david mertz (python metaclasses), but i haven't seen any decent ones recently.
in short:

you can't use the licensor's trademarks.

license revoked if you make a patent claim against the licensor :)

if you distribute source, you must do so under this license (but you can distribute object code under any license which "complies" with this one).

no warranty.

an interesting license; it seems designed to allow the contributors to distribute each other's contributions in a closed source form.

this seems to be even a little saner than the bsd license, which allows source code to be distributed under another license, but definitely designed to allow contributors to get the most out of open-source without reducing their profit potential.
&gt; if my algorithm can't run fast enough in c (but it can in assembly), it's ahead of its time.

right?
if we are ready to sink to the murky depths of c, then we should be just as ready to sink to the murkier depths of assembly for the sake of efficiency, the latest god in computing.

i won't resort to assembly, to do pagerank on the
pdp-10. neither will i resort to c to do a quicksort on the intel xeon duo.
i don't think sacrificing now for gains later is "cognitive dissonance". that's goal setting.

i don't like lifting heavy weights, but i sure as shit want muscles. 

i don't like serving you fries, but i love getting that pay check.

i don't like getting my phd, but having an army of ta's to fondle my balls for a lifetime is going to be rocking. 
sorry, site went down after submission. it seems to be back up now.
http://www.theonion.com/content/node/30017
  the goal in commercial software development is to add features over time to drive sales.

you can't sell version 2.0 of widget automaton  pro by putting "fewer bugs than version 1.0!" in the sales brochure.  this is the role of support staff: "sir/madam, this problem is possibly fixed in our new version of the product."

since goals such as reducing flaws and code bloat are then secondary to mandatory feature creep, is it any surprise what happens to commercial software?  it's one instance of second system syndrome after another. 

not that free software or boutique/micro isv software is totally immune to this, of course.  
it's not that, as they were going to support c++, too (and they *do*).

btw... java in .net, what for!? c# is "java for .net". it really makes them look stomping around in the dark. strange, seeing achieved platform quality (on par with java).
this article will set you thinking about: moving…the key to your success are you moving forward, or standing still?
if the algorithm can't run fast enough in c, but it can in assembly, it's not ahead of its time, it's just ahead of your time. if you choose not to write it at all, then you're a picky programmer. i totally respect that, but don't blame the algorithm or the language.

and by the way, you totally just contradicted what you said before:
&gt; c isn't slow enough to make a good algorithm slow. if an algo is fast in assembly, it is fast in c. if it is too slow in c, it is too slow in assembly
 &gt; license revoked if you make a patent claim against the licensor :)

you only lose the royalty-free patent grant from that contributor, not the rest of the license.  (and you're still free to re-obtain that patent grant through normal means, obviously.) 
i don't get your transition from 
&gt; that access would be abused by every asshole with a compiler looking to pwn your iphone    
    
to    
    
&gt; that sucks    
    
the 'assholes' are exactly who nokia (and apparently apple, in the near future) is trying to keep out with their 'signed applications' programme.
i think he was taking a cheap shot at your incorrect grammar. (it should be 'written'.)
what he's implying is that your grammar could use some work. that sentence should be "have you ever written a grant request?"
has anyone written a text editor for emacs?
i have a linkedin endorsement from the author of an oreilly book on a leading web framework, who recommends me for *any* project, yet a recruiter told me an employer decided i didn't have the requisite experience with that framework.  recruiters, be they independent or within companies, seem to be on crack.
they want the cost for people to start using .net to be as low as possible. if all your old java code just works (and is intercompatible with your c# code), then that's a big advantage. 
no, you learned from qwe1234 that you are stupid, a moron, an idiot, an asshole, etc.
er... did you read the article? seemed pretty clear to me.
conversely, if a vendor fails to release anything but bug fixes to an application for enough time, people start to think of the app as “abandoned” and eventually jump ship, even if the program is still working fine.
not necessarily. visual basic is not very java-like. neither is brainfuck.

http://code.google.com/p/brainfucker/

_edit: hmm, explicit hyperlinks no longer work in comments?_   
http://news.nationalgeographic.com/news/2003/02/0224_030224_dnacomputer.html
worst cover art ever
i'm just following ihaveanidea's reasoning there:

&gt; but they sure as hell won't happily live off of ramen in a tiny dirty apartment like i can.
you know, if that's the case, you are paying way too much for sex.
while knuth's tex just marches onwards towards version π.
most compilers have an option to read the command line from file because of that.
&gt;as of now, the dna computer can only perform rudimentary functions, and it has no practical applications. "our computer is programmable, but it's not universal," said shapiro. "there are computing tasks it inherently can't do."

 not really.

at least, none of them are in the least like lisp or any other 'functional' programming language.

how come working, usable specialized processors exist for rendering triangles in 3d, or for solving the n-body problem, etc. -- but none running lisp with anything resembling efficiency?

p.s. you're going to have to stretch hard to explain the 'different programming model' part of your post.

reading comprehension, plz.

quote:

&gt; for the real deal you need the cpu described in sussman and steele's "lambda: the ultimate opcode".

http://repository.readscheme.org/ftp/papers/ai-lab-pubs/aim-514.pdf

it describes a cpu -- actually designed and built -- wherein evaluating lisp programs is the native execution model.

oh, and even the commercial lispms, though they had a more traditional architecture, were not really closely matched with c's execution model. it was possible to get a c compiler going on some of them, but performance suffered and as a consequence it was easier and faster just to write your program in lisp.

as for being inefficient, lispms were solving advanced problems like 3d computer rendering that their workstation brethren of the day couldn't touch.
 obqwe1234:

&gt; lord, how many times do i have to repeat this **iron-clad fact** to you?

&gt; # lambda calculus machines have not been built.

&gt; anything you have to say to the contrary notwithstanding, qwe1234 asserting it == _fact_.
your point being?

this is just a new _type_ of dna computer. others have been built, some of them universal:

http://en.wikipedia.org/wiki/dna_computing
http://programming.reddit.com/info/2tj0x/comments/c2trmd :)
nudge: itym: [[citation needed]](http://xkcd.com/285/)

edit: i mean, make it a link to the relevant xkcd strip.
obqwe1234:

&gt; if it wasn't successful (and for the sake of argument let's define successful as having, say, at least a million daily users) then, to sane people at least, for all intents and purposes _it doesn't exist_.

&gt; do you want to take your words back?
and he even got upmodded for missing the point.
a religious point for *him*? i don't see him trying to say that c++ is the one true execution model...
yeah. because f#, python, sml, and even [scheme](http://www-sop.inria.fr/mimosa/manuel.serrano/publi/jot04/jot04.html) are so very "java-like". 
 'the one true' in the sense of 'the only one known to science and engineering', yes.

i might concede that this is a fault of our science and engineering knowledge and practices, but it's going to take more than illogical lisp handwaving cookery to make that point valid.
 
that wikipedia article is not in the least bit convincing.

 yes, you must indeed be reading something else, or not reading very carefully:

&gt; we will be partnering with don syme and others in microsoft research to fully integrate the f# language into visual studio and continue innovating and evolving f#. 

also, if you follow the link to don syme's blog:

&gt;today is an exciting day for the f# team. the corporate vp for the microsoft developer division, s. somasegar, has announced the formation of a team to take f# forward. 

&gt;...

&gt;this marks the "end of the beginning" for f#, and we're looking forward to the times ahead! 
 so?

lots of crazy useless shit has been 'actually designed and built'. that doesn't make the shit in question valid from a scientific and engineering viewpoint.

also, if lisp machines were efficient, we'd be using them now. the self-brainwashing routine isn't even convincing to yourself. 
&gt; at least, none of them are in the least like lisp or any other 'functional' programming language.

_wrong._

even if you stick with the c execution model -- the newer versions of gcc implement an optimization technique that employs an intermediate form known as static single-assignment or ssa, which has been proven to be equivalent to functional programming. and not in the "computational power" sense -- in the "one can be trivially translated into the other" sense.

this has not been done for brainfuck, intercal, or any of the other straw men you toss out there.

functional programming: making the world a better place, even for c++ programmers.
we're not using dec alphas now either. it doesn't mean they weren't efficient.
boy, your scientific and engineering viewpoint must be way different from sane peoples', where anything that's been physically built and shown to work is valid.
 heh, i've taught too. if you can write code that forks, you can write a controller + view + model no worries.

i wasn't suggesting getting rid of all language study, merely complementing it with some understanding of where a product might finally end up.

if business graduates can think about the bigger picture, then why can't it graduates? it's like you think they are totally incapable, perhaps you should encourage your students to think creatively instead of giving them no reason to push the boundaries. 

it's like it's taboo to give students the opportunity to excel in something other than java/.net
fta:

&gt; and since the iphone is the most advanced phone ever

not even close. my phone does a lot more and it's almost three years old. 
 if you constrain your view of "science and engineering" to include only what you want to see to be the truth, that's behavior a lot like many fundamentalists. therefore, you're the one more like a religious zealot than augustss.

qed.

(btw, "science and engineering" have little to do with what cpu architectures or software systems become prevalent, in all but perhaps mission-critical embedded systems)
&gt; third-parts apps will not have the same api access that apple apps have.

microsoft got sued over that on the desktop os.  office was using secret apis that improved performance etc iirc.

&gt; it will cost quite a chunk to become certified and get your very own key to distribute iphone apps.

they will also have to be tested and certified, as will every update to the application. other phones already have a similar systems and hardly any applications go down this route. thankfully most telcos do not activate the "don't allow unsigned apps" restrictions. 
have you used haskell? you really don't need to know category theory to do even extensive io. 

in fact, using do-notation in the io monad is a lot like programming in c.
i don't understand the war here. vim/vi is an editor and a damn good one. emacs is that and much more. if you want the much more go with emacs.
&gt; third-party software won't get to play with the radio. 

i don't think any mobile apis allow direct access to the radio. most allow access to the tcp stack so they can use network access. i doubt apple would not allow that, it's the network access that makes these mobile devices useful.
do you have several accounts or something? edtek raises an interesting point, you don't even argue against him but instead call him a "fucking idiot", and you have been upvoted to +3? i don't get it.
there is no such thing as an apple-hater. there are normal people and apple fanatics. just look at the moderation patterns in this article's comments. concise accurate posts talking about precedents in this area are modded down while fanboy speculation is modded up. 
you've gotten upmods, but your latter statement seems largely incoherent.  did you perhaps have a typo?  how could it ever be ill-typed to pop a turtle from an array&lt;turtle&gt;?  perhaps you meant that it's ill-typed to pop a turtle from an array&lt;animal&gt;, in which case you're right, at least at compile time: a dynamic downcast should be necessary to resolve the issue.
luckily, i don't write grant requests in english :)

however, i understood that he was joking about my grammar (i don't do any grammar, it's all pattern matching), but the way he said it also looked like: "you think that writing grant request is not fun because yours get rejected".
;-) means "i am winking"

yes, i know there are dozens (hundreds?) of languages running on top of jvm or cli.

but there are also numerous complaints about language x not fitting the vm or vice-versa. that's what i was hinting at: when paradigms are too different, it doesn't fit. you can shoehorn it, though, and that's what's happening.
meh, his lousy gnu emacs os doesn't even have native bignum support or oo yet. it has a long way to go.
a product is something that is produced.  if you create something, you produced it.  it's a product.
but i already knew that :)
well, elisp drivers for 3d video cards are still pretty scarce.
 haskell needs something practical where it stomps the competition into the ground.

joe armstrong gets it:

http://article.gmane.org/gmane.comp.lang.erlang.general/24512 

&gt; (but you shouldn’t use images for simple graphics like curves or gradients anyway; there are cocoa drawing routines for that and nsbezierpath is your friend)

better yet, use pdf files. a pure-vector pdf graphic is cheap to load in mac os x, and they're easy to make, [especially if you know postscript](http://boredzo.org/blog/archives/2006-12-06/compiling-eps-files-to-pdf-files-using-xcode).

yeah, god forbid you ship an app with debugging symbols. someone might be able figure out where a crash happened! or a universal binary---even the newest windows-grandmother convert to macos understands how to choose between ppc and intel downloads.

this is for (hopefully savvy) end users who want to remove extraneous bytes from the disk.
from the pc world article he links to:

&gt; eudora

&gt; lots of long-time pc users have fond memories of this e-mail client; indeed, for many old-timers, it was the first e-mail software they ever used. but some of the changes the program introduced over the years, such as a feature that read your e-mail to warn you if it was potentially insulting, seemed less than necessary to lots of users.

... warn you if the email was insulting?  is there anyone here who used eudora and saw that feature?
agreed. using pyparsing is good for the brain. i like it a lot (parsing nwn files ;) ).
*nods* no umts no gps, i am going to get a n95
he throws candy!
release of version 1.5 of the great file commander pro plugin is coming closer.
  i'd say the bad design decision was bringing the broken-ness into c#.  i think the expected utility of making it possible to support java was probably deemed worth the small damage to the platform.  the bad decision was that the damage was treated like a feature when c# was designed!  
you don't need to ship the debugging symbols to get a usable stack trace. when you get the crash log (without debug symbols) from the user, build the same version of your app with debug symbols, run it, note the pid, and then do something like this:

	atos -p $pid 0x0926ad37 0x0370f3f0 0x000c658f

the hex numbers are memory addresses from the stack trace.

atos translates each **a**ddress into a **s**ymbol—a function name or method selector and a line number. for example:

	-[aimessageentrytextview concludedragoperation:] (in adium) (aimessageentrytextview.m:999)
	-[aimessageentrytextview menuforevent:] (in adium) (aimessageentrytextview.m:914)
	-[aimessageentrytextview menuforevent:] (in adium) (aimessageentrytextview.m:934)
  
did you really link to that just for the cover?  it won’t let me read past the table of contents.
not that i know much about emacs, but text-based video editing does exist; see [avisynth](http://www.avisynth.org).

while it's used more for video processing (deinterlacing, artifact cleanup, etc.) than actual editing, the functions are there.
&gt; pragdave.blogs.pragprog.com

i thought dave called these types of references "train wrecks" :p 
&gt; testing (proving correctness)

testing doesn't prove correctness.  testing disproves incorrectness in a limited number of cases (in particular, the cases tested).  quickcheck's probabilistic testing, though swell, does not in any way *prove* correctness.  (a quality type system, on the other hand, *does* prove correctness, at least for certain program properties.  but even c++ provides a decent enough typesystem for those needs).

&gt; if you can't be sure that c's strlen doesn't affect any global variables

a ridiculously simple compiler analysis can uncover that fact. next!
misleading headline, apple *never* stated there wouldn't be an sdk, they stated there wouldn't be an sdk at the release, which made sense (they were tight on time and even had to pull resources from leopard to release the iphone on schedule, so they didn't have the time to properly build apis and and sdk to allow third parties to build apps).

about a year later, apple now has 12-18 months worth of experience building iphone software and have a much view of what needs to be done, what would be needed by third parties, which apis they should consolidate before public release, ...
&gt; why does software spoil?

because u touch urself at night
wow! it's possible to inject any code to any java application. as i know the same thing is provided in java 6, but described way can work with java 1.3 or higher.

cool!
haha, i m so funny
no, as has been said before, emacs is an intriguing os with a sucky default text editor.
didn't you get the memo?  any comment complaining about the dilution of programming.reddit gets instant kudos, regardless of content or circumstance.

i'll make sure you get a copy.
that was a smilie comment, please don't take it personal. nice meeting you, maynard.
yup.  in a language that supports subtype polymorphism, static typing is like a suit of clothes that never quite fits.
1) http://wc.pima.edu/~carem/mathtext.html 
2) http://www.stonehill.edu/compsci/history_math/math-read.htm
: are the only ones i came across. i saw some references to "easy maths". but i was looking for something more practical rather than theoritical - like read patiently....
&gt; bubble sort will always be slower than merge sort.

not for already sorted lists :)
i was a vax pdp programmer in basic but i started with edt. teco, was even before me. :)
the bsd license does not allow source code to be relicensed. 

also, you cannot distribute ms-pl source code with another license that governs the distribution, unless it is in object code (thus the separation of source code / object code).

ms-pl is also gpl-incompatible.
&gt; is it possible to write assembly code that can outperform compiled code? hell yes. is that likely to happen in the average case? hell no.

is it possible to write haskell, compile it, disassemble it, and then tweak the assembly to be faster?  hell yes.  ergo, haskell (or any other language, for that matter) cannot outperform assembly.
the haskell mod squad is clearly on the warpath in this thread.  original poster makes a reasonable assertion, gets downmodded.  haskellers tell jokes about fictional compiler ghc 12.5, completely ignoring the actual claim made, and get upmodded to 10+.

ridiculous.
umm technically j# is java for .net ;)
c 2012 will be much faster than assembly as well.
 by php6 the runtime will even be able to tell whether it's executing a [class method or an instance method](http://sami.samhuri.net/2006/7/21/class-method-instance-method-it-doesn-t-matter-to-php).  now that's progress! :p
  the t-60 seems pretty solid to me.  a magnesium chassis prevents flexing, battery life is really good while still having room for a disk reader/extra battery/swappable sata drive bay, depending on your needs.  ultra portables like the x seem more like a gee wiz hi-tech toy then an actual tool to me.  too small for extended typing, needs docking station. 
i'm a gentoo user and don't plan to use gutsy on a daily basis, but i just want to download the cd through bittorrent to see how fast it goes =)

edit: in case you're wondering, i'm going to seed for a few nights.
but h2g2 said that god exists though faith... so google should vanish in a puff of logic any minute now.

...any minute...
now i have to be gutsy? i kinda liked being feisty...

... what comes next? horney?
damnit. i only started using ubuntu like a month or so ago, and so had to struggle changing all the x settings with the config files. trying to get my monitor to show 1280 x 1024 right, and -now- they put a gui front-end for it?
gits.
is it a 500-piece puzzle of a kitten on a quilt? those are my favorite.
i also use gentoo, but my patience is growing thin.  i've run into a number of issues that i simply cannot solve and getting useful help from the community these days is very difficult.  i love gentoo linux, but unless the level of innovation and community get back to what they used to be, i may be switching to ubuntu.
hairy hardon, er..i mean hardy heron.
don't worry, you still have to fiddle if you want the correct resolution in gdm.
 i'd rather go with the ps3s for the wow factor, plus they will hold their value longer.     the downside is having to highly specialize your code.
i'm waiting for severus snake to get here...
let me guess, it's because gentoo makes you chase down all the application dependencies and compile from scratch, right?

&gt; in this blog previously, i've dismissed the notion of a "geek gene."  it can't be that it's nature -- there must be some experience or reflections that those who "get it" have had, and those that don't have not had.

lost me there.  there's just not enough evidence to dismiss this entirely.
i like turtles
ubuntu may have all the brand-name recognition in the news, yet it is pclinuxos that occupies the number 1 position on distrowatch.  why is that?  is distrowatch mistaken, or is it being manipulated?
i recommend ubuntu... i came in at edgy, and admit it was rough then getting sound, and video the way i wanted it. feisty came along and was so much tighter... i cannot wait to press my "upgrade" button. 
so what? a new version of an o.s is released... what's so special?
i'm no scientist, but i'm pretty sure that fred brooks nailed it and called it the second-system effect ( http://en.wikipedia.org/wiki/second-system_effect ) back in the day.
icarus isn't the only one who manages to fly a little too close to the sun.
you guys are so impatient. i wait for xenophobic xenu as does my friend tom cruise. 
matt, matt, matt, you are so glib. i know about waiting, you don't.
[an interesting recent thread on slashdot](http://science.slashdot.org/science/07/10/15/0052240.shtml) and [one here on reddit](http://reddit.com/info/2pbix/comments) that might help.
&gt; ... proving correctness ...

oops. yeah. testing only uncovers incorrectness, of course. it takes only an ewd to remember this. :o) my bad.

still ... ever wondered why the c compilers don't do this `simple analysis'?
i'm thinking that what he was trying to get at was that if you've been working on a larger number of different types of problems that you'll have a broader base of language usage than someone who did a damn good job on one project.  

which might be desirable except in the case that you're hiring the guy to do the same project he did before all over again.

this is basically just picking nits at a good general point though.
so video editing didn't come to emacs, emacs dropped by to do some video editing.
you do? ssssh. don't tell my laptop, which is regularily plugged in to different monitors and projectors, with the correct resolution.
i think my issues are mostly down to incompatibiliies with this bullshit dell monitor i inherited.

i'm going to buy another one soon anyway, i'm sick of dealing with it.
still doesn't explain why ubuntu just wont work with any resolution above 1024x768.
arre maamu, home page ko link kar ke kya faayada? new features page ko link kar na:
[http://www.ubuntu.com/getubuntu/releasenotes/710tour](http://www.ubuntu.com/getubuntu/releasenotes/710tour#head-e5d571a1b519d7a4b7fa03f80cffc5c342abb553)   
at least gpl incompatibility is a bonus. ;-)
drink the kool-aid
i'm shocked to find marketing guff on apple's website. 
in gdm?
it isn't either/or. there are times when the computer's efficiency is much more important than how much programmer time is needed. i would argue there are many parts like this in most production software. it really matters, a lot, if you can serve the same number of web pages with 3 servers or 1. users really do notice the difference between 0.5 seconds and 1, and their time is multiplied again and again.

this article appears naive and insulting for giving me a lecture denying this even exists. 
i would like to be able to put turtles, chemises, coin collections, medical curiosities, garden rakes, breakfast cereal, large dogs, and corsican snake-handlers in my arrays.

thus my preference for python lists, unless i really need the extra grief, and cognitive load, of static typing.
try a fresh install with 7.10  i had some similar problems in past versions.   another thing to try is the alternate cd if you have any hanging while installing issues.   i am blessed with an ati card that gave me fits until i started using the alternate cd.   no problems since.    do you know your max resolution and freq?   it really helps when you are setting up.   try the dell site for them if you don't know them.
hrm.  i just upgraded the other day.  it went ok, but.. there were still issues.   emacs did not upgrade smoothly at all.
&gt; what's so special?

arre pyaare, itna kuchh special hai, ki kya bataaoon?

* compiz fusion is enabled by default and works out of box.
* graphical configuration tool for x: no need to edit xorg.conf  
* dynamic screen configuration
* fast user switching: bas, panel pe click karne ka
* deskbar applet is now included in the default configuration
* [gnome 2.20](http://www.gnome.org/start/2.20/notes/en/)
* fully automatic printer installation
* ntfs writing
* the user has the option to encrypt the entire hard disk (or individual parts if you partition manually)
* [apparmor](https://help.ubuntu.com/community/apparmor).

aur kya maangta hai tere ko? bol.  
yup. it's called [moodwatch](http://www.eudora.com/email/features/moodwatch.html).
all distros have been getting better with each new release.   i recently tried centos and was shocked at how much it has improved since the last version.   i have tried a bunch, but usually come back to ubuntu for a workstation.   there are so many things that make using it easier then some of the others.   suse was good too, but i like ubuntu the best so far.   the ubuntu forums have been pretty good at helping me when i had a problem too.  they are moderated well too so you don't get a lot of the lame comments in some of the other forums.   i hope that helps
slightly different. the second-system effect is a single sequel that is planned to be a hundred times better than the original, and ends up bloated as a result; by comparison, the effect described in the article is a gradual process over time. 
none of this is special. none of this is new. pointless link.
 sure, you can use ubuntu and let apt-get figure out all the dependencies, plus download and install the software, but where's the inflated sense of self-esteem? 
remember it was still in beta.   try a fresh install now that it is officially out.   
ubuntu burn out, i think. if you read the pclos newsletters, half of it are thinly veiled jabs at ubuntu.

there was a survey of linux users several months ago (posted on reddit) and a surprisingly small number of users admitted to using pclos, even though it's been in the top 10 for quite a long time.
i use nant at work for build scripts and it works like a champ.
is there an easy way to cross compile from a gnu/linux based system, to target macosx universal binaries? there are a set of simple one-page opengl demos by christophe devine that would be ideal to base a sample off of.

what language is this, klingon?
edit: google says hindi.
kind of like whenever apple releases a new version of the os. actually, it's exactly like that. new features, speed enhancements, etc. etc.

except it costs nothing.
sure, doe whaterver the hell you want. just don't complain when you can't afford a car or a home or food...
that's kind of weird... the only distro i had that couldn't figure out my screen res was simplymepis. i have a notebook running 1280x800.

are there funky refresh rates? it's strange that it would act up like that...
&gt;you can install things on your company's ceo computer

not this job.   but there are enough people here that if our stupid programs were vs 6.0 specific (with plugins that we don't have the source to and those who do don't want to port it) i could get a nice speed up from the other developer's machines.   one of my ideas if i ever get moved to the next project...

in a smaller company it and developer are generally the same person, and there you can do things to the ceo's computer.
ah; i see.  where would one find a more reliable indicator of linux distribution usage, i wonder?  i'm not fully informed of the present situation.
marketing guff != outright lie.

if this were a uk website it would quite likely be breaking the law in this claim. 
hi,

this looks like an excellent find. the bayesian filtering idea sounds great. i'll try it asap.

thanks!
hard drive space is cheap, the number of apps an average user downloads is fairly low. things like universal binaries put user experience over more free disk space and i think that's fine.
&gt; java.lang.exception: repl:2: repl:2: repl:2: repl:3: repl:6: unable to resolve symbol: dotimes in this context

as usual, i'm probably doing it wrong.
they already do.  the compiler knows at compile time whether a given variable is global or local; this is necessary for proper scoping.  the problem is that there's no real optimization that can be done to strlen(3) based on that information.

seriously, what optimization would that knowledge enable for this code?

    int strlen(const char *s) {
        int i = 0;
        while(*s++) {
            i++;
        }
        return i;
     }

i can't think of any.  furthermore, the const declaration indicates that strlen doesn't modify its argument, making strlen pure and thus just as optimizable by a c compiler as pure functions by a haskell compiler.
abe jaa, jaakar bill gates ke paaon dabaa, or go and clean steve jobs' boots. ubuntu rocks, and everything is special about it.
why is this posted on the programming reddit?  it has nothing to do with programming.
this is a really great comment
not too many computer science curricula have economics class requirements. that, and software development is a problem that can be very hard to get a grip on, as much of the work lacks tangibility.
 &gt; we've all seen **puzzled** like "here are 9 dots -- cross all of them with four lines"

color me puzzles, then. overall though i liked the article, i'd certainly be interested in seeing what solutions non-programmers came up with.
oh, you don't think simd is different programming model?
here's an excellent guide.  prepare to dedicate some real quality time. the secret is to read math, you must understand math. [pdf warning]
http://www.ams.org/notices/200510/comm-fowler.pdf

don't forget the mathematical alphabet:
http://en.wikipedia.org/wiki/mathematical_symbols
http://en.wikipedia.org/wiki/greek_letters_used_in_mathematics
http://en.wikipedia.org/wiki/roman_letters_used_in_mathematics

these are a good place to start.

weird, ubuntu detected, and enabled compiz for my dual 24" lcds (1920*1200) without any effort.
slava, take a pill, guy.  :-)

you can say exactly the same thing, with the same condescension, with kindness.  instead of "he sucks,"  say "he has potential for future development."

everyone has something they have written in the past, that might embarrass them today.  give the guy a break.

besides, developerworks looks little like an edited news magazine, and more like a forum for featured writers.



why the fsck is this on programming.reddit.com?  geez, people.  try to be *remotely* topical, please!
and incorrect, too: either the software has a digital signature or the user approves the instalation (like drivers in windows)
forgive me quux, for i have written bad code.
yeah!  this one actually works!  nice interface, too.
i tried all i could on my own, finally gave up when i put the model and "ubuntu" into google and found a billion posts where people have had the same problem - with no viable solution that has worked.

i hope that 7.10 has sorted it, probably not, i'll try it when i get home anyway.
why?

with gpl at least you don't have to agree to the license to use the software.

ms-pl is an eula, gpl is a copyright license.

or are you just trolling?
didnt that freak you out?
do i really smell like curry?

:(
my ubuntu machine (7.04) brings up gdm in the proper resolution whether i attach it to a monitor (1600x1200) or a tv (800x600) via s-video.  i've not touched a single config file on it, nor have i run any gui display configs (other than to choose large fonts and high-contrast).  the chosen display does need to be plugged in and powered on when x starts its scanning, though.
does anyone know if there have been updates to the 915resolution utility?

i use a dell latitude with the intel 945gm graphics chipset, and my only problem is that switching between docked (1900x1200) and undocked (1200x800) states is a pain in the ass, because it requires manually editing the 915resolution config file at boot.
fwiw, i had the same issue.

sudo dpkg-reconfigure xserver-xorg

...fixed this issue by letting me manually specify resolutions without have to mess with the config file.

by the way this was in a gutsy beta install, so don't set your hopes too high.


 ridiculously microsoft-centric. i don't even know where to begin.

&gt;but don't walk around with a "vb or c#" mindset.

don't worry, i wasn't. 
 &gt; still doesn't explain why ubuntu just wont work with any resolution above 1024x768.

ubuntu does work with higher resolutions, obviously, given that the distro has literally millions of happy users! sorry to sound harsh, but this is your setup, either vga card or monitor.

i've personally had ubuntu powering an old 22" crt at 1280x960 and 1600x1200, two 1280x1024 panels, and a 1680x1050 panel. it also runs out the box in dual-head mode on most modern nvidia cards, and if you're prepared to tweak xorg.conf, most ati cards as well. 
yes, the primitive 'if' of any given programming language is not a function in the language, but rather syntax, a control structure. sure, in a lazy language you can write a function that behaves just like 'if', but what i was trying to say in my previous post is that the if you defined and the if of any given programming language are not evaluated in the same way.

the heart of the matter is this statement by the author: "a jump is basically the most primitive mode of lazy evaluation. you evaluate as much as is needed, and then abandon the course. that's lazy. lazy evaluation."

to call a jump a form of lazy evaluation is absurd. if is nothing more than a conditional jump.


wait until you encounter renounification.
i think i'll go and buy a porsche or get a trophy wife instead... perhaps both
 or maybe it has to do with the fact that "page hit ranking" from one site is an awful metric to determine number of installs or popularity. 

i think the last time i went to distrowatch was in 2000.
there's a long list waiting to be used...
http://www.tipotheday.com/ubuntu-names-repository/
i suspect that we're vehemently agreeing here. to me, brooks is describing how you go from a perfectly good system that people can use and enjoy to a system that's so ambitiously overwrought it can't do anything quite right.  whether you get there in one release or a dozen is, to me anyway, purely academic.
yeah, me too.  the whole reason i clicked the link was that i wanted to see the non-programmer solutions to the ticket-booth problem.
i think that some distros finally changing their default architecture from i386 to i686 took a lot of momentum from gentoo.  something as simple as that.
agreed. it's a popularity contest. but correct me if i'm wrong, there's no real way to gauge what people are running.

though, in fairness, it does give you a rough idea of what generally has piqued the interest of the community.
what the fuck, this is somehow newsworthy?

"people are able to create algorithms" without being programmers.
my hypothesis is that it's not that the distribution of intelligence is more polarized in programming classes than elsewhere, its just that its easier to fake smartness by rote learning in other classes. in programming (as in math classes for that matter) you need to understand for your programs to work. the fault is not on the students here either. it's the universities who depend on high number of students passing to get funding that make exams everybody can pass. its just harder to make these easy exams with programming tasks. it's harder to tailor the evaluations for the stupid/lasy people since programming forces them to produce actual thought out results, not just regurgitate dumb facts. imo society should use programming or maths as basic evaluation of reasoning abilities as a requirement for every university level diploma. some of the great universities like cambridge used to do that in the past. and yes this applies even to fields like the arts! if you look at the greatest artists throughout history, the ones who really left their mark, you will see that they almost always had a very mathematically logic and scientific approach to their art. the obvious examples are leonardo da vinci, michaelangelo, mozart or bach but there are many more.
sorry for the tinyurl, he uses internal bookmarks for permalinks, so i can't post the actual url.
 since the site has slowed to a crawl, here's the direct link to the torrent:

http://releases.ubuntu.com/7.10/ubuntu-7.10-desktop-i386.iso.torrent
(27k) 
no.
then click the commonsense computing (episode 3): concurrency and concert tickets link on http://www.cc.gatech.edu/conferences/icer2007/program.html
that argument is hypocritical.

'&gt;&gt;' is 'more important than.

my efficiency &gt;&gt; my computers efficiency &gt;&gt; your efficiency.

therefore i will code in haskell but i want to use your libs and i prefer you write them in c for my computers efficiency.
 here's where i wrote about it, the other day:

http://journal.dedasys.com/articles/2007/10/14/feisty-to-gutsy-upgrade

it looks like they have not fixed this bug:

https://bugs.launchpad.net/ubuntu/+source/linux-source-2.6.22/+bug/115616

as of a few days ago, at least.
&gt;my dual 24" lcds (1920*1200) 

something got hard in my pants.
nah - caddr is so much more 1337 than cadr!  assuming he's just cons'ing new languages on the front of the list, of course...

no, it wasn't very funny, but it was just too tempting *not* to try to make a scheme joke.

also, i think the point was that even a language as old as scheme borrowed lots of ideas from ancestors.
for all this and more, try opensuse 10.3
you might be interested in [this](http://programming.reddit.com/info/9zfb/comments) article, if you haven't read it; its thesis is that some people have the ability to make abstract models in their head, while others don't. 
aww that's mean slava... even retards need a place to talk about their enterprisey world, and developerworks happens to be that place.

the erudite can hang at the programming subreddit.

...btw if you haven't gathered, i'm being slightly facetious, comp.lang.lisp style :-)
&gt; instead of "he sucks," say "he has potential for future development."

personally, i prefer a world where those mean two different things, because they aren't the same at all. 
maybe because here at programming.reddit.com we enjoy operating systems and software in general.
so... brown.
 &gt; but again, no other language takes it to such an extreme as haskell, or attempts to impose a background in category theory on the user in order to explain how to open a file.

arguably, java does. a different theory, but as it has been pointed out, the minimal "read from a file example", to be fully understood, still requires an awful lot of rather tricky oo (the local category concept) to be understood.

you're just used to that, that's all. 
i just got my new version, so i haven't had a chance to install it yet.   usually these types of problems happen on an upgrade but are not there on a fresh install.   i will try it later and let you know.
aren't comics supposed to be funny?
welp, someone ignored the rest of my reply where i acknowledged it was an issue with the hardware.
i am a programmer, but... give them each half the seats to sell? if either sells out, he goes to the other booth and re-stocks with half of the unsold tickets.
&gt; happs

i don't count this one. i tried to use it and it's effectively totally undocumented at this time. 

the previous version is only useful if you don't mind tossing out your entire state every time you want to make a change to the type of your state, i.e., utterly useless in practice.

happs is nothing more than "promising", not proof that large projects can work in haskell.
it sucks that people are lazy, selfish assholes, and apple has to keep their phone closed to cover their asses.
yep. that's why this is a comic.
it's funny because it's true!™
i think the tickets are for specific seats, not general admission.  so, in your case, a customer can ask for a specific seat that the other booth might have.
sure, but i'd just like to split hairs ;) ... 

imnsho, it gives you a rough idea of what has piqued the interest of people at distrowatch. if you hear about a new distribution that sounds "hot", wouldn't you either go directly to their site or search google? how much of the community use distrowatch?
wasn't this on reddit before?
  i like it a lot, too, sluggish though it can be.  i also wasn't crazy about forward(), and having two distinct operators for defining rules ('&lt;&lt;' for rules defined with forward, and '=' otherwise).

i made a nice [workaround](http://aspn.activestate.com/aspn/cookbook/python/recipe/528934), though, for those who are interested.

  
i need another link that isn't blocked by my company's firewall.  anyone?
excellent, thank you.
this is quite an old article. i'm looking at a few build systems at the moment. anyone know of a more recent comparison?
i use microsoft® word™. what does that make me?
coincidentally, i just spent an hour this morning fighting with windows vista, which had spontaneously decided that the copy of windows i'd been running for *months* wasn't "genuine".

i'll leave my next step up to your imagination.
     animal[] animals = new giraffe[10];

&gt;since giraffe is **smaller** than animal...

what?   
in general, such problems are unlikely to be a distribution-specific issue.  it all depends on whether x.org has a workaround for your hardware, and which version of x.org ships with the distribution.

no thanks
so label the queues. this queue for rows 1, 2 and 3, that queue for rows 4, 5 and 6. and omit the re-split step. if a booth sells out, it closes.
ah, the "if of **any given programming language**" part is what i wasn't getting.
aero ape, which apes the vista aero gooey.
actually, one of the main reasons that i used gentoo for so long is that the repositories are absolutely *huge*. virtually any piece of software that i ever wanted was just one command away.

oh, and portage has fantastic (automatic, effective) dependency handling.
any news on the mobile edition? i read somewhere that it was supposed to be released with 7.10.
one queue is in boston and the other is in seattle?
the 915resolution utility has been rendeered useless with the new intel driver.
the rankings don't fluctuate wildly, and leaving and entering the top 10 doesn't happen all too frequently. to go back to my "piqued interest" comment, i think where you rank in the top 10 is irrelevant - i think being in the top 10 indicates an above average userbase. visiting those sites' forums tend agree with this trend, in my opinion.

as far as distrowatch goes, i haven't come across any site that does what dw does and does it nearly as well, so i would *assume* that a plurality of users visit it at least periodically. i use it to see what versions of software each distro packs in - it's a lot faster and more convenient than trying to get to the distro's site - for instance, ubuntu's, which is getting beat on at the moment.
does it weigh more than a duck?
?????
 he is angry. that's different. all these idiots, suckers, second grades and sales people around. this makes him angry. frustration is nearby: he is better at everything but it doesn't really help because the world is dominated by second grades and this won't ever change. maybe that's even desparation but he is too angry and he works too hard to be despaired.

other people just grow old and learn to stop worrying and love trash. everything fails. but for the angry programmer there is no excuse and those old daddies are just pre-senile if not harmfull. 

to be a good programmer *as* a programmer is not just a matter of smartness but also one of morality. a moralist is the prototype of an angry person.  
couple major points here when comparing it to the gpl have to do with use of the software when you decide not to accept the license. with gpl you can proceed to run it, with mspl they want you to be hands off. similarly with the gpl the patent protection extends out downstream to the user base, where as with mspl the patent clause is very narrow and limits patent losses/exchanges between two companies and any patents they licensed through each other.

i'm sure rms can point out numerous other differences, but these were the two areas that jumped out at me. the main problem i see is that with simple sound bites either from companies or magazine editors the licenses may be portrayed as one and the same when that really isn't the case at all.

dilbert is blocked by your company's firewall?
that is funny. it should give a dilbert-comic about it. :-)
boost.build v2 is actually quite good once you figure it out. we use it on some fairly large projects and it's not so slow i notice.

the documentation is somewhat lacking though. i've kinda found that with a lot of build systems though.
lol  great idea.
sell the tickets, *then* build the theater.
about $50 poorer.
don't do that.

fixed tickets and widely separated queues makes no sense. switch to floating tickets or nearby queues.

edit: why the down-mods?
how do you do the online program?   the point is to solve this problem, kicking it off to someone else (a programmer) is not solving it.   it would be the right thing for management, but here you are not pretending to be management, you are pretending to be the programmer.

when i see a pothole in the road i call the hiway department and tell them to fix it.  however the guy who runs the shovel on the hiway department needs to know more than i do about fixing that pothole.   (what tar to use, how to prep the hole before putting tar in, how much tar to put in, how to compact it in, and i'm sure a dozen more things i don't know)  
[*scene: asok is visiting alice's cubicle.*]

asok: i found a clever way to write my application code in one hour! normally this sort of thing would take weeks. i assume my high level of efficiency will be recognized and rewarded.

alice: let me know how that works out for you.

[*scene: phb's office.*]

phb: you did all of that in one hour?

asok: yes, i did.

phb: from now on, i expect you to finish all of your projects in one hour. otherwise i'll assume you're ripping off the company.

[*scene: back in alice's cubicle.*]

asok: you could have warned me.

alice: that's not how experience works. 
you don't need to know category theory to do anything, except maybe category theory.
the best seat is 10th row, dead center (for clasical music), you can only put one person in that seat, even though 12 rich people want that seat. 

edit: i should mention that two rich persons  have paid bribes to get to the front of the line, one for each booth.   only one can get that ideal seat though.
points taken...

if i were looking for stats on this. i think i would look at web traffic for a several specific sites (sites that would receive higher than usual *nix traffic), including distrowatch.

however, it seems that any method other than a client that "phones home" to the distro's servers, is subject to serious error margins.
i'll go build my own theme park, with black jack, and hookers...  forget the black jack!
i miss my ubuntu days, but im already running to many os on my 160g hard drive
nice.  thanks!
realize that much math is written poorly, even by professionals.

think of all the awfully written, hard-to-read code out there.  their math would probably read in the same way.

when i'm reading a paper on math, i make sure to take a note of each convention i see being used.  a lot of papers establish their own ad hoc conventions mid-paper in a footnote or a parenthetical remark to elid certain information which is "clear from context."  i consider this bad practice, but it happens all the time.

also, realize that a lot of variables in math (especially in physics) are dynamically scoped as opposed to lexically scoped.  for instance, you might see:

 a = q * m

and, later on, da/dq.  as a programming languages researcher, i'd much rather see this written as:

 a(q,m) = q * m

and, then da(q,m)/dq.  even more clear would be d_1(a), which is the function a differentiated with respect to its first argument, which would make d_1(a)(q,m) equivalent to the expression da(q,m)/dq.  (i admit that the conventions employed in physics  are more economical---but at the expense of being ambiguous to outsiders.)

einstein's (popular) summation notation is particularly brutal if it sneaks up on you without warning.

a lot of mathematicians have little regard for unambiguously defining the range of iteration variable for iterated operators like sigma, pi, etc.  the range of the variable often depends on how it's used (e.g. attached to a vector with a known dimension).

sadly, i could just keep going and going with all the conventions and ambiguities that plague mathematics.  i firmly believe math would be a lot easier to learn and read if mathematicians took the time and ink to do it right.

so, whenever i'm studying other branches of mathematics, i make a conscious effort to translate it all to a clean, unambiguous lambda-calculus notation.  after doing this for a couple years, i can now usually do the translation in my head.
 the book i typically recommend to people starting out in real mathematics is michael spivak's "calculus". the presentation is excellent, it doesn't assume much (it starts out with very basic properties of the real numbers), and it covers a good chunk of what would perhaps more properly be called analysis. 

it is generally very carefully worded, and the presentation is laid out in such a way as to suggest generalisations to come in later mathematics courses without actually getting tied up in them.

unlike most introductory calculus textbooks, this one actually presents mathematics in such a way as to show why one might enjoy mathematics for its own beauty and not see it as merely a tool for solving science and engineering problems.

that said, there is a chapter on planetary motion thrown in to illustrate a serious real-world application of the ideas developed.

the exercises range from warm-up material, to very hard things which should probably be looked over, perhaps attempted for a while and then come back to later on. many of the exercises foreshadow later results and definitions in analysis. while there are plenty of computational problems (finding limits, derivatives, integrals, etc.), the majority of the problems actually involve proving something more generally interesting.

even though it was my textbook for calculus 1 in the first year of university, it's still probably my favourite text. it is actually fun to come back to it much later and be able to better appreciate the presentation (and perhaps to learn something about how one might present mathematical concepts to beginners in general). 
mono centric development coming from novell is one major difference
that's why plugins are such a great idea. the core program has a minimal amount of features but a robust plugin system. windows media player could be purely like media player classic with a plugin system. great out of the box, but if your the person who wants snazzy playlist functions then add a plugin or two and there you go.
in all honestly i havent tried ubuntu 7.10, but for me it has always been behind opensuse.

as ever with linux, ymmv, but the best thing is, to give them both a go, and see which one works best with your system.
 
opensuse for me has always required less fiddling with, on all the systems i've installed it on, and as compiz is closely linked to opensuse, it works like a charm.

then again i dont use gnome so it might differ.
true, but i think modes like this are an exception to the exception. most of the functions bound to keys will be useless for video editing. it makes sense to replace them with analogies to improve use of muscle memory.
upgraded from fiesty to this a week ago. i love it! only thing i had to do to get it working properly after upgrade, was make a new user account.
actually, the patent grant is very broad and was probably designed to avoid issues like have happened with gplv2. you get a free license to all the patents of everyone involved in producing the code...but only for the purpose of using, distributing etc the software. :p

this means that any copyright holder distributing under the ms-pl *can't* bring a patent action against you, at least where their ms-pl code is concerned. the only exception is when you bring a patent action against the code's owner--then you lose any patent license.
they (both authors and poster) meant "non-modal".
i can't find the post on the blog at all - looks like the author deleted it. :-)
where is the mouseover image title?
and i thought it was hungry hippo... or was it happy homo?
who cares if it's not completely new? factor is very well done, and that's all that matters. 
there was also a lot of music on the titanic.
http://olympiads.win.tue.nl/imo/books.html
&gt; how to effectively reorganize existing code
&gt; bases for gains in compilation speed

the lakos book he mentions goes into that a bit.  definitely worth a read if you work on large c++ codebases.
try looking for one of the rss feeds, and using an online aggregator.  bloglines isn't blocked at my work, even though some comics are.
no, search isn't broken, it's just that redditors have collectively decided en masse that ron paul isn't really all that interesting, and everybody deleted all their ron paul stories.

didn't anybody tell you?

this is just more proof that i.i.t., asok's alma mater, is the best school ever. 

here's some more:
http://people.csail.mit.edu/adonovan/dilbert/show.php?day=30&amp;month=10&amp;year=2005
http://www.iitbombay.org/shared/images/dilbert09152003.gif


[try this](http://people.csail.mit.edu/adonovan/dilbert/show.php?day=14&amp;month=8&amp;year=2004)
i agree. is it true irony that his article shows all the flaws that he criticizes in his evil enemy programmers?

you know what is apparent? this guy couldn't work in a team. ever. unless given unlimited time and money, he'd never get anything done.

without compromising one of his principles.
damn it. i logged in just to post that same comment.
99% of paid programming is simply pushing data around and munging it for presentation or compatibility.
 someone pls tell me why i should bother to move on from my current 7.04 (running as desktop pc)
hey, great link!  it works!  unfortunately, it doesn't seem to be frequently updated.  i can only get to early october.  still, great site!

you guys are all really helpful.  and i thought reddit was just full of jerks like myself.
and this is sad at the same time.

i sometimes have to show a current dilbert comic to my co-worker because it fits something we are experiencing.

a few weeks ago she told a story about me to her friend and he replied that this was similar to a dilbert comic. (and by the way: why is my chair missing every time i'm away for more than 3 days??????)

it's not like the solutions they came up with were great. here are the solution quotes:

“the program would have to temporarily mark seats that are being looked at … so that vendors couldn’t sell seats simultaneously”

“set up the database so that only one person
could access the database at a time.”

“instead of multiple people selling tickets and being involved in every step… the selling process [is] divided between two employees… while the second employee was taking care of the payment, the first could start to deal with the next sale”

“each vendor is responsible for a section of the concert hall”

“sellers organize to sell specific seat sections. there can be an operator that finds out the general section that is desired, and
forward the call to the seller of the section.”

“there should be some communication between the sellers. ideally, the sellers would mark the seats as unavailable on the same documents, so that there would never be any doubling.”

“use a computer program that networks each seller. this way, every seller has access to every seat available as soon as a booking is
made, it will automatically register on every seller’s screen and the chance of there being a double booking will be close to impossible.”
i'm an engineer: combine the booths into one.
it's also funny because he said "application code".
 yep, and then you realize that you essentially entered into a permanent contract with an expensive prostitute. personally i would never marry a woman that has no ambitions other than to sit on her ass all day watching oprah while hubby slaves away at the office to satisfy her desire to go to the mall with a credit card. 
is there a published paper available?  the link on that page is to the talk pdf.
http://ec2-67-202-46-37.compute-1.amazonaws.com/ubuntu-7.10-desktop-i386.iso.torrent

have at it on my dime. the same file, but on a non-crushed server.

edit: nevermind, releases.ubuntu.com is now answering.
ntfs writing@?!?!!?  it's about damn time.
i'm tired of using a fat32 partition to transfer files between linux and xp.
&gt;you don't need a million dollars to do nothing. take a look at my cousin. he's broke and don't do shit!

lawrence
also realise that most of this complaining is primarily better aimed at physicists and engineers, as well as a few of the more applied mathematicians, though they're typically better.

there is a lot of context still used everywhere, but pure mathematicians are generally very picky about notation. perhaps not so much as those who want to make the notation easily machine readable, but one must keep in mind that mathematicians are generally writing for *other mathematicians* (be they professionals or students), and not machines.

to abuse your example above, i would probably not write down the definition of a function without unambiguously somewhere stating its domain and codomain, either explicitly, or by having context force it to be something in particular. (for example, stating that something is an automorphism of a group g unambiguously fixes its domain and codomain to be g). what you wrote above is not the definition of a function, it is simply a property which might be satisfied by a function. i also prefer the total derivative to partial ones, for instance, the derivative of a function r^m -&gt; r^n is a function from r^m to the space of linear maps from r^m to r^n. this can typically be restricted to components where needed. where i use partial derivatives, i'd typically prefer something closer to your notation. then again, i don't do much physics.

using less ink to write things is okay if the stuff that you don't write is very easily determined by your audience. i think people too often forget that when mathematics is (well) written, like any other piece of writing, the audience is kept in mind. this means neither cluttering the page with baroque syntax, nor leaving so much out that they find it less than easy to understand what it is that you're talking about.

this applies to proofs as well. boring the reader with technical details which they can easily fill in as they read, and very likely obscuring the core ideas while you're at it is just as bad as leaving out so much that it's impossible to follow the proof. the goal is not really something that is actually rigour*ous* in a machine-checkable sense, but something which is rigour*isable* in, let's say linear time by the reader. as one progresses and sees the same things over and over, what is necessary in order to express a concept gets more and more terse, because both writer and audience have more experience to draw on. they're communicating the ideas at the level at which they think about them, and not necessarily directly at the level at which they've been formalised. 
i wonder how many straight male porn actors are wondering how long it will be before they have to do that "5 guy and 1 girl" scene. 
i work with some people who went there. both of those comics are 100% true.
more than that these days, innit? or can you buy word unbundled from office?
dilbert just isn't funny.
 indians have told me that most americans smell like "spoiled milk" because of our dairy diet.  
i think you missed the *two ticket booths* part.
the repos are getting nailed like jodie foster on the pinball machine in the accused
buffalo buffalo buffalo buffalo buffalo buffalo buffalo buffalo.
&gt; any posts about f# are de-facto spam.

eh?  who said that programming.reddit.com is for open source only?  what about all posts about the iphone, for example?  or all the posts about reddit itself?  it's definitely not open source, and all the income goes directly into the pockets of a commercial company.

(when did you last contribute to open source, by the way?  care to post some pointers to some useful stuff you've done?)

&gt; *people who don't do stuff can have opinions all they want. i just can't bring myself to care.* -- chromatic
 
i think the only real solution is to break down and learn the config file format, find a modeline that properly describes your monitor, and just edit it by hand.

it isn't so hard, although the man page is hardly complete.

granted, this is an area where linux is still probably not ready for the desktop. but, hey, if you've got a vt220 sitting around, i'm sure that will work just great.
can you provide something more specific than "manually"? is this the command-line based quiz that forces you to answer a bunch of vague questions about your mouse and keyboard *every time*? or is it something else?
but i do think this could be a fun starting point for a discussion of concurrency in a programming class.  what programming constructs do these ideas correspond to?  what are the efficiency implications of one approach versus another?  are you sure that the solution guarantees that no seats are double sold?  what are the edge conditions.

maybe give each student or team of students someone else's idea and have them try to find flaws or places where it might break down.
an n95. 

and yeah, the n95 has some serious hardware. 
it's a bit more complicated than that: the video card and driver has to transact with the monitor to get information as to available video modes. some monitors are not so great at providing it in exactly the format the driver expects. that leads to the x server falling back on some vesa defaults that might or might not fit the exact timing of your monitor.
&gt; an ml dialect has just become a 'safe' choice for conservative corporate departments and shops.

given that conservative departments haven't picked up c# yet ("c++ should be good enough for everyone!"), i'd say you have to wait a few more years before it's a 'safe' choice for any corporate department.
this is hard. i think only one booth should be able to sell a seat at a given time. but then, it's not really concurrent. just sequenced.
pclinuxos is to ubuntu what ron paul is to barack obama.
  distrowatch is a predominantly english language web site. ubuntu is very popular across countries and regions such as india, brazil, africa, eastern europe, etc. places where i suspect pclinuxos is only weakly represented. 

it's worth bearing in mind that canonical are pouring resources into linux in schools, into translation and localization, into outreach, and into linux on the server. they also offer corporate support, a la redhat. m. shuttleworth and canonical are also working hard to make linux available throughout the less affluent areas of the world -- something few other linux distributions, it seems, have the resource (or motivation) to focus on.

from what i've seen of the ubuntu project, it's more like a movement that champions 'free' technology. currently, it happens to be focussed upon a linux distribution, but my feeling is that its self-imposed mandate is much broader than that. i won't be surprised to see the ubuntu badge appearing on other software, and maybe hardware as well in the not too distant future.        
emerge does exactly the same. 
no, i don't think it is.

going from bit operations what operate on 32 bits to bit operations that operate on 128 (256, 1024,...) bits does not count as a 'different programming model'.

you can learn a good deal on how the mathematics is taught around the world by watching various video lectures.

i have collected most of the maths lectures there are on the net on my free lecture blog:

basic maths (algebra review, intermediate algebra, elementary statistics, applied probability, trigonometry, pre-calculus, calculus, **mathematical writing** (by **donald knuth**):
http://freescienceonline.blogspot.com/2006/06/more-mathematics-and-theoretical.html

intermediate maths (discrete maths, algebra, linear algebra, differential equations, math methods for engineers):
http://freescienceonline.blogspot.com/2006/06/free-mathematics-video-courses.html

advanced maths (practice of mathematics, geometry and topology, string theory maths):
http://freescienceonline.blogspot.com/2006/09/mathematics-video-lectures.html

have fun :)
would they settle for bunk seats?
why wouldn't you?  it's not like windows, all you have to do is click the upgrade button.

for actual features, go read a list.
you have an lcd in your pants??
 what a cop-out of an argument.

all i'm saying is that *if* lisp machines were a viable hardware/software computational model, then we'd have available off-the-shelf lisp machines today.

 
bugs happen, and mistakes too.  but you need to know when to stop, as he notes in the comments:

&gt; actually a single failure would have been excused.  stuff does happen, and we all know that.

&gt; the reason this became a legend was that i did it a second time.

&gt; and that was inexcusable.


lisp machines were never 'shown to work'. qed.

ntfs-3g has been an easy install for at least a year now.
i can upgrade directly from within 7.04 ?
ah yes, the same old "fail more people" argument.

i, for one, know that universities generally do a terrible job at teaching in the first place. i say that schools should learn to teach programming.
hahahaha. that's so funny i'm gonna fart... *burp*
*it's depressing to me that there are very few apps i can stick with for more than five years before they become an untenable, unbearable mess.*

he should try using non-commercial software for a change. they either start out as bloated, or stay lean for pretty long.
you're thinking of a different, less funny comic.
color me surprised.  i thought there were still problems writing to ntfs.
name the four middle rows "10"
and the four middle seats "dead center"

:&gt;
&gt; i think being in the top 10 indicates an above average userbase

in english speaking countries perhaps. but linux is a global phenomenon.
yep. it sinks.
more importantly than saving hard drive space, it’s also about speeding up downloads.

but it’s a trade-off — i agree that in most cases providing a universal binary is better than halving download times.
great read
huh?

non-functional programming has been proven to be equivalent to functional programming. 

*of course* functional programming is a valid idea in the sense that it helps make certain programs more safe. 

the real point is that functional programming is too constrained to efficiently implement all but the most simple programs. you have to either stick strictly to those simple programs, or accept very serious performance and complexity degradation.

i took "voidspace's" comment to mean being non gpl it can be used with a a larger variety of licenses.

i don't think she/he was trolling.
this article is nothing you haven't read before and only briefly touches on the puzzle aspect.  no stars!

oh, wait, this is reddit...
thanks for your reply. not exactly what i want. i have that great plugin already. i also use flash block http://flashblock.mozdev.org/

i like pufuwozu's suggestion of using "work offline" although i have not tried it out yet.

my rational is that i don't want to waste bandwidth continuing to load a flash movie if i don't want to watch the remainder of it. yet, i might still want to read the remainder of the web page.

thanks again to for the replies.
i *hate* einstein's summation notation. hate. hate. hate. are people so lazy that they can't put a simple summation symbol?

i don't really see the ambiguity in your a=q*m and da/dq example...

but as someone else may have pointed out, it's usually the non-mathematicians who are sloppy. i don't think mathematicians use einstein notation. and when integrating, they actually put the dx after the integrand, unlike most physicists.
i think the idea of asking people to describe solutions to problems like this is compelling. 

i see that as analogous to high-level design. the next phase (composition or implementation) is analogous to being the theater manager who has to come up with good enough directions that they can still be followed by the cheapest workers possible (who are still smart enough to follow your directions.)

medium to large companies.  web applications, mostly microsoft technologies.
i would love to switch to a linux, the killer app for me would be having parallels coherence or vmware unity feature. at work there are still apps that require windows, i understand there is seamlessvirtualization in ubuntu: does it work as well as coheremce/unity?
not denying that at all. i can't speak on anything but english and hindi &amp; malayalam, but for the latter two, my family members overseas still use english based websites, and those working on various linux (xen) projects do all the documentation in linux. they all use distrowatch.
 
further, depending on the country, there may be distros that are 100% localized which the country/region may prefer - while the usage may be heavy in that region, relative to the global usage of linux it may be small, which doesn't discredit my previous point (i think).
m-x text-mode
oh. well.

your problem seems to sit a bit deeper, then.

the point is that you normally cannot "sell the tickets however you like", however convenient that might be. thus you have to settle for the next best strategy, namely, make it as easy as possible for your customers to *buy the tickets however they like*.
why does nobody love kubuntu. :(
well, as explained a bit lower; you can run vi on emacs...
or some sort of new ferrofluid
wrong, it's hungry hobo
i think the name debugger gives people the wrong idea about what it is, at least in smalltalk.  when i first came to smalltalk in december of last year i tried not to use the debugger, and i did think of it as a crutch.  now i use it all the time to get my bearings around a codebase.  in fact, i write quite a bit of my code directly in the debugger, often with my web browser spinning in the background waiting for me to send the response.

i now think of it as a method context browser, where you have an active repl at every step of the call stack.  this is nice because you can send messages to the objects, to poke them and figure out how they're going to respond. 
known in the field as 'anti-lulz'
if the op has to ask that question, then i don't think he'd need calculus. calculus is only fun when you're doing physics. probably he'd be more interested in discrete math, which has many day to day applications. if you want beautiful math with quite low "barrier to entry", i recommend (euclidean) geometry.

in any case, there are many ways people write math. some are expository (think feynman style), some are monologue definition-lemma-theorem (where i find myself reading the same page, even same couple of paragraphs, for 2 days to a week), most are a balance of the two styles, and then there are those applied math books that are really boring but can somehow make your head ache. 

so for "casual" math you'd want those expository-type books. looking at my bookshelf, i'd recommend "a diary on information theory," collected stuffs of renyi. it's not all about information theory, there's also some probability and number theory (fibonacci stuffs) inside.


i agree. my feeling though, is that of all the 'generic' (i.e. not language specific) variants of linux, ubuntu has by far the greatest linguistic reach - and momentum.
see bill's link (above in "oldest first" mode).
wierd. gdm used 800x600 (i think) with my lcd's native 1680x1050 as virtual resolution for me. my screen only has vga, no dvi. can that be an issue? i had to manually put 1680x1050 as the first resolution in xorg.conf to fix it. also, the gui-tool did not recognize my screen, i had to pick a generic 1680x1050 lcd and remember to check the "widescreen"-box. caveat: i upgraded 7.04 to gutsy two weeks ago, it may work now.
well... it might be true but when you show something "magical" to the boss and he expects everything else to be just as magically done... it could create a lot of frustration. this reaches maximums for me when he asks me "you could do that couldn't you?" and i realize that  it might be a whim for him that will result in hours of work that could be discarded just because... "it looked better before" :)
&gt; f# on mono? looks like that's a "yes".

i've successfully run it on mono on feisty, so i can confirm this first hand.
"everybody's a jerk. you, me, that jerk."
sure. start up update manager, there will be a button to upgrade to 7.10.

but don't do it now. the servers are too busy at the moment. wait a couple of days and then upgrade.
i meant editing xorg.conf by hand, in a text editor.

this program in ncurses based... but i've used similar versions previously. it did ask some vague questions... but the default answers worked just fine. the relevant screen resolution questions weren't vague.
yes, update manager should tell you that there is a distribution upgrade available.
too much blue, and the k thing drives me kompletely krazy ;)
http://www.ubuntu.com/getubuntu/upgrading
i think you mean "jerks like *me*", asshat.
sorry, i didn't realize you were up and running. the example needs the latest boot.clj.
you can grab the latest [release](http://sourceforge.net/project/showfiles.php?group_id=137961&amp;package_id=151481&amp;release_id=547945)

 i feel like composers may not be the best evidence for your last point, given the mathematical qualities inherent in many forms of music...and even in those avant-garde styles that eschew mathematical structure or patterns, well they require some knowledge of just what those patterns are in the first place.

as a student of both mathematics and language arts myself, i can certainly say that the two do help each other in various ways. my english papers tend to have a better organizational structure and more logical approach, as well as proof-like terminology i might otherwise not use in a paper. 

conversely, some of my proofs have clearer and more illuminating diction because of my english studies. i certainly favor the "artistic" side over the scientific/mathematical and am by no means some super-student, but there are definitely benefits, at least for me.

however, when i see students who do better in math than me write horrible papers, or students who write better papers than me cringe at the mere thought of math, i can't see me being the rule rather than the exception. it's great to have skills in both realms (which is why i'm majoring in them), but math isn't going to make everyone a better writer.  
"if business graduates can think about the bigger picture, then why can't it graduates? it's like you think they are totally incapable, perhaps you should encourage your students to think creatively instead of giving them no reason to push the boundaries."

i am pushing the boundaries.  i'm trying to teach them what pointers are, how to analyze efficiencies of algorithms, how to estimate space/time requirement tradeoffs for different solutions.  that's hard for them (based on my experience as a hiring manager- we don't even do a good job at that).

if i had my way, they would only see java or .net in a survey of languages course.  java would be only introduced from the point of view of a synthesis of earlier techniques and in context of earlier research.  i wouldn't use it to teach algorithms or data structures - it sucks for that kind of exposition.

there is that whole tension between desire for vocational skills and education that universities seek to straddle.  that is the key problem.
have they taken out all the gay shit yet in this release?

no thought not. anti-lulz


because it's packed full of sexually insecure blue.
nope linux sucks wake up sheeple!!!!!111
ok, that comment reveals enough of your ignorance on how these simd machines are programmed.  think conditional execution.

perhaps you should have a look at how they work.  you'll find that your c intuition will not help you much.  nor will haskell intuition.
mathematicians actually use einsten's convention (since it's useful; so instead of hating, try turning your hate into love :), especially those working in differential geometry. 

also, i know at least two physicist-turned-mathematician guy, who are the antithesis of sloppiness: they are much more precise than your average mathematician (to the degree of being *painfully* precise...)
a rich person?   get real.   if they are there to be seen they will settle for any box seat near the stage (even though the view and sound sucks).  if they are there for the music they want the best seat.  they still want to be comfortable though. 

besides, the bunk seat will have different acoustics in other levels, so it wouldn't be ideal.

edit: changed back seats in the back to box seats by the stage, because wriiight's reply is correct.
nasm has always had a special place in my heart for no real good reason. this was interesting. maybe i should look at gas again.
um, no. even simpler. let's say the tickets are just for admission, no seats or whatever. even then your scheme provides no means to forecast how many will be bought in *location a* and how many in *location b*.
exercise your eyes - focus near - far - near - far.  does wonders.
 i wish it will have an option to filter buzzworded text, too.
 
i think the big factor is the ability to simultaneously consider a huge multitude of possibilities and somehow pluck out the one that's correct.

like when [they used dna to solve the travelling salesman problem through brute force](http://physicsworld.com/cws/article/news/5229).

in other words, maybe the "programming gene" is the ability to solve np-hard problems in one's head.
caveat: i'm not a mathemetician.

what's your current education level?? if you haven't gone through 1 year of algebra and another year of calculus with a math professor who inspires and teaches math like it were english, then you are putting the cart before the horse. don't "settle" on a prof - if you have a bad feeling about one, find another. despite the stereotypes of mathematicians, i have met some extraordinarily funny, charming, patient and humble professors even at community colleges. 

i'm not against the "teach yourself" route, but know that you've got to have some extreme diligence and probably won't face half the challenges you would in school. i've had problems dropped on me in assignments that i'd be far more likely to just skip over while studying at home. 

the links you provided:
1) http://wc.pima.edu/~carem/mathtext.html 2) http://www.stonehill.edu/compsci/history_math/math-read.htm 
both offer sound advice. don't speed over equations - write them down, understand how to go between them and other equations, understand where they come from. do not try to read them like english - that comes later, way later. 
i've taken a few programming classes in the past and had a great degree of difficulty. for me, it was like being given a story problem and then returning the answer as a step by step mathematical proof: declare the givens and the variables, discover a way of manipulating them to solve the problem and then return the answer. this is what the [curry-howard correspondence]( http://en.wikipedia.org/wiki/curry-howard) is, i think. that computer was so stupid that you had to tell it what to do every step of the way; making assumptions and missing steps resulted in multiple compile time errors.

as an avid linguist, i found computer languages very disappointing. they could declare, do, perform and make, but they could never be; they could never articulate or express or understand *dasein*.
not if you install viper mode! :p
  &gt; unlike other languages we read about here f# is not open source, is not standardized, and has various patent and other intellectual property protections on it.

agreed. it's always been released under microsoft's "shared source license", which is emphatically *not* an open source license. this is in contrast to ironpython, which is released under the microsoft permissive license. mspl has not been accepted by osi (yet?), but at the very least, it shares enough characteristics with a bsd license that i think you can use it in nearly any way you would use bsd-licensed code.

if you have no interest in developing for .net anyway, surely all this is irrelevant to you.

on the other hand, if you're writing .net code anyway, f# is really no better and no worse in this regard than any of the other ms tools. this is simply a commitment by microsoft to offer developer support and full-blown visual studio integration.

iirc, you have criticized c# on many occasions for technical reasons having nothing to do with the evilness of microsoft. f# may still have the stain of microsoft upon it, but for those interested in writing functional code, it provides technical advantages over using c# or vb.net.  
note to self: do not bite
go watch porn?
how true.  i'm a salesman and international broker, but there's no way in hell that i'd pass a programming exam.  my worth in society is determined by if i can program or not.

oh wait, no it isn't, society indicates my worth with a big fat paycheck.  not my math ability.
nope, that's all still in there. which is fortunate because it discourages knuckle-draggers like you.
for some reason i couldn't reply to you unless i clicked your permalink...

anyway, if you want to be seen, you get one of those boxes just to either side of the stage.  the view and sound from these seats suck, but everyone can see you without them having to turn around.  
[*edit:* pdf warning]

http://portal.acm.org/ft_gateway.cfm?id=1288598&amp;type=pdf&amp;coll=&amp;dl=guide&amp;cfid=15151515&amp;cftoken=6184618

it's on acm so the link may or may not work for you. 
i cannot speak for flash lite 3, but can speak quite authoritatively for flash lite 2.

flash lite is still considerably behind the newer flash vms that are available for other platforms. it's still at flash 7 and there is no flex support. making flash lite applications is a painful affair involving fishing into flash professional. there are (were) also some insane limitations like if an 'operation' blocks for 750ms wall clock time you'll get an "actionscript stuck" message. nevermind that most of these phones are multitasking systems, so you have no idea what else the user is running. once you get this message, the party is over.  niggling issues like this are still really debilitating for the platform. 

it's probable that adobe has more resources to work on this than the past, but it still seems to be a challenge.
 
hey if i add enough conditionals i can cover everyone **and** if i just list them then i don't have to justify myself.
guess i have to change my screen name...
you have to learn to think, not to read, first. and for that, i can recommend [shafarevich's basic notions of algebra](http://www.amazon.com/basic-notions-algebra-i-r-shafarevich/dp/3540612211), which is the best math book i ever read.
well, the deal maker for me was bios raid support out of the box with opensuse.  i had one look at the steps to get this working in ubuntu and gave up.

that and all the brown...ugh.
there are a lot of good suggestions here, but keep in mind that you will never really "read math as you read english".  english is an often imprecise and redundant means of communicating information.  we're used to reading paragraphs quickly and getting 80% of the information, then filling in the gaps.  mathematical notation, on the other hand, is extremely precise and has very little redundancy.  if you don't give your full attention to every character of it, you will likely misinterpret it.  so no matter how fluent you get in reading math, you will still have to read it more carefully and in a different mode from english.
considering how "ridiculously microsoft-centric" much of the programming world is, it's actually sound advice to that significant segment. the name of the magazine is after all _**redmond** developer news_, and guess where all those redmond developers are working if not nintendo. :)
do you write large real program in haskell?

what field is it in?

no, really.  :) 
true, true. i grew up programming (since i was 4 or something) and then stopped programming when from my 16th to my 24th.
i was just thinking today that when i was 12 i could program almost as well as i can today... just imagine what would've happened if i had continued ....
i'm still at level 1. lobster is definitely not readily available until i level up my career. seriously, when is the career world going to start handing out experience points? 
&gt;i use an alt. i am a coward.
 my dad just asked me completely out of the blue to help him install ubuntu on his computer. thought that was pretty neat, i haven't told him about the new release and i never preach about linux, so he must have a genuine interest in it (and he knows about gutsy, wtf).
*programming x will make you a better programmer in y*

not necessarily. being really, really good in x is usually much better than being a student language dilettante in x, y, z and w.

first of all, what the fuck is bdd? i'm guessing since i've only heard this term on ruby blogs, it's something useless i can safely ignore.

&gt; asking why ruby has weak debugger support is like asking why a dolphin doesn't have gills. ruby has weak debugger support because ruby programmers shouldn't be using a debugger. ruby supports tdd and bdd better than any other language except possibly smalltalk. debugger support is for languages that you can't run tests against gracefully.

if you need any more proof that the ruby community is full of degenerates, look no further than crap like this.

"ruby doesn't need a good native compiler; slow languages encourage you to optimize and write scalable code"

"ruby doesn't need a debugger because debuggers are for pussies"

"ruby doesn't need a working gc because memory leaks encourage you to write short lived scripts in line with the unix philosophy"

"ruby doesn't need consist naming conventions because this is web 2.0, baby!"

"ruby doesn't need stable libraries because hunting bugs is a fun use of a developer's time"   
click the second link in the article, scroll down a bit, and you'll see a screenshot showing the video actually embedded in emacs. so it's a little more than just using any ol' text editor on the edl.
 &gt; i thought there were still problems writing to ntfs.  

same here. 
space/time complexity is often more important than correctness.

can quickcheck check for time complexity?

i'd rather use c++, thanks. it's easier to add a unit test framework to idiomatic c++ than it is to add real value type semantics to haskell.


i think maybe you're onto something. the only people who can program are people who aren't bummed out when they find out how difficult it has been for so many people to make computing as cool as it is!
indeed, it is.

however, my intent was to make fun of vanderbilt's slackware-like tone, not educate him in gentoo's package manangement.
ok, my bad.
**encrypted hard disks**  

&gt; [...] please keep in mind that this only protects the data when the machine is powered off.  

any idea why ? i can't see how a locked screen can be any less secure than a turned off machine.
if in exchange for making so much money, i have to endure the rantings of some dude on the net who thinks i need to pass his math test to be worth a college education....

good trade.
thanks.

now i know that there's at least one person on this site that knows something about programming.

i wonder where most of these people work that they don't understand basic truths?


i wonder.  let's say we had programming methods that didn't presume an autistic level of literalism -- it truly allowed vagueness of expression.    would current computer scientists and programmers, used to very precise and formal constructs, really want to use it?  it would be quite a cultural divide.
and the other 1% is testing.
&gt; sell the tickets, then build the theater.

the good thing about this approach is that you can build a theater based on demand for particular seats. for example, a theater where every seat is in the front row.

your comment just isn't relevant
behavior driven development.  what is it?  don't know, don't care, it's probably a dsl with a gajillion colons or something...
&gt; so, whenever i'm studying other branches of mathematics, i make a conscious effort to translate it all to a clean, unambiguous lambda-calculus notation.

well, the first thing i do is to try and sort out what *objects* all those variables refer to.  

(true anecdote:  math conference, physicist talking, formula throwing contest.  common in almost all formulae were integrals after some my. question after talk:  what object is this my you integrate against (measure on path space, on r^n, function, distribution)?  answer:  well, that would be a great subject for future research.)

*then* i aim for lambda calculus.  then i try to find a trivial example.  then a not-completely-trivial.  the i try to understand the difference of 'condition x applies' and 'applies not' more intuitively.  then i try to link this with things i know.  

if you want to make readable articles, i would prefer you to help me with those points, in that order.  the first one is often completely forgotten.  
  boost build is quite awesome, actually.

it's also actively maintained, so i've seen the documentation problem get better over time.
 
p.s. evaluating build systems on *build times*  of all things is positively *retarded*, for crimeney's sake.
 
i look at it and its just a "dsl" for writing unit tests:

    @foo.bar.should == 3

instead of

    assert(@foo.bar == 3)
if you're not downloading over a dial up modem the difference will only be a few seconds. download time doesn't even enter my mind when i'm thinking about downloading new software.
whatever we don't have we don't need. but once we have it we not only need it but invented it. 
reminds me of dos users slamming the mac back in the day.

"we don't need windows, we can just type in our commands a lot faster".  yeah, whatever.
i know how simd machines work, thank you very much.

i think you don't really understand how non-simd machines are really the same thing at the core. i can't really tell, nor can i reply without you clarifying what you really mean by 'simd machines' here.

&gt; huh?

that about sums it up. let me show you something so that you, in the depths of your ignorance, might come to understand why functional programming is important.

http://citeseer.ist.psu.edu/363289.html

in other words, gcc (and g++) from version 4.0 on, convert your c program into a functional program expressed in a special (internal to the compiler) notation to perform optimizations, i.e., code restructurings to make programs _faster_.

if "functional programming [were] too constrained to efficiently implement all but the most simple programs" these optimizations would not be possible. qed.
i posit that such a method cannot exist as a general purpose language.  we use formal constructs to ensure consistency and reproducibility.
omg!!~ this is so hawt, what was i thinking using `self.assertequal()` in python?!
text.  xml is evil; text is good.  xml cannot be easily grepped/parsed/handled; text can.  xml is lame; text is powerful.  if there's a reason to use xml for anything, i don't know what it is.
it's weird to see those apps (appzaper, xtrimmer, path finder). those apps remind me of .... microsoft windows. 

if mac osx ui is so neat, user-friendly and good, why do we need another file explorer (path finder)?

if mac osx is a superior software/platform (and the devs are great), why do we need a tool to clean up mess (appzaper)?

if osx is so slim and cool, why are these apps become so much bloated?
note the name, though "second system". it's not "same system", "later system", or anything else. it's "second system", because it's an attempt to make a new and different thing which is *much better* than the original it is supposed to replace.
experience is a hard teacher: she gives the tests first and the lessons after.
i’m too much in a linux mindset. everytime i read "glib", i read it as a reference to the libglib library...

ps: i’m not a native english speaker.
the guy who thinks debuggers are useless just wrote this on his blog:

&gt; i definitely still consider debuggers harmful. sorry about the closed comments, and the comments deleted for rudeness, but how much time am i supposed to have? i don't need people stressing me out. i got angry and lost sleep last night.

the "rude comments" in question were people (james robertson and others) telling him that indeed, he's full of shit, and if he ever tried to develop any real software he would realize debuggers are a useful tool to have (not in those words).

as for the lost sleep, i can just imagine some crazy ruby zealot, shaking and twitching all night long... "must convert those infidels to ruby... it is my mission... it is my life... must convert..."
my co-workers and i used to pass dilbert comics around and just insert the names of our bosses.  we thought scott adams was spying on us to get material for his comics!  
 i understand why functional programming is important. i have lots and lots of years of functional programming experience, thank you very much.

you've managed to prove the very point i was trying to make: the 'optimizations' you showed are exactly an example of the kinds of very primitive, very simple programs i was talking about. compilers are still very dumb; necessarily, they can analyze or optimize only the very simplest, most primitive parts of the compiled code.
 

(i mean *come on*, figuring out how many times a variable was defined and assigned isn't exactly rocket science.)

obviously i know that. 

but regular joe sees firefox icon on their desktop and what they do is click it to use it. they don't know how to "show up" the actual window. they have to be "educated" to do so.

when i'm selecting the app (cmd-tabbing), i select it for a reason too! because i simply want to use it. why would i bother selecting the app and not using it? where's the logic in that?

  i didn't know mathematicians use the einstein convention (other than applied ones). i've even asked a few mathematicians and none had seen it. maybe it's just limited to those in certain branches. nevertheless, i still hate it.

as for those two physicists, there are always exceptions. it's just that i've taken plenty of physics courses in two different universities, read a number of physicists' papers for my work, and they're just plain sloppy in notation. clearly, anyone in their field knows what they are talking about, but not because it's merely alternative notation (it isn't) - but because they're used to it. think pharmacists who can read the doctor's handwriting.
  
since when was ajax a language?
i'd have to double-check with the coolest ruby bloggers, but your approach just doesn't seem _agile_ to me.
those people whose passion is their work and work is their passion are truly lucky, and i believe, in the minority.  
the first couple people in line are going to be scalpers who buy all the tickets anyway, so let them deal with the problem.
yes.  the programs are large as haskell programs go and they are real.

currently i'm working for an investment bank.  the code is used daily by a number of people here.  all i can say is that it is a dsel.

before that i worked on a compiler for a hardware design language.  you can check out the web site of the company, bluespec.com.

before that i wrote a partial evaluator that was (is?) used by carmen systems (carmen.se).  their software is used by most major airlines around the world for crew scheduling.

all in haskell, of course.

(i've done other things in between, of course.  like writing device drivers in c.)

i like how if you had to do this on windows everyone would say switch to linux but when people have problems with linux no one says that. i guess its up to me: switch to windows.
fantastic, thanks.
no, tom cruise made a fool of himself in a matt lauer interview. i was just paraphrasing some of his lines.
kubuntu is part of the ubuntu family.   that is what i started with.  
are these internal tools or are the 'deliverables' used by actual users?
&gt; but regular joe sees firefox icon on their desktop and what they do is click it to use it. they don't know how to "show up" the actual window. they have to be "educated" to do so.

everything is an education, if they are 'educated' to realise they should exit an app when finished with it this wouldn't be a problem.

&gt; when i'm selecting the app (cmd-tabbing), i select it for a reason too! because i simply want to use it. why would i bother selecting the app and not using it? where's the logic in that?

an app does not necessarily have one window. at a particular time using firefox you might have say the main browser window open and the downloads dialog minimised. if you cmd-tab to firefox the download window should not raise, the app should appear in the state you left it. 
this reminded me of my old unionized job: never raise the bar, otherwise they'll expect you to do it all the time.
do you do similar things with debuggers in other langauges at all? i've always shied away from debuggers in favor of printf debugging, but what you're describing sounds wonderful if i could get it in my languages of choice easily.
you don't have to, and probably shouldn't if you are happy with the way your computer runs and aren't looking forward t any of the new features.    i always install the new versions on a different drive in case i don't like it or the machine has problems.   i personally don't mind a little tinkering and i really like what the developers are doing with ubuntu, so i like to go to the new version as soon as i can to help them find solutions to problems as they happen.   everyone has their own reasons for switching or not.
i miss the pre-rails ruby :-(
i can cross them all with just one line. 
obqwe1234:

&gt; doesn't matter. haskell isn't viable for production code.

&gt; and by production code i mean "used by actual users".

&gt; and by "actual users" i mean at least a million a day.

&gt; and by "a million a day" i mean "all at the same time".

&gt; and by "viable" i mean "produces the exact same results a c++ compiler would".

&gt; no thanks. you can keep your little toy apps. the work i do is far too complex to be entrusted to the likes of haskell. c++ ftw!
&gt; i remember ...

you have excessive confidence in the reliability of your own memories, a lot of opinion and apparently little knowledge or experience teaching teenagers.
http://biolpc22.york.ac.uk/pub/linux-mac-cross/
you weren't paying attention. thanks for making that obvious.

in brief, goat.
i applaud the arrogance egotism and elitism that created this idea. 
aye - typical code is what that is.
 i'm not at all convinced that pyparsing eases parsing in any way. 

just look at the code that is required to define a parser for [pythons grammar](http://pyparsing.wikispaces.com/space/showimage/pythongrammarparser.py) ( 90 lines of code appended to the grammar text )
and compare it with the description it needs to define ebnf in ebnf using this very same grammar and pythons stdlib tokenizer that strips whitespaces and single comments:

      file_input: ( rule | newline )* endmarker
      rule: name ':' rhs newline
      rhs: alt ( '|' alt )*
      alt: item+
      item: '[' rhs ']' | atom [ '*' | '+' ]
      atom: '(' rhs ')' | name | string

call me an ebnf zealot but that's the *meaning of life*: short, concise, readable, expressive, on the spot.
 
this is probably one of the most important lessons for fresh-out-of-school workers to learn.  kind of like showing requiem for a dream to scare people away from drugs, dilbert should be used to show the truth/horrors of modern office work
 like you, in other languages i use printf debugging mostly, or a repl if one is available.  the smalltalk debugger has a richness that is missing from the other ones i've used.  

i think factor is doing some interesting things, and i look forward to where it'll be in a year's time.
indeed, that's how it happens.
sometimes i've messed around for hours getting something to work right in linux. the nice thing is, once you get it right, it stays fixed. windows just deteriorates for no apparent reason, so by the time you've got the system customised the way you want, it's time to wipe and re-install.
they missed the opportunity for gaping goatse.
 &gt; does this mean that ruby sucks? no, of course not.

actually, i'd argue that it does. languages are nice and all, but it's the whole ecosystem that makes or breaks development. 

i write a rails app for my daily bread at the moment, and hunting down and fixing bugs is... fairly primitive. it's better than using _no_ debugger though; what a wonderful time-sink.

as for giles, i think he should be hanging out with the manual-memory management crowd. gc's are a crutch! real programmers don't make mistakes! 
i suggest you look up 'science' in a dictionary, and you'll find that your definition is one (simplified) meaning of several.

http://dictionary.reference.com/browse/science
well, i remember what i used to feel about school.  i absolutely hated it.  and i still feel that way, even though people used to tell me "but later, you'll think back to school days and say 'oh, back then life was good.'"

no, it wasn't.  it was hell on earth.  everything after school was much much better, even college, which wasn't too great, either.
ron paul is more like a 1982 calculator watch.

giuliani is a 9/11 special edition email worm.

ctrl+alt+f2 will bring you to another screen.
 maybe if the other languages support [**resumable exceptions**](http://www.object-arts.com/docs/index.html?resumablevsnon_resumableexceptions.htm)  
let me make you an offer then: make a formal definition of *dasein*, and i'll make it into a programm. 
this reminds me of working for walmart. anytime someone did something commendable, it was ignored, or the manager expected everything to be done that same way (which sucks if you only got it done because it was a slow night and it was annoying you that none of the cameras on the camera bar worked). but, if someone complains, even if that person is being a jerk, they yell at you and tell you how "it just isn't done like that here." 
i have upgraded my gf’s feisty through update-manager without problems. i did it today, though.
just when the onion print and web edition started to become less hilarious, they manage to hit a homerun with the onion news network.  you can easily kill an entire hour watching those videos.  lord knows i have.
if he's look for short code in the sorting example, he could shorten it a bunch by just doing:

return new integer(length0).compareto(new integer(length1));

i haven't written java code in a while, so i don't know what the state of autoboxing is in java.
it is not only the job candidates that lie. the employers often lie too, by adding "sexy" technonlogies like, python, xml asp.net or whatever they think is cool, even if they only have a vague plan to apply it in some future project. then remove unsexy ones, like cobol or visual basic, to not scare applicants. then you discover after a while that the job you got is quite different from the description. 

then the list is given to a recruiter, which have no idea of what the employer needs or the potential employee want.
you are right, this should’ve gone to entertainment or sports section. maybe politics.

/sarcasm
&gt; they don’t understand relational databases. they use too many tables.

funny, i usually see the *opposite* problem with people who don't understand relational databases.
 funny, i've programmed on just about all windowing platforms. while people like to take the easy swipe at win32, they never seem to create any apps that look or work better. from my experience, x is a disaster.
is that your way of admitting that you lost the argument?

or in no subreddit at all.  the release of an operating system has *nothing* to do with programming.
i wonder how many guys on one girl it will take  to get to a point where you can no longer call it "straight porn".
wow, its just dilbert, big fucking deal. why is this number 1?
been running the beta for the last two weeks or so with some success. only problem i had was installation. the live cds wouldn't boot on my computer - the screen would blank about a minute into boot each time. i was able to install using the alternative install cd, and it's run pretty much flawlessly since.

so, if you're having problems getting the installer to work, try the text-based alternative installer instead. 
&gt; calculus is only fun when you're doing physics.

no! that is quite untrue. calculus, in its proper context as part of analysis, has lots of fun results from a purely mathematical perspective.

looked at in a particular light, calculus is the study of the behaviour (and misbehaviour!) of real valued functions, various conditions (continuity, differentiability, integrability) you can put on them to make them behave "nicely", and how "poorly" they can still behave even under those conditions. it's also a subject that has lots of geometric appeal to add some visual aspect to that process, and to help build intuition for proving things.

i think it's an excellent starting point. perhaps not the most ideal one from a computer science standpoint, but good nonetheless.

linear algebra is another decent starting point, as it showcases many ideas which will occur in other abstract algebraic topics, while involving quite a bit of geometry. it's also quite a bit more applicable to cs, particularly graphics, but in many other places as well.

for discrete mathematics which would be interesting to cs people, enumerative and algebraic combinatorics (in particular the theory of generating series) is full of great ideas just waiting to be stolen and applied to data structures. unfortunately, i don't know of a text which is simultaneously widely available, introductory, and has a decent presentation of the material. (as far as i can tell, it's one of those pick any two situations.)

for widely available and introductory, you might try "generatingfunctionology". however, in my humble opinion it's awful. the overall approach is confusing, as are some of the definitions, and many of the proofs are way more complicated than they need to be. i struggled to understand its definition of exponential generating series, and i already knew very well at that point how exponential generating series worked.

for introductory and has a decent presentation of the material, try the university of waterloo c&amp;o 249 and 330 course notes by d. m. jackson. they're absolutely excellent. it might be tricky to get hold of them, but you could try calling up the math printing services. they'll probably ship them to you if you'd like.

for widely available and has a decent presentation, you might try "combinatorial enumeration", by jackson and goulden, which is nicely encyclopedic in scope, while maintaining a fair bit of expository text, but certainly isn't gentle. any book which uses joyal's combinatorial species approach would also be on the right track, i suspect.
 &gt; what was i thinking using self.assertequal() in python?!

yeah, what were you thinking?  here's how it's spelled in python, when using the one true testing tool &lt;wink&gt;:

    &gt;&gt;&gt; foo.bar
    3

(where all you actually typed was foo.bar; the rest is just good old cut and paste). 
bigus dickus for 8.20 
at the bank the only users are internal; we don't produce software for external use.  the dsel itself is used by non-haskell people.

the compiler sold by bluespec is written in haskell and is intended for end users (who get an executable and don't care what it's written in).

the partial evaluator is one program in a suite that is sold and is run by the end user.  (btw, this program was first used in 1995 running on hp boxes.)

if you worked for yourself, the next step could well be "take three days of vacation and do the same thing next thursday".
who was it that said, "debugging is twice as hard as writing code. therefore, when writing code, only be half as clever as you think you are."?
     
i'm pretty sure, in certain situations (say, any compiled language?) debuggers are your best friend.
    
nice explanation of smalltalk's debugging power from the blog's comments -
&gt;in smalltalk, the debugger is a surgeon's tool, the programmer/surgeon can work on a living patient and fix the patient in realtime.

&gt;in other environments, the debugger is a medical examiner's tool. the patient is dead or dying, and the debugger is just a way of opening the code body to figure out what went wrong. no fixing is possible. 
oh, i forgot another program that is being sold.  it translates cryptol to fpgas.  it's hard to tell how many users it has because the customers tell you nothing.  http://www.cryptol.net/
 yes, because the operating systems aren’t coded at all.

otoh, i do understand what you mean. but those who don’t care about oses at all will not find this newsworthy. programming is the geek basement of reddit. 
you're not able to write to a ntfs volume if it's not clean. you'll need to boot into windows and let it check/repair the volume, and then go back do ubuntu.
how is this comment interesting? he's just stating an opinion (i think documentation is nifty!) not telling me anything i dobn't already know. 
because people voted on it.
believe it or not, this is how sql was sold. managers can query your database -- in english! data is referred to by its properties, not by arcane pointers and file record positions!! imagine the incredible business returns you're going to achieve when management can get information in an eyeblink without any intermediaries!!!

automated information systems are always going to require some amount of expertise -- at least until they are endowed with common sense.  
&gt;ever tried to develop any real software  

heh, he was my roommate the first part of the year, and i can reliably say that he hasn't 
i think it's mostly just the differential geometers who use einstein summation. i don't know of anyone else who does. (except of course physicists.)

personally, when working with tensors (which is where einstein summation is typically used), i prefer defining sufficient operations to get past the coordinatised versions of things as quickly as possible.

what's worse than ordinary einstein summation is the variant where the index variable which is used determines the basis with respect to which that coordinate is picked out in the first place. this is clearly awful, because one can't actually replace the index variable with the integers that it is meant to range over, because then the information about which basis it was would be lost. regardless of how i may feel about plain einstein summation, i personally think that variant is a genuine case of irritating and poorly thought out notation to be avoided. 
ugh, how true.  that was me in the financial sector a year ago.  if i finished my work too fast, the boss would say "hm, i don't have anything else left for you to do".  so during my copious amounts of free time, i was able to find another job.
ha ha, what bullshit.
after you get out of the dungeon. they aren't offered in the first level since that's really only to learn the controls.

after you slay the manager dragon, he drops the real items you need, and you start acquiring experience points.

let me know how that goes :)
this book is so important because it is so common for development managers to add resources to a late project, which typically only makes things worse. considering that most of the manager who make this mistake come from a business background rather thana programming background, it is a wonder that they didn't learn this in their classes.

i think the problem is that they don't really understand software development so they can't understand why adding people to the project would hurt rather than help. 

even if the principle is well established in other domains, this book explains it in terms that are specific and relevant to software development.
 the [training examples](http://stupidfilter.org/random.php) could need some work. this comment only get a stupidity rating of 3/5, which will end up confusing the filter:

&gt; aaahhhhhhhhhhh ï»¿ yooooooooooooooooooooo

clicking around a bit didn't reveal any not-stupid ones. btw, is it really necessary to moderate the database by hand? just code a spider to grab 1,000 comments each from youtube and ltu and teach the filter to tell the difference. 
while i agree that you should stick to the older version if you're happy with it, note that ubuntu doesn't allow you to skip upgrades (i.e., if you want to upgrade to horny heron or whatever it's going to be called, you'll have to upgrade to gutsy gibbon first, or otherwise do a clean install).
way to go, baghdad bob. declaring yourself the winner of an argument that somehow ceased to be. an argument requires two parties who can agree on terms and premises. you spun off towards the moon a couple posts ago.
 [a _lot_ more.](http://www.amazon.com/microsoft-059-05468-word-2007/dp/b000hcz8gw/ref=sr_1_16/102-9228744-8733739?ie=utf8&amp;s=software&amp;qid=1192730481&amp;sr=8-16)
 
  except for the "division of labor" idea, i have seen every single one of those solutions tried by professional programmers. 

some of those solutions are perfectly fine given a maximum scaling requirement of two point-of-sales and perhaps one medium-sized theatre.
no, that's the welease after woderick.
good post. reading it made me have haskell flashbacks.
how do you found that out?
p.s. munnabhai is a character in a famous hindi movie and the sentence is not pure hindi but a dialect used by that character in the movie.
&gt; like you, in other languages i use printf debugging mostly, or a repl if one is available. the smalltalk debugger has a richness that is missing from the other ones i've used.

i think the point here is that useless debuggers are useless, but useful debuggers are not.

(and for languages with useless debuggers, most people qualified to write a really good one has already learned to live without it... sigh.)
my daughter, who is in tenth grade, has already figured this out on her own.  in pe she has to take the presidential fitness test at the beginning and end of the year so they can find out how much progress she has made in the class.

as a result, the first time she took it she did the minimum needed to pass although she could have done more.  next time she has to take it she will automatically be able to do more since she wasn't at her limit the first time.

i don't condone what she has done but she is pretty smart to have figured it out on her own.
giles is just trying to be contrary.

the rails code can be so convoluded with metaprogramming techniques that you can not decypher what is going on without tracing execution. 

i actually *worked with giles* at a company on some rails apps. i've watched him struggle to detangle some weird happenings in rails and ultimately fail. then i watched another team mate bust out the ruby debugger and quickly zone in on a similar internal problem and make sense of it all.

giles technique matches my continual experience with rails and why i've stopped using it. tdd has nothing to do with it -- if you can't understand why seemingly sensible code is failing, no amount of testing will save you.

the other teammate's technique is why i consider him one of the best programmers i have had the experience of working with. 

because of this experience, i make an effort to learn the debuggers for the languages that i do use, but recognize that i still have a long way to go here because debuggers generally are hard to master.
not really. this section of my article is specifically addressing experience. i've already made the point that experience does not equal expertise. but there is still something to be said for experience. there are lessons that can best be learned from personal experience. 

with that premise, i'm suggesting that experience should still not be measured in time but in some unit that is more closely related to the amount of stuff you've done. 

please note the use of "generally" and "likely" in the quoted sections. there are no hard and fast rules. some people gain expertise and experience faster than others.

--scott westfall 
i pretty much always go the route of a clean install.   there is just too many reasons potential problems that are not necessarily there if you do the clean install.   i have had the upgrade work well and have had it fail.  

clean installs always give me a fresh drive to start with.  
out of the box support for installing all the codecs, flash, java, binary nvidia drivers, binary intel wireless drivers and ripping softwares. to paraphrase [mark](http://diveintomark.org/archives/2006/06/26/essentials-2006#comment-6753)   
 &gt; take all the pain out of violating patents, breaking laws, and compromising the very principles that led you to linux in the first place, in exchange for being able to watch a recreation of the latest box office hit in 30 seconds with bunnies.

you're missing the point. my point isn't that people who write more verobse code are more experienced than those who write tighter code. within an acceptably succint coding style, the person who has written more code to address more problems will be more experienced. 

were i to use your logic, then we could infer that the best programmer is the one who has written no code whatsoever. let's avoid these logcial falasies.

--scott westfall
thats a case of pkb syndrome if i ever heard one
yep, it sucks, but it's a known issue that you only have to deal with once, and it's a well documented issue so it is usually easy to fix.

i'll take xorg.conf over random windows bugs anyday.
ah, an association for computing machinery link, including the obligatory

 - warning that the link might not work for you
 - warning that it's in a document format your web browser can't view normally

and it's a paper that says, basically, "omfg non-computer geeks can solve problems!!1".

does this not strike anybody else as highly ironic?
i agree there's a problem.  we don't allow one man to have many wives (at the same time) but we'll let one person speak to many people via mass media or the internet?  doesn't sound safe to me.

social intercourse and physical intercourse are similar enough.  but sex only influences bodily fluids.  open free exchange of thoughts contaminate our minds.  you can't get much more intimate than allowing someone in your head.  and there is no "morning after" pill to clear your mind after reading or hearing a dumb thought.  just try listening to republican (hate) talk radio for a disturbing example.

so i agree, there's a problem.  but an open source stupidity filter?  good luck.    
i have a paid-for copy of windows xp that i had to crack to make "genuine".

if you're eager to share the experience in the latest ubuntu, install this software: http://www.linuxgenuineadvantage.org/
dont forget that you can only upgrade from the preceding version, so you'll have to call yourself 'ubuntufeisty' before you can change to 'ubuntugutsy'.
were you looking because you inundated your boss with other analogies that lacked relevancy?
the transcript also demonstrates that dilbert's visuals are more or less dispensable.
 if your primary example of a static type system is java's, you probably shouldn't write an article about how static type systems in general suck.

edit: i'm being serious here. there are many static type systems out there which are much more expressive and concise and useful than java's. comparing a fairly nice dynamically typed language like smalltalk to java and then concluding something in general about static and dynamic type systems is just completely unfair to static typing. 
i wasn't so lucky.  upgrading was a nightmare, and has left me with essentially nothing but a bunch of regressions and bugs for my trouble http://lukeplant.me.uk/blog.php?id=1107301679 . 

there has been no word on all the bugs i filed.  perhaps it is just me, i guess, but there is no reason why this should have happened at all -- i only ever used standard ubuntu repositories, and didn't mess around with any significant manual changes to my system.
not programming.
the latter statement, as you will see, was predicated on "array&lt;animal&gt; &lt;: array&lt;turtle&gt;" where "&lt;:" is pronounced "is a subtype of".

in this case, by liskov substitution and the covariance of function arguments, i should be able to pass an array&lt;animal&gt; to pop and get a turtle out.

sadly, no.
i do not suggest that you can rate someone solely by the number of lines of code they have written. my point is that given a comparable coding style, the person who has written more code in their career will typically be more experienced.

there are lessons that are learned by doing. even repitition can be instructive, provding a greater opportunity to hone skills and introduce more efficient methods. a person who only has to paint one fence is less likely to come up with a better way of painting fences than someone who has painted many fences. 

besides, if we follow your logic, then we would all want to hire programmers who haven't written any code at all. 8^)

seriously, though lines of code written is an imperfect metric it certainly says more than something that can't be measured: lines of code written/lines of code that could have been written.

--scott westfall
i think we can allude the message of this comic to one of [calvin and hobbes](http://www.s-anand.net/calvinandhobbes.html#19881213)
hm i guess reddit = osx fanbase?
&gt;in this blog previously, i've dismissed the notion of a "geek gene."  it can't be that it's nature -- there must be some experience or reflections that those who "get it" have had, and those that don't have not had. 

no, it's massively genetic. it's not entirely genetic, but wow is it genetic.
huh.  i'm having a lot of trouble understanding why anyone would care.  if i'm someone who has to choose which to use, on what basis should i make the choice?  the article doesn't really say which is better or why it matters.  ok, the syntax is different, i get it.  isn't compatibility with existing or surrounding code going to be the overriding factor?


by the way, why didn't a higher-level syntax for asm ever take off?  you know, like c but with a 1-1 translation to machine code.  people have been talking about that for 25 years at least.

    _start {
      // move the contents of variables
      $ecx = *var1;        // mov ecx,[var1]
      if($ecx &lt;= *var2)    // cmp ecx [var2],jg
        $ecx = *var2;
      else if($ecx &lt;= *var3)
        $ecx = *var3;

      $eax = 1;
      $ebx = $ecx;
      int(0x80);
    }
     
the one i used did not seem to allow for sync frequency ranges that depended on resolution, as needed for my lcd monitor. that's why i gave up and learned how to edit the file. for which the man page and howto's were only slightly helpful
if you google "arre pyaare, itna kuchh special hai, ki kya bataaoon" the first result has hindi in the title.
what's even funnier is that dilbert is blocked and reddit isn't. :)
 nasm is better in some ways, and the original authors had their hearts in the right places, but overall it feels like trading one set of quirks for another.  at least gas has been through the wringer a lot more than nasm.

for windows i'd still use nasm, because it breaks free of the rest of the gnu tooolchain (i'd also seriously look at fasm).  for linux and os x, i'd stick with gas. 
there can be "one true default" for each possible set of solutions. i can just envision a compiler using `amb` and a manager sitting in front of it, raising exceptions...
don't be such a snarky tool, dipshit.
can you give an example of what this kind of method would look like?
most writers can't reason. and since most of their audience can't reason either, they seem like perfectly good writers to them.

from your self-description i'm willing to bet you've got both analytic and synthetic function.

most of the population lacks analytic function (which confers abstract reasoning) and the near totality lacks synthetic function (which confers creativity).
well i must say that you are right it's more concise.  however i find the longer version more readable, because of my less educated brain.

i know python very well but i have found ebnf impenetrable.  i have tried several times to learn it with frustrating results. so in my case it helps me look at the code to figure out the rules.

so it would ease my effort in building a simple parser.
well, the type system of most functional languages is pretty much the same, except that type inference removes the need to declare types in simple cases (but not in cases where you need named variants).

oh, and you can't easily have destructively updated objects in purely functional language, and they're handy for a large class of problems.
my favorite lie is 5 years of .net and 10 years java, which i started seeing about the time .net turned 2 (which would make java about 7)
frankly, you shouldn't have to endure anything at all. i suggest you kill yourself to escape these pains.
&gt; i said it was a product you and others said it wasn't.

until a couple of days ago, it wasn't a product. the very fact we are seeing news about it being changed from a research project to a product is proof of that.

honestly though, i don't see what your point is. many of us, myself included, were hoping that it would become an official product.
100% agree. the problem is that to developers their code or api makes 100% sense and is trivially easy to pick-up. 

not..even..close.
i had that exact same obsession with it:
http://programming.reddit.com/info/5ylvw/comments/
the comment "i'm guessing since i've only heard this term on ruby blogs, it's something useless i can safely ignore." seems along the same lines as the original guy claiming debuggers aren't needed. perhaps there might be a middle ground here, where ruby developers faced with a problem (the lack of a good debugger) came up with an alternate solution that is useful too. from posts i've been reading elsewhere, the [rubinius project](http://rubini.us/) has been using this style of test writing to generate a [specification for ruby](http://rubini.us/pages/specs-overview). 

as for the dsl/syntax thing: if the developers need to write a *lot* of this code because there currently aren't good specs and test cases for ruby, then maybe even modest gains (e.g. the assert v should) might save a good deal of work. it doesn't look like groundbreaking work... may not have been worth the invention of a new [tla](http://www.catb.org/jargon/html/t/tla.html), but it still looks kind of nifty. [specs style guid](http://rubinius.lighthouseapp.com/projects/5089/specs-style-guide)
 
edit: i'm not trying to imply that debuggers aren't all kinds of awesome, just that debuggers don't write specifications. they are only half the tool set.
more than twice as fast in ruby!
http://programming.reddit.com/info/5ylvw/comments/

have you posted your solution somewhere?
once again i pick the wrong technology.  i just spent 5 years becoming an expert at eating crab legs (king crab prefered but i can eat snow crab as well).  now everyone wants lobster eaters.

i think i'm going to become an expert at visual basic next - as a service to my fellow programmers who won't have to deal with that anymore.
well, no one said that it was ready for production use yet.
i don't understand why do teachers consider it a mystery that many people can't learn to program. it's simply a question of intelligence. it's weird - it seems these teachers would go any length to avoid accepting the fact that people have different levels of iq, and you can't make people with average iq successful in an elite profession. 

why is it that doctors don't ask why many people can't learn to do brain surgery?
 &gt; if mac osx ui is so neat, user-friendly and good, why do we need another file explorer (path finder)?

because some people prefer it and are willing to pay money for that ui. i mean, you might as well ask why mac os x needs a gui at all given that it has a command line...

&gt;if mac osx is a superior software/platform (and the devs are great), why do we need a tool to clean up mess (appzaper)?

you don't actually need appzapper. if a few apps leave things lying around after you uninstall them, it wastes a tiny amount of disk space and doesn't hurt anything. i don't actually uninstall anything to begin with -- why bother? it doesn't hurt anything having it there and the disk space is worth less than the time it'd take me to remove it.

&gt;if osx is so slim and cool, why are these apps become so much bloated?

mac os x doesn't exactly have a reputation for being "slim and cool" (whatever that's supposed to mean), but even if it did, third-party apps are not made by apple, hence the term "third-party apps." it's not as though developing for the mac magically makes programmers perfect. many mac developers are small companies (often one person) whose testing philosophy boils down to "it runs on my mac, ship it." same as on windows, really. 
(adding to the flow of conversation)

generally in concurrency, a "lock" is placed on data when it comes into use, be it by reading or by writing. writing is obvious, but with reading, you could re-read that data a few times, rather than buffering it, and might have it change in-between reads, as in the case with parent's inconvenienced customer.

the second customer should be told (1, 1) isn't available, even if it hasn't been sold yet.
you should have tried aztec c. it included its own un*x like command shell.
functional languages tend to have much better support for parametric polymorphism than java's generics.
the great mathematician and pedagogue n. bourbaki has written a series of books beginning with the most basic notions of mathematics and working up to many interesting and powerful results. highly recommended for motivated self-learners.
i prefer kubuntu when the linux bug bites. hey, does anyone know if compiz-fusion is built into kubuntu as well, or is it just the gnome flavour?
hit the nail on the head.  sometimes the best way to get to know something new is to find an expert and ask what would be a good problem to solve with it is that will let you use a big chunk of it.
of course, mathematics /isn't/ a language.  it's just that mathematicians talk about math using specialized language.  you need to learn the language, of course, but you also need to understand what the language is talking about.
 you're wrong on both counts.

haskell's type system in particular has universally quantified type variables (parametric polymorphism). java recently got support for "generics" which is essentially parametric polymorphism, but they're somewhat crippled and not all that commonly used. haskell has typeclasses, java doesn't have anything like that. algebraic data types. java has nothing remotely like that.

if you start looking at what's in ghc, things like gadts, existentially quantified types, higher rank types, type families, and so on, there's just no comparison.

you can easily have destructively updated objects in a purely functional language, via monads which allow you to express those imperative computations which manipulate those structures. you can even have a monad like st, which will let you do all the imperative stuff you want involving mutable references and so on, as long as there are no *real* side effects, and it will wrap that up into a pure function for you, and it's not really any harder than using an ordinary imperative language. it's only harder *in comparison* to using immutable data structures which you can reason about equationally, and for which you typically only pay a logarithmic factor (essentially part of the constant factor). but this is really true in any language, only that in most imperative languages, equational reasoning is hard enough no matter what you do that people don't bother to think that way.
the problem is when a customer (booth 1) wants to see what's available.

does booth 1 then lock out all of the seats away from booth 2 until the booth 1 customer makes a choice?


if booth 1 has to lock out all of the seats then this kills the concurrency.

a _try it and then correct it if taken_ is a good compromise if you have a write lock during the time between the check and the write.

i would have 2 checks, a general check and then a specific check (after choosing) with locking.




if it takes more steps and not really intuitive to do things in osx, why are people saying osx is user-friendly?

every time i went to my arts lab, immediately i knew there are apps still running because the previous users do not know how to close the apps properly. 

it's true that an app does not necessarily have only one window. 

but here's the flaw (well, i guess it depends on how you view things): 

on windows, whether i use alt-tab or i chose it from my bottom bar, when i click that "download" window, windows shows the "download" window. the behavior is constant. on osx, cmd-tab and choosing from your dock behaves differently. thus, it's faster to view a "minimize" window in windows than osx.

on windows, all opened apps are visible on your desktop. on osx, all opened apps might not be readily visible on your desktop. thus the visibility of windows app is higher than osx.
who cares?
i dont know why "i-bunt-u" gets so much hype. :/
i wanted to like it. i must have downloaded a half dozen versions of ubuntu. it has never installed smoothly for me. and i see others say the same thing, so it's not just me! if it isn't some kind of hardware compatibility and driver problems. and i've tried it on a dozen various machines.
i've run the live cd, but even that often craps out on newer machines. often fails on laptop hardware.
give me vector linux distro anyday! that's what i've been using for a year now, and no problems! i thought it was just for old machines, but it runs great on my core duo and recognized all hardware, unlike "i-bunt-u off my machine!"
and even pclinuxos!
this doesn't just apply to programmers. i'm interested in being a writer for a magazine or another publication, but all of the employers want you to have "at least 3 years experience in the _____ industry". employers are just greedy. they don't want to allow you *any* learning curve at all to learn how to do the job. and it's probably hurting them more in the long run. a person who is applying for a job that has *exactly* the skills you *think* they need (eg, a writer who has been in the insurance industry for 5 years, or a programmer who has worked in java for 8 years) is probably not going to be able to do anything else. if the requirements of the job change unexpectedly, what do you do then? oops, i guess you should have hired the enthusiastic, intelligent candidate with little experience instead of the guy who has been doing the same thing for ten years.
if u implement c++ on an fpga, al is wel in la la land.

in any case, u r wrong about "ther's no such thing as a physical 'lambda calculus machine', &amp; ¬ 1 has been actually built in al of th years that computing has been known to man."

then again, logic was nevr ur forté. for that reason, "'[c++] implemented on an fpga' is as insane &amp; ridiculous as 'brainfuck on an fpga'. ther's a reason for that." | even betr, a god, i mean, turing machine. o yeah, &amp;amp; fpgas can't execute anything in parallel. qwe1234 said so it must b true. all bow to the qwe1234 overloard.

good thing u don't understand logic, | u wouldn't make such a fool of yourself.
they're not so lazy they can't put a simple summation symbol.  they are so lazy that they can't put 3 on each and every single line of a 100 line derivation.  this does matter.
i still get insulted when i try to run an old game (that i purchased) on dos 6.2 on a k6-233 processor, and it bombs because of the built-in pentium math flaw.
ha! i noticed that too when i was looking at programming jobs. some of them wanted you to have 5 years of experience with python! didn't python not become a "hot" technology until a few years ago?
 &gt; in this case, by liskov substitution and the covariance of function arguments, i should be able to pass an array&lt;animal&gt; to pop and get a turtle out.

yes, but you didn't say "turtle pop(array&lt;animal&gt;)" -- you said "turtle pop(array&lt;turtle&gt;)".  hence my suspicion that you have a typo, and meant the former while spelling the latter.
 &gt; while john learned **alot** about what language features people wanted

why is it that intelligent people have a problem with this?

alot?  would you write "alittle"?  how about "afew"?
that's more along the lines of what i was expecting.
um, i've easily got eight years of experience programming in python.  for a 16 year old language, that's not unreasonable at all.
comma separated strings? yeah, let's toss some of those in there! and we should duplicate that across several tables! and then update only some of them! we'll *remember* which ones have the most recent information!
 actually yeah, i do tend to agree with you on 10.1

10.2 was great apart from package installation, but with smart it was great

so far 10.3 really does seem to have it all - not found any faults with it yet! 
 i do similar things in the sbcl debugger. this is something i only really started doing in the last month or so---until then, i'd just quit back to the top level whenever the debugger came up and spam format statements everywhere when i couldn't figure out why something was breaking.

yeah, i don't know what the fuck i was thinking.

in any event, using the debugger has made me so much more efficient, i don't quite believe it myself.  
dicks? or just not grade a angus?
i'd have to disagree and say it's one of the worst introductions.

elementary mathematics from an advanced standpoint, by felix klein is my favorite math book, but sadly not suitable for beginners.
i'm far more afraid of seeing the results.
i know the language has been around for a while, but it didn't become popular enough for there to be books on it in every major bookstore or for employers to require it until recently.
i wonder if anyone's written software to scan the resumes for buzzwords and automatically schedule interviews...
wow that's really interesting.

this kinda throws a wrench in my plans though, i've been developing this theory that math should be taught as programming from a young age... i wonder if math suffers from the same affliction as programming?
what?  natural language vs. computer language?  what the hell does that have to do with anything?

have you seen how **poorly* most people write in their native tongue?  it's absolutely no mystery to me at all why most people find programming hard and 20% find it impossible.  just look at the writing you see on the internet!
there is an old story about how to test documentation:

dec was testing their instructions for setting up a new vax computer with vms (1980's timeshare mid-range system). they got a college student that was a music major, set her down with the docs, hardware, and installation tapes. she was able to build the system, and her feedback pointed out where information was missing that wasn't obvious to her. 
&gt;haskell has typeclasses, java doesn't have anything like that.

the equivalent feature of java's object system to type classes is dynamic dispatch.
i can say the most challenging part is holding all the pieces of each system in my head while keeping their relationships to each other, then updating as i update the code. if the pieces are jumbled, the code will be jumbled.


i'm a little confused by what you mean by "reading math as you read english".  if you mean being able see, for example, ∈, and think "member of", then i think the answer is...do more math.  like anything else, the lingo becomes natural with use.  

a lot of it's also pretty contextual, so the idea of being able to learn how to "read math" without understanding it is not terribly meaningful.  for instance, in the finance theory book i'm reading right now, **h** is usually a hessian matrix.  **h** in a mechanics book may be the hamiltonian operator.  it's not confusing, because (at least so far in the book), we don't try to apply the hamiltonian operator to utility functions. :)  
keep reading...
the problem really is that you want osx to work exactly like windows, and if you define "intuitiveness" as being as similar as possible to the behaviour of windows then all you're doing is begging the question.

&gt;when i click that "download" window, windows shows the "download" window.

yes, when you click the icon corresponding to that window. similarly if you minimise "downloads" on osx you can click its minimised logo to restore it. if you click the button of the main firefox window on windows the downloads window does not raise also. 

&gt; the behavior is constant. on osx, cmd-tab and choosing from your dock behaves differently.

in what way?

&gt; on osx, all opened apps might not be readily visible on your desktop.

absolutely all open apps are visible in the dock, i suspect you mean all *windows*, that's not a problem — it's simply how osx works. if you want to see all unminimised windows use exposé, if you want a minimised window then check the dock for it.

the thing is i view alt-tab or cmd-tab as a way of switching between apps. i expect the app to be in the same state as when i left it, that seems intuitive to me. when i switch desks in work i expect the desk to be how i left it, i don't expect it to 'conveniently' pull all the documents i put in a drawer out and spread them over the desk every time. osx is consistent, windows is not.
&gt; i haven't written java code in a while, so i don't know what the state of autoboxing is in java.

1.5 adds some autoboxing:

http://java.sun.com/j2se/1.5.0/docs/guide/language/autoboxing.html 

you can do this:

    return new integer(length0).compareto(length1);

but you still can't do things like:

    return length0.compareto(length1);

or:

    return 5.compareto(3);

the former gets you an "int cannot be dereferenced" compile error, the latter a "not a statement" compile error.
no, that's not really equivalent.

java's dynamic dispatch has the methods carried along with the data. typeclasses have the methods carried separately from the data they act on.

as a result of this, the operation which is performed can depend on the type of the desired result, not just the inputs to the operation.

that's just the first major difference. if you start talking about constructor classes or multiparameter typeclasses, then you can get even farther away from anything which looks like java.

for example, with multiparameter classes, the operations chosen can vary based on any number of types involved in the operation. 
couldn't agree more. can't understand how ub manages to get such a following. i'd imagine most of its users are trying linux for the first time
 exactly.  it's often the power users who want the extra features and they have no problem downloading add-ons, as long as the software makes it easy enough (firefox, amarok). 
absolutely. your grammar has to be defined "bottom up", and it's definitely not a speed demon.

so damn fun to use though.
i bunt u?

it's pronounce you boon to. 
whoa, i just read up on this "person".  that's neat stuff, especially the terminology they introduced.
that's not a nail - it's a screw.

seriously, though, this article falls for creating and finding communities of practice with adept practitioners, mentors and difficult questions. otherwise we just end up with an echo chamber fro university.

i suppose the barcamsp are a good example of these ad-hoc practice grounds. any other ideas? i am purposefully eschewing corporate mandated training here.
i usually, though not always, find things like printf to be a poor-mans excuse for a debugger.

even without edit-and-continue, a debugger lets you see everything that is going on, not just the few variables you thought were important.
(totally unrelated, but am i the only one who's seeing odd rendering glitches on reddit today?  for example, the "reply" button doesn't always show up, and the above poster's name was replaced with a link to the original article (!).  thought it was a ie bug when i noticed it earlier today, but now i'm getting it in firefox too, on a different machine.)
&gt; the rails code can be so convoluded with metaprogramming techniques that you can not decypher what is going on without tracing execution.

my thoughts exactly.

  yeah, the bottom-up thing was what bugged me most, having worked with yacc before, which is very friendly to the top-down idiom.  that's why i made my [pyparsing helper](http://aspn.activestate.com/aspn/cookbook/python/recipe/528934).  with it, you can write stuff like this:

    a = b + c
    b = literal('b')
    c = literal('c')
    dlist = d | (d + dlist)  
    d = literal('d')

i.e., top-down, with recursive rules, and *no forward(), and no &lt;&lt;*.  much prettier. 
 i remember hanging out in the workstation room in graduate school, seeing fellow compsci master's students struggling for hours debugging something like a doubly-linked list implemented in c.  they'd be printf debugging or using what i call "zen master contemplates code," which mostly involves staring at your code and talking yourself into hypotheses that have less and less to do with reality as the minutes drag into hours.  i'd ask them if i could show them how to use the gnu debugger (gdb), and they'd shoo me away, saying they didn't have time for it.  eventually, at 3:00 am or so, they'd be desperate enough to let me fire up gdb on their project.  usually, we'd find the bug they'd been pulling their hair out over for hours in about 30 seconds to two minutes.  yes, that's not an exaggeration.  30 seconds to two minutes usually.  

these are the same sort of students who, later when i was a teaching assistant for a unix system programming course where all the students implemented their own shell, complained that implementing the features for their shell in the 2nd half of the course broke the features they implemented in the 1st half.  they argued that i should give them credit for those features anyways.  well, it just so happened, that i wrote some tcl/expect scripts for them to test their features.  i told them that they should use it to regression test.  in fact, i told them that their shells would be *graded using the script.*  how many of them regression tested?  about 3 out of the entire class.  one of those 3 told me i was the best ta they'd ever had.  the rest of them *hated* me!  go figure.   
re: database template/script code:

at my first job, we had a database driven template system.  you had to "check out" and "in" the template from the template editor, so it was a type of rudimentary version control...
  i'm tired of people trying to be politically correct and spare every idiot's feelings.  sometimes it's best to just call a spade a spade, like with that [miss teen south carolina](http://www.youtube.com/watch?v=lj3inxz8dww) and [her opportunity to save face](http://www.youtube.com/watch?v=fqknvpn3v-8) where she ended up looking even worse.  she would've been better off admitting she was uneducated instead of trying to fake like she was in the know.
&gt; why is it that doctors don't ask why many people can't learn to do brain surgery?

i don't think there's a reason to believe they can't.

anyone who can find a computer can probably get access to a programming environment.  for the sake of simplicity, we'll call those people ``everybody.''

so, in this scenario, everybody can try programming at no cost.  many of them fail at it.  if availability is as infinitely high as the cost of entry id low, the question then is why doesn't this everybody do it?

brain surgery is a different matter.  even if you find a brain to work on, you'll need expensive equipment.  if you mess up, somebody dies (or maybe just loses all cognitive abilities).

the availability is very low (brains to hack), and the cost is very high (equipment and life).

i *might* be a good brain surgeon, but i'll probably never find out.
&gt; i'm pretty sure, in certain situations (say, any compiled language?) debuggers are your best friend.

i think you need debuggers more in a dynamic language that a static one.

with a static langauge you can generally see everything that is going on. bench-testing becomes trivial.

with a dynamic language where even library load order can drastically change things, even simple things like finidng which version of a function is being called can be hard.

i actually think the disk image is the worst possible format for shipping an application.  you've wrapped the program in another file format that does nothing more than bundle everything together in a fake disk.  that's wasteful.  combine that with the common developer's desire to include another 500k of background artwork and you're on the way to bloat.

then there's the issue of writability.  a lot of people open programs right off the disk image to test them.  that leads to errors in some programs that want to write to themselves or setup some form of automatic launching (which they cannot since the disk will not always be available).  it's a technical hurdle that requires code to solve, which is wasted time.

what i do with notae is very simple: i zip it up in the finder and post the zip file.  when you download it, it unarchives into the program itself and you're done.  everything you need is inside the application and you can install it wherever you want (or leave it in your downloads folder, whatever).

so, i'd say use a simple compression format if you can (zip, or tgz, or whatever the finder can undo) or use an installer package if you must.
why the paranoia?  if svg was the compelling, best solution, people would use it.

its time to give up the paranoid fantasies.  i know that the internets is populated with self-made cs experts, but please stop propagating delusions.
&gt; this theory that math should be taught as programming from a young age

well, the result is that *college-age* people may either have an abstracting facility or not. there's no reason to believe that younger people can't *develop* that ability - it would certainly be fascinating to study.
&gt; eschewing corporate mandated training here.

join an open source project in the language and dive in.
your first error: putting "real software" and ruby in the first sentence.

flame on. :)
the number of upvotes this has is creepily disturbing.
outside of the higher-kinded type classes and multi-parameter type classes, the main reason you use type classes is for the dynamic dispatch. remember, the whole reason type classes were developed was to solve the problem of ad-hoc polymorphism.
universal binaries are a must, but there's a lot of other things in the shipped products that should be tuned for size as well.  drives are getting bigger, yes, but data shouldn't go with it.

it will very soon be like processor speeds.  things get faster, so developers get sloppier and do more things with brute force because they can.  in the end, any gains in technology are lost in normal use.  it's silly.

we need more people paying attention to code style and disk size so that our really powerful computers will actually be really powerful and not be drowning in bad software design.
 you mean re-read since the author later included a paragraph to try and clarify his statement.  but this in turn did not improve anything:

&gt;and by “bigger than” and “smaller than” i explicitly do not mean “is a supertype of” and “is a subtype of”.

that being the case you should always get a type exception when attempting the line the author wrote.  how can you make an array of animals be an array of giraffe if giraffe is not a sub of animal?
to post code, put four spaces at the beginning of each line.
not at all.  you simply make a bad comparison.  it's the choice of the developers to make sloppy code, not the platform.
what a stupid study, especially since ajax appears as a language.

i also don't totally mind those cto surveys on software development magazine or something like that.  if a company (software or it firm) has an agenda to use x programming language over a 5-10 year period (lifecycle) then that is probably what the developers will be using.  for example, i think ms has some developer slides on some of their projects (visual studio for example) over the next decade or so.  eg, microsoft and their reports are an example of a company plan to use x technology.  that survey above is garbage.

list/scheme?

jesus.
  &gt; i'm a salesman and international broker, but there's no way in hell that i'd pass a programming exam.

shouldn't you be hanging out on businesstools.reddit.com or something, then?

&gt; oh wait, no it isn't, society indicates my worth with a big fat paycheck. not my math ability.

i was almost impressed by the amount of money society awards you, but then i got a job offer for infinity+1 dollars per year.  i'll probably take the job even though it's a pay cut, but it's more rewarding work.

besides, i'm sick of having to dock my yacht to fill out and deposit the blank paychecks my employer gives me for my programming skills.  
&gt; with a dynamic language where even library load order can drastically change things

if you work with people who keep writing code that does that, you need a big stick, not a debugger.
did the person who came up with the worst solution get a job working for an airline on their reservation system?
thanks for the tip, bogtha.
voip communications made easy - ring anyway with the fun and ease of using a normal phone
they don't seem that bad to me. temporarily marking seats is how ticketmaster does it.

if there are only two sellers, it is easy for them to listen for each other offering the same seat.

the idea of splitting up the steps is a viable one as well.

all in all, i can see situations where any of these methods would work. though obviously none of them would work in every scenario.
and the other 10% is testing.
0.4.0?  if the code is production ready and the api is stable, bump the number to 1.0 already.  it's not like there's a shortage of integers larger than zero.
svg is at the center of adobe's recent work on the mars pdf format (pdf as xml), so i'm not buying this. http://labs.adobe.com/technologies/mars/
the experience of coding in the smalltalk debugger is also a little like sculpting.  you find yourself doing many little tweaks and experiments, instead of one big, heavy brain-squeeze.  your code then slowly converges on the "shape" that you want.  it feels like you're molding something into shape in a sturdy, but responsive medium.  
&gt; the problem is when a customer (booth 1) wants to see what's available.

i have been to many shows in the last couple of years, and none of them work that way. each salesman offers two or three choices fopr a given price or one choice in each of several prices.

many of them didn't offer any choices at all. if all tickets are the same price, they just grab the best open seat.

don't forget, too many choices will cause a consumer to walk away without deciding on anything.
i get the feeling that [this](http://www.redcanary.ca/files/redcanary/top-programming/top-10-2013.jpg) is what our game consoles will look like in 2013...
 from reading the article, i think the author would agree with you.  maybe the headline should have been: "microsoft and adobe killing svg?  no"

also, it seems to me that svg is more alive than ever.  firefox, safari, and the flash media player all support it, so i don't even see this as an issue.

edit: infinite's [beloved inkscape](http://www.inkscape.org/) too... 
he cites some good examples i think in paint shop pro bloating into a vector drawing package, acrobat reader forgetting that its primary function is to display a pdf and shut the fuck and media player deciding to play bad cop.

i think those three alone merit his argument, and all three were efficient and effective for a very long time.

the reddit comments section is a good example of having the courage to stay true to purpose. there's no tag-lines, emoticons, avatars, bb code and all the attendant fluff that results in unreadable message boards. i'd like to be in on the meetings when some suit from conde naste's marketing department asks why reddit can't have a *cool winking smiley* on reddit like he saw last night.
  it would be fantastic if canonical start working with the openmoko project - a true 'free' phone: hardware, software and firmware. how cool would that be? 

if openmoko can get their device accepted by the networks, and when you compare the openness to apple, it'll be bye-bye iphone, at least for more technical users. 
same here.  when replying to something earlier i had to go to the comment's permalink, then reply from there.
&gt; with a dynamic language where even library load order can drastically change things, even simple things like finidng which version of a function is being called can be hard.  

i find this isn't really a problem per se.  in fact, the proper way is to think of all the different versions of a function holistically, unless you're certain only a specific one applies.  
that's what she said!
ideally yes, but when your working on a five-year-old code base and the original developers have long since been bludgened to death, the stick won't help any more.
 yeah, but the types of dynamic dispatch available are fundamentally different.

also, it doesn't just give simple dynamic dispatch, but functions which use typeclass polymorphic functions can themselves become typeclass polymorphic.

it's not really plain ad-hoc polymorphism. a better name for it is bounded parametric polymorphism, since it has more in common with that than the usual sort of ad-hoc polymorphism where the implementation to be used is determined only at the call site.
sure, but as cgibbard pointed out the dynamic dispatch is more flexible when the methods are not part of the objects but travel separately.  (existentials allow you to package them together if you want.)

okay, i need to know: what does one replace nero burning rom with? that can master and burn bootable data dvds, i mean.
if svg+javascript weren't slow as balls it might find more purchase as a dynamic rendering/animation language.

not like flash _isn't_ slow as balls. but it is considerably faster; look at that lively kernel which, while cool in concept, is patently unfit for serious use. plus flash has native support for things like movies and sound. :)
ddd saved my sanity when i was first learning linked lists in c...
i have worked on systems where each customer could have their own version of a function loaded at runtime from a database or file.

this was with a 'mostly static' langauge, vbscript. (eval support, but no monkey-patching.) i can't imagine working on something where literally anything can be changed *without a debugger*.

edit: clarified my meaning in last sentence.
 
it's comments like this that keep me (and probably most people) a million miles away from linux.

x settings?
gui front-end?

fuck that. i've has a dell laptop with windows for years and i only just figured out the "print screen" button captures a picture of the screen. not only that but i think it's awesome.
i am fluent in lobster. i have recently obtained my lemc. (lobster eating microsoft cert.) and i am moving up very expensively, i might add to my dblemc. (drawn butter lobster eating microsoft cert.)
well, maybe not all of reddit, but redditors who click through to read mac stories. know your audience (subset).

(disclaimer: i do not approve of ⬇ing comments you disagree with; i'm merely recognizing that others do.)
&lt;dances a jig&gt;

finally! :d
off to try to install on my mbp.  wish me luck!
this reddit "post" brought "to you" by the "editors" at "zagat".
eh, i'm just reading the book. i don't need the hands-on training, the experience is really the same.
i've been eating lobster for 23 years (am 21)
  apologies, i've been frequenting several different threads recently (e.g. the recent gutsy article on theregister.co.uk) where users of other distros have been bitching about pretty much everything that ubuntu does and doesn't do. i assumed that your comment was another such gripe, but having read it again, you sound like a new user. sorry for being impatient.  
i remember a quote from arnold rimmer, regarding a report that he "constantly fails the engineering exam":


"constantly fails the exam?  i'd hardly call eleven times 'constantly.' i mean, if you eat roast beef eleven times in your life, one would hardly say that person constantly eats roast beef.  no, it would be a rare, nay, freak occurrence."
having perl 6 emit common lisp is a brilliant way to make perl 6 extensible.  
it's probably a perl script that reads an xml configuration file that lists all the words to look for and connects to an sql database to schedule the interview. oh, and they have an [air](http://labs.adobe.com/technologies/air/) application in the works too!
[here](http://www.whyprogramsfail.com/) is a book recommendation for those like me who believe they can't live without a debugger. 
you need to go to the immersion classes... six hours a day for a week. but boy, when you are done you can do a lobster upgrade in your sleep, man...

* the lobsters hate these immersion classes, by the way...
sorry to "um" you again, but i learned the language from a book i bought at a major bookstore in 1999, "python essential reference" by david beazley.  there were already several python books available in places like borders and barnes&amp;noble before the dotcom crash.
&gt;each salesman offers two or three choices...

then you have the school teacher with 30 kids that want to sit together in a block.
and get horribly flamed for trying to check-in code that sucks.

open source projects are not the place for novices, though mid-level developers can use them to grow.
automattic? gravatar?

why am i having flashbacks to ten years ago and dot-com hype?
&gt; it's comments like this that keep me (and probably most people) a million miles away from linux.

fellow linux users, is this even a bad thing?
try alt+print_screen to totally blow your mind.
&gt;you'll need to wait (up to several minutes) while cusp starts and connects to lisp process.

uh, what?
the author is right but the point of his article, i think, is that people claim themselves masters when they really know very little.  

you've got to start somewhere, and modern languages are huge compared to their yesteryear relatives.   so you have to take a well-known, well-defined problem and start there and then grow your program and your understanding.   it's possibly the safest and easiest path to follow.   just don't ever forget that you know a lot less than you think you do.   that's the message.
this is the sign of the end of the world.
mathematics' great advancement is that it *liberates* us from language. to ask how one can make mathematics more like a language completely misses the point.

mathematics is a tool for manipulating symbols to produce logical conclusions, completely separated from your ability to internalize the meanings of individual steps used in the operations. if you trust the operations (and you can because you've proven them), then you can follow the chain of conclusions on faith, without having to "talk them out". it gets us away from the tricky business of having to trust our language processing, and lets us incrementally solve problems that are much bigger than will fit in our heads.

try reading your way through newton's principia and you'll come to appreciate how powerful it is not having to read your equations. deprived of our modern notation, newton spelled out his theorems in long, labored english, which is incredibly burdensome to follow. please don't send us back there.

&gt;also, it doesn't just give simple dynamic dispatch, but functions which use typeclass polymorphic functions can themselves become typeclass polymorphic.

this is also possible using dynamic dispatch and interfaces.

to put this to an end i will say this: i am guilty of overstating my case, and i think you're guilty of being disingenuous.

obviously dynamic dispatch doesn't do everything that type classes do. but it's also not correct to say that java has nothing comparable to type classes. 
sorry, i haven't seen that movie.  is she brought to her knees as well?
ubuntu is for africans
 yes, compiz fusion is very much present in kubuntu - i very clearly remember reading about this, you can google around a bit. i myself prefer kde to gnome (though i must admit i like awn, which works best with gnome), possibly because i've been brainwashed by linus. however, i'm expecting both ubuntu and kubuntu (edubuntu sucks, and i wouldn't use xfce) in the mail.

i switched from fc6 to f7 a week ago (i must be really fucked up), hoping that i would get fusion running, but it didn't happen; probably due to the overal suckiness of fglrx. thankfully beryl worked!     
i've returned to a dodgy nouse more than once.
they're could of bin alot mor rong then it
ah, i read your blog post. i use gnome. on standard ubuntu. 

did you try making a new user account just to test. i had all sort of issues until i did this. it cleared up 90% of them.
"list/scheme"
"objective c + ("

...what?

also, no ml at all?  how silly.
lisp is a slow, dead language that is difficult to read. and it's for gays. because gays lisp.
thanks for that, best laugh the whole week.
you're right i shouldn't have bothered trying to point out that there might be a baby in that thar bathwater.
no, a second system is the second system the architect designs.   it need not have anything to do with the first.
no, ironically enough, it is not: fedora is.
i didn't say type classes are plain ad-hoc polymorphsim. i said that they were developed to solve to the problem of ad-hoc polymorphism in a statically typed language.
the point of writing it wasn't to be insightful. it was to get people off their asses and actually do the things we've all agreed are good ideas. unit tests are the classic example. everyone agrees they're a good idea but hardly anyone actually writes them.
what's funny about it? if you can have "device driver code" (the code for a device driver), why not "application code"?
whoa!
tell me why this is better than vista and i'll try it.

odds are you won't convince me.  
* buzzword based software
* doesn't work on my browser
* need to login on that live stuff
* scary certificate popping up
* needs silverlight which nobody has
* "most popular" mashups rated by just one user

sounds promising..  
i did the same when i was in highschool. it was pretty funny watching the jocks go all out for the first test and then at the end of the year they all got c's or something on the second test because they hadn't improved.
i think in order to truly understand a language, you should write a program for every new thing you learn. this may seem tedious, but it works.
allow me to regain the moral high ground:

nerrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrds
i read that as noose at first, good old optimism
scriptaculous is one of many great new javascript libraries created to answer the call for well written 'web 2.0' javascript libraries.
thanks for the tip. i shall download and try it.
python didn't become popular for sexy web 2.0 websites until a couple of years ago, but it was definitely popular for other purposes before then.

i was using python on the job in 2001 mostly as an alternative to perl in scripting tedious tasks.
&gt; (and by the way: why is my chair missing every time i'm away for more than 3 days??????)

a little reference booklet i made for myself went missing during my recent vacation. i'm pretty annoyed
there's actually no video embedded in emacs. in the screenshot mplayer's window is above emacs. we put a [short screencast](http://gneve-webma-dev.blogspot.com/2007/10/gneve-gnu-emacs-video-editor-mode-in.html) on youtube demostrating how gneve may work.
thank god.
now you mention it; the wire was a bit twisted.
 (ok, you were probably only being facetious, but...)

if he can't use it, then (most) children won't be able to use it. if children can't use linux, then it's not going to be the world's all-conquering, default operating system.

techno-elitism and techno-snobbery is partly to blame for free software never seemingly being ready for the big time. manual configuration needs to be coated with a whole bunch of slick gui sugar before linux has a cat's chance in hell of making the big time. we all know this to be the case, so we need to drop the rhetoric and make our minds up. is linux for the bearded minority or is it something much bigger and more important? 

if all you're concerned about is a command line, that needn't go away. if you don't want x window, it's always going to be possible to run only a shell (not least because of linux's embedded uses). why do people find non-technical users so threatening? 
when i say "by the covariance of function arguments", i mean that for all functions f that take an argument b and return an a:

a f(b)

and for all types c &lt;: b, f(c) is well-typed.

in many languages, this is what subtyping means.
smashing magazine has amazing articles. afaik it's the best site out there to keep up with the state of web design.
it's stable, secure, highly customizable, and with wine is probably capable of running hl2 faster than on that bloated, user-hostile microsoft beta you seem keen on.

also: "odds are you won't convince me" makes you look like a twat. either don't say it or don't ask.
i grew up in a small rural town without many mathematicians in it, but i still managed to become fluent in mathematics. i attribute these books to teaching me math: "mathematics: a discrete introduction" by ed scheinerman and "calculus" by michael spivak.
&gt; who was it

brian kernighan, c deity
yes, it is a bad thing. he'll be a pain to support, but i'll take that over the levels of spam and other disruption caused when people like that run windows.
what makes you think an adult's incapacity for change has anything to do with a child's ability to learn, or to figure stuff out? 

"adult x can't use linux, so neither could a child."

"adult x can't use the metric system, so neither could a child."

see what's wrong with that?

edit: okay, i've re-read this comment and decided it was overly snarky. let me just clarify that i wasn't attacking whatdoesoutsidemean; i'm merely making the observation that adults are not good at change and that for most adults, "computer = windows". linux, even unpolished linux with these annoying config file edits and so on, isn't inherently more difficult to use than windows is; a large part of why it seems so is simply due to the fact that people know windows, and can't/won't/aren't interested in going through the learning curve again. children don't have these inertias, however, and wouldn't be so severly affected even if they did; it's not so long ago that computers were even less shiny than unpolished linux, and children got on just fine with those.
it didn't freak me out. i just think it will be a disaster for the osi and as i said previously it will be a win for the fsf.

as a fan of free software i think osi certification for ms licenses is a big win for the gpl whose brand an license will not be diluted.

i have no animosity towards the osi and i do think it's sad that they inflicted this on themselves but they have nobody to blame except themselves.

in a nutshell the osi certification of ms licenses is ..

* bad for the osi
* good for the fsf
* good for ms
* bad for the ms shills and fanbois who can no longer rail against open sores and communists.


&gt; except for the "division of labor" idea, i have seen every single one of those solutions tried by professional programmers.

really?


    ls | grep hello
   i spent a lot of time looking at free and preferably open source charts packages (mostly ones that can be used from python, but also pretty much all of the flash landscape, because i was hoping to find something as snazzy as the google finance thing). there are lots of packages, but many of them are very limited to only simple line/bar charts, and a lot of them don't give very nice output. no anti-aliasing, no nice fonts, no pretty default colors. seems like in many cases it's a lot of work to get something actually good-looking (and performant for larger datasets -- i felt this ruled out the js-based toolkits).

i looked at the plotrs and the plotkits and the amcharts and the fusioncharts software and several others. i looked at cairo (decided it probably wouldn't be that easy to get a robust version of cairo and pycairo running on some of the windows boxes we have) and antigrain (would need aggdraw to use it from python, couldn't get that to work on the linux box). i finally wrote four or five separate graphics generating scripts:

* one using [matplotlib](http://matplotlib.sourceforge.net/); it was alright, but i didn't like the api that much. does have a lot of backends, though (a pdf one, an agg one, etc). it seems organized very differently from all the other packages i got to use.
* one using [pil](http://www.pythonware.com/products/pil/). i tried to use the aggdraw package, but couldn't get it working. pil worked alright for producing png images, but i decided i wanted vector graphics in the end, because they make zooming nicer.
* one using pure svg. this was pretty nice; generating useful svg is not that hard. only problem is, when you feed it a lot of elements, it gets pretty darn slow. firefox couldn't really cope with some of my graphics . (i tried opera as well as i'd heard its svg performance was better, but that didn't help much.) i even tried to get a svg-to-pdf conversion thing going using some glue code someone had released that used librsvg and cairo, but that ran out of memory.
* one of the nicer ones i tried was [pyx](http://pyx.sourceforge.net/). it renders to pdf or postscript and has quite a lot of features. only problem with it is that it requires tex or latex to render text, which i consider a hefty dependency and which hurt the windows compatibility story (although i'm told it is possible to get it to work).

so in the end i ended up a little disappointed by what the open source community had to offer by way of cross-platform vector-rendering charts packages and dove into the new mars thing, which is like pdf but defined in svg and some adobe-defined xml (all zipped-up together like mozilla extensions or odf files). couldn't get that entirely working (though i'm still conversing with mars engineers on their forum) and am now plowing my way through the pdf spec (which is suprisingly readable, with lots of examples, i feel pretty good about it despite the nih). 
achewood is actually far funnier than dilbert.
since when did python have a library that could   parse on a ebnf? link please?
people like that?
oh you bitch!
[the art of assembly language](http://books.google.com/books?id=094tyob7ipqc&amp;dq=art+of+assembly+language&amp;pg=pp1&amp;ots=e586gqtdh5&amp;sig=g0bcaz_tthi3nmuerdsnotbtpvc&amp;prev=http://www.google.com/search%3fq%3dart%2bof%2bassembly%2blanguage%26ie%3dutf-8%26oe%3dutf-8%26aq%3dt%26rls%3dorg.mozilla:en-us:official%26client%3dfirefox-a&amp;sa=x&amp;oi=print&amp;ct=title&amp;cad=one-book-with-thumbnail)
&gt;eh? who said that programming.reddit.com is for open source only?

nobody. 

&gt;what about all posts about the iphone, for example? 

it all depends doesn't it. 

if somebody at apple writes a gushing article about iphone and publishes it at blogs.apple.com and puts the link to reddit then it's spam.

if a user or a third party observer writes an objective review or analysis of it and posts it from a non apple web site then it's not spam.

we all recognize spam when we see it. it doesn't make a difference if it's from ms or apple does it? why do you want to give ms permission to spam reddit? what is so special about them?

&gt;(when did you last contribute to open source, by the way? care to post some pointers to some useful stuff you've done?)

i think a more relevant question would be "when did you last spam reddit with a product you made". 

the answer to that is never.


giles comments on his own blog:

&gt; sorry, i know i'm a hypocrite with all the swearing i do, but i just don't tolerate it.

???  that reads like "this sentence is false"
yeah, i never fully understood why people use printf statements when they have access to a debugger. there are a some cases where a debugger is not useful, but when it is, why not use it?

in addition using a debugger allows you to evaluate expressions and inject code at runtime. that's pretty useful if you have some complex data structure you need to access while debugging.
progamming is said to be difficult--and it is, and yet programmers are paid so poorly. whassup wit dat? 


most people are not prepared to accept the fact that a person's current worth to society (which is not the same as their "value as a human being") is measured directly by the size of their paycheck.  those who do realize it early tend to do better in their careers.
i'm actually more than willing to change but it has to be made seamless for people like me who are not very technically minded and if not it has to be really worth my while to make the switch. if it's not, then why bother?
manual configuration sucks, plain and simple.
i've been running gutsy for a while and wow linux and open source in general has come a long way since when i started using it about 5 years ago (oddly enough, when my 12th grade english teacher gave me an openoffice.org 1.0 cd).

i have virtually no complaints, and i'm surpised by how well compiz fusion just works with everything. the only thing bothering now is it just seems to randomly freeze for no good reason. looking around i found it might have something to do with the nvidia-glx-new drivers (it started happening after i installed those, so i guess that's it), but trying to downgrade back to the nvidia-glx drivers seems to be a pain. 
 &gt; see what's wrong with that?

yeah, the metric system vs. imperial is largely a matter of convention. linux vs. windows is often a matter of degree/complexity. quite distinct.

software that isn't a no-brainer for the average user isn't going to hit the big time, which is largely why the original subject of this thread is so popular. 
i was *out* of the dungeon, but shortly after getting out, the server crashed and i spent some time trying to get back in.

and that's what you have to do with the md! 
 i just make shit up nowadays.  they make shit up, so do i.  i have 20 years experience with ajax and web 2.0!
the fact that i have a cs degree should mean that i am a professional, competent to pick up skills necessary to ply my trade.  since programmers have opted out of professional organization/unionization, they get treated like monkeys.  places want to hire somebody with an exact skill set rather than wait a couple of weeks for them to research the new technology.  do you expect your doctor to have command of every esoteric disease at their fingertips?  your lawyer?  no, these professionals do research.  so do we.
&gt;if you have no interest in developing for .net anyway, surely all this is irrelevant to you.



the only relevance to me is to keep reddit spam free.

there are a lot of proprietary languages out there and we don't see the makers of those languages post gushing articles about their languages on reddit.  some of those languages and platforms are very nice too.

the odd thing is that reddit agrees with me in most cases but makes an exception for microsoft corporation. apparently only microsoft corporation is allowed to spam reddit.

i have posted articles about rebol and runtime revolution for example and they were promptly modded down. both of those languages are very useful and interesting on their own merits but posting an article about them at their web sites is spam and redditors acted swiftly to bury them.

we all need to be diligent about keeping reddit spam free.

&gt;iirc, you have criticized c# on many occasions for technical reasons having nothing to do with the evilness of microsoft.

my only criticism about c# is that it has gone from a relatively clean copy of java to being a garbage dump of "paradigms"


&gt;f# may still have the stain of microsoft upon it, but for those interested in writing functional code, it provides technical advantages over using c# or vb.net.

i really don't care if it washes my car and cleans my pool. my only interest is in keeping reddit spam free.

well i don't suggest you start checking in code right away. start by using the project, reading its source code, contributing good bug reports, watching the patch history. then by all means try checking in a bug fix. if you get horribly flamed then you picked a project run by assholes.
&gt;honestly though, i don't see what your point is. many of us, myself included, were hoping that it would become an official product.

i have a keen interest in keeping reddit spam free.
eh? what has the manifestness of the types got to do with it? you would get the same problem if c# had type inference.
i did not know amazon provided blogs. very well-written article!
so i will get two nicks., one for getting horrible code and getting flamed to death, the other to implement the elegant suggestions from the community.

i only have to learn to distinguish between spaghetti and beautiful code.
 you can just do apt-get install xserver-xgl, and it works without any messing around in gutsy (they've made some proper install scripts this time). of course, you'll have to use xgl, but it doesn't matter much (or does it? if anyone care to elaborate, i'd like to know).
*what a stupid study, especially since ajax appears as a language.*

may i remind you that the study was made in 2013. back in 2007 ajax wasn't a language of course ;)
[henry baker](http://home.pipeline.com/~hbaker1/) has a "medium-level" approach to assembler, called
[comfy](http://home.pipeline.com/~hbaker1/sigplannotices/comfy.txt)
implemented for the [6502 in emacs lisp](http://home.pipeline.com/~hbaker1/sigplannotices/cfycmp1.lsp)

an implementation of his ideas for intel x86 apparently exists, and is called [sassy](http://www.call-with-current-continuation.org/eggs/sassy.html)
1. that's valid c++
2. even if it weren't, the code could scroll off of the screen in any language, so the story is not diminished by it
well, foo. my math teacher, the only person i discussed this with, was more interested in talking about plato then programming, so i didn't really have access to the necessary information at the time.
yes i wonder at this point if it can ever separate itself from the association.
 &gt; they are crappy developers. i am one of them. i try not to be one of them. it’s not easy.

seems like he does compromise his principles, all the time.
no.

people who base their technological decisions on what random people say on reddit are sure to be a ton of pain. 
i wish fluxbuntu got more love, or rather, just support in general.
most adults can't set the time on their vcr/dvd player. most children can.
no people will use what ships with ie since that has %95 of the market share.

svg could have some hack to make images appear in 3d without the aid of glasses or a special monitor and people still wouldn't use it. they would wait 4 years for ms to reimplement it in a patented way and claim it as their own.

you think adobe flash will survive beyond silverlight being included in windows? it will go the way realplayer did when wmp was introduced. granted there are still a few sites that use real but its generally in tandem with wmp as its main target.
and the final 10% is also testing.
interesting to note that hoary old make is still one of the fastest build systems there is.
pshaw, i just type up a "hello world" program and a quicksort.  language mastered!
this comic really parodies what happens in corporate work environments today!
 i mentioned pythons *tokenizer*. it's available in lib/tokenizer.py

an ebnf based parser generator is not in the stdlib. 

one ebnf parser is available with [this](http://www.fiber-space.de/easyextend/doc/ee.html) package. the parser being used is a python transcription of cpythons parser. it can obviously parse python and accepts all ll(1) grammars. it is highly optimized and definitely not a toy parser generator.

 
smart
i am afraid that a little more then a year ago gnome became the de-facto desktop of linux and is now the default desktop on virtually every distribution (and solaris).

don't know how or why but the community just seemed to adopt it all of a sudden.

of course there is nothing preventing you from installing kubuntu or installing kde after afterwards.
if upgrading from within 7.04 to 7.10 via broadband (cable, ny usa region)...
how long would it possibly take ?
lol
even better.
i think this is the right model for software, and sounds a lot like the unix philosophy: small, single purpose tools that can be pieced together by the user to do more than just the sum of their parts. but i fear that once outside of the opensource realm, it gets difficult to differentiate products using that model. how do you stand out? how do you make users pay more (or keep paying) when it would appear they're getting less, no matter how much of a "good thing(tm)" that may be?

perhaps there's a market waiting to happen in really thin freelance apps. sure, there's code bounty websites around, but i don't think the mentality is there on the user's part, or their population is sufficient to achieve critical mass yet.
i actually just checked to see if that was there
no joke, i just installed 7.04 this morning.

this is just my luck.
with modern ubuntu distributions like ubuntu it's mostly a matter of convention. 
umm.... it's free?
i think you're dramatically underestimating the enthusiastic child's capacity for learning. your other point is valid though; children simply won't be exposed to linux of any variety, typically, unless their parents are already comfortable with it to use it day-to-day about the house.
yes, but there's a problem.  i downloaded the alpha version and ran it against the stupidfilter.org website.  the result came back: "stupid.  reason: impractical, won't work."

k3b for linux (though not sure if it can create bootable disks by itself), http://cdburnerxp.se/ for windows.


&gt;(and by the way: why is my chair missing every time i'm away for more than 3 days??????)

i once came back from a day off and found my keyboard missing.  it took three days for the helpdesk to bring me a new one.  when the two guys delivered the replacement, it was so dirty that 10 minutes of typing left my fingertips black with dirt.  i had to individually clean each key. 
new englander here, listen up:

i've been eating lobster my whole life, bits of it in a bisque, or lobster rolls, or the like. now i'd had a few steamed lobsters, ie, whole lobsters, but i never really knew how to eat them properly. i would eat the claws, and the tail, and not bother with the legs. then i learned how to eat the legs. then, the body, then the roe, then the tomalley. now, when i eat a lobster, i leave nothing edible on the plate. it takes quite a while, btw.

don't hire based on years of experience, hire the guy who leaves nothing on the plate.

[will teach lobster-eating for lobster]
well, there's xubuntu, but i'm with you. i prefer fluxbox to xfce.
by just asserting that you are correct? of course, the burden of proof is on me/us, right? i agree.

i will start by refuting with: there exists an element in the set of machines, such that that element is also in the subset denoted, 'lambda calculus machines'. i can point to such an element from our universe.

before i do, i want your reassurance that if i do (since you claim i cannot, right?), you will admit that you are wrong, publicly, like an honest intellectual *ahem*. then you might even consider *learning* from such an error, then we can move on. of course, if *i* make a mistake, i will freely admit same.

sound fair?
i like how you rail against political correctness and then judge another human being on 30 seconds of (non direct) exposure to them.
insufficiently clever algorithms, i fear.
despite how dilbert is held up as some kind of secret log of the pain of working programmers, i've noticed that the bosses i've had who liked dilbert the best have also been the ones who are most like dilbert characters.
details: instructions for linux (debian), apache, mysql, php, ruby on rails, mongrel, phpmyadmin, gd and more! :)
what did he do before reddit?
what i don't understand is, if 80% (or whatever the number is) of the population do not understand programming, why do many programmers make interfaces for non-programmers that have features that only programmers can understand?
that's a good question. what the hell didn't any of us do before reddit??
holy shit.
changing things dynamically is like using macros in c.  it's a power tool that can hurt you just as easily as it does something cool.  like any power tool, you should know your tool well, and be well versed in its proper use.  

in a competent shop, it's something that is used to good effect by someone who knows what they are doing.  if someone starts using it willy-nilly, then they should be smacked.  do goofy hacks on your own time, in your own code, not in the production code!

(in the same way, you can define your own language using c macros that in no way resembles c.  not something you should do willy-nilly.)
  the first thing you need to know is that you don't read math the way you read english.  

when you read a novel, you sort of relax and let the story flow into your brain.

when you read a math text or a math paper, the process is very different.  you read a sentence.  then you think for a long time.  then you read another sentence.

when a sentence says something like "clearly, *a*=*b*" or "it is easy to show that *a*=*b*" then you take up your pencil and paper and work for thirty minutes to show that *a*=*b*.  you do not just take the author's word for it that *a*=*b*, because if you do, then later on, when you see the explanantion of why *aaaa*=*bbbb* you will not understand it, not having seen the simpler version yet.


hope this helps.
  
no, it was a car rental agency.
it must be a nice universe you live in. sometime i'd like to visit.
&gt;this is what the curry-howard correspondence is, i think.

no, not really.
1. no it isn't. in c++, the public keyword is followed by a colon.
2. i was making a joke.
not quite, the new intel driver is buggy as hell, crashes suspend to ram, and screws up with displayconfig-gtk. i had to revert back to 915resolution and the i810 driver to get everything working again on my 700m
way to not read the post you're replying to.
&gt; no it isn't. in c++, the public keyword is followed by a colon

ah, i stand corrected

&gt; i was making a joke

i confused "making a joke" for "being an asshole" (not sarcasm; i really did). i apologise.
you'll get no arguments from me. i can barely imagine doing my job without at least the limited late binding i currently use.
my first idea was to set up a booking server that, when requested, marks the next available seat as taken and sends the next available seat to the seller. when a purchase is made, the seller requests a seat number and then gives it to the buyer. when the seats run out, the booking server should return some sort of error indicator.

i suppose that might not be the most efficient method, though.
not to mention free of any mention of programming langauges, techniques, or tools.
you're a fool, and you apparently only talk to fools that think they know ruby.

1. ruby doesn't need a "good native compiler" because it's a freaking interpreted language.  show me a native python compiler then we'll talk (don't point to bytecode because ruby is getting that).

2. stupid statement, and no one of any real substance would say that.

3. i don't even know where that statement even comes from.  ruby has a gc, as do all the alternative implementations.

4. ruby has consistent naming conventions, some of them forced.  classes have to be namedlikethis, 99% of the time methods are named_like_this, and so on.

5. *sigh*

and bdd is behavior driven development, a concept that is in play in other arenas outside of ruby also.  bdd isn't just a "dsl for writing unit tests" (though i suppose you could just boil it down to that).  it's an entirely new way of thinking about testing, which makes it especially easy to get newcomers into it.  for example, why do i assert things about code i haven't written yet?  it's odd.  but with bdd, i get the same effect, except that i'm specifying behavior: "this object should, when implemented, do this when i execute this code."  it's much more natural.

please try not to make your ignorance so apparent the next time you want to look so darned smart!
ruby people say *real* these days, not agile.  you read *getting real*, right? 

neither did i. 
all since i read the first post about experience, i got a feeling that there is actually another dimension to it. too much experience can be a warning sign also. when a programmer comes up and says that he has 15 years of c++ experience my first instinct is to quiz him/her about stl, raii and exceptions. usually i find out that the person in question has a very outdated style and is going to have hard time working on any code i write. 
subscribe to feeds (rss and atom) from your favorite web sites and enjoy the most powerful and elegant web-based feed reading experience ever created. feedlounge supports importing (and exporting)... 
how do these things require infinite time or money?  a lot of the time, problems can be avoided by just spending a few extra seconds to go "hey, wait, maybe this should go in a separate table" or "this is confusing- maybe i should toss in a comment."

just by making a conscious effort to try to improve your code, you improve your code- but there are so many pitfalls that you just can't do everything right all the time.  

if you don't try to build 'good' software,  what's the point?  
&gt;to see how fast it goes =)

such a typical gentoo user...
i know i didn't read.
dang!!!!!!!!!!!!!!!!
check this out.
this sweet website has this weird glitch!!!!
my friend showed it to me
http://dreamsteam.freehostia.com

http://dreamsteam.freehostia.com
ok, hands up, not a great lover of the bayesian filter outside of it's use in email filters.   not because it's wrong but because spammers can subvert it.   

but is this brilliant or misguided?  "there is a certain amount of subjectivity, and our software is aware of that; scoring will be normalized to eliminate excessively generous or harsh estimations of stupidity."

this quote from the faq smacks of garbage to me.   this result 'tweaking' will be it's downfall unless the authors are able to open-source themselves so that we can all get the benefit of their genius ...
commercial and pretty much closed are definitely the things that jump out from his list. i'm sure they exist, but i can't think of much in the way of free parallels.
take a bow, aleks grigorievich [stakhanov](http://en.wikipedia.org/wiki/aleksei_grigorievich_stakhanov)
if an application expects to be able to write to its own bundle then it's already broken.  not every user of your application will be the administrator on their computer.
wow - the true test of its capabilities will be if it can filter itself out of existence.
building the same version of your application with debug symbols isn't guaranteed to put any functions at the same addresses.  the best approach is to build your release application with symbols enabled, archive the binaries containing symbols for future use, and then strip the binaries that will be shipped.  this process is made even simpler by the introduction of "dwarf with dsym" debugging format in recent versions of xcode, as the debugging symbols are stored separately from the binary itself.
  &gt; i think you're dramatically underestimating the enthusiastic child's capacity for learning

how many under 11s do you know who can edit routing tables, how many can configure ndiswrapper, can insert guuids into fstab, can master basic shell commands with options, can edit xorg.conf when their ati card fails to work in dual-head mode, etc? honestly now, how many?  
pyparsing is a great tool written by a helpful person. i would have had many problems with my higher-ups if it were not for his tireless service. he was even helping me out from an airport in germany on his laptop while waiting for a plane!

  hmm. while i don't exactly doubt you (it's surely plausible... i can't imagine coding a large real world app without a debugger), i'm not sure it's safe to believe you. the internet is too anonymous for such a basic slander of someone's experience to be taken at face value.  
this is pretty cool, something new to play with.

i also recommend other network weenies out there take a look at bro. it is much more robust than snort (it also accepts the snort rule syntax). it does, however, have a steeper learning curve. 
it's not _always_ wrong.

i admit i am not business expert, but the fact that they are willing to buy this many companies seems to be nothing short of an admission that they have no great ideas in process and are hoping to buy that one company that does. 

"we have money! can we pay you to think for us!" 
croak(), for example.
&gt; 99% of the time methods are named_like_this, and so on.

markdown strikes again. he meant to say:

&gt; 99% of the time methods are named\_like\_this, and so on.
how long does that article really need to be? i now have 1 year more experience reading unnecessary verbiage.
i am right now in the process of backing up my home folder so that i can freshly install gutsy! sooo excited
wait, i'm really confused. ruby does have a debugger, in fact it has several to choose from. i enjoy ruby-debug myself http://brian.maybeyoureinsane.net/blog/2007/05/07/ruby-debug-basics-screencast/

i'll admit, it doesn't have a fancy gui surrounding it, but it does give me everything i every used gdb for.

it also lets you jump into an interactive console at the breakpoint so you can inspect any variables, run methods, or do anything else to help you figure out where your bugs are.
pshaw mastered lisp over breakfast and algol 60 between commercials on wheel of fortune.
ditto for flex.
yea, it works.  i have been contacted about youtube positions twice and se positions a couple of times.

they stopped the interview process once they found out my gpa was lackluster and from the school i went to.

screw those elitist pricks with their web advertising scheme.  you have one or two technologies, get over yourselves.

not that i care that i was rejected 500 times by google, i would probably fail at a mcdonalds interview (i am a paid developer by the grace of god) because i hate the concept of work and interviews in general.
less funny when you relate it to the 'hinge' incident in schindler's list if you've read the book or seen the film.
thanks for the info.
 what's wrong with a ext2/ext3 partition?

http://www.fs-driver.org/ 
 one word counter-argument: emacs.  ;)
&gt;if he can't use it, then (most) children won't be able to use it.

i think you wildly underestimate how smart children are. heck, if i was able to use an amstrad cpc 6128, a child can probably figure out how to use ubuntu :)
for an example of a project with great docs, check out jquery.com. those guys have built documentation *and* testing into the source code. the docs are always up to date.
in today’s competitive world, it pays to be smart. no matter how smart you are, i am sure there is something you could “get smarter” about. below are some qualities of smart people. as you read the list,
http://common-lisp.net/project/cl-objc/ might help? (thanks to zach's blog)...
indeed; i just heard about it today (from zach's blog). it doesn't, currently, support ppc macs entirely, apparently, but according to the author it's just a case of changing a few things to fit in with apple's ppc32 abi; i plan to have a go at fixing it as soon as i have time (realistically probably on saturday).
i noticed it. sometimes hitting refresh is enough to bring it back.
opposing hat:
chicks dig fat32 guys.
&gt; the obvious examples are leonardo da vinci, michaelangelo, mozart or bach but there are many more.

i realize you're white, but there's more to the classics than just europe.
http://www.ubuntu.com/getubuntu/upgrading
i guess google has to try [harder](http://www.techcrunch.com/2007/10/11/does-googles-equality-drive-extend-to-old-people/) and [harder](http://yro.slashdot.org/article.pl?sid=07/10/05/1334234) to find candidates these days.
...but in that good end-of-the-world way.
it has a special place in mine for many good reasons: syntax is nice, macros and labeling is nice, small, fast, and open source.  gas is nice and all, but it's at&amp;t style syntax is hard to write without breaking your fingers.
i've been having some funny issue with dialog windows since i upgraded this morning. the popup used by firefox to ask for http authentication is slightly too small and the buttons end up clipped.
just as a counterpoint, i work at google, my degree is from oklahoma state, and i had a gpa of about 3.2.  of course i had over a decade of industry experience which i'm sure counted for a lot.
the next release will be called giggity goo. allright!!!
&gt; no people will use what ships with ie since that has %95 of the market share.

by that standard, neither pdf nor flash should exist.

&gt; it will go the way realplayer did when wmp was introduced. 

realplayer lost because it became a bloated and unusable. to this day i won't install it because i don't want all the crap running even with realplayer is turned off.

microsoft can give a product a jump start, but nothing can keep it alive if it doesn't give people what they want.

this a subreddit about *programming*. this ain't digg tech.

i don't know why this would get so much attention.
fuck google, who cares
  he's also a cowriter on my blog, http://illicittech.blogspot.com/ (not that he ever posts there, either! but still)

and if you don't believe that's me, well, [look at my resume](http://www.jaggederest.com/resume.pdf)  

anyway, i'm not saying that he's never developed software, just that i've never seen him build substantial things from scratch.
er, i think perhaps i wasn't clear enough about the point of what i was saying. i'm not suggesting students should complete full blown projects, merely suggesting that they think about how something may be useful in the real world, to a real customer.

i'm a huge supporter of programming theory, but that isn't what i'm talking about. i want to encourage students to think beyond the next line of code, and see how a market might be interested in what they are doing. 

implementation in context. :)
that may be it. mind you i haven't touched assembly in a few years. maybe i should pick it backup. i always did want to write a forth or classic basic interpreter.
heavenly hyrax sounds good.
&gt; alot? would you write "alittle"? how about "afew"?

that's specious reasoning. we also don't say "a bout" or "a round", but that has no bearing on the problem. meanwhile, the meaning of "a lot" is idiomatic and not related to other uses of the word "lot" such as "the lot" or "on a lot of land". yeah, it's considered a usage error, but it's silly to pretend like the phrase "a lot" isn't an idiom that people have to be taught to break up, just like they have to be taught to say "cannot" instead of "can not". 
arguing that the radio will be locked up tight is a non-starter.

and i do have to say that is a healthy bit of backpedalling on your part.  your original point:

&gt; third-parts apps will not have the same api access that apple apps have.

api means "application program interface".  direct access to the hardware is never a function of an api.
jerry: i don't understand, i made a reservation, do you have my reservation?

rental car agent: yes, we do, unfortunately we ran out of cars.

jerry: but the reservation keeps the car here. that's why you have the reservation.

rental car agent: i know why we have reservations.

jerry: i don't think you do. if you did, i'd have a car. see, you know how to take the reservation, you just don't know how to *hold* the reservation and that's really the most important part of the reservation, the holding. anybody can just take them.
they also have a shovel with "reizerfs guys dig chicks".
depends on which merge sort you use.
poor you, you just got rid of him, and you have to hear about him here :)
 ugh, no.

"the cardinality of the set defined by {x| x + 3 = 0} is equal to one." 

what [corbusier](http://www.affordablehousinginstitute.org/blogs/us/le_corbusier_vision_paris_small.jpg) did to architecture, the bourbakistes tried to do to math.  the result is pedantic, boring, divorced from realty, and otherwise typical of the snotty elitism of european intellectualism in the early 20th century. 
heh, arthritic is the new agile
well, to be fair, he was an interesting roommate, maybe not 'good' per se, but interesting. he's not a bad fellow, he just mumbles on about programming as though he knows what he's doing ;)

remember, this is him marketing himself. when was the last time you saw truth in advertising?
maybe they'll buy ea and the entire universe will implode in a giant matter/anti-matter reaction
is it just me, or does the figure 1 in the story describe the mechanics for flying a helicopter rather than driving a car? unless there's some new car out with collective and cyclic roll and pitch controls that i'm unaware of?
&gt; i think the point here is that useless debuggers are useless, but useful debuggers are not.

i couldn't resist:
http://dabbledb.com/avi/useless.png
no, you're thinking of add
ah, the *interesting* roommate.  say no more.
 +1 for beating me to it. it might even wrap into the special characters, i think !dd (bang driven development) works nice. 
the [yasm](http://www.tortall.net/projects/yasm/) modular assembler project is a complete rewrite of the nasm assembler which accepts nasm and gas assembler syntaxes, outputs binary, elf32, elf64, 32 and 64-bit mach-o, rdoff2, coff, win32, and win64 object formats.
i keep a collection of just such keyboards for my 'special' customers.

this just points up the difference between geeks and goths: goths have t-shirts that say (in white lettering on a pure-black shirt, of course): "chicks dig scrawny pale guys."

i wonder if anyone ever bothers polling the "chicks" on what they *actually* like?

i have begun learning lisp by taking the first steps of reading through practical common lisp, typing in everything into emacs and playing around with it as i read.  taking the slow, but consistent approach reading though a book rather then jumping from quick tutorial to yet another quick tutorial on the web seemed like a good idea to try.  even started a blog with my notes from each chapter: http://takentheredpill.blogspot.com/ 
i agree with his point in general, but when applied to commercial, closed products. my point was that there are alternatives that don't get bloated. i use mostly open source software (on linux), and the bloat rate is much smaller than what he cites for his examples. 

put in a concise way: it seems he's picking examples to make his case, rather than vice versa.
value is never the same as price. price is merely trade-value (and imperfect trade-value at that) which is never the same as use-value. 

the price society pays for someone (the size of their paycheck) is not the same as their value to that society. or even their contributions to the economy.

many people with negative contributions to the economy are given fat paychecks thus draining the economy even more. note that only the rich can be such parasites.
some projects have janitor todo lists.  these are usually easy task that that developers know that the people fixing it will need help and are more open to not yelling at you, but helping to guild and mentor you.
* alternative to aim: pidgin? 10 mb seems bloated, though. if all he wants is a tool to text chat and exchange files, though, i'm sure i could find a nonbloated one. 
* media players: there's media player classic or vlc.
* paint shop pro: gimp
* acrobat reader: he already mentions an alternative. but i use xpdf...
* eudora: thunderbird? or even pine?
i have tried a whole bunch of linux flavours in the last few month, i am now using opensuse at home and away - and everything works.

"we [he and halmos] share a philosophy about linear algebra: we think basis-free, we write basis-free, but when the chips are down we close the office door and compute with matrices like fury." - irving kaplansky

(by the way, i don't understand your last paragraph at all. could you elaborate?)
"what i don't understand is, if 80% (or whatever the number is) of the population do not understand programming, why do many programmers make interfaces for non-programmers that have features that only programmers can understand?"

because the steps involved in creating a technically efficient computer program are different than the steps needed to design a usable interface.  people don't think like programmers.

the best designed interfaces are those where the developers have spent a lot of time with the users of the system learning how they would actually use it to do their jobs.  unfortunately many programmers are too arrogant to pay any attention to the users, and their systems reflect this.

ps - why don't the postings have reply links?
but eventually it came full-circle: windows (still) sucks, but the mac comes with a decent shell.

 &gt; alternative to aim: pidgin? 10 mb seems bloated, though. if all he wants is a tool to text chat and exchange files, though, i'm sure i could find a nonbloated one.

pidgin isn't just an alternative to aim, though: it's an alternative to (almost) *every* im client. fortunately, pidgin has protocol plug-ins, though i'm not sure how easy it is to remove the ones you won't use.

i stand corrected.  how did you do in the puzzle, interviews.

i wouldn't mind getting in and i think i have relevant experience.  but can you get in if you are reallllllllly lazy about interviews and to some degree work?
what about [r](http://r-project.org)?  there are r-python interfaces available.
what i found a little ironic is the tone of the comments in this thread:  there's an implicit assumption that programming is the most intellectually demanding profession.

in choice of college majors, there was an hierarchy in the abstract reasoning ability required:

math&gt;physics&gt;electrical engineering&gt;comp sci.  

people who couldn't hack it as a mathematician might try physics or ee.  those who didn't have what it took to be an ee would trickle down to the comp sci department.
[this exposition on the tensor product of vector spaces](http://planetmath.org/encyclopedia/tensorproductclassical.html) makes the point as clearly as i could manage it.

essentially the problem is that the choice of dummy variable ends up being used to represent not just the index but also the basis with respect to which the tensor is being broken into components. so you can't replace a^i with a^5 to mean the fifth component, because the i also carries the information about which basis it was you needed to use, and without it you don't actually know what a^5 is supposed to mean.
can you elaborate why? 
thanks, investigating...
that's essentially what i'm doing right now with c++. it's working rather well.
downvoted for suggesting that there is something wrong with not being in a union. 
 &gt; a text which is simultaneously widely available, introductory, and has a decent presentation of the material.

[a=b](http://www.cis.upenn.edu/~wilf/aeqb.html) and [generatingfunctionology](http://www.math.upenn.edu/~wilf/downldgf.html) come to mind.

*edit:* ah, ok, you mention gfnology. seen a=b?
or charge the client for a week's worth of work and take on another job.
at the company i work for, we're building an application for our customers to view all sorts of data and reports.  we're going to be dealing with a large amount of data.  we have millions of rows of log records right now, and eventually will have billions.  we're all programmers, and so we're looking for a library or tool that we can build a ui on top of.

we want the reports to display instantly to the user, we want it to be highly scalable, and we want to be very flexible with the data we show.

the current options we are looking at include:
  -using a database with straight sql
  -log to a file, and then run custom coded parsers on it to build reports.
  -use a database, but also run batch processing to generate periodic reports.
  -use an etl tool like jasper
  -use some other business intelligence tool

any thoughts?
a=b is good for what it is, but it really covers a different (if somewhat related) topic than what i'm talking about here.
&gt; when or a sentence says something like "clearly *blah* [...]"

oh don't i *hate* those. especially galling when it is myself that wrote "obviously", "clearly" or (the dreaded) "trivially" six months ago, and revisiting it i have to spend 20 minutes figuring out what exactly is the correct rabbit to pull off to make the thing "trivial".
kudzu is redhat software 

lang agnostic web frameworks suck.  
you want to marry your framework to the language so that its children ( your blog, wiki, flickr implementation in 20 minutes) are completely idiomatic.
i create new lock-free algorithms because ordinary multi-threaded programming isn't sufficiently challenging enough.  it's actually easier than you think but i don't want to give away all the tricks of the trade. :)

it is an acquired skill.  it takes a while to get used to thinking that way.  kind of like thinking in 4 dimensions.
mochiads is using a combination of postgres with batch processing scripts in python for etl.  sounds like they are doing something similar to what you are asking.
http://weblog.hypotheticalabs.com/?p=171

take a look at the dlr. that is a hell of a lot more support than you'll find on any other platform.
are you larry wall lazy or dagwood bumstead lazy?  they might care.
but vb must be like java cause, you know, they both use objects and such.
can you provide us with your altitude above sea level?  i can't properly answer this until you do.  thanks.
larry wall lazy.

give me some credit, i am a programming.reddit user.
 intelligence is a curse. we shall purge it with pitchforks! 

yes lots of pitchforks, lots of brains on the floor.
 &gt; ... translate it all to a clean, unambiguous lambda-calculus notation...

[sussman has similar ideas about physics](http://video.google.com/videoplay?docid=-2726904509434151616) 
you can't license already-licensed code, that's built into every single existing license.  license is a function of copyright.

the reason i said no open source license would prevent that sort of situation is simply because no license will prevent microsoft (or whoever) from trying if they want to.  "do what the fuck you want" means that you can try to put your own license on a derivative work, but it doesn't mean the courts will now recognize that you're the copyright owner for the purpose of suing the original author.

my point is that an "except change the license on the unmodified code" addendum is unnecessary, as it is (afaik, ianal) an implied condition of all licenses.
 i have a hunch that many things written in svg+javascript are written badly, and that this is why they are slow.

for example, the tetris svg example has no such issues:

http://croczilla.com/svg/samples/svgtetris

there are some slowly building "best practices" for svg and javascript, but yes it is definitely very much slow as balls for the most part. one solution is (and i'm not kidding) using a java applet to render the svg. seriously. that's how broken things are across platforms in svg that i'm actually advocating an applet.

as an aside, you know what's missing from that tetris game? sound. which is another thing that an svg-rendering java applet can get you in the bargain. (with the devil.)
pdf here:
http://www.masukomi.org/writings/best_practices.pdf
1. ruby is not an interpreted language, ruby has an interpreted implementation; why couldn't it be implemented with a compiler generating native code?

2. you're telling us that nobody in the ruby community would ever benefit from having a solid debugger like the one smalltalk has?

3. ruby's gc is not the best and apparently leaks memory.

4. `9.sqrt`, wait, that's actually `math.sqrt(9)`...

and basically, instead of saying `assert`, bdd is about using the method `should` instead?  sounds easy enough...
 i don't recall any puzzles.  my interview lasted most of a day and involved 5 or 6 people.  each interviewer quizzed me to figure out how much stuff i actually knew and asked me to write code on the whiteboard.  this is a pretty standard format for developer interviews -- both microsoft and amazon interviews are similar.  i had technically applied for an ajax developer positions, so most of my questions were javascript related.  i must say it's much easier to code javascript on a whiteboard than c++.  oh yeah, the most important thing to know about the google hiring process is that they are glacially slow.  there was a six month delay between my application and my interview, and a whopping 1 year between my interview and job offer (the latter is kind of an outlier, but 6 months is not that uncommon).
 that is a logical fallacy.

it's simply an admission that they don't have all the great ideas, and they are hoping to buy companies that have at least one great idea.

 
 there is this elevation of "commercial" experience over experience in a technology which was not applied to profit.

you program a website or an app that does x, y, z and don't make money off it. you program a website or an app that does x, y, z for a company, that makes money of your skill. that's the same skill.

indeed i found the commercial world to be far less demanding of skill than, say, comp. sci. at university.

more, commercial world projects often make rare the opportunity to update one's tech skills. the demands of the project require you to exercise familiar skills (which you needed to get hired in the first place).

 
yes and no.  some apps can hide themselves from the dock by changing their info.plist, and others, like adium, can change their own icon.  others register themselves in the application itself so that it can go on disks and such (podworks comes to mind).

it's non-standard, and should have checks incase it fails, but there are uses for it that don't qualify as broken.
try to avoid employers that look for such specific eating skills.  far more important are the generally applicable eating principles -- proper chewing and nutritional balance beats detailed knowledge of particular exoskeleton extraction techniques.
totally!

weekend project imo 
dec documentation used to be great - if you wanted a wall of books that all looked a like someplace.   it also told you everything you needed to do, in the exact order.  (but by the time i started they will just extra machines in the test lab and not used for anything more complex than ping)
i might catch some flak here but, i might say rails. it's definately *not* the greatest web framework ever, but i think with that and a copy of [agile web development](http://www.pragprog.com/titles/rails2) he could get something interesting/rewarding running really easily which keeps the motivation pumping.
i go where the money is - particularly when i don't have a job.  i consider looking for a job one of the least interesting things i have to do, so once i get a job i avoid leaving it.   (i've only once left a job that i could have kept.   sometimes regret leaving mcdonald's just because i would have saved looking for a job 5 times (and counting - i expect this contract to run out sometime next year)
[add,aad,ddd,etc](http://en.wikipedia.org/wiki/spars_cod)
 just upgraded my home machine over ssh.  it worked seamlessly and all services came back up fully functional. well done guys! 
the lack of context in the [random comment generator](http://stupidfilter.org/random.php) cracks me up.
 bear in mind that intel is [selling something](http://www.google.com/search?q=intel+larrabee) here. speaking of which, i think no-one should underestimate intel's determination to have larrabee and its descendants [crush all before them](http://blogs.intel.com/research/2007/10/real_time_raytracing_the_end_o.html). 
oh man tell me about it... every time i try to get back into ruby, another asshole wannabe barfs all over the intarwebs with bdd this and dsl that... 

j.t.f.c !!!! i'm sick of these posers!
i've used [php/swf charts](http://www.maani.us/charts/index.php?menu=gallery) before and it was pretty sweet.
"ion is not perfect and certainly not for everyone, but neither is any user interface. usability is subjective. to ultimately solve usability problems to the extent possible with current technologies, applications should be written independent of their user interfaces and the uis should be built according to the user's preferences based on a high-level semantic description of commands provided by the application."
teach himself to lie very well then find a well educated developer from another country who will either do the work in secret or have him or herself surgically altered to resemble your boss should face to face contact with whomever needs to evaluate your boss's prowness be required.
1.  it could in theory, and i certainly wouldn't be against it.  but it's dynamic features make that sort of thing very difficult, hence why microsoft is building the dlr instead of trying to shoehorn it into the clr.

2. no.  i meant that saying we don't need a debugger is stupid.  i think the ones we have are decent, but a nicer one would surely be welcomed.  i think their usage is somewhat rare for the most part, but those who have to use them would be thankful. :)

3. it doesn't "leak memory."  crappy code leaks memory.  crappy usage of the ffi leaks memory.  ruby's gc isn't perfect, and could certainly use improvement, but it's one of the better ones i've seen in a dynamic language.

4. why would you put sqrt in the integer class?  it's a math function, hence the math module.  if you don't like it, then open the class and add it yourself.  i'm not totally sure of the rational behind it, but one though on it might be that the same method implements sqrt for integers, floats, and bignums.

you obviously didn't read what i said about bdd.  it's not just changing the word; it's a change in thought process.  if you want a better explanation, there are lots out there, though you probably won't read them just like you didn't read what i said.
age, sex, location, r?
sounds good... maybe when one guy is down to 50 or less, and has no waiting customers, he can go compare tickets with other guy, and split them... do same closer to end.
someone hasn't read the unix philosophy 
programming for the real world solution: 

both ticket booths compete to sell as many tickets as possible. for case = seat sold twice. tell offending extra ticket holder(s) to sit down, or you will call the police. better yet, just tase them.   :-) 
i am afraid i am unable to parse your reply.

i will re-iterate. i have a keen interest in keeping reddit (especially programming.reddit.com) spam free.

this means i will verbally object to and downmod any articles which are spam.

i would hope that all my fellow redditors would also do the same thing. a spam free reddit is in the best interest of everybody.

i know that many people here want to make an exception for microsoft and feel that there is nothing wrong with using reddit to hype microsoft products. the same people will automatically downmod any comment which criticizes ms or even mentions ms in anything other then flowery terms. 

that's a real problem.

broads hate it when you call em chicks.
softies must refer to their soft craniums. 
where's your helmet buddy! 
&gt; but it's dynamic features make that sort of thing very difficult, hence why microsoft is building the dlr instead of trying to shoehorn it into the clr.

the dlr certainly does not mandate interpreted implementations.

&gt; ruby's gc isn't perfect, and could certainly use improvement, but it's one of the better ones i've seen in a dynamic language.

ruby uses a conservative mark and sweep gc. this is imprecise, slow, and suffers from unpredictable pause times.

squeak has incremental gc for example. sbcl has a generational gc. most gc'd languages i can think of have a better gc than ruby.

the only reason ruby's gc hasn't been replaced yet is the mri code is an unmaintainable nightmare nobody wants to touch anymore (hence all the rewrite projects underway).

&gt; crappy usage of the ffi leaks memory.

does mri even have an ffi, or are you still required to write c code which binds your c library to ruby's internal, undocumented interpreter api? 
there goes slava erecting straw men to shit on a community.

&gt;if you need any more proof that the ruby community is full of degenerates, look no further than crap like this.

i tell you what slava. if the factor community is full of degenerates like you i will hang out with the ruby community every day.

&gt;"ruby doesn't need a good native compiler; slow languages encourage you to optimize and write scalable code"

is that why there are four or five efforts are building a ruby complier and porting ruby to different vms?

&gt;slava_pestov 32 points 8 hours ago *

first of all, what the fuck is bdd? i'm guessing since i've only heard this term on ruby blogs, it's something useless i can safely ignore.

    asking why ruby has weak debugger support is like asking why a dolphin doesn't have gills. ruby has weak debugger support because ruby programmers shouldn't be using a debugger. ruby supports tdd and bdd better than any other language except possibly smalltalk. debugger support is for languages that you can't run tests against gracefully.

if you need any more proof that the ruby community is full of degenerates, look no further than crap like this.

"ruby doesn't need a good native compiler; slow languages encourage you to optimize and write scalable code"

"ruby doesn't need a debugger because debuggers are for pussies"

"ruby doesn't need a working gc because memory leaks encourage you to write short lived scripts in line with the unix philosophy"

"ruby doesn't need consist naming conventions because this is web 2.0, baby!"

"ruby doesn't need stable libraries because hunting bugs is a fun use of a developer's time"

ruby has a vast library and most of the are stable.

&gt;"ruby doesn't need a debugger because debuggers are for pussies"

ruby has a debugger. the new version of rails integrates even more closely with the debugger. if the rails team didn't think a debugger was important then why did they spend all that effort improving integration with it?

&gt;"ruby doesn't need a working gc because memory leaks encourage you to write short lived scripts in line with the unix philosophy"

you contention is that rubies garbage collection is not working?

"ruby doesn't need consist naming conventions because this is web 2.0, baby!"

well this is an enterprisey request.

&gt;"ruby doesn't need stable libraries because hunting bugs is a fun use of a developer's time"

repeating a lie doesn't make it true.






sounds like he wants to transform ms into a venture capital firm.


something you seem to have intentionally refrained from doing in the article is recommend specific tools.  ie, you list several dvcses, but you don't seem to recommend any particular one.  i've seen your sscm project, but i am curious what your preference is.
here comes the holy ruby warrior, ready to defend his religion to the death!
honestly if i'm interviewing someone, i'm going to just assume there is a certain amount of bs in their resume.  i've found that generally within a few minutes of talking to someone, you can tell how much bs and the degree/relevance of the bs (i.e. the candidate that fudged his/her amount of time spent with a technology vs. the candidate that doesn't know the name of their home os).
 when you have as much cash as microsoft has socked away (us$21 billion), it's almost inevitable you will have more money than ideas. 
my mit water computer quip! my scathing critique on java! my "c is assembly language made glorious"! 

they'll come for you next!
no, not really.
its down again. i'd say, forget quality and speed, give me reliability :)
what does he want to do with it? "mvc context" is that database programming? web development? just mvc more generally? is it for a specific project or a skill he'd like to acquire for whatever will come up? 

as for which language, microsoft's visual studio express in c# or java (excuse me while i downmod myself with a sledgehammer) have a large community of intermediate to expert and professional users; java more than any of them. hope this helps
great, now my earth will be reduced to a burned-out cinder. thanks.
"what i don't understand is..."
it's beacause 80% of programmers forget how regular people think.

"ps - why don't the postings have reply links?"
well, if it is the same thing that just now happened to me it is when you log in from the comments page you have to refresh before the whole page is rewritten.
turn off the computer.  go outside.  get some fresh air.
amen.
&gt; what the fuck is bdd? i'm guessing since i've only heard this term on ruby blogs, it's something useless i can safely ignore.

it's exactly the same as tdd, except with added smug.

obviously, it works.
it's true that a lot of the ideas beg the question. "make the computer not let it happen".

"each vendor is responsible for a section of the concert hall" is however a pretty good idea. would help in getting maximum capacity out of the venue also.

i was surprised not to see something like "do not sell specific seats, but seats in a certain zone (maybe a row, or half row)" that way you can repack the zone right up until the tickets are picked up.
for the 20%, retard. the percentage would likely be higher for the people who use the program too...retard.
that gpus are bad at "messy" data and control flow is no secret.  but i like that the author also discussed the cpu-gpu bottleneck.  in my apps, simply getting the data to the video card produces dramatic latencies; this is a weak link indeed.
haha, you always get to be popular with the 'normal people are stupid' argument, don't you.
well, i've seen goth guys with chicks...
i remember when nerds were supposed to be skinny.
chicks who cheat on their reiserfs boyfriends are pretty much fscked.
 8.04 - hapless hillbilly...

the default desktop will have a nascar theme, a web-browser dedicated for porn, and a music downloading service called yee-haw.  also there will be no more new versions, because evolution of the linux desktop doesn't exist, there is only one creator(linus torvalds).   
but that's a perfectly respectable gpa, and state schools tend to be pretty good. i'm not familiar with oklahoma state, but browsing the department's website didn't raise any red flags.
&gt; the fact is that the industry moves far too rapidly for universities to teach more than a small portion of the knowledge required to be competent on the job, even at an entry level.

if that were true, they would concentrate more on teaching the fundamentals, like how to use a debugger. i've taken a couple of college level programming classes, but none of them even mentioned it.
it makes you look like an ass when you have to resort to lying in order to shit on somebody.

there are tons of very legitimate reasons to criticize ruby and you somehow could not stumble on one of them.

or maybe i should make up some lies about ruby and post them here so i can get mad upmods!
you left off an e
learn both syntaxes.  once you know assembly language the syntactical differences are trivial.
just the world as we know it.

and i feel fine.
tommah cloned multics during the boring part of jeopardy where the contestants tell us a little something about themselves and alex trebek pretends to be charismatic.
google has a reputation of only wanting to hire the best and brightest (gpas approaching 4.0) from top-tier schools like mit and stanford.  there is some truth to that, but from my experience it's not that extreme.  getting in fresh out of school might be quite difficult, but if you've got some industry experience that counts for a lot, too.
this story has gotten a lot of play, but i'm actually more excited by the sandboxing feature. 
[keanu?](http://reddit.com/user/keanu_reeves)
it's funny because it's not a joke. dilbert comics are so funny because they're disturbingly real.
ms has thousands of patents right? 

let's say somebody forks a project under this license. they add some value to it and publish it under the same license. let's say that additional functionality violates some patent held by ms on another project (for the purpose of this discussion let's presume it's sql server).

what happens then? can ms sue you?
not all old people, just the ones he's met
&gt;if children can't use linux...

both my chidren (6 and 4 years old) use linux quite merrily. they prefer it to windows, which they have used a few times when out.
more like never raise the bar because you might make someone more senior look bad.  or you might make management realize they don't need as many workers.
and that my liege is why the earth is banana shaped...
that whooshing sound was the point missing you.

http://en.wikipedia.org/wiki/x_window_system#nomenclature
they haven't figured out that windows has games yet.
i've tried to poll them, but they're too busy ignoring me.
i as well.  i would like to subscribe to your newsletter and circle all the spelling errors and mail it back to you
anybody know how many contractors work at google? i work at a major tech company and the best way to get hired here seems to be to work as a contractor for a couple years first.
how the heck does this only get 3?

&gt; i think france have the real ghettos chlichy suois bois bobigny and and i can not french but i think french is a nice language hard for learn but nice i was in chlichy souis bois and i say this is a real ghetto germany have not ghettos germany have gays
indeed.  there's no programmer like a programmer with a six-shooter.

bang!  take that, threaded nondeterminism!

bang!  not in my backyard, division by zero segfault!
looks like spam to me...  unless there's something i'm missing.

oh yeah, i *live* for popularity.
  i never liked people giving good advices they don't follow themselves or they might follow them but they also get stuck and dissimulate this. it's all vanity and hypocrisy. the programming world is not any more honest than showbusiness. 

reflecting my times with c++ i realize that i did not grasped its idioms well ( i hated them ) but just tried to avoid problems and worked around them until getting comfortable. in the end i programmed in something like qt ( although not qt actually but a set of libraries with similar shape ) which feels more like java than c++ although more concise. so what did it buy me? 6 years of c++ on my resume and a very special way to design programs stemming from avoiding the language face-to-face. what does this particular tell us about the nature of a programmers subjectivity?

programming tolerates this behaviour because you can easily create your own niche. the effect is strange: you feel very capable just because you find a way living with your deficits.

when being confronted with someone else who also found a way to live with his deficists you consider him as a complete idiot who doesn't master anything right and doesn't know about elementary details. be aware chances are he's your own mirror. it's like meeting someone speaking a dialect and believe he just can't speak properly.  
i was thinking along the same lines -- learn a good web app framework, rails, one of the python frameworks, whatever.  it's pretty easy to make something useful while learning a thing or two about oo design.
if your boss needs to learn oo and he has "some basic programming experience" then you are about to become a human man page.

look for another job.


wtf! it's one line of code. i agree, "foreach" is nicer, but please...
that happens to me all the time. i have very flaky hardware, so my computer occasionally breaks, but when i ran windows on it, it *stayed* broken. now that i use ubuntu, i can usually fix it without reinstalling everything.
it's odd how many of my friends are just saying "the hell with this" and moving to ubuntu. their reaction afterward is generally, "huh. this is actually not as scary as i thought. and things work comfortably."
ok, let me spell it out for you.  people who have not even bothered to look at the language (or at most gave it a cursory glance) make up some argument based on hear-say and handwaivy reasons for why haskell must be having a performance problem.  dons, having written extremely efficient app/libs in haskell (e.g., yi, bytestring, xmonad), gets fed up and starts to talk about ghc 12.5.  it's funny, because it suggests how ridiculous the original arguments were without actually overtly offending anybody.

btw, when was the last time somebody argued that perl/python/java/c# must be doomed to failure because their performance sucks?  this whole performance discussion is plainly silly.  making jokes about it is the only way to stay sane.
 they're trying to kill open source.

sorry, but the comments were horribly sensible and dangerously lacking in hyperbole.
&gt; @foo.bar.should == 3

that's the ugliest line of code i've ever seen.
dwm is better than ion--although this one seems to be very nice, too. i shall investigate.
i hate your job.
thank you, captain obvious!
to be fair, slava, there are idiots and stupid gits in every language community.

i mean, just look at yourself as an example. i do not judge factor because you happen to be completely useless.
"don't bring a fact to a mudfight." 
  one part of the puzzle that this (otherwise very reasonable) solution conveniently ignores is the stipulation that each customer is offered the "*n* best seats that are available" at the time the transaction takes place.

if you have two separate vendors each selling half the auditorium, you may get crappier seats by going to the wrong one. indeed, this is the case with the two tkts locations in new york... you'll get more show options and better seat selection if you go the south street seaport booth rather than the times square one.
i must disagree midly about vlc being lightweight.  it's not stupid bloated, but it's packed with deep features, and it plays 99% of what i throw at it.  if vlc doesn't play it then i just assume the file is corrupted. 

i'm a total vlc fanboy, it's fantastic, but it's not lightweight.

also kinda ditto about pidgin, which you already mentioned as being questionable.
if you're overwhelmed by the complexity of a loop counter, you're in the wrong field.
 dumbass. this is a google co-op search that's framed into a 3rd-party site, [search4candidates](http://www.search4candidates.com/).

you just failed google interview #0. 
i'm pretty with it, but i have no idea what a bootable data dvd is.
disturbed that no one has mentioned the haskell road to maths, logic and programming.

http://www.cwi.nl/~jve/hr

the book handles all 3 concurrently, so you understand what you're reading by doing.  and it takes as a basic assumption that you do not know math, so it spells out each tiny bit clearly.
what's disturbing is that his comment will probably pass the bayesian filter.

on a second thought, is that precisely what johnmudd is trying to demonstrate?
&gt; is this the command-line based quiz that forces you to answer a bunch of vague questions about your mouse and keyboard every time? or is it something else?

\*shiver\*

i'm having a flashback to my brief experience attempting to use gentoo on the desktop. ugh, what a mess.
&gt; why does nobody love kubuntu. :(

that caps-lock bug is a real deal-breaker. ;-)
&gt; for example, a theater where every seat is in the front row.

the downside is that if demand is high, the front row ends up mighty far from the show.
very easy on the eyes when you get used to the color, in a way it makes sense though doesn't it?
yeah me too :(
i'm not a programmer.  i would have split the tickets between the booths, like east-side and west-side or maybe split by price.  then, i'd post a sign telling people which booth to go to for which tickets.

i'm unfamiliar enough with programming that i don't even know what sort of programming problem it is supposed to represent.
 ubuntu is alright, but i keep going back to gentoo, especially after a few months when ubuntu's repository gets stale and i want something bleeding edge. 
awesome! i've been using xmonad since 0.2; i'm happy about the new binary distributions to make it easier to install.

and i encourage anyone who's curious to try it out.
i took an intro cs course and it kicked my lazy ass.  working with problems in that way was interesting but difficult.

i think the biggest difficulty in communicating with a computer through programming is that the computer has no idea what my end goal is.  so, it's willing to do any stupid, mistaken thing i ask it too.  it's different from giving a friend directions to the mcdonald's.  my friend knows what a mcdonald's generally looks like and he knows that i'm not going to ask him to drive off a cliff to get there.

is it possible to program in cooperation with a computer?  like building a bridge from both ends?  i may very well have no idea what i'm talking about.
 &gt; proper chewing and nutritional balance beats detailed knowledge of particular exoskeleton extraction techniques.

i interviewed a guy like that once.  after about 20 minutes of watching him try to chew on the shell i pretended that i had another appointment soon, and that we'd call him back.

we never called him back. 
i can't describe it better: you made me feel like i've actually read a poem or something. amazing! if reddit had more upmods, i'd spend them here.

(note to self: what's with sentimentality, gotebe!?)
nice comparison with mozart and beatles in the linked [norvig](http://norvig.com/21-days.html) article, too.
  their faq is great.
 
&gt; *isn't filtering stupidity elitist?*
&gt;
&gt;    yes. yes, it is. that's sort of the whole point.

 
&gt;*do you really expect to be able to detect and filter anything that's conceivably stupid?*
&gt;
&gt;    no, of course not. you'd need real ai for that, and beyond a certain point it's simply subjective; after all, a sufficiently advanced ai would probably filter out the whole of human discourse, which isn't the idea.

 
&gt; *won't people just try to defeat the filter, the way spammers try to get around spam filtering?*
&gt;
&gt;    we certainly hope they will -- that implies they're no longer generating text statistically likely to be stupid. it's true that an obvious attack on the stupidfilter would be to salt a short, stupid comment with a long excerpt copy-pasted from, say, project gutenberg, but we think it's reasonable to count on the laziness of the stupidest commenters not to do this.  
i use (and pay) for fusion charts, so i can recommend that one over php/swf charts, i'm not familiar with the others.
every time i read something like this i can't help but think that you need to read "a new kind of science" by stephen wolfram.   it's enlightening and a never ending way to reach into mathematics.  i can open the book any day and learn something new, find a new path to explore, or think about something differently.   to me this is the essential book on mathematics to possess form the text to the footnotes,
don't forget my beloved inkscape.
nobody's mentioned [fasm](http://flatassembler.net/) yet? well, that's fixed.
as a balancing perspective, many people (especially mathematicians and computer scientists) hate the book.  it's long winded and is essentially a discussion of automata.  since math is more than automata, *a new kind of science* might not be the best book for learning "mathematics as a language".
 i've found that for programmers who have enough low-level (as in c) experience, the simplest way to explain a continuation is this: you save the stack, but not the heap.  later, as many times as you want, you can copy that saved stack and jump back into it.
anyone able to link a compilation of programming exercises?  the hardest part about learning new languages for me is often finding good uses for the language.  having a list of exercises to try would be invaluable.
  for real.  and what about if you wanted more than one exit condition?  of course you could use an if statement with a break inside the loop... or you could just add it to the for statement.

honestly, where's the problem in defining what the loop does in the first line. seems pretty logical to me.

much like a while loop or do while loop, except for's give you that chance to automatically adjust a variable in that defining line.


and how about those (quite common) cases where you just don't have a list object to call a block on in the first place? 
that was when they still had to run from jocks.
i'm posting from windows
that's not quite fair.  it was relative complexity, and i do think it's a valid point.

relatively, the thing he wanted to do with each element was a lot more simple than the thing itself.  i mean, it's just a collection fold.  if i were writing the same thing in ocaml, it'd look like this:

    list.fold_left (+) 0 element
  to quote [butters stotch](http://en.wikipedia.org/wiki/butters_stotch), _"[i'd rather be a crying, little pussy than a faggy goth kid](http://en.wikipedia.org/wiki/raisins_%28south_park_episode%29)."_.  
;-)

if up/downmods are anything to go buy, i have to give it to redditors! slava's comment is offending and rude, but on another level more accurate than yours. and redditor's votes recognize that!

kinda see-through higher level of thruth!
that's cool, i'll give it a shot.
you have to view the bourbaki books in their proper historical context. when many of them were written, there were _no_ complete and modern expositions of their subjects available; set theory had recently been put on rigorous footing; important abstractions such as initial and final object had just been hatched, and bourbaki were the first to put them to systematic use in exposition.

this was certainly the case with topologie generale and espaces vectoriels topologiques. some of the later books (which were written by serre), like algebre commutative and algebre homologique, don't serve that original bourbaki mission statement at all, but they also tend to be less weighed down by the excessive formalism of the earlier books.

yes, today you can find better expositions today for every area they wrote on; yet they're still fun and enlightening to read once you've gained a firm grasp of the basics.
... sure, but the article was using a toy example, which is the reason why the loop body was so trivial. the loop counter is a totally standard idiom --  it is perhaps slightly verbose, but it hardly qualifies as "complex".
it makes no difference whether the cms in question is off-the-shelf or in-house, the principle is the same.  somehow you need to be able to automate the generation of test data, either in the front-end (e.g. with a web screen scraper) or, more likely, in the backend by talking directly to its database.

the precise syntax of what's in the database, and even the runtime behaviour that the data influence, are also irrelevant to testing.  what matters is that you find a way to load the data set on which your tests rely in a repeatable way.

w.e. deming got it exactly right (paraphrased): the first step toward achieving quality is to stamp out variance.  once you can produce identical crappy widgets in quantity, make one change in the production process at a time, and measure the output.  improvements are cumulative, and regressions can be isolated and reverted.
huh?  since when does ie not support pdf or flash?

on just about any pc both are preinstalled, while java for instance (an up-to-date, non-ms version), or a svg viewer, are often *not* installed.
i don't think you can honestly say you only have one such line in your code.  a large number of such loops i've seen are really trying to do one of three things:

* mapping (transformation)
* filtering
* reduction

each has associated overhead.  in the mapping case, you need a collection to store the result.  well, except one day, you figure out that you can reduce the overhead of such transformations by using lazily evaluating wrapper collections (a la google collect).  now look through all of your mapping loops to figure out which ones can benefit from this optimization.

filtering is similar, but you are conditionally adding members to the collection, so you are doing the same sort of loop thing with an additional branch.  it can benefit from the same optimization as above, though.

reduction is more complicated and not necessarily natural in many languages.  now getting this right means you can come up with really cool reusable reductions.  i did this with a java project at work that consolidated a lot of code and fixed several bugs by making a few simple reduction functions that turned out to be needed in quite a few places.


what i've found in real cases is that complexity can be traded for testability in a lot of cases.

a guy at work had a function that did some various setup and then did some loops in a loop to try to match some info against an ldap server.  testing that code was nearly impossible, but i had him restate it as a filter and it became trivial.  there were three test cases he had to run against his filter with a mock ldap interface and he could be confident that his code would do the right thing in all situations.
no. the problem is repetition. for loops roll off my hands like water off a waterfall, when i have to write them. i am literally expanding a macro, whenever i write a for loop.

that is bad, because programming shouldn't be a typing challenge, but a logical challenge. i am doing a function's work when i start typing out a line that barely changes _except for the arguments_, see.

and the fold function doesn't have to incur any runtime costs. hell, it should be inlined wherever it occurs.
nobody has a problem with for loops. i have a problem with repetition.
the for loop is one thing that carries a minimum of four delicate statements in it.
three of these statements barely change at all wherever they occur.

now, what did your master tell you, again?

me, i rebelled against the for loop.
please.  there is a *reason* i stopped reading their rss feed after a while.  most articles on beautiful code suck, like this one.

if you think a counting for-loop is too complex in java, then *fucking write the non-counting for-loop*, such as:

    for (string s : stringarray)
        println(s);

oh yes, it's *so much more readable* to write that instead as:

    stringarray.each(fun s =&gt; println(s));

no, i'm joking.  as soon as that function has multiple lines, you're *much better off* with something like the for-loop (or lisp's dolist) than with something like blocks, closures, or scheme's for-each, simply because the loop spells out just what you're going to do.
hey, university of illinois has a great program whereby mathematics are taught with mathematica:
http://www-cm.math.uiuc.edu/

and the courseware is downloadable here:
http://calcand.math.uiuc.edu/courseware/mathematica%206.0%20courseware/
each for loop increases the cyclomatic complexity of your function by definition.

he didn't want a loop he wanted a reduction (specifically a summation).  his language made him express that as a for loop.  while it's not terribly common, people do get the loops wrong.

if you have an abstraction that allows you to say something closer to what you mean, it can be optimized better, and it can be harder to get wrong.
dames like that are a dime a dozen.
&gt; stringarray.each(fun s =&gt; println(s));

i don't know what that language is, but i'd guess that any language that would support that kind of construct would also allow this:

    stringarray.each(println);

the loop spells out *how* you're asking the computer to solve a problem that's in your head.  it's not just obviously the right abstraction for anything that you may need to do more than once.
yep, fixed. :-)
as a math major, my fluency in mathematics only came with my understanding of the rigor required in proofs, which only came with experience.  as with your example of english, there is no way to learn a language except by using it.    

you'll have to read and write lots of formal proofs. learn a mathematical markup system like latex, and type out your proofs, so you can send your proofs to others to read.  once  others can read what you write, you can probably be considered fluent (:
the joy of python: if it's simple, make it a comprehension. if it's complicated, make it a loop. 
 i may not be able to understand how to write an algorithm, but there aren't many features that require me to be able to write an algorithm. a complicated interface doesn't mean only programmers can understand it...it means the interface will take some time to get used to.
yeah, now my wifi (stupid broadcom) won't work anymore.
load more comments load more comments load more comments
how do you figure it's more accurate.

he claims that the ruby community is not concerned about performance. i point out that there are numerous compilers actively being worked on.

he told a flat out lie. i told the truth. his comment has 40 mod points mine has -3.

why is that?

i tell you why. it's not kool to program in ruby on reddit. it's just like back in high school except with geeks. in high school the jocks beat up the geeks and here they do the equivalent by downmodding "unpopular" people.

every single one of slavas points was a straw man or a flat out lie and he was a total asshole about it too.  i guess asshole liars are popular here.

 &gt; hence why microsoft is building the dlr instead of trying to shoehorn it into the clr.

do you know what the dlr is? it's a library that runs on the clr; it isn't an alternative run-time, contrary to what its name leads you to believe. it just generates code at run-time for shims and interfaces that let the static and dynamic worlds talk together. 
agreed, apologies for the dodgy link.
not sure about sound, but: http://www.bluishcoder.co.nz/2007/08/svg-video-demo.html
another vote from me. it's one of the best programming-related books i read in 2006. while some of it just retreaded ground that was familiar to me, substantial parts were complete news to me. it's the worth its price tag for its discussion of delta debugging alone.
won't somebody think of the **value semantics**!??!
linked description was awful - this one actually makes sense.
seriously - they'd have to pay me a lot to convince me to basically make my office my life. i hear a **large** percentage of people who work there take advantage of the free dinners. while some people think that sounds cool, i find it amazingly depressing.
i need a new dad. mine emails me on my birthday to ask for fixes to his ms access database.
the point is that you can eliminate the inconsistencies by simply dropping the requirement to type variables.  it doesnt' work when you have subtypes.  there is always some paradox that arises.
walk first, run later.  new grads can barely crawl.
is there a point in there?  are you're saying that smalltalk will see the light and dump their debugger while ruby will finally decide to implement one?  i don't get your point.
bah. windows has had that for decades.

*oh, they meant controlled randomization*
the main thing is the difference in perspective from imperative to functional programming.  you don't have loops, you have recursion.  even in the absence of higher order functions such as map, fold, and filter, recursion is often times a better expression of the actual semantics.

this can be tricky to see when you've learned the ins and outs of for-loops and imperative reasoning over the years.

&gt; and how about those (quite common) cases where you just don't have a list object to call a block on in the first place?

well, at least in the case of lazy functional languages, the difference between computation and data is quite fuzzy.  the list type of haskell more readily represents a generator (as found in python) than a concrete structure.  so, with an optimizing compiler, mapm_ print [0..1000] is just as good as for(unsigned i = 0; i &lt; 1000; i++) { std::cout &lt;&lt; i &lt;&lt; "\n"; }
wow, nice.
as a programmer, i wish i had a game where i could train my own ai, for example a tank-squad in a strategy game so that i get rid of the dumb task of telling each single tank what to do. it would be more fun planning big attacs. not the player with the highest click-rate, the one with the better ai would win.

or any other language with comprehensions, for that matter:

http://en.wikipedia.org/wiki/list_comprehension
 the developers *already know* the api. that's what makes it hard to write documentation for it: they don't know what the users will need to know.

for example, “sets the frobnitzer to foo” is a good *start* on documenting a hypothetical setter method. but why would you want to do that? what effects would setting it to foo have on the frobnitzer? what benefits would other objects reap from the frobnitzer being set to foo? what risks are run by setting it to that, or in fact by setting it at all?

the best way to get your api documented, imo, is to enlist somebody who does not already know the api and wants to write code using it. ask that person to either write the documentation itself, or at least keep notes that can be digested later into the documentation.

it works for the subject, as well: documenting an api is a good way to learn it. i've actually learned a couple of the adium internal apis by writing their documentation. you may be able to get the same effect by writing unit tests.
the best interfaces are the ones that can do complex things but are really simple.

a toilet is quite an invention, using mechanics, gravity and air pressure.

let's say a programmer invented the toilet. there would be a handle for the water level in the tank, how many gallons per flush, an adjuster for how far the flusher had to be pressed, a sensor to tell if a male or female is sitting and will automatically place the seat down, a button to inject the tank with blue disinfectant, a bowl windshield-wiper button, a "number one" mode and a "number two" mode, etc.

&amp;nbsp;

or, you could make a toilet with just a freakin' flusher handle.

some interfaces shouldn't take time to get used to. shit could happen....   
actually, that's why they like linux better than windows.

my 6 year old does a little bit of programming, but otherwise, it's mostly games.
&gt; the dlr certainly does not mandate interpreted implementations.

in fact, your code is compiled to .net bytecode and jited. there are of course a bunch of hooks back into the dynamic world, since things like method dispatch obviously can't happen statically (though there's some pretty heavy optimization so that a full dynamic lookup doesn't have to be done every time). so for sufficiently broad definitions of "compiled", the dlr qualifies.

is that it? you want to ask for advice but you offer no details at all?

do you like c++? do you like ruby? have you ever done rails development? 

if you think you can do well then take the money and the ruby job. you will probably have more fun.

just stay away from slava. he will hate your guts as soon as you write your first line of ruby :)


sweet! gnome panel support!
what about if you use "natural merge sort".  in natural merge sort you scan the input and divide it into already sorted subsequences and then you merge those.  so if the list is already sorted you get one subsequence and it runs in linear time.
the best way is to have a cv that starts off with something like "i am guido van rossum", or  "i am rob pike" or something along those lines.
from the rest of the comments i've seen, i'm not sure if my comment is related or not.  but here is a site that explains tricks on how to do math problems in your head (by reading the problems from left to right, kind of like you would read english).

http://www.jimloy.com/arith/speed.htm
ubuntu comes on one.
  in theory, recursion is a beautiful construct. however, in practice, for loops are often the more reasonable choice because of the risk of stack overflows when using recursion. when the depth of a recursion depends on the size of the input (e.g. the length of a list), you can easily make it crash by feeding it an excessively lengthy input.  
see if this helps you - http://www.rosettacode.org/wiki/main_page
while typing and "classes" are useful i would really very much prefer true lambda support, nested functions, and things to that effect. boost just doesn't cut it imo because it has to work within constraints of current c++. it drives me nuts to think that they are choosing a library for support in what should be a language feature.
i don't actually own an xbox 360, but i always found [its graphics architecture](http://en.wikipedia.org/wiki/xbox_360#hardware) quite interesting. basically, cpu and gpu share the same 512mb of memory, just like in low-end pc hardware. in contrast to those however, the gpu has been integrated into the northbridge so that it is directly connected to that memory. this means that for both gpu and cpu, memory access should be roughly as fast as with a more traditional architecture.

i imagine that any data in memory with the right format can be used as a texture right away, with a simple call to the gpu. an algorithm optimized for the gpu would keep the data in that format anyway, effectively removing the cpu-gpu bottleneck.
when is it correct?
http://en.wikipedia.org/wiki/tail_recursion
&gt;i'm pretty with it, but i have no idea what a bootable data dvd is.

um...it's a dvd. with data on it. that you can...boot from.
 there will be language support for lambdas, but no mandatory garbage collection nor (i think) a fixed point operator so it won't be able to do everything.

i understand that local functions and external linkage requirements for template parameters should also get lifted which will also make many things easier. (edit) i.e. local functions, and function local classes as template parameters.

the concepts _is_ a language level feature, and has to be such so boost is really a red herring when discussing it. 
update on this -
i updated with the update manager, found that i could select the exact model i had in the x settings front-end. i selected 1280 x 1024 and lo and behold it worked.

then i restarted and found that 1) it had reset the keyboard layout to qwerty 2) my username and password didn't want to work.

so to top off, i spent all last night after work updating ubuntu and getting it to accept my resolution, then when i finally do get it right it inexplicably wipes my user account.

what's the password for the root account in ubuntu? oh wait, it doesn't have one unless you enable it. fucking sudo can sudofuckitself.

*shoots self*
they are just pissed that [nvidia's tesla](http://www.nvidia.com/object/tesla_computing_solutions.html) is going to kick their asses in terms of processing power...
problem: loops are bad at expressing complicated algorithms.  if it's simple enough to be expressed as a loop, it's usually simple enough to be a higher-order function.
why's that?
go for it.  no question.

1.  you seem to hate your current job.  you have a nonzero chance of liking the next job.
2.  you seem excited about the new job.  this may wear off, but until then, you'll probably *like* the new job, which still leaves you ahead of the previous one.
3.  it is easier (less painful) to regret something you have done than it is to regret something you haven't done.
4.  using a new language or two for 8 hours a day will make you a better programmer, even if you go back to c++ later.
5.  if you are getting offers out of the blue for higher salary jobs, you are probably underpaid now.  this wouldn't matter so much if you liked the current job, but...

as for ruby: the vocal part of ruby's current community is incredibly annoying; as a result, you get fanboys claiming that problems are "features", *and* antifanboys claiming the problems are cataclysmically bad.  the truth is somewhere in the middle.  you'll learn to avoid ruby's pitfalls just like you avoid c++'s pitfalls now.
...and if you're underwhelmed by it?

the amount of people on this thread who don't understand the purpose of a higher-order abstraction is quite disheartening.

too bad if it was a non-trivial example.

*sigh*
i was using sarcasm to show how the author was wrong.
why isn't [boost::concept check](http://www.boost.org/libs/concept_check/using_concept_check.htm) enough?
   heck, *i* can't tell if this is meant seriously and thus stupid, or a clever joke... what should a bayesian filter do? but at least they have this problem in the faq:

&gt; the stupidfilter is blind to irony.   
&gt; mandatory garbage collection

why is this a bad thing though?  i can understand people feeling one or another about what the default is(gc or no gc) but i don't get it not being mandatory.  

there are too many situations where speed is still absolutely key. 

but upmodded for talking about c++ and 1) knowing what you're talking about and 2) keeping abreast of the current proposals.  rare these days for reddit.
&gt; osx is also well supported.

anyone got a link to a os x binary?
i guess between all the programmers longing for more functional programming, aspect oriented programming, true threading support and more template tricks, the standardization groups are happy if they can keep most features contained in libraries. i've been actively following the [cpp-threads](http://www.decadentplace.org.uk/pipermail/cpp-threads/) group for the past two years, and the details in the already complex language are mind-boggling.

a good overview of all the new features is the [wikipedia entry](http://en.wikipedia.org/wiki/c%2b%2b0x).
why would they kill open source. it's going to be a rich mine of lawsuits for them. did you know they have over 200 patents which linux is infringing on right now?
&gt;the bsd license does not allow source code to be relicensed.

you better tell apple that. they are going to in a heap of trouble.
if its on tdwtf, it would be true, false and filenotfound.
ahem. mostly good and solid list. but one name is missing. richard stallmann: emacs, gcc, etc. etc. even guy steele was full of awe: [extreme pair programming - guy steele and richard stallman](http://cycle-gap.blogspot.com/2007/09/extreme-pair-programming-guy-steele-and.html)
this is an advertisement or spam with attractive subject, worse than plain spam
  "naive set theory" by halmos is simply fantastic.  it's readable, rigorous, and all-around awesome.   iirc, paul hlmos has won multiple awrds for the clarity of his writing and the quality of that book. 
you can put lipstick on a pig, but its still a pig.

&gt; what the fuck is bdd? i'm guessing since i've only heard this term on ruby blogs,

blog driven design?
i've been using plotr for a project i'm working on, and it seems pretty nice.  no way would i ever use any of those flash things...yuck.  it's just a chart.
a damn efficient pig, nonetheless.
i know what you worry about: instead of being a c++ duke on the throne of a wasteland you become a pawn in ruby country where you have to play with hysterical kids instead of doing serious conversations with engineers.

but when you function more in the ruby mode emotionally and do not appreciate the grandezza and deeper meaning of stl you might be lost for c++ anyway. 


&gt; once you've gained a firm grasp of the basics.

they're clearly no good for beginners.  the bourbaki papers i've read, even when i know the stuff have been uniformly terrible.
i actually think knuth's concrete mathematics isn't bad at all for getting one to approach problems in the right spirit, including "decoding" all the specialized math language.

http://www-cs-faculty.stanford.edu/~knuth/gkp.html
&gt; realplayer lost because it became a bloated and unusable. to this day i won't install it because i don't want all the crap running even with realplayer is turned off.

but why did it get bloated? you could make the case that it was out of desperation: they had to do *something* after microsoft effectively destroyed their market. it's hard to compete with free. if you add features that people don't want, they call it bloat, and monetizing in other ways (advertising etc.) goes down even worse.

the [crap-free bbc edition][bbcrp] isn't bad, by the way.

[bbcrp]: http://www.bbc.co.uk/webwise/categories/plug/real/newreal.shtml?intro2
if the cart ain't moving fast enough for you,  why don't you get out and push?

while abcl does not currently have a core set of developers with commit rights, a roadmap, and so forth, patches are promptly reviewed and comitted to the cvs head.  bug reports with reproducible test cases are answered fairly fast as well.

as for speed, i find it surprisingly fast for binding together java libraries, as [have others][1].  for any serious use, i would recommend using alan ruttenburgs [jss][2] package, which introduces a nice read macro syntax on '#"' *and* dynamically looks up classes on a classpath (ala beanshell):

(let ((sw (new 'stringwriter)))
  (#"write" sw "hello ")
  (#"write" sw "world")
   (print (#"tostring" sw)))



[1]: http://article.gmane.org/gmane.editors.j.devel/1382

[2]: http://mumble.net:8080/svn/lsw/
parent is absolutely correct. i stumbled across this book as a naive freshman and it blew my mind, i coded up cellular automata in c and watched them evolve and interact and thought it was just the greatest thing going, but when you begin to read into the background of the book itself and to examine critically some of the theories within cracks do appear. in the end i was left with the conclusion that 'a new kind of science' was primarily an excellent source of trippy posters.
&gt; what corbusier did to architecture

that's *le* corbusier to you ya little whipper snapper.
&gt; if you think a counting for-loop is too complex in java, then fucking write the non-counting for-loop, such as:

and then, you also need the index (on top of the element), but since you're using java you're fucked.

&gt;     stringarray.each(fun s =&gt; println(s));

why would you write that when nearly every language out there would allow you to write `stringarray.each(println)` to get exactly the same result?
that's what i meant, in case it wasn't clear: i don't think they're good for beginners, or even those who have only a casual acquaintance with the material. hence the "firm grasp". what characterizes bourbaki is a very systematic, rigorous, matter-of-factly development, starting from a foundation of very little presupposed knowledge, and building on top of it the vast edifice, brick by brick; you won't find much, if anything, in the way of motivational material or illustrative examples.
&gt; if it's simple, make it a comprehension. if it's complicated, make it a loop.

or extract the complexity in a local function and *still make it a comprehension* (or a map/filter/reduce)
good point.

otoh, any serious (sic!) code bases are just not for novices.

i *of now* wouldn't let *me 10 of years before* even touch what i'm working on. ;-)
 the horrible syntax for one.

    template &lt;class iter&gt;
    struct randomaccessiteratorconcept
    {
      void constraints() {
        function_requires&lt; bidirectionaliteratorconcept&lt;iter&gt; &gt;();
        function_requires&lt; lessthancomparableconcept&lt;iter&gt; &gt;();
        function_requires&lt; convertibleconcept&lt;
          typename std::iterator_traits&lt;iter&gt;::iterator_category,
          std::random_access_iterator_tag&gt; &gt;();
  
        i += n;
        i = i + n; i = n + i;
        i -= n;
        i = i - n;
        n = i - j;
        i[n];
      }
      iter i, j;
      typename std::iterator_traits&lt;iter&gt;::difference_type n;
   };

versus something like

    concept inputiterator&lt;typename iter, typename value&gt;
    {
      requires regular&lt;iter&gt;;
      value operator*(const iter&amp;);
      iter&amp; operator++(iter&amp;);
      iter operator++(iter&amp;, int);
    } 

edit: formatting
and marinated in kool aid.
hello there, mr. troll.
 i certainly hope you didn't use this to do it:

\#define for(i, n) for(i=0;i&lt;n;i++)  
i'd never used a tiling wm before trying out xmonad a few months ago and i'm a convert -- totally hooked and my mouse is beginning to gather dust. sticking to the keyboard (and being a touch typist, albeit not a fast one) makes it feel like there's nothing in between me and what's happening on the screen. fortunately all of the apps i depend on play nicely with the keyboard to a greater or lesser degree. 

thanks, dons &amp; co! 

&gt; thinking about data structures, anything that wants a graph, tree, sparse matrix representation is going to behave this way…and that covers a lot of interesting stuff. the trick that nobody has mastered is how to deliver this level of performance with the flexibility to do the interesting stuff in gpu or cpu. yet.

but people are getting there. for example, [octrees are possible on the gpu](http://lefebvre.sylvain.free.fr/octreetex/), by using a structure that is quite similar to linked lists (pointers to cells). plus gpu architects are working very  hard to make dynamic control flow more and more performant so you can traverse those data structures without always getting into the worst case scenario.

gpgpu people want the flexibility, that is correct, but gpu need to keep up on graphics performance. for example the new shader model  (4.0) allows data of arbitrary length to be streamed out of a shader. in practice, you can currently only stream out 1024 32-bit values per processed element, but performance drops significantly on current gpu even when you push more then 128 values. that is a good example on how flexibility is getting into gpu architecture, but it also shows that it needs a lot of time for new features to become fast. 

basically that's because nvidia cannot say something like: "ok our new graphics card can do geometry shader very fast now, but we dropped half of our pixel fill rate"
the similarity to haskell is not by accident.  have a look at [jeremy siek](http://ece.colorado.edu/~siek/)'s papers, especially [essential language support for generic programming](http://ece.colorado.edu/~siek/pubs/pubs/2005/siek05_fg_pldi.pdf).  he clearly knows fl type systems very well.
also, number of second cousins please
often people who try to become smarter are just becoming more stupid.
having waded through the thread, yes, you're right. but your weird notation isn't doing you any favours.

to paraphrase:

&gt; array&lt;turtle&gt; can't be a subtype of
&gt; array&lt;animal&gt;, because then it's not
&gt; necessarily legal to insert an elephant
&gt; into an array&lt;animal&gt;.

&gt; and array&lt;animal&gt; can't be a subtype of
&gt; array&lt;turtle&gt;, because then you can't
&gt; guarantee that popping an array&lt;turtle&gt;
&gt; will give you turtles. 

which is fair enough.

my conclusion: array&lt;turtle&gt; is only a subtype of array&lt;animal&gt; if it's read-only. and array&lt;animal&gt; is only a subtype of array&lt;turtle&gt; if it's write-only.   
it won't compile on my computer. throws me this error:

xmonad.hs:67:5:
    no instance for (read rectangle)
      arising from the 'deriving' clause of a data type declaration
      at xmonad.hs:67:5
    possible fix: add an instance declaration for (read rectangle)
    when deriving the instance for `read screendetail'

now i'm sad.
      orders.each { | order | ... }

or 

    for (order order : orders) {...}

zomg!! the difference! there are real advantages to languages such as ruby and python. don't waste our time with trivial crap like this. 

edit: map, fold etc. are useful. but that is nothing to do with this idiots point.
just curious, why are you a programmer?
utter bullshit. 
if that's from darcs, try the tarball.
list comprehensions suck. for nested loops they are written in the wrong order.
 &gt; a large number of such loops i've seen are really trying to do one of three things:

or one of one things since filtering and mapping are special cases of reduction. 
actually it is tarball i'm trying to compile. i had no such problem with 0.3.
...didn't stop your father did it?

who'd have thought trolling felt so good :-)

*edit: thank you mr. grammar nazi*
the original post is not about higher order abstraction. it is about a minor syntactic difference.
absolute freedom to create anything you want on the abstract level, while possibly having substantial real world impact with it. the limit is your capabilites and your time, nothing else.
gah, so do i. mine emails me -- *from beyond the grave*.
simply because i love solving the types of problems writing software presents.
&gt; the loop spells out just what you're going to do.

and hof iterators don't? i think you lost me there.

i mean, let's take a regular loop:

    for(string s: stringarray)

what does it say about what you're going to do? nothing at all, you could be performing an action, mapping, filtering, whatever

    stringarray.each

that already tells me something: this is going to perform an action (side-effectful usually, since i don't care about the return value), and it's very different than if i had

    stringarray.map

which would perform a (usually side-effect less) transformation over each element of the list or

    stringarray.filter

which would only select some of the list's elements.

ok, so from the start whatever the case you're in, hof iterators tell you more than a for-loop *before you even reached the loop body*.

now let's check the loop body

    println(s);

versus

    println

yeess, i can see how the loop *spells out just what you're going to do* much better than the hof iterator... (or not, sorry)
money
excellent article. the part about not needing to know the genre in the netflix algorithm is fascinating.
write-only arrays. hmm.... an interesting concept.

thinking about this further, if you're treating an array&lt;animal&gt; as an array&lt;turtle&gt;, then it ought to be legal to get the length of it, delete it, clear it, etc - basically anything you could do to a generic array&lt;foo&gt; should be legal.

the only thing you _can't_ do is get a turtle out of it (because you might unexpectedly get an elephant instead).

perhaps array&lt;writeonly turtle&gt; is a good notation for this? the array itself is not writeonly, only the elements are.   
...except the halting problem =)
  i find the whole process of getting the program out of my head and onto the computer very fascinating. i picked up a basic book in the library when i was a kid (i had no computer at the time, or regular access to one) and i ended up solving all the exercises at the end of the chapters on paper. i guess that makes it love at first sight :) also i now despise basic, especially its visual reincarnation  
&gt; lambda support

[take a look here](http://en.wikipedia.org/wiki/c%2b%2b0x#lambda_functions_and_expressions)
pays the bills for my family and always new problems to solve.
how did you start your 6 year old in programing.  just curious.  i have a 6 year old of my own that i think would really get a kick out it, but i haven't decided how to get him started.
i've been using linux for years, and i can't say i've had to do any of that stuff on the desktop.

i wonder how many under 11s can install windows, and secure it to the point where they can surf the web and not become a spam bot.
i love to create something others use on daily bases but have no idea how or even why it works. 

i also like to solve other people problems and/or make their job easier with a tiny perl script or a php-interface. 

oh, and it pays the bills :)
penis too small for porn.
value of courage is about acknowledging the fact that the best way to produce the best possible products is to be honest and transparent on all the possible levels from customer communication to the way you type code despite how uncomfortable the idea of high transparency might look like from the beginning. the courage is needed to admit the team and organization weaknesses
i've been using [project euler](http://projecteuler.net/) to learn haskell.
i was young and i needed the money...

... then i started to like it - both the money and programming.

now i'm addicted.

`... smell like haskell type classes`

oh no! this is, in fact, a goodthing. haskell type classes are doingitright.

now if only ms could see this and extend .net generic constraints to be equally flexible. then we'd be cooking with gas.
having been an ion zealot, finally trying wmii has made me realise that the latter is much more productive. try it!
indoor work with no heavy lifting.
huh?

you're replying to an argument i never made.

cool.
i half agree too, i'd not argue either case with true conviction.

i was trying to think of a mainstream app that has not been bloated with age and can only think of internet explorer. compared to **my** install of firefox it is positively svelte.
*some* people do.

the ones writing software that doesn't involve recursive factorial or quicksort or monad combinators.
haskell type classes smell like c++ concepts.

garbage collection in c++ will never happen.

thus, anything that requires gc will never be in the standard.

&gt;i can understand people feeling one or another about what the default is(gc or no gc) but i don't get it not being mandatory.

i wasn't at the kona talks, but from what i've been told, gc will not be in the standard. it may be in a technical report. of course, people can still link against libgc if they really want that functionality now.
because i'm good at it and it is really easy for me.  i just happen to think in the way that programming comes naturally.  

it also helps that the money is really good.
that's why i fell in love with programming and how i got my degree but now i've lost some of the passion. it may be due to the tedious bug fixing i'm doing. now i do it because of the money.
simply for the enjoyment of learning and the satisfaction i get when my program works
because i like logic problems and having a pretty well paid job :)
  because language support of concepts yields much more clear compiler error messages! have a look at the [conceptgcc](http://www.generic-programming.org/software/conceptgcc/) page:

    #include &lt;list&gt;
    #include &lt;algorithm&gt;
    using namespace std;
    
    void f() {
      list&lt;int&gt; l;
      sort(l.begin(), l.end());
    }

yields

    sort.cpp: in function 'void f()':
    sort.cpp:7: error: no matching function for call to 'sort(std::_list_iterator&lt;int&gt;, std::_list_iterator&lt;int&gt;)'
    &lt;path&gt;: note: candidates are: void std::sort(_iter, _iter) [with _iter = std::_list_iterator&lt;int&gt;] &lt;where clause&gt;
    sort.cpp:7: note:   no concept map for requirement 'std::mutablerandomaccessiterator&lt;std::_list_iterator&lt;int&gt; &gt;'  
"for each" in vb.net is sooo much better than the for loop. i seem write a few every week.

dim total as int32 = 0

for each subtotal as int32 in elements
  total += subtotal
24 ways to impress your *geek* friends
several reasons

* it's synthesis and composition, you get to design and build things that people use.  i like making things.

* still a relatively new field that is evolving quickly.  i like learning and discovering new things, keeps the mind sharp.

* the pay ain't bad.  people actually pay me to do it.

* hell, there is an outside chance that i might either discover or create something that no one ever thought of before. 

* i get a rush when the damn things work, and work as i intended them to work.

* i'm too ugly for movies or tv, and i can't play musical instruments or sing worth a damn.



dads at war where would i be without you dad? my hero of night and day i'm so glad you love my mother, and take time for us each day.
&gt; if the cart ain't moving fast enough for you, why don't you get out and push?

i didn't say i wanted abcl to be moving faster: just that kawa was way way ahead.
to try and takeover the world!! muhahahah...
why oh why do people do video interviews? i was interested in the subject but i'm not going to sit through a crappy video.
it's mathematics that executes on a computer.  that's kind of awesome.  it took haskell to make me realize i actually liked programming, but i enjoy working in most languages now.
i like to fix problems and i am lazy, so i'd rather have someone/something else actually do the mechanical work.
 its fun.

i like making things.

it's been my hobby since i was 8.

getting paid to have fun and make things whilst doing your hobby is pretty rare in the "real world"  
you meant "(and pay for)"
i was replying to "[haskell] attempts to impose a background in category theory on the user in order to explain how to open a file."

it doesn't.
i fell into it by accident after college, and after i met all the different people who worked in software, i quickly came to the conclusion that programming was where i wanted to be.  no one else in a software company really knows what they are talking about in a technical sense, at the level of understanding i wanted.  
i was an anthropologist (specializing in human genetics), and during my thesis work i did a bunch of monte carlo simulations for various purposes. i had taken some programming courses before (i was a math major undergrad), and done well, but i really fell in love with programming while working on my thesis. meanwhile, i fell out of love with the idea of working as an academic; i worked as a post-doc for a while, but then jumped into programming when an opportunity came up. and i've been doing it ever since.

the thing i like best about it is that there is always something new to learn. the thing i like least about it is getting mired in working on messy problems with crummy tools. but on balance it was a great career switch for me, and not coming in through the front door gave me the opportunity to teach myself lots of things (most of which we'll never use. oh, well...).
because i have an affinity for computers and i would like nothing more than to optimize programs.
i am not a programmer!
  how about urls should be concise? 

i like the way aaronsw does it on his blog. here are some recent permalinks for example:

 - http://www.aaronsw.com/weblog/dearcolleagues
 - http://www.aaronsw.com/weblog/publicspeaking
 - http://www.aaronsw.com/weblog/rachelcarson
 - http://www.aaronsw.com/weblog/sweatsmall

see? concise, descriptive, easy to remember, simple.
&gt;however, i know that developerworks articles on java are just as bad, if not worse. hell, any developerworks article, on any topic, is usually extremely useless, misleading and poorly written.

thanks god...at last, someone has mentioned this absolute truth
yep. this.
also because i grew up obsessed with computers and making them do things my way.

they very rarely do though.
i agree...i'm lazy.  thats why i'm a programmer.
i'm sorry, but doesn't all this rather smell like ocaml or sml modules?

    module type inputiterator = sig
      type iter
      type value
      include regular(struct type t = iter end)
      val ( * ) : iter -&gt; unit
      val incr : iter -&gt; iter
      val ( ++ ) : iter -&gt; int -&gt; iter
    end 
since the tag line is "ruby on rails for .net developers" i guess it refers to people who are micro and soft.
there was this hot girl in the computer science department. i just followed her footsteps.
i'm torn between bazaar and mercurial. i like bazaar better because when i try and merge in a patch (instead of pulling a full revision history) it tends to just work whereas, for me, mercurial keeps generating conflicts where there are none. maybe i'm doing something wrong. the reason i'm torn is that mercurial is a really nice tool and it's probably getting the greatest mind-share these days and i want to use something others will have (of course, thanks to [sscm](http://sscm.masukomi.org/), my repos are now maintained in darcs, mercurial, git, and bazaar). i actually really like git too but you can't easily run it on anything other than linux and the interface just isn't to a point where your average programmer isn't going to encounter issues. darcs has an awesome interface but is slower than molasses ( relatively speaking) and has given me enough problems that i've stopped using it except via sscm.
sony ericsson w series mobile phones are the best music phones, among a huge list of phone models from mobile manufacturers globally. the power-packed walkman series is adorned with amazing music phones.
good one
humorously, java 7 closures probably won't.
one word - mathematics. i love math.

true or false. it works or it doesn't (and most of the time it doesn't :p ). there are no gray areas.

when programming languages are broken down to their simplest form, they are nothing more than a simple mathematical operations. 

so, to give you a concrete answer; i love programming because it is mathematics made into a language.
pays pretty well and i don't have to work too hard.
when i was younger and still in highschool i was programming instead of doing my homework. then when i finished school, i got a job offer from a friend of mine. ever since i haven't done anything else, and the jobs have been great so far! i never regretted for even one second that i didn't study anything.
this was all i could find.

http://blogs.codegear.com/abauer/2007/10/04/38829/

the relevant bit...

&gt; next discussion is more informal and is related to garbage collection… should be interesting.  apparently there will be a minimal specification of garbage collection in the next standard (at least at this point).  main sticking points are about obscured pointers, leak detection, and destructors.  no, no… gc, as defined in the original proposal, is not in.

maybe i'll find out today.  stroustrup is giving a talk today at university of houston on c++0x.  they have a live webcast( http://www.cs.uh.edu/events/2007.10.19_sec/webcast.shtml ) but i'm not sure if his talk is going to be included.


i think this ranks as black hat seo.

for instance, like the url's must be hackable part.  but, take a look at the url of this article.  how can i modify it to get to the previous article?  i can't.  then check out the url's at flickr or google.  most of them can be modified to do what you want.  an example is zooming to level 23 on google maps.  i just think that the person who wrote this would say that's bad url design, when i believe if you are worried about url design, the rest of you site will be lacking.
as chak already noted, ml and haskell were part of the inspiration for the current proposal.
i really remember being sick to the teeth of writing for loops in c++.  tedious and error prone when you even have a little bit of nesting.

it really did feel like drudgery:
 http://psychicorigami.com/2007/07/31/termination-condition/
i became a programmer because i am bad a certain types of maths. i was always good at applied maths but bad at pure, astract maths. i enjoyed maths but not being able to "see" the maths at work is a bit of a problem. enter the computer, not only will it do the tedious maths  for me but i can imagine the bits flipping and "see" the maths at work.
note what rhoomba says: the author gets wood for

    array.each { |x| ... }

which is basically just some weird ruby syntactic shuffling.  and i'd say the "amount" is many gallons, or liters (or cubic meters?) less than what you find "quite disheartening", certainly much less than the amount of people who mindlessly parrot lisp/haskell/erlang (or even factor!) propaganda.
can we just say "seem" or is it because there isn't a noun form of seems?   
  
new c++ concepts seem like haskell type classes.
avi++

this quote is the gem of the entire post:

&gt; what giles glosses over is how you come to understand the code in the first place. nothing helps you understand code - whether you wrote it or someone else did - better than stepping through it in a debugger.
i too failed "the pencil test" :-/
i love the freedom to create - i'm a terrible drawer and musician, but i can create wonderful things that are useful to others.
laziness is one of the virtues of a good programmer!
...and now you want a cookie?
ianap?
because i have nowhere else to go
&gt; i must say it's much easier to code javascript on a whiteboard than c++.

we're still working on the compiler back-end.
when confronted with this article, you can either (1) read it and respond, or (2) use it as a jumping-off point to the same tired harangue about macros/hofs/dry that i've only read hundreds of times on reddit.  unfortunately you chose (2).  will your next move be "macros are go(o)d," "drydrydry", or "omg haskell catamorphisms"?
i.e. "lusers", muarhaa haaa haaa haa
i really don't know to do anything else, so...
each reduction increases the hylomorphic complexity of the function.  so?
i couldn't tell if there were links in the text or my astigmatism had gotten worse.
\*yawn\*
there will always be problems to solve in the world even though management believes that they don't need programmers in 5 years. (in a telco .. riiiight!)

it is strangely fun, to take complicated processes and automate them... 
agreed, i came in this comments page just to make sure someone was pointing out that glaring mistake. he also mentions the apache collections libraries...i guess he's never heard of java.util.iterator. 
it's incredible how redundant the information we take to be essential is. i recently wrote an image classifier which functioned roughly similarly to his netflix design (data similarity measured as proximity in a high-dimensional space), what struck me about it was how semantics emerged from a relatively bare structure.
(defun praise-emacs nil
  (interactive)
  (message "hail emacs")
)


there ya, go! :-)
and i've been drinking the [beer of kings](http://www.budvar.cz/en/web/produkty/svetly-lezak.html) for fifty ... 
i'm new to ubuntu, didn't know you could do that.  thanks a ton.
yeah but... everybody thinks that they are the best in the world.  nothing surprising or wrong with that.


put a bunch of people in the same profession in the same place and they will tell each other how great they all are.


truck driving would probably be somewhere below physics and engineering... but i'm sure that they are all sure that they have the whole world figured out.


reddit is just a truck stop.  for fucktards.
i hate you. (as another new englander, who happens to have recently acquired an allergy to lobster)
&gt; i was young, and needed the money.

&gt; i had money, but i needed more!

&gt; i was filthy rich, and all i wanted was love (and a little more money.)

 ~ steve taylor *cash cow*    
the author could not write a simple stack-based max word? i have a hard time believing this, as it is trivial:

: max 2dup &gt; if drop else nip then ;
i was having so many problems with xp so a few days ago i decided to switch.  as i was downloading the torrent for ubuntu, windows blue screened on me.  

i think it knew i was planning to betray it.
you mean giraffe\[\] and animal\[\]?
you sir, fail at satire.
of course.   the larger point is if you sit too close the music doens't blend right, and too far back you can't hear as well.   some halls are better than others, and i doubt that anyone can hear the difference between 10th and 11th row, or off by a couple seats from dead center, in a "standard" hall.     however there is one best seat even if you cannot tell the difference between it and second best. 
the reddit union got you.
last union i knew well was screwing the employees it supposedly "protected".  all in all, they got 10 cents over minimum wage and paid 30+ cents out of every hour in union dues.  they were prevented from getting state health care because they had company health care that triggered after two years (and cost almost half of their paycheck).  they were protected from termination based solely upon seniority and activity in the union, and never the least bit on whether they had earned termination or not.
being able to visualize that data set would be nice... if its possible to represent items positioned on 12 axis on a 2d monitor.
beats working.
url optimization is nowhere near black hat.
because i love to code.
even better: know both!

but please note: c-x c-s will make vi/m stop talking to you, for some reason..

if my locally installed emacs can reach the files i want to edit (via tramp) i'll use emacs. 

if i have to edit files on a system that i have reached via a step stone, i'll happily use vim or vi if it gives me a chance to do my stuff. 

anything to get the job done.


try to explain that to human resources
it's like making things, but with undo.

don't you hate it when you dismantle half a device to find the problem is somewhere else, undo! undo! undo! it never comes back together.
one of the fundamental design principles of c++, as i understand it, is that "you don't pay for what you don't use", i.e., if you add feature x to the language, it has to be implemented in a way so that programs that never use x do not become less efficient.

making garbage collection mandatory in c++ would incur a speed and/or memory-usage penalty for programs that continued to rely on explicit memory management.
because it's sterile and i like the taste.
 but dropping the requirement to type variables wouldn't get rid of the inconsistencies here. whatever type inference engine you have is ultimately going to have to assign types to everything, and you'll end up with the same problems. to avoid the paradox you'd have to change the type system.
&gt; let's say a programmer invented the toilet. there would be a handle for the water level in the tank, how many gallons per flush, an adjuster for how far the flusher had to be pressed, a sensor to tell if a male or female is sitting and will automatically place the seat down, a button to inject the tank with blue disinfectant, a bowl windshield-wiper button, a "number one" mode and a "number two" mode, etc.

you haven't tried a japanese toilet then, have you? :)
been said numerous times here already, but i see it as my opportunity to be creative and solve problems without having an "artistic" bone in my body.  it's nearly constantly intellectually stimulating, and when something gets boring, there's always something new on the horizon to challenge you.
  you're not making any sense. why is preprocessing the python assert statement more difficult using parser combinators than using some other approach? you do realize that it's perfectly possible to manipulate the parse tree after it's been created by running your combinator parser.
i do know what it is.  but that's different than trying to directly shoehorn it into the clr, like past implementations of ruby on .net have done.
 no, no, since we are talking about reference types of c#, *type[]* in c# is kind-of equivalent to type_*_* in c++. 
i always knew i wanted to be a programmer, but never quite understood why.

i keep doing it because i love learning, and there are so many new and interesting things to learn in our field.
there are lots of names missing.  for starters, many good programmers don't seak out the lime light, so if you don't work with them you don't know about them.   their projects are great (at least the part they do), but not well known, and may be specalized stuff that won't get well known.
ah. well that makes sense. as i said in my original comment i'm really not versed in all the relations between copyright/licensing/etc.

thanks.

but it still makes me wonder. infact, if you look at the site at the very bottom is a q/a section that says, in effect, "if you dont like the license just relicense it under some other license you like"... so i don't know, maybe the addendum is unnecessary but in this case it looks like they're explicitly allowing you to change the license... maybe all you'd have left then is internet timestamps, so you better make sure your code is on google code or sourceforge or something eh? :p
&gt; the author could not write a simple stack-based max word?

the author has learned as much as a wikipedia article accidentally taught -- which is to say, the author hasn't even started on a tutorial.  i've then an easy time believing this.
there are valid complaints against recursion: almost all programmers can understand a well-written loop on first sight.  mediocre programmers cannot understand well-written functional-style recursion on the first sight.  a great many programmers cannot understand well-written arbitrary recursion (not designed with lambda calculus in mind) on first sight.)

please drop the worthless arguments ;)
what are we going to do tomorrow night? :p
fame, blingbling and the jetset livestyle...
high money to effort ratio
i'm a geek.
i think there won't be a management layer in 5 years. 

we simply replace them by a bunch of bpel and rules engine or simply a 1kb shell script...
while (true){
    idle();
}
// :)
this actually looks a lot more like c# interfaces than haskell type classes.  they're both similar to begin with, but this seems more like a c# ripoff than a haskell ripoff.
are you pondering what i'm pondering? :)
"even peter norvig needs ten years to learn a new language."

how idiotic. i stopped reading right there.
yeah, been there.  a post not too long back included a java snippet and showed how much easier it was to write the same code in python.   i saw like a dozen obvious improvements to the java code so i submitted the simpler java code to his blog comments section.  the comment was quickly deleted.
i think so, but this time you wear the tutu.
i played ultima 5 as a small child, spent a day daydreaming up praise for the origin team -- how tediously they must have composed every possible tiled image in the game! -- and then my dad got me an hp48g.

to answer the "how did you start programming?" question you didn't ask, as i can't say that i 'am' a programmer.  to answer the "why do you still program?" question you didn't ask: it is a skill that i enjoy applying, that i've gotten considerable use out of, and that i enjoy advancing.  there's also an important investment angle -- not in the sense that i'll lose out if the skill atrophies, but in the sense that i've developed it to the point where i frequently discover that i can apply it to some new problem that occurs to me.  or that i *nearly* can, which means that i invest more in the skill.  if programming were a bad thing, i'd call it its own slippery slope.
&gt; avi++

i don't think avi would appreciate something that close to c++, even if it is a complement... ;)
modern functional programming languages have much better cross-platform support, performance, reliability and many other features.

i'm sure you would find it much easier to just learn the modern approaches and forget about lisp altogether...

1- is basically

: 1- 1 - ;

but in most systems it's optimized (using e.g. a specific "subtract one" assembly instruction). 1- is better than 1 - in all cases, i'd say
the costs are relatively low (just time and effort for the most part) and the rewards can be extremely high.
what the hell does this have to do with programming?
&gt; titles (converted to a readable slug format so that those nasty %20 things aren’t visible everywhere) 

i understand the concept but have never heard the terminology "slug format" can anyone enlighten me?

first for the money, after i switched from php (yeah, i know, i wasn't really a programmer back then :) ) to python because i liked it. i still like it. 
go study your nlp. you are visual, author is olfactory. ;-)
 and your shoe size 
dissatisfaction with the design and quality of software today and a drive to create things.
 hopefully this will be of use to someone wondering, as i once did, how dynamically generated sites (php, perl, asp) maintain static urls.

if you are using apache put this into your .htaccess file:

rewriterule ^([a-za-z0-9_-]+)?/?([a-za-z0-9_-]+)?/?$ /index.php?section=$1&amp;page=$2 [qsa]

what this does is allow you to have
http://www.yoursite.com/news_and_events/mudkipz
which internally will be
/index.php?section=news_and_events&amp;page=mudkipz
 
[edit] the underscores around the and in news  and events were replaced with italics
the principle which is, by the way, broken by stack maintenance required by the mere existence of exceptions.
no social skills.
well, i got it working. i had x11-extras 0.4 installed somehow wrong but after i cleaned it and reinstalled, xmonad compiled just fine. actually from darcs this time... but if someone has this problem, try to clean your x11-extras and reinstall it. quite helpful people on #xmonad@freenode btw :)
i so hear you - i bang my head against c++'s limitations every day and i feel my product has outgrown it. and i'm talking millions of lines of code here, not a pet project.
"gtfo"  lmao!.
i don't get it.  i mean, you don't ever have to write for loops in c++.  you could write any *for* loop as a *do* or a *while* loop, not that you would want to do that.  anyway, just seems like an odd thing to complain about.  to process data, you have to loop through it.
i agree. haskell has many interesting features but performance is not among them.

i'd much rather the haskell community just admit that haskell does not provide the same optimization potential as c++/ocaml etc., rather than pretend that performance is always unimportant.

they should either do that or optimize the haskell implementations on the ray tracer language comparison...

i'm going to add hasty hyena, which isn't currently on there. this post is my certificate of authenticity, in case it is later picked. :)
no reason; it's just the way i am
i don't know.

i said "nearly" though. for example, erlang doesn't allow you to directly reference to a regular function, you have to make it into a fun (`fun foo/1` instead of just `foo`) and in ruby if you want to use a method as a block/proc you have to convert it (e.g. if you have a `foo` method/function defined through `def` you write `[1,2,3].each &amp;method(:foo)`)
what are these 'modern' functional programming languages of which you speak? ml and so forth? common lisp isn't really _that_ archaic, and it's certainly competitive as far as reliability and performance go...
you mean haskell has philippa and the other fpls have nobody? ;-)

pics or it didn't happen.
then why is optimized haskell 3x slower than the fastest languages on the ray tracer language comparison?
 i didn't see *any* binaries on the xmonad page.

maybe they're still updating their site? 

disregard that, i am a moron.
save some for the rest of us
rubbish! haskell does not provide the same optimization opportunities as almost all other compiled languages (c, c++, ocaml, f#, c#, java etc.).

just like python, haskell can be competitively fast at certain operations but it is not uniformly fast.

i think haskell will get a bad name quite quickly if its community keep trying to pretend otherwise.

as a programmer i can work in nearly any other profession.  robotics, medicine, research, business, entertainment.  it is all open to me.  what other profession offers so many choices.
makes sense? why? because poop is brown?
well put.

i feel the same way: i wanted to create but don't have extraordinary fine motor skills, so art was out.  i didn't want to make a plane that crashed or a building that collapsed, so that ruled out most engineering.

i just hope my content management system doesn't kill someone...
yes. don't forget that haskellers don't take nomenclature to have its conventional meaning: they have their own set of definitions. ask them what "functional programming" is, for example...

&gt;imagine showing a modern computer to a person who has never even seen a mechanical clock, an electric light bulb or a pocket calculator: you would expect the person to be convinced that it must work by magic.

that was my grandma's reaction to computers - they were powered by magic.  i didn't even try to explain that they weren't magic - she didn't even understand calculators (she could balance a checkbook, but that was about the extent of her math prowess).  calculators were magic as well.

--

*sigh*


&gt; i believe if you are worried about url design, the rest of you site will be lacking.

this is a silly statement.

url's play a big part of any seo tactics.
it's up there with keyword density and meta tagging.
  a slug is a short (temporary) name or title to refer to an article.  it comes from [the newspaper business](http://en.wikipedia.org/wiki/slug_%28production%29).  
yea, i became a programmer to be where all the hot girls are.
what book are you using?
this actually came about, cause of a thread on erlang-questions where someone asked about erlang vs. o'caml, and mr. ippolito responded in the list archived here: 


http://article.gmane.org/gmane.comp.lang.erlang.general/24715  
i am a programmer because i enjoy ..... who am i kidding...it's because i suck at everything else...
amen
well, yeah brain, but where are we gonna find rubber pants our size?
what i'm saying is, if you worry about any seo tactic, your site will be lacking.  i'm sure url's play a big part in seo tactics.  at the end of the day, seo tactics don't mean much.  sure you need a site that can be indexed, but beyond that, content is king.

sure, write good code, have it validate, have it be readable.

i wouldn't worry about keywords to much.  at the end of the day, you have great content, you have a great application, or you don't.  if you have enjoyable or insightful content, people will visit.  if you have a solid application, people will visit.  keywords and a fancy url won't get you very far. 
while (true) { fork(); } // &gt;:)
tableau software has a great visual analytical/reporting tool that can take most types of datasets. for the back end, hyperion + oracle maybe? microsoft reporting services integrates well if you want to automate report generation since they use xml to define their reports. you can write code in c# or vb to handle the automation for you. sql server also ships with analysis server for you to build cubes with.
for the chicks.
the pay is utterly absurd if you make the right connections.
same here.  it's like building with legos, but i have infinite pieces. :d
    puts stringarray

:)
here's hoping the next version of c/c++/java/etc. supports the each statement, as well as: stringarray.reverseeach(...), stringarray.everyothereach(...), and everyone's favorite stringarray.reverseeveryhundretheach(...)?
by accident!?

in childhood, i was good at maths, physics, chemistry. started high school to be a radio/tv/video technician (but that was really more of a preparation class for electrical engineering at the university).

started ee at the uni, but preferred maths and circuit theory to "practical" electronics (main high school subject). got much better with impulse electronics, then kinda moved to automatic control systems, then to programming in this field. that, mostly due to a couple of good programming courses. (incidentally, ones that actually used c were the worst. understood memory and pointers in (gasp!) pascal-based courses).

for life, in and out, doing programming for industrial automatic control systems. like it fine. pay isn't great (i envy friends working in finance), but current employer is best so far, really.
you got it wrong, you put that on your resume, not here. ;-)
enter a comment here
 in more academic terms, what the poster means by urls being "hackable" is that urls need to be orthogonal.  there should be enough consistency so that users can "re-mix" a url in meaningful ways.  (for laypeople out there: this is also a desirable quality for most computational systems, including programming languages.)  
yes, but `avi increment` doesn't have quite the same meaning. :) 
the point is not that you need to loop through your data to process it, but that you shouldn't teed to worry about setting that up, or how it works.  

the language should be smart/organized  enough that you can simply *tell* it to apply a block of code to each item in a collection, and then the language will automatically know how to use iterators/closures/etc to apply that block of code to each element.  

to the programmer, they spend more time telling the computer *what* to do, rather than *how* to do each individual task.
i'm too lazy to work for a living.


one woman's struggle against (*insert socio-political hot potato*).
enter a comment here
it's different if you say "with elements in loop do 'something'", or if you say "over this loop, do with element 'something'".  you have to create a new function with a new parameter, while looping constructs *automatically* bind the variable for you, so you don't have to write ugly blocks/functions/lambdas.
you might need more than just println.  in that case you can either simply write another line into the loop body, or you need to create a closure, which is slightly more inconvenient and less readable, imho.  you may of course disagree, but that's my stance (and it seems to be mr. van rossum's choice, too).
i feel like i should be modding this _sideways_ or something.
oh, duh; i didn't even read your whole message i guess :/
being idiomatic is a little overrated.  you can still use whatever idioms your preferred language provides, but the application object just uses straight method calls, which are available in almost every scripting language anyway.

as far as third-party apis go, you don't care what language they're written in, because they look like objects in your native language when you use them.
it's this sort of mad scientist type work that keeps me programming in perl. 
yeah.  but if we sided with the runner beans the lima beans won't have a chance!
well i'm relatively new to the world of programming, having only been seriously coding for 4 years or so. from what i've read about coding in the real world (i'm a student), it sounds like it could be easy to become disillusioned. i just hope it doesn't happen to me.
"slug format" in this instance basically refers to converting blog-style titles, like **i had a nice day** to friendly urls, like **i-had-a-nice-day**. otherwise, it would read **i%20had%20a%20nice%20day**, a url full of strange characters and case-sensitive words.
while it's true that some standard optimizations are more difficult because of laziness, it's also the case that there are some new ones that are only valid with laziness.  an example is deforestation of list processing.

why, it's just generic programming (ok, not really, but *templates*) with type constraints, i.e., restricted polymorphism.

seems like a pretty normal idea to me, good, but not outstanding in a way like it takes a genius (or a haskell wizard).

java and probably c# also allow you to constrain type variables, like "class &lt;t implements bla&gt;", which is very similar to tfa's concepts.  whooohoo, interfaces are clearly something that turns my whole world upside down.
linux doesn't have to be the default os for everyone.  i just want linux to be the best os for me.
well, now you know... ubuntu releases a new version every 6 months.
hello, would you like to connect?
&gt; in that case you can either simply write another line into the loop body

wrong, in the way you wrote it you also need to add the brace or you get yourself a wonderful bug.

&gt; or you need to create a closure, which is slightly more inconvenient and less readable, imho

less readable than just sending the function? of course, there are 2 lines and a level of indirection. less readable than the for loop? i strongly disagree.
at 9, girls would not talk to me; so i learned to code in basic on a trs-80 mc-10. i stopped programming 5 years ago and dedicated to network and pc tech support.

went from basic -&gt; quickbasic -&gt; gwbasic -&gt; dbase iii+ -&gt; pascal -&gt; c -&gt; visualbasic -&gt; c++. i learned others, but these are the ones i could say i 'know'.

learning how to code in one or two languages really helps you know how to read other languages.
[pagii](http://www.pagii.com/) is using it.
i learned it from watching you, ok? sob!
&gt; it's different if you say "with elements in loop do 'something'", or if you say "over this loop, do with element 'something'"

i'm not sure i understood what you said. but no.

&gt; while looping constructs automatically bind the variable for you

it doesn't, the binding is included in the looping statement which is very different, and size of that binding is pretty much the same as in a closure:

    for(string s: stringarray) {
        dosomething(s)
        dosomethingelse(s)
    }

versus

    stringarray.each do |string s|
        dosomething(s)
        dosomethingelse(s)
    end


but it's true! :(
sure. i was making an observation rather than trying to refute your point.
i'm not really a programmer, but i've  known i wanted to do computing since i was eight or so. it wasn't until i was a senior in college that i realized this was unusual.

i find the infinite building and abstractions neat. the fundental primacy of process is... great.
a fix has been pushed into the darcs branch.
i would if i could be bothered. their office is 2 floors away!
 yay for the w3c: http://www.w3.org/provider/style/uri - cool uris don't change. much of the same with some additional hints to what might be a good and a bad thing to have in an ur[i|l] 
debuggers always seemed like a solution looking for a problem to me. 

most of the bugs i make are the result of incomplete understandings of language features and library functions. because of that, i go into the debugger with incorrect preconceptions of what i'm supposed to be doing, beat at the problem for a while, give up, read the documentation, isolate the problem in a unit test or dummy program, and then fix it. it took me a while to realize that the first step in that process almost never tells me what i need to fix.

i'm sure there's some case out there where a debugger is the most useful way to fix something, but i really can't come up with it.
&gt; aside: i wrote a quick test program to see the output and holy crap i forgot how picky c is. i had to google to get rid of all the warnings!

for some reason that clears up a lot for me.
for many it is a job.  for others like myself we're programmers because that is what we are.

similar to artist or musician who paints or sings.  and will regardless of whether it makes money, is popular, socially acceptable, etc.
   best way to make a racing game fun: consistent ai performance.  nothing pisses me off more than racing games where, given the same car and the same opponents on the same track, if you win, it's always by approximately the same margin (i.e., when you drive better, the opponents magically get better too, so the only indication that your skills are improving is faster lap times.)  

that's one of the things i love about gran turismo, and it generalizes to all kinds of games (for instance, rpg's where all the monsters in the world dynamically toughen up along with your character - the only way you improve your character in any meaningful way is by collecting better gear, and so it's no more an rpg than super mario bros. 3).  

can you imagine what a colossal failure ddr would have been if it dynamically added steps based on your performance, so that no matter what song you picked or what your skill level was, 'perfect' was always damn-near impossible, but a b was pretty much achievable by anyone on any song? 
i thought about that, but didnt think reddit would allow you to produce h_n_ tags in your comments ... 
that's kind of sad. the other day i corrected an entry in the perl -&gt; python phrase book. the perl code opened a file or died with an error message. the python code caught an ioerror exception and then tossed out a "could not find file" message. fortunately python has sane error messages and so that's unnecessary (ioerror gives a "could not find file or directory" message).
cause i lucked into a "programmer trainee" job the month after i got married, 9 years ago, and my salary has more or less steadily increased to where i command 4 times what i did originally.

and, oh yeah: i love programming ;)
  ... from last year. 

still a good read tho.
check out [rescue time](http://www.rescuetime.com/). [they seem](http://blog.rescuetime.com/2007/09/26/diy-web-marketing-16-resources-for-seo-social-media-marketing-viral-marketing/) to worry about [seo stuff](http://www.tonywright.com/category/seo/) but their product is kickass in any case.
what about...

    avi += 1

or

    (set! avi (+ avi 1))

or

    (incf avi)
i think a lot of people have trouble with whiteboard coding because they can't, in general, write correct code without compiling it and testing it as they go along.  the important thing to remember is that the interviewer can't write correct code that way either, and they know it.  the point of the whiteboard coding exercise is not to write correct code, it's to convince the interviewer that you *can* write correct code given access to tools and the proper amount of time.
i am to impatient to talk to people from human resources ... ultimately, that will probably be my hybris..

[quoth, larry wall](http://open.nit.ca/wiki/index.php?page=threeprogrammervirtues)

"premature optimisation is the root of all evil" my father always used to say. (not really :)
great idea! the deal with dell (a hardware vendor) has been quite successful for them. another hardware deal, under the right circumstances, could put them even further into the spotlight.
please note that i did not say anything about java.  i said "the type system of most functional languages is pretty much the same."  that is, haskell, clean, ml, miranda, etc.
it was kind of inevitable.  my dad brought home  some kind of ibm 286 when i was four or five years old.  i've basically been strapped to a desk chair ever since, getting up every once in a while to eat, exercise, sleep, and woo the ladies.

my brain decided for me.
didn't stop you from coaching the lakers and bulls, though.
hello world
programming is the closest thing to hermetic magic.
write some weird words, curse out loud, pray, and you'll be able to do anything.

programming is just beautiful.
i knew somebody was going to bring that up, but i think there's a qualitative difference.

vim, my editor of choice, keeps accruing features left and right, and yet i haven't noticed that the software is actually getting _worse_.
because it's the closest thing to gardening in the sky.
i dunno, i kind of like to have dinners at home with my family. eating dinner at google would likely mean getting home after baby sblinn's bedtime.
"there are no gray areas."

what about probability and statistics? :)
jwz doesn't code anymore 
 * it is written in java
 * the only thing i got when i tried this in ubuntu 7.10 was a grey window.
i meant i couldn't think of much free software that suffered from this kind of decay, not that i couldn't think of replacements for most of the list - i haven't used windows, other than on the job, in years.

anyway, if you want a free (windows) aim alternative that's _really_ non-bloated, try [miniaim](http://miniaim.net/).
you certainly don't know how to write ;p
of course.  or you use python, and simply add an indented line (just like in haskell, by the way).
&gt; stringarray.reverseeach(...)

your other examples might be more interesting, but surely this would simply be:

    stringarray.reverse().each(...)
that's right, in block-structured languages you can indent the function, so it looks almost like the block, but in lisp or ml that's not the case:

    (for-each stringarray
      (lambda (s)
        (do-this s)
        (do-that s)))

while

    (dolist (s stringlist)
      (do-this s)
      (do-that s))

ok, still not that bad, but you quickly end up with indentation spaghetti (imho), likewise in ml.

and by the way, iirc in scheme the for-each's function parameters are *reversed*, so you have to specify the function first, which is really inane.
tldr
you could file a bug report for your "grey window" problem...
and fantastically bad.
but maybe not "i am brian reid"
 you should have linked to my [official announcement](http://ygingras.net/b/2007/10/a-new-kind-of-wiki)
where i blame svn for all the problems.  blaming svn seems popular on reddit these days.  if you ask me, it's about time.
i can think of some enhancements for this. as you scroll forward in time, the code should go from brightly color coded syntax to a dull gray, and the font should become crusty and blurred. about one year into the time line, the speaker should start to play muffled screaming sounds. the only remaining thing that i'd like to see is odors of rotting meat based on code complexity, but that may be a bit tough to implement.
my point had nothing to do with smalltalk or debugging. just the irony that after all these years, if you want to get something done with the command line, the mac is a much better platform than windows.
not having the "bleeding edge" is worth not having to compile fucking everything from source.
this service hands out broken asf files (wrt mplayer)
exactly.  i went through a period where i tried pretty much every linux distro under the sun (and more than a couple bsd's), but i'm just too lazy to run anything other than ubuntu.  gentoo is fine for a hobby box, but it's really not for something you rely on every day.
where are all the "reply" buttons? i can't reply to anything!
which is hillarious because, in practice, sql is just a simplified language with a horrific syntax that increases in complexity far more quickly than can be imagined once you leave the most basic of queries
i first saw mention of [code smells](http://www.c2.com/cgi/wiki/wiki?codesmell) on the c2 wiki, where the phrase is attributed to kent beck.  and the metaphor is *supposed* to sound a little bit unpleasant.  a code smell is an indication of code that needs to be refactored or otherwise improved.

i think the poster's use of smell in the title has nothing to do with the code smell usage and is just common english usage that's probably been around for centuries.
that's the difference between artifacts (chairs) and natural kinds (pigs).  kids know this, and if you don't, it's time for you to take a class on lexical semantics.
well i was referring more to the shade of the human skin, which is really just a different shade of brown for all races. but poop works too.
quit your job.
why is programming hard?

or maybe the question is: why are some people (way) better at programming than others?

i have been a programmer type for 16 years and have worked with maybe a couple hundred programmers. and the variability in the quantity and quality of code that these people write is amazing.  in fact, in my experience that gap is much greater than brooks law, where some can program effortlessly and others just simply can’t do it at all.

the best i can describe the “gap” comes down to two fundamental attributes in the way that people think:

one is abstraction.  the people that can visualize or abstract the incredible complexity that is software seem to parse and program the solution in mere moments, where others simply cannot do it at all.

the other is mathematics.  what i mean is the general way that you think is either decision tree based (i.e. a binary type of person) or shades of grey.  if you think binary, programming comes easy, it is like solving a math equation – you know how the “formulas” work.  for people that think in shades of grey, well, programming seems really hard.

i know this is a generalization, but in my experience, it is these two specific attributes in the way people think that seem to explain the gap to me anyways.

great article!

interfaces put the burden on the callee, c++ concepts put it on the caller.
come back after solving the n-queens problem (for any natural number n in general).
code is sculpture. use an inspector.
well, let's think about it as a programmer.  for one, how vague do you want to go?  at a certain level of vagueness, you have to actually use randomness or arbitrary decision (with exhaustiveness if you want to make sure to be *eventually* right).  those principles exist and are absolutely hideous to use unless nothing else will do.

if you want to get even *more* vague (no clue what the method is, just the final goal), assuming that it's possible, you would sacrifice all understanding of the underlying system, which can not ever be perfect.  "func go_to_mcdonalds()" would require massive amounts of knowledge (nevermind common sense), as well as large amounts of time.  a human can fail to find mcdonalds, or end up so late it no longer matters.  a computer rarely has that freedom in the matter, and allowing it to wander blindly until it succeeds is insane.

less vague than rand or amb and we're talking about relaxing preconditions and asserting post-conditions.  very reasonable, but not definably better.
supply and demand.  being difficult just means you won't have infinite supply.
hey, man, no hard feelings, you just sometimes go all pompous about things ;) i'm not an expert, you're not an expert, we just program.
&gt;it's not like the solutions they came up with were great

i have to laugh for one simple reason...

&gt;“the program would have to temporarily mark seats that are being looked at … so that vendors couldn’t sell seats simultaneously”

this is what ticketmaster does.  seeing they're the de facto standard for ticket sales, please explain why this solution is so bad.

every solution makes sense from a simple standpoint.  some will not resolve simultaneous purchase, but most will.
your so right...i have to sharpen my stick every morning so i can beat off all of the chicks trying to hassle me for a date.
yes, that's good. and we're counting all non-stack data as heap there (not just allocated mem). global and static vars too.

so it's a setjmp without the limitation that you can't return from the function which called it.
you really don't know how to eat crabs until you master eating blue crabs, steamed, with plenty of old bay.  note that this is the way they're done in maryland, while the boiling of crabs (like in virginia) is an abomination unto nature itself.

preferably without needing a mallet.  i'm still torn on the knife issue.  suffice it to say, you should be able to be adequately fed if dropped onto a desert island for dinner with nothing but a bushel of steamed crabs, and maybe find a pointy rock and a flat rock...
why that?  if i call something with a typed/constrained parameter, i have to provide appropriate values.  this holds true for templates as well as for java methods/classes.
simplest solution just requires a seat-check at the end of the sale.

is a seat available? yes.
enact seat purchase. (first-come-first-serve)
is the seat sold to *my* customer? no.
inform customer the seat was sold.

of course, it's rude.  that's why seat-holding is usually used in a large enough scale.  when a ticketmaster kiosk offers me a ticket, they can hold it almost indefinitely.  when the webpage offers me a ticket, they hold it for a minute.  it's easy to use the above "sale" algorithm for seats to verify that only one site holds a ticket.

are professional programmers really so uneducated as to not be able to solve that in the blink of an eye?
&gt; why is my chair missing every time i'm away for more than 3 days??????

dropped by the main office today, for the first time in a couple of weeks.  found two chairs at my desk, but someone had taken the network cable.
well, your code can still run, but it might not halt.

(and by the way, many applications are supposed to run and run and run, but of course that often involves event loops or similar things that are supposed to halt)
if you assume that everybody will try to mess you around, assume you can deliver software to ridiculous time scales they make up, you'd be about right.

still, when you get into a good team, in the right company things can really swing.
no, it's dirty.

at least most of the time.
i see a pretty site, nice abstract, good line lengths, readable urls and...
&gt; url design is one of the most important areas of website design, not only do urls generally have huge visual priority in web browsers but they’re also shown on search result listings and get used for matching search terms; not to mention all the usability factors, what does a bunch of seemingly meaningless query strings and numerical database keys tell your users about where they are in the site?

...this godawful run-on sentence.  it's a decent article, but he doesn't exactly put his best foot forward there.
same here.  i'd suck as an author, painter, or musician/composer.  i also can't cook.  so i develop software.  at least something.
   after reading the article i can't find a single example of real evolution.  the author apparently does not know the difference between evolution and natural selection.  he seems to start off by re-defining evolution as an equilibrium-seeking strategy and then confusing other similar strategies with evolution (e.g. "jellyfish have no bones, ice cream has no bones, therefore ice cream is a kind of jellyfish...")

wikipedia edits are not random, and there is no crossover between pages.  it is actively directed by its users.  if wikipedia randomly added a link between pages and then watched to see if an editor removed the link or let it stand then it would be evolution.  if wikipedia randomly mixed pages and then let users select those pages that made sense and offered additional information it would be an evolutionary system.

oh yeah, the netflix "solution" he offers also has another widely known name: [k-nn](http://en.wikipedia.org/wiki/k-nn).   
 q: how does scientist become a mad perl programmer? 

a: by trying to maintain perl code.

 
exactly.  the few skills i didn't have for my current job, i picked up in a matter of days.  so why bother asking?

the only thing that should be interesting to your clients/employers should be your *ability* to pick up new stuff, and to solve their damn problems, but then most of the average hiring process has *nothing at all* in that direction.  so guess who most of them end up with?
try without compiz.
i'm not sure you fully understand the halting problem.  yes some applications can run and run and are designed for that purpose, however, the problem itself consists of the inability to tell how long it will run without running it.  we cannot tell when or if it will stop.  if it runs more than a month then it may run for years.  a solution to the halting problem would mean a program which can look at the source of another program and tell you how long it would run.  google p vs np
 &gt; and by the way, iirc in scheme the for-each's function parameters are reversed, so you have to specify the function first, which is really inane.

i'm not sure why they did it for scheme, but it comes in *real* handy for partial application such as when you have naturally curried function (as in haskell).

also, it's not really a problem when you have a language that supports post-facto definitions, such as haskell's `where` block.
what does p or np complexity have to do with the halting problem?  different things, in my eyes.  if it's sure to halt, it might still be p or np.
got hooked onto it in my seventh grade when i got my hands on my first 8086 machine...gwbasic was all i used to spend my time on....those were the days! of course 386 anc c programming was what changed my (and many others') world of programming
you must be doing it wrong. :)
right, never thought about currying, but probably because scheme doesn't have auto-currying.

haskell's where is awesome, too, but it a language with sexp-structured syntax i think it wouldn't really fit due to its infix-style syntax.

probably we need something where declaring functions or variables can be done anytime and doesn't need a surrounding let .. in .. end or locals or let.  in c dialects i usually call a function and then define it later a bit further down.
ah, that's better, although it still has nothing to do with racing games. unless there are helicopter racing games, now? definitely an untapped genre! :-)
&gt; you could make the case that it was out of desperation

it is just the natural way of software. the developers finish all the important parts, get bored, and start adding random crap.

consider adobe acrobat reader. it literally had no competition until after it became so bloated.

&gt; they had to do something after microsoft effectively destroyed their market. 

what market? nobody bought realaudio, they got it free with their sounds cards or just downloaded it. realaudio's market was streaming servers, which they still sell today.

&gt; the crap-free bbc edition isn't bad, by the way.

thanks! i've been wanting to install a realaudio player for some time, but i was hesitant from all the times i've been burned.

looks like i can ditch quicktime as well now, another craptacular product i have grown to hate.

because i'm good at it. 

i have a natural talent for programming which far exceeds my ability to do anything else. if i were not a programmer i would probably be digging ditches for a living.
readability?  how about not using 6-pixel-high letters on your fucking web page?  god damn this web 2.0 typography sucks.  not that this is a particularly bad example, it just happens to have tipped my bile-overflow meter.  don't specify font sizes you assholes!!!  and while you're at it, lay off the fancy text colors -- if you simply must, if you just can't be happy with good old black, #181818 will do fine.

that said, this is good advice, though presented in a typically pompous "i am a *web designer*" mode.
programming is the most interesting thing in the world.
i find it funny that the mac screenshot goes to a flickr album.  
  &gt; i'm sure there's some case out there where a debugger is the most useful way to fix something, but i really can't come up with it.

you can get some ideas here: http://programming.reddit.com/info/5yle2/comments
true true... (looks around for someone to pass the joint)
while i agree with you on the topic of complex loops, the vast majority of the loops i write are the simple kind that really would benefit from the dot-notation.
 if you have great content, people will link to it and you'll get plenty of traffic. but if you want to be found in search engines, you need to at least put some signals on the page indicating its subject matter. keep in mind that such signals (titles, headings, content, inbound links and even the url containing the keywords the page targets) are good for users as well as search engines. 

if you're referring to something else when you mention seo tactics, i think you're misunderstanding the main thrust of what seo is about. 
guess i'm going to have to visit maryland someday.   we don't eat crab like that here, and i have never seen blue crab so i'm not even sure how it is different.

i open my crab with my bare hands.  it isn't hard - i often eat with a 10 year old girl  (my best friend's daughter) who also breaks her crab open with her bare hands.  
it's important.  computer programming is the best way we have to transfer the knowledge of how to do something without the recipient of the knowledge having to understand it.

for example, let's take something simple like photoshop.  when somebody buys photoshop, they are buying the knowledge of how to do edge detection, for instance.  but the kicker is that they don't have to understand edge detection at all.  in fact, all they have to do is try it, see if it does what they want, and throw away the results if they don't like it.

i say software is only the best not the only because most physical machines transfer "how to" knowledge as well -- it's just the number of functions are generally limited and fixed.
 i'm not so keen on the videos, but [the book](http://tex.loria.fr/typographie/mathwriting.pdf) (pdf, 118 pages) is excellent!  
 
in vb 9 and type inference, that becomes

    for each subtotal in elements 
        total += subtotal
    next

or with linq:

        dim total = aggregate subtotal in elements into sum(subtotal)

or with dot-notation and extension methods

        dim total = elements.sum
 
i installed 7.04 on monday, and had no problems getting everything set up within a couple of hours (accelerated nvidia drivers, ssh, network).  today i've spent all morning so far trying to get 7.10 to the same point.  network setup didn't work correctly (i have 3 nics), no hw accel for the nvidia card, and i can't even figure out how to get the ssh server working.  this is a waste of time, i'm going back to 7.04.
i'm looking over my code right now, and for every complex for loop i have about 6 with a single-line body.

complexity should be reserved for complex things. i'm not saying we should throw away the for-loop, but it shouldn't be the default either.
sure.  i have an elaborate set of rules that construct a contraption in [the incredible machine](http://en.wikipedia.org/wiki/the_incredible_machine) from a purely qualitative description.  it works from an inscrutably large set of interacting preconditions, so that a slightly different word order can result in different placement.  and it incorporates feedback from running the system itself.  but working interactively, it would be pretty clear what was happening.

now, i think you can see how this could be maddening to use to get precisely what you want in complicated scenarios.  it would not be well suited for maintenance, reuse, abstraction or structure.  and yet in return for that sacrifice, it could also be very compact and expressive, very humane, in describing common-sense scenarios.
indeed.  sometimes i like seeing how big and fragile i can make something before it crashes to the ground
the fsf kooks get crazier and crazier every fucking day.
because i can create a disproportionally large impact on the world through programming.
here's the original proposal this guy wrote for doing this sort of thing:
http://www.puffinry.freeserve.co.uk/regex-extension.html

i believe the feature is now implemented in pcre.
i don't know if you should call it lazy.  a computer is a tool, and should not be that difficult to maintain or set up.    if other distros are more difficult then they will probably, eventually go away in favor of ones that are more user friendly.   so far, i think ubuntu is doing a great job in getting a usable linux to the masses.   the users have to do their part and help with the troubleshooting of problems for it to be a success. 
 &gt; * it is written in java

and ...    

&gt; * the only thing i got when i tried this in ubuntu 7.10 was a grey window.

have you filed a bug? 
gobuntu sounds like it should involve super saijyans
thanks.
so i can fart in peace
except for the fact that he mentions iterators:
&gt;concept of an iterator, which was great, but then we had to live with this for years in java:

    for (iterator it = orders.iterator(); it.hasnext(); )  {
       order order = (order)it.next();
       …
    }

which suffers from the same problem he has with for loops, it has a lot of code that's just there for bookkeeping.
 

*almost*

you can write a map or filter in terms of a reduction, but you can also make a specialized map or filter that will perform better (as in the google collect example).
update on the setup:

i got a spare drive out last night and did the install.   i highly suggest doing a clean install on your machine.   i have been with 7.10 since the late alpha and it has all worked, but there were things that didn't get upgraded properly when i went to the full version.  there were little things that just didn't work all of the way.   it might be the same for you.  you may want to wait a day or two though.   the repositories were getting hammered last night and it took about 3 hours to install flash.    the new effects on the desktop even work without a problem.   kudos to the dev team.
for god's sake.. there is no appeasing the freaks.
i agree. it smells like the submitter is slanting things by suggesting subversive tactics on the part of the c++ designers.
  i still chuckle a bit every morning when i get to work, and the first thing i do after logging into my workstation is to launch iceweasel and icedove, the debian-named variants of firefox and thunderbird, respectively.

i'm quite thoroughly in support of the debian folks on this one. the protection earned for the firefox "brand" by barring modification of its freaking *logo* is minimal, and the ill-will they're earning in the community is real.

then again, the whole mozilla/firefox concept has never really been about open source as an end so much as getting a competitor to ie out there when netscape couldn't keep up. if you can't effectively *build* an open source app, does it really count as open source?

i don't think that makes it evil, mind you; safari and opera are fine browsers, too, and i think that diversity in the web browser market is essential. 

that being said, let's call a spade a spade, and acknowledge that the mozilla foundation is no more a supported of free software than is sun, or ibm, or any other group who has latched onto "open source" as a life-preserver after nearly drowning in the ms sea.  
i especially like the way you neglected to provide evidence for your position; that shows just how strong your convictions are, and gives me **faith** in what you say. bravo, sir.
try the alt install disk and do a clean install.  i had a few nagging issues that completely went away last night when i installed it from scratch.   keep us updated.

i have seen many more problems with the video cards then monitors.   lets hope that it works.
would be nice if you could give a more detailed description of using the sbcl debugger over format.
the "author" seems to be having trouble recognizing that forth allows one to use "1-" as a 'function name' ...

the author needs to pay mr. noble a visit or something...
 what kind of tdd doesn't involve debugging? as if debuggers are useless if you're doing tdd. seems like a silly view. 
i'm with sigfpe on this one. however fitting as a metaphor, 'code smells' is a clunky, ugly and unnatural phrase.
&gt; since when does ie not support pdf or flash?

ie never did, but they were popular enough that users installed the plug-ins, and later the vendors included them by default.

the svg plug-in for ie could have followed this path as well, but didn't. why?
boilerplate titles considered harmful
&gt; you can also make a specialized map or filter that will perform better (as in the google collect example).

yeah but that's an implementation detail.
&gt; of course. it's called economics. why else would they pay more?

so you're saying your code is crap?

why would you work for a low-paying company then? it can't be intrinsic motivation, since you just said your work correlates to how much you're paid.

&gt; in c dialects i usually call a function and then define it later a bit further down.

yeah but that's because c functions are not nested, as in say php all functions are global, and they get "created" before you have a chance to access it so the problem is moot.
&gt; true or false.

or independent.
 what's wrong with debuggers?  think of a debugger as a repl (yes, a repl even for c, c++, and java) that can crack open a problem by allowing precious visibility into a running process.
thanks!
great read.  thanks for posting.   the last thing that ff wants to do is lose their base.

i appreciate all that the devs are doing to get some worthwhile competition out there, but to be that crazy over an icon is stupid.   they should worry more about the unpatched problems and less about the icons.   
 and c++ grows farther from what made c beautiful.  oh, the semantics here are nice.  but except for some ambiguity -- is numeric a type or a typeclass? -- that is indeed quite familiar to c, this seems good:

    template &lt;numeric t&gt;

and if there were any fear of ambiguity, they could do what once was done for structs:

    template &lt;typename numeric t&gt; 
the end of the article says: "...therefore it has failed in its stated goal of providing a 100% modifiable and redistributable ubuntu distribution..."

ok. except that "it's stated goal" is (from further up the page): "this means that we *try* to strip out..."

operative word... try. it's their goal to remove as much proprietary content as possible. they clearly dont feel that firefoxes logo 'issues' are important enough to warranty removing firefox entirely.

what's the big deal?
i actually didn't see your blog post, i saw it from your posting on the pylons list.  i thought i achieved title buzzword compliance anyway with "distributed version control", "git", and "mercurial" `:)`

great work by the way, i already tested it out and it looks very promising.  i have a empty spot in my toolbox for a nice easy to use, easy to hack wiki.  i love trac's wiki, but it has too much extraneous stuff just for a wiki system...  pylons is my current framework of choice, so this fits the bill!
personally, i could give not one shit for the sanity of the fsf folks, but i'm also very thankful they're there...
it's broken in a number of places.

a subtle example is uniquing-requirements on certain symbols, such as static variables in inline functions, or vtables themselves.  this requires the dynamic linker to do a surprising amount of work at launch time.  see [vague linkage](http://gcc.gnu.org/onlinedocs/gcc/vague-linkage.html).
if the user was a responsible user and has a password on the administrator account (like they should) this won't work.   you don't even have to go through all of that to do it though.   most people never put a password in for the administrator account and don't even know it exists.   do a ctrl+alt+del 2 times fast and you can enter the word administrator and leave the password blank.   
that only works in an ideal work where you always have 100% coverage, and bugs only pop up in new code.

of course, this is the real world. 

regardless of how i find an error (automated, ad hoc or reported), i have to hunt down where it's coming from. sometimes it's obvious, but sometimes it isn't. this is where a debugger is useful.

suggesting otherwise isn't just presenting a false dichotomy, it's patently retarded. take the hint already.
i see no indication that hobel doesn't understand the problem.  the halting problem is recursively enumerable, but not recursive.  hence, it's possible to write code that can solve it correctly in the positive case, but may fail to terminate if the answer is no.
 i've seen the opposite extreme, and it's not pretty either.  a tell-tale sign of a developer using a debugger as a crutch is the complete lack of a runtime-inspection capability when the software goes to production.

i find debuggers very helpful when locating issues with third-party apis, but i rely even more on logging and console output, to tell me not only that something happened which is likely due to a programmer error, but also which component or class caused the screwup. 
nah.  c#'s interfaces are already subsumed by c++'s multiple inheritance.  this "concepts" notion is entirely in the template-world of c++, which is entirely alien to c#.

c#'s closest feature is generics, which are pretty much only used in c# for better type checking of collections.  c++'s templates do a lot more.
i forgot to add that 100% coverage doesn't indicate there are no bugs either. it just means you test all code at least once, and says nothing about other cases.
complexity means even *more* reason to avoid the *for loop*.

for simple examples, they're quite similar.  however, the functional equivalents (particularly involving map, or a good list comprehension) can *compose*.

take a loop where you need the first or last to be treated differently - requiring a flag to be set outside of the for loop (or numerical iteration) - abstract the problem out in a function like *intersperse*.

the complexity that piles up inside or around a for loop can be broken down into cleaner steps.


i could have used that last night.   
the community is always here to help. :d

also, get really familiar with the ubuntu website, there is alot of help there without having to ask.
sounds like a lot of sour grapes to me.
could i ask what the fsf has to do with this? the players involved in tfa, as far as i can see, were mark, canonical, ubuntu and gobuntu, the mozilla corporation and debian.

where the fuck does the fsf come into play?
&gt; a tell-tale sign of a developer using a debugger as a crutch is the complete lack of a runtime-inspection capability when the software goes to production.

i cannot argue with you there. too often i've seen applications without even basic error logging.
i think that what revolutions meant (or what i hope he meant) is that even given superhuman capabilities and enough time to get you to the heat death of the universe, you could still not write a single algorithm that could determine, for all possible programs, whether or not a given program would halt.
i'm glad to see that this article points out the connection between classical logic and continuations. none of the other papers/tutorials i've read on the curry-howard correspondance ever mention this; they restrict themselves to intuitionistic logic.

is it just me, or is there a striking resemblance between propcc and [peirce's law](http://en.wikipedia.org/wiki/peirce's_law)?

&gt; propcc :: ((forall q. p -&gt; cprop r q) -&gt; cprop r p) -&gt; cprop r p

the type for callcc is also suspicious.

&gt; forall a (m :: * -&gt; *) b. (monadcont m) =&gt; ((a -&gt; m b) -&gt; m a) -&gt; m a

i guess that is peirce's law for the identity monad, which makes callcc slightly more general. does peirce's law also have a more generalized version in logic that is well known?
&gt; to be that crazy over an icon is stupid

not really, it's important because it's both a legal issue and a philosophical issue.

on the legal front, if you say you're distributing free software, your users have a number of expectations, such as the right to modify and redistribute *all* of what you provide. in firefox' case, doing that *may* land them in deep trouble.

on the philosophical front, either you're gung-ho about free software or you're not, but if you're not don't say you are.
hardy wrote that the only two believable reasons someone does math are: (1) it's the only thing they do well, or (2) they do nothing well, but it's what came their way by pure chance.  if programming is the same, here's hoping we all fall into the first category.
 there's a very simple one: don't lie, and don't be misleading.

management? 
yeah, walking to the bus to go to the mall.  they don't have a car because they spent all of their allowance on makeup.
the big problem with ruby-debug is that "debugger" you have to insert into your code. bleh.

since we're on the topic, is there any way to resume from where an exception was thrown in ruby? i'm thinking of stuffing ruby-debug into the exception class, but if i can't fiddle around and then resume from the point of exception it really reduces the usefulness.

i'm told ruby cannot do this, but would be pleased to learn otherwise.
"clean install" is windows crap.  this is linux, and should be held to a higher standard.  debian has been doing in place upgrades for years, and if ubuntu makes that difficult, then i will go back to debian with no hesitation whatsoever.  it's simply unacceptable to not do upgrades well.



or in perl.
&gt; and c++ grows farther from what made c beautiful.

if you think it's beautiful to be unable to define powerful and useful abstract data types, then i think we're just going to have to agree to disagree.  i find nothing beautiful about c's inability to define typesafe parameterized datatypes.
because i like being the first department to get the axe despite being the department that does most of the work.
&gt; what's the big deal?

i'll redirect you to mark's *second* paragraph:

&gt; what’s the point of gobuntu’s existence if it still contains non-free components?

if one wants ubuntu with non-free components, there's ubuntu. if one wants ubuntu without non-free component, there isn't gobuntu, because there are non-free component in it.
what's crazy about this?  the point of gobuntu was to have a totally free distribution.  it intentionally includes files that are not free, thus rendering the distribution pointless.

now if you don't value a totally free distribution, then all that means is that this distribution is not for you.  but that doesn't mean that somebody is a "crazy kook" for pointing out this contradiction.

[darl, is that you?](http://en.wikipedia.org/wiki/darl_mcbride)
now my head hurts.

i so long for intelligent software development...
that's what i meant.  for a computer that needs to be working for school/work/porn, it needs to be easy to set up and troubleshoot.  i've used gentoo when i needed a box with absolutely nothing extraneous on it but otherwise it's a pain.
no worries. c still likes you.
&gt; read the documentation

what documentation? i find most of the documentation for libaries to be quite poor, especially when dealing with edge cases. often the only way to figure out what is going on is to explore using the debugger.
i'm running this on my macbook pro now, and i think it'll come in handy. it's a nice visual representation of changes in the svn repository!

the one thing i'd like would be the ability to browse the remote repository and select a file instead of having to type in the filepath. looks like that's already been suggested though!
this is a cool feature, but it's unusably slow for larger files. a  6k-line c file took over 3 seconds to switch versions on my macbook pro. 

if this project gets some speed-enhancements in the future, it will be very useful.
issue tracker:

http://code.google.com/p/svn-time-lapse-view/issues/list
you do know that you can't apply tail recursion to all recursive problems, right?

or you can only apply it to part of the problem (the second partition of a recursive quicksort, for example).

considering the stack isn't that bad a thing, especially on embedded devices.
so basically, the easy answer is that every language should just have a cli development environment.

memory/assembly level debugging is really only needed for languages where memory allocation/referencing is a user responsibilty?  i'm not even 100% sure on that answer.

can we assume the debugger/cli is bug-free?
 i think so, brain, but... me and pippi longstocking? what would the children look like? 
 ya, what is with all the negative vibe for my comment?  i figured that most of the people on reddit aren't in unions and would notice the negative energy in the parent comment regarding programmers not in unions.

i wasn't kidding or trolling, i actually voted down his comment because he made it sound like not being in a union was a bad thing.  i am glad i'm not unionized and that has nothing to do with being (or not being) treated like a monkey.

unions have no good place in highly skilled jobs.  they are for jobs that require no significant skills and therefore require other forms of protection.  even then i wouldn't join a union again, but i can see how other people might.
 
i would think any device powered by *black smoke* would be considered magic.
well, what do you expect?
lets see.
i had the aspiration to program in my teenage years so i started teaching myself and implementing little hacks. from there i kind of gradually excelled in it. i started in vb5/vb6 then learned c# and c++ after that, i've also picked up some php &amp; sql to make a long story short i'm a fairly well rounded programmer in various languages. eventually i attempted to work from home for myself &amp; build up a client base but that wasn't exactly successful my first time around. it took awhile before i landed my first job as a programmer which i've currently been working at for about 7 months now.
i definitely enjoy my current job more then my previous jobs in construction. the pay is pretty good, better then anything i've had before. i like the challenge, it keeps my mind sharp. i get a satisfaction out of writing good code that works well. it can be fun &amp; exciting. the exposure to interacting with people &amp; learning new things about different industries that programming can apply to is also appealing.
the video is full of mpeg artefacts. not very pleasant to watch. (used mplayer)


musicians tend to have far fewer problems with the "social acceptability" of their work than programmers do.
: $#£%! expletive tell ;
:-) ok i got it... maybe 
i think it's an issue between ideals and reality.  you *could* legally and reasonably unionize skilled labor.  skilled workers are  a lot more in demand and therefore less likely to require a union.

unions are really only useful if the union is run by people who genuinely give a damn (usually insiders with the same issues as the other workers) and if the workers are actually being abused.
the best thing i've done for my stress &amp; distraction level at work in the past 3 months has been disabling the new mail notification icon.

with it enabled, i was constantly interrupted &amp; stressed out by the email i was receiving. now i check my email when i want to (or am expecting something) and i'm able to focus on priorities.
good suggestion. its amazing that the smalltalk packages are still around. i remember when those folks used to charge $1000 a copy. crazy.
when i was a kid on the bbss, i wrote and sold some telemate scripts for tradewars. 

it felt like magic. just a few words in a text editor, and you could save yourself hours and hours. it's like having a mystical, invisible servant doing work for you.

through coding, you can give yourself the power of many humans. kinda like how a superhero might have the strength of 10 men, we can scrape and process data from 1000 websites in a moment with a magic python incantation.

it feels like magic sometimes, still.
i didn't know they were.  in fact, i'm pretty sure i've seen some.
probably because of the problems with the thousands of spam blogs that evil \/14gr4 salespeople keep setting up on blogger and the fact that posting a link on reddit would be a great way to "guarantee you an extra 3 inches" or you cut in their father's secretly stashed fortune.
real programmers are artists and artists are beings capable of creation, creation is the power of a god.
those would be erlang flashbacks. haskell flashbacks are done on a whiteboard and then etched into your brain.
   i just posted one from blogspot and really didn't show up on /new. see [here](http://programming.reddit.com/info/5youe/comments/ )  
i think the "they" in immrlizard's comment refers to mozilla, not canonical.  so, he thinks mozilla is being unreasonable about the icon, not the author of the article.
currently only one, "c++ from the ground up". when i'm done with that one, i'll see.
it took 20 hours to install, i am at work now;  hopefully the process is done when i get home.
i ran into the same problem.  there was no indication it had been blocked -- it just never showed up on the new page or anywhere else.

at the very least the submission page should provide feedback.
   you are wrong, the tomalley is definitely  not edible, eating some thing that looks like you blew it out of you nose and has the constancy of cream of wheat is not a good thing.   
easy hours.  no heavy lifting.  not to mention the infinite "x rocks, y sucks" arguments.
mmmm indeed that's a way to read it i didn't see at first.
that's a really interesting story.

i'm curious: did you have a tough time getting your first programming job with a graduate degree in anthropology?
yeah, i was wondering the same thing.  i didn't disagree with his comments, they just weren't anything i hadn't heard a million times before.
i totally agree. there should be a visible feedback with an explanation of such blockout (if there really is)
&gt; ...powered by *black smoke*...

the [magic smoke](http://catb.org/~esr/jargon/html/m/magic-smoke.html) is definitely [blue](http://en.wikipedia.org/wiki/blue_smoke).

  "pinky, are you pondering what i'm pondering?"

(pinky)  whoof, oh, i'd have to say the odds of that are terribly slim brain.

(brain)  true.

(pinky)  i mean, really, when have i ever been pondering what you've been pondering?

(brain)  to my knowledge, never.

(pinky)  exactly. so, what are the chances that this time, i'm pondering what you're pondering?

(brain)  next to nil.

(pinky)  well, that's exactly what i'm thinking, too.

(brain)  therefore, you *are* pondering what i'm pondering.

(pinky)  poit, i guess i am!  
looks like i hit a nerve with some people.  having a title and heading is understandable.  when you start to cram keywords in your url, you are starting to get a bit spammy.

in general, you shouldn't optimize your page for robots, but for humans.  seems like a lot of people are targeting the wrong audience.  it's the search engines jobs to find you.  now, if you don't have valid html, or if you don't have a title on your page, or your site's nothing but flash or js, i'd say it's not good for human consumption.

the url in the blog that this thing links to is not useful in any other way than to spam google.  right?  i'm never going to type that out.  and the show subject of this guys blog seems to be finding better ways to spam google.

so, everyone, go ahead and down mod me.  you know in your heart of hearts that i'm right.
i'm not sure the point of intel's position is. it's coming off as two separate reasons. first is because too much email distracts workers (i agree with this), but the second, to get people to talk face to face, seems like it may have the same effect. emails may get in the way, but encouraging someone to get up and leave to go talk to another engineer seems like it might result in more cooler talk than work.
most good ides are capable of creating a for loop iterating over a number, collection, array, etc. 

while one could argue that it's only hiding the issue, the fact of the matter is i can write a for loop iterating over a collection in 3 seconds.
well, i wasn't entirely accurate in my assessment of my skills in other activities.

i do, in fact, enjoy programming, and like to think that i am good at it.  i haven't really tried much else.

i was just trying to be funny....apparently i do suck at that.
i agree.  i don't understand how tdd and debugging are antithetical.  no one is going to write completely correct code on the first try, even with tdd.  when a problem is found, often a debugger is useful for easily discovering the source.  when that is discovered, in addition to fixing the error, write a test to ensure that if it breaks again, you will know.
mathematics.   my degree is in math, but i have almost always worked as a software engineer.   but math is infinitely applicable.

...and one for the "java" problem as well.
 the ray-tracing problem is one of the more concurrent around. add the fact that it could change the multi-billion game indsutry and suddendly this looks like a very very important topic.

any info on what to read first to understand what going on ? i mean to understand current siggraph papers on the subject.
 
 that's not all there is to it.  the particular c# feature i was referring to is the one that allows you to write code like this:

    class set&lt;t&gt; where t:icomparable { ... }

you can have the compiler check that a generic argument meets certain requirements.  in c#, the requirements are given as an interface.  in the new c++ stuff, the requirements are given as a 'concept'.  the only difference is that in c#, a class has to intentionally implement an interface (same with type classes in haskell), but in the new c++ stuff, a class can conform to a concept without making any reference to the concept. 
i was about to ask where the source was, but it's part of the larger bro nids, whose source you can find [here](http://www.bro-ids.org/download.html).
in the archives, it's under src\binpac.

i wonder how well it works as a standalone library separate from bro...
ubuntu 7.10 is a huge improvement over 7.04. the graphics are crisp, my resolution was set without any manual configuration. compiz is better than i imagined it to be. the whole system seems more responsive and i still can't get over to how nice it looks.
that's fair, but why should you have to?
&gt;one year latter, tim purcell also published a paper on gpu based photon-mapping.

i tried implementing that algorithm on a radeon 9800 pro. two words: not recommendable. 

the radeon 9800 pro is only capable of a few texture reads per processing cycle. so i had to split a rather simple algorithm into six or so steps. after each step, i saved the intermediate result encoded as rgb colors for in the output image. before each step i fetched the result of the previous image.

debugging it was even worse. i used some photo editing tool to manually read the colour of each pixel to get the values of intermediate results. :(
&gt; no, i'm joking. as soon as that function has multiple lines, you're much better off with something like the for-loop (or lisp's dolist) than with something like blocks, closures, or scheme's for-each, simply because the loop spells out just what you're going to do.

can you spell that out?  it's hard to imagine that a multi-line ruby-style *each* is worse in all cases than an equivalent *for*. 
i don't think that hiding it under a heavy layer of syntactic sugar is necessarily any better.
&gt; i'd like to see is odors of rotting meat based on code complexity, but *that may be a bit tough to implement.*

nah. you can borrow my visual basic disks.
hmm... i'm getting a org.tmatesoft.svn.core.svnexception: svn: propfind of '/': 405 method not allowed
stripping didn't work out. plus have you seen swordfish? halle berry loves programmers, and it's so mentally intense.
i know this is a lame comment, but that font made my eyes bleed. i'd comment on the article if i'd actually been able to read it...
i just don't see *each* as heavy.
sure it is.  you just have to slice it in some meaningful way.  perhaps by choosing two genres such that the distance from one is one axis and the distance from the other is the other axis -- it's fuzzy, but would give meaning.
&gt; looks like i hit a nerve with some people.

if you consider saying stupid things to be "hitting a nerve", then yes.

&gt; when you start to cram keywords in your url, you are starting to get a bit spammy.

the article didn't say anything about "cramming keywords in your url", and neither did anybody here.  you are confusing "hey, search engines pay attention to uris, so that's a nice side-effect" with "let's abuse uris to cater to search engines".  they are two totally different things.

&gt; now, if you don't have valid html, or if you don't have a title on your page, or your site's nothing but flash or js, i'd say it's not good for human consumption.

what on earth does that have to do with this article?

&gt; the url in the blog that this thing links to is not useful in any other way than to spam google. right?

it's the title of the article.  that's a perfectly appropriate way of referring to an article.

&gt; i'm never going to type that out.

neither am i.  i clicked on a link.

&gt; and the show subject of this guys blog seems to be finding better ways to spam google.

why do you get that impression?  from the site:

&gt; latest entries

&gt; 1. readable url slugs
&gt; 2. readability, uniqueness, hackability and meaning in url design
&gt; 3. question concerning django and templates
&gt; 4. undo form reset for kids who can’t reset good
&gt; 5. be careful with jquery

so the guy writes an article about uri design, and happens to mention in passing that search engines pay attention to them, and warns you not to pay too much attention to this, and you label him a black-hat seo who only writes about spamming google?  you are delusional or have an axe to grind.

in fact, the article says the opposite of what you claim:

&gt; search rankings should never be your primary aim in url design.

&gt; keywords shouldn’t be stuffed into the url if they have no actual effect on what page is returned by the system.

&gt; if any design decision is made purely for seo purposes you risk adversely affecting the user experience.

yeah, i can really see how "this ranks as black hat seo."

no file browsing. i see.
i agree, but beta is exactly that.   unstable, non proven software that is not quite ready for release.   these versions often have errors in coding that break the ability to fix some problems through normal methods.   i you have errors like the one you had, or the other user at the top of the page had, sometimes the best way to correct those problems is a clean rebuild.   an hour is a short time to spend in comparison to many hours trying to locate a specific problem and correct that.   if you would have waited until yesterday to do the upgrade (when the full release version came out) and your system was working, then you may not have had the problems.   that is all i am saying.   being a windows user for so long makes me appreciate the work that they are doing all the more.
personally i think it is a good thing that gc is not mandatory. there are some smart pointer libraries that are looking to add gc support to suitably typed (smart) pointers. i think this is the best of everything. gc where it makes your life easy and known de-allocation times where you need that.

the reason for the caveat with them on the lambdas is that my understanding of the issue is that some use cases for lambdas rely on gc. if those use cases can be covered by an optional gc system then great, but i've not seen any work on it one way or another.

the lack of a fixed point operator is a problem, but given the way that c++ has been moulded in the past it may be that somebody clever enough will be able to find a way to write it.

c++ is one of those languages that people discover new things in rather than are told what is possible in.
*salaries... i know.

 probably not the most ethical of questions, but i figure this is fairly anonymous so it's not all bad.

what kind of salary do you programmers make?  i'm currently a year and a half out of college and am making $67,000.  i'm pretty happy with that, but i don't know how high i can expect to go.  

right now i'm mostly just doing javascript, which is ridiculous, but i am familiar with a whole host of languages, proficient in a few, and trying to learn java right now.  how would you say i'm doing compared to the market?

oh, and i'm a contractor which i know raises my salary to compensate for my stability.
things to complain about:

strange behavior with gimp. tool window resizes itself with animation and all very small and unusable. works fine when window is not floating.
another thing i've found is that some windows are not reacting any way to my mouse after some use, i have to switch workspace and back to get it work again.

nice thing is that kicker, gnome-panel etc. works very well now without much effort.
actually i meant it ironically. i think it's a perfectly good thing :)

type classes are very useful and to be able to specify the interface required by a template in terms of operations rather than interface is a very useful thing as it allows the logical operations to be specified rather than just the subset that happens to be used in the implementation (as happens now) - talk about leaky abstraction!
what if you are debugging a bug in a gui?

what if you have a tens of thousands lines library with undocumented behaviour?

what if the documentation is non-existant or very sparce?

what if you don't have time to "give up, read the documentation, etc."?

what if you are actually paid for your time and spending time immersing yourself in the problem isn't what you are getting paid for?

etc.
that is the way i meant it.   sorry for not making it clear.   i fully appreciate what canonical is trying to do.   i feel that it is only a matter of time before that is much easier for  them to do it.    there are limits to what you are able to do if you are not going to use any non free software.   users that do that will need to accept that.   
started 2 months out of school, 45k/year salaried with 401k, full health, 3k/year in free tuition and all that jazz


i was a contractor in school though at $25/hour but it's so unstable

basically going from contract to salaried i made the trade from interesting and unstable to boring and stable


my complaint is strictly with the syntax.  they have:

    template&lt;typename t&gt;
    requires numeric&lt;t&gt;

when they could just as well have:

    template&lt;numeric t&gt;

and unless they have other plans for the **requires** keyword, it smells unnecessary, even recognizing that you could in this case **require** more than one **concept**.
or, written more succinctly:

    s -&gt; (b)
    b -&gt; epsilon
    b -&gt; (b)
    b -&gt; bb

given that these regexp engines are capable of behaving like pdas, why don't they accept input in the form of actual cfgs written out as productions like above?

of course, the best generic cfg matching algorithm i know of is o(n^3), so perhaps that's why they try to make it hard to write expression that will require a lot of backtracking.
i agree with that.  however choosing the right abstraction is really the key to this whole discussion.

i'd be as confused seeing someone use a reduction when they really want a filter or map or something as i am when i see someone write a for loop in terms of a while loop (which i used to see a lot).
gremlins, with possible sinister overtones of revenge
hit refresh and they do.
probably not the most ethical of questions, but i figure this is fairly anonymous so it's not all bad.

what kind of salary do you programmers make? i'm currently a year and a half out of college and am making $67,000. i'm pretty happy with that, but i don't know how high i can expect to go.

right now i'm mostly just doing javascript, which is ridiculous, but i am familiar with a whole host of languages, proficient in a few, and trying to learn java right now. how would you say i'm doing compared to the market?

oh, and i'm a contractor which i know raises my salary to compensate for my instability.
oh not the god damn gremlins again
if you use them for a short time and then drop out to think they are great.  they can tell you what happens at the moment of failure.  however debuggers make it far to easy to stop thinking and just start stepping through code, modifying variables to what they should be, without getting any closer to understanding or fixing what is wrong.

use a debugger wisely, and they are great.  abuse them, and they are a waste of time.
well, there's urls and urls.  

web sites should have nice meaningful easy to read urls.

web applications should have opaque urls devoid of meaning.  specifically i refer to urls that do things like post comments on a blog.  there would be a lot less comment spam if the urls were salted with junk in a time dependent way and thus rendered non-scriptable and rapidly invalid after creation.  failing to do this leaves your site open to abuse from script kiddies.
hmm.  looks like i picked the wrong free blog provider then?
an internet evangelist?  well, is he fer it er agin' it?
so write some [ldraw](http://ldraw.org/) software and blow your mind!
"salting urls with junk" doesn't prevent spam scripting, all the spammers have to do is get the form and look for the uri before sending the spam.  you can get exactly the same effect by using a hidden field instead.  messing with the uri for this just isn't necessary.
right. google is offering to *be* your family; there's no reason to take up the offer if you already have one.
in smalltalk i'm not sure it matters as the debugger is written in smalltalk and if it has a bug, ...well..., so long as you can debug the bug without hitting the same bug you'll be able to debug it with the debugger.

as for cli development environment, i'm not sure that's always the best course, but i understand many people like it a lot and we should always strive to give everybody the interface they like the best.
that's because you're educated stupid and can't compute a time cube.

seek in haste to attend a lecture by dr. gene ray, cubic and wisest human - his wisdom is awesome.
well, it's just a matter of how low you go.  a cli development environment can be easily used for any debugger function that doesn't require lower-level visibility than that of the language itself.

a nice cli in c could theoretically be used to debug most c stuff, but since pointers are lower level than c code (numeric memory locations that are really never viewed/used), you'd be otherwise kinda stuck.

i have a feeling i could debug almost any piece of code in common lisp using the cli and trace functionality.  a better coder could probably point out debugger libraries or such.

really, in what way does a debugger significantly differ from a cli development architecture, in the topic of debugging?


very nice. just the thing i've been looking for. i could wish that it made use of my pageant ssh credentials, but that's minor. pointed it to a file in my local working copy, and it retrieved full version history from the repository on the svn server.
&gt; there are limits to what you are able to do if you are not going to use any non free software. users that do that will need to accept that.

you make it sound like the non-free files are necessary for functionality or something.  we're talking about a web browser branding here.  there's no functionality gained by including these non-free files.

gobuntu already dropped non-free stuff that provided actual functionality.  why can't they drop non-free stuff that is only necessary for the firefox branding?

guis can still have logs, and probably should.

huge logs of poorly documented code are a pretty good case for a debugger. they're also a good case for one off programs to find your edge cases without filling your project with even more code you don't understand.

my point was that in my experience, my time spent in the debugger was more often wasted than my time spent analyzing the problem outside of it. likewise, i don't get paid for delivering something that doesn't work.

i don't think that debuggers are useless, but i have found plenty cases where improperly using one has wasted my time. 

most of those cases have been in java or .net. maybe i'm just using crappy debuggers?
oh.

you know, i'm not \*really\* writing a compiler back-end for my whiteboard.
cli - command line interface? or are you talking about something else?
yes.
please spare us this flamewar. try both and use what _you_ like more.
 exactly. i'd love to up-mod it, but his submitting this to programming.reddit annoyed me too much. 
&gt; i'd be as confused seeing someone use a reduction when they really want a filter or map

oh yes, so would i, i already have trouble when people use reduction when they want a reduction so it could only get worse. i was just being a smartass, really.
should have used a golf pencil
they have 'definitely probably true' and 'definitely probably false'. :)
i've heard quite a bit about ruby and python here on reddit. now, i've finally decided to try one of them. 

but question is which one? 

please, no programming language religious flamewars, i'm only looking for cold, hard facts. 

how are the tools (ides, debuggers, profilers, test suits, etc.) of each language? i'd graetly appreciate a small list of invaluable tools for each language.

which "features" are supported by one language and not the other? closures, dynamic typing, static typing, object oriented, funtional, etc.

which one has the best library support? in which areas are the library support strong for each language strong?

finally, which are some great books to learn either language?

my language experience is lots of java and c++, some c and ml (and a crappy language i was taught at the university that i'm trying my damndest to forget).
 i am salaried, and i make 51k canadian
behold, the power of haskell!

    let total = sum elements
so in another week, you'll be making twice what i do, as the usd drops off the charts...
it makes me so  happy that i can annoy you with a click of the mouse.
i guess it's so spare us from the really lame blogs that exist on it *ahem*
 maybe because we post programming related posts from blogspot too? 
no college degree, been four years with the same company.

started off maintaining a little asp-based site, moved on to building and maintaining a large, uninteresting, "yank data out of a pipe, brush it off, and put it in labeled boxes" backend application in c#.

$50k a year.  i'm also the sole programmer here, which makes things a lot more boring.   nobody to talk to :-(

i'll get the goddamn degree eventually. argh.
&gt; i'm not saying we should throw away the for-loop, but it shouldn't be the default either.

most modern languages (and many older languages) do just fine without the original for loop (the c-style one where you do everything manually). so i'm pretty sure we can get rid of it period, for all but the most low-level languages.
 &gt; &gt;now, if you don't have valid html, or if you don't have a title on your page, or your site's nothing but flash or js, i'd say it's not good for human consumption.

&gt;what on earth does that have to do with this article?

nothing, it relates to the comment i was replying to, you cunt.

&gt;it's the title of the article. that's a perfectly appropriate way of referring to an article.

of an article that says urls should be hackable.  my point is, no one's going to type that in... ever.  the author is more worried about getting keywords to the robots, than his is with making the url hackable by the human readers.

&gt;why do you get that impression? from the site:

it's all articles on how to make your site more robot friendly.

&gt;you label him a black-hat seo who only writes about spamming google

url's should be unique.  that goes without saying.  making them where a user can hack them is nice, but that's not what he's doing.  giving them "meaning" is just applying a fluff word that has no meaning.  what he's really going for is readability, and *not for humans*.  imagine calling up someone on the phone and trying to read his url to them, and getting them to enter it correctly.  do you think they will be able to?  i don't.

so, the people who do this, can spend their time, searching for there keywords, and think it means something, but it's just lame, and it will get you no where.

look at the url's on any good application, like craigslist or youtube, and they break every suggesting that he's talking about.  youtube url's are not unique, in that multiple url's can point to the same location.  craigslist urls are not hackable, or readable.  the only reason to make sure that you don't have two url's pointing at the same content, is so your pagerank doesn't get cut in half.

this page gives what some may think is good seo advice.  it's nothing more than seo advice, and it's lame, and it will get you nowhere in the end.  people don't like to hear it, because they spend their time doing this shit to their blog, but it's just shit. 

edit: quotes were merging
if there were a right answer, there wouldn't be two languages.
and the drugs
programming is as close as you can come to being a god.
strawberries or raspberries? convince me.

go.
pick one at random. skills acquired in one are transferable to the other.
i agree with 

&gt; the point is not that you need to loop through your data to process it, but that you shouldn't teed to worry about setting that up, or how it works.

but i agree a bit less with

&gt; the language should be smart/organized enough that you can simply tell it to apply a block of code to each item in a collection, and then the language will automatically know how to use iterators/closures/etc to apply that block of code to each element.

internal (using blocks) versus external (using foreaches) iteration really is a matter of taste/desire. python has been using external iterators (and list comprehensions) for years and i like it, even though i have no problem with using internal iteration in haskell, erlang or ruby.

the only iteration that *sucks* is the explicit one (c-style, where you have to do everything manually).

also, while java's foreach syntax is a progress over old-style iteration, it's lacking in so many area it's not really funny. simple (hell, trivial): when iterating through a collection, try getting the index of the current element (not in the collection, in the iteration).

it's not possible, you have to create and maintain a counter by hand...
they're probably going where some of my posts went.
 i'm salaried. more than 140k

how much more i won't say :)) 
kinda weird bug .. i use firefox on linux, anybody else has experienced this bug ?
me too! we should start a club!
all hail yaakov
i tried it, worked fine for me.
what do you do?

*edit - besides reddit?
take a class or two a semester. in ~6 years you'll have a degree, and won't have been inconvenienced too much.
get into a place where there are other developers, even if you don't agree with them it is much better than no one understanding your job. i did the solo thing for a non-profit and it was a drain on my soul because i was just another company expense instead of an income as i am for my current employer.
isn't contractor better?  higher rate of pay for the same kind of work.
because it's like being some kind of god - m-x let-there-be-light.
works great in safari on osx and firefox on debian
great advice, i've thought about doing this.  even though i already have an mis degree, i've been thinking about going back for something else.  not necessarily for my professional progression, just personal interests.
good one!

(at least one person understood the reference)
huh?

i'm running ff2.0.8 on os x, no weirdness that i can find.
this is the biggest problem i have with compiz fusion, and particularly with ubuntu's default usage of it.  the use of accelerated video rendering has made numerous applications appear as grey boxes because they don't comply with the compiz way of rendering windows.  i especially see this with opengl applications and games, but some framebuffer reliant applications (like my beloved tilda) also fall prey to this behavior. =[
and you don't break your teeth getting the pieces apart.
i thought being a contractor raises your rates because the company you work for doesn't pay taxes on you. doing contract work i pay nearly 30% of it back to taxes.

your salary compared to your market must also take into account your location. for 1.5 years out of college i'd think your doing fine.
&gt; my complaint is strictly with the syntax.

everyone has his or her [bikeshed](http://www.freebsd.org/doc/en_us.iso8859-1/books/faq/misc.html#bikeshed-painting) :)
whats wrong with ml?
not to the arts.
stick with java, c++ and ml. python and ruby have nothing to offer over those three you already know.
day dream? :d
 he does number 3 in the list


...

3: ???

4: profit! 
i don't know about the tax writeoffs.  i'm contracted through another company, not personally, so the taxes are coming out somewhere.  i was just told that if they hire you on, to expect a much lower salary.

oh, i'm in the cincinnati area.
yep, i've seen it happen with links in comments - a horizontal scrollbar appears, the comment text wraps slightly differently, and the link jumps away from under the mouse. i wonder if this will show it: http://programming.reddit.com/info/5yp23/comments/
hahaha. nice one.

(please be sarcasm, please be sarcasm, please be sarcasm.)
strawberry has much better real-world support. if you use ihop, the rooty tooty fresh 'n fruity dish supports strawberry toppings by default.
isn't the pci express supposed to alleviate this issue considerably? the bandwidth from cpu to gpu is supposed to be increased a lot.
no it didn't :-(
thanks for your feedback, i've taken another stab at the introductory paragraph. let me know if you spot anything else.
no degree worked my way up. 60k. work for a large company. 
i bet a vb/oracle developer?
i was getting it pretty regularly last night.

also, i'm seeing something where nicknames in comments are replaced by the title of the story - anyone else noticing this?
hmm... i used to write vb/sql server.  oracle can't be that much different if i were to sit down and try to learn it.
using the very unscientific http://cgi.money.cnn.com/tools/costofliving/costofliving.html as my tool it says that your doing great! right around what we hire front-end developers at, not sure about the back end but i do plenty of javascript.

i make about $60,000 - in finland.

for some perspective, maybe we should consider some of our living expenses too?

i'm renting a 32 square meter apartment for around 668 dollars per month, in a "decent" or "average" part of the city.


i'm serious. if he wants to learn a dynamically typed language, a much better choice would be lisp or erlang.
not terrible, but i find the 'www.' domain prefix and the 'weblog/' in the path to be unnecessary and redundant. and the slug titles could use hyphen or underscore to be more readable.

i was kind of just kidding.  i mock the rich developer.  most of rich developers are doing some niche development that no-one on the planet can do like writing vhdl compilers for the intel neutron 100 core cpu or something.  or .net/j2ee developers that really aren't developers but business analysts.
also live in a fairly nice area of town, rent 1280sqft apartment, drive a 2001 bmw z3...  i guess i live pretty comfortably (at least for what i'm used to) but i'm not really putting anything back right now, and i know i should be.
i deliver :))

well, jokes aside, java, delphi, lisp.

range of applications including windows based order mgmt system, web site for our customers, different inhouse tools for ocr-ing, dicom, creating pdfs, multi-page tiffs, electronic data-transfer to our customers networks, webservices.

firefox on windows. for me, the bug happens when ctrl+clicking on a link in a comment.
it's all getting a bit heated here :/

i'll admit that the most compelling arguments for having unique urls are for seo reasons (which aren't bad, but also weren't really the point of the article).

having unique urls means that should you change your url schema at some point (it happens) you can easily write a redirect filter that directly maps the old urls to the new ones. obviously this is also possible with non-unique urls but the process becomes more challenging.

as simon willison mentioned in my comments, having multiple urls also breaks visited link functionality.

there are also a number of technical programming-related reasons why unique urls are preferred but that's moving away from the domain of user experience.

my motivation for writing the article was that i was fed up with seo being the justification behind almost every decision to do with the sites i work on, specifically url design. almost every character in some of our urls is keyword fluff that exists purely for seo purposes. i was looking for a way of keeping urls with a certain level of keywords (to appease those people who make the decisions) but using those keywords to provide structure to the site and enhance usability rather then degrade it.
 i think the code could be better..


jquery.fn.extend({

    log: function(){

        args = $.map(arguments, function(a){ return a;});

        args.unshift(this);

        return console.log.apply(this, args);

    }

}); 
i know about the usenet groups for lisp, scheme and python but is there something more like perlmonks with voting/experience-points and sections such as "cool uses of ..."?
ask a lawyer.
started in daycare, haven't stopped since.

 did he even attempt reading retroforth's overview?

&gt;there are plenty of full-featured forth compilers, e.g. isforth, bigforth, win32forth, gforth, and the commercial forths.
...
&gt;it may not have many features, and it may not be particularly useful by itself, but it's easy to grasp, easily adapted to various uses - even on other cpu architectures. i think that's our niche.

instead he states that retro is bad because it doesn't baby you.  **that's not its goal.**

not to mention the problems stated below.

downmoded.
 
to cut down on all of the ask reddits.
btw, regarding college degree. i have masters degree in cs, but noone gives a shit, really.

it is not what you have, but what you can do.

  the languages are mostly interchangeable (they're quite similar in syntax and principles). but here goes for the python side:

* much better repls than in ruby. ruby has `irb` (note to ruby guys: if there's anything really better than irb, please tell me) which is a piece of dung. python's base repl (`python`) is leaps and bounds beyond that, and it stacks first-party `idle` (graphical repl) and third-party `ipython` (console) on top of it.

* much better documentation all around, on any platform. no only in python itself, but from my experience python modules also have a much better doc, not just an rdoc dump.

* more third-party modules, often more mature, especially in specialized high-perf areas (pil for image processing, pygame for games, numpy/scipy for scientific or big mathematical stuff)

* mature community full of long timer users (as opposed to people who were brought to ruby via rails 2 years ago or less, not that it's bad but "old timers" provide insight gotten through long years of experience)

* maybe it sounds stupid, but i also think python's module system is *much* better than ruby: in python, if i `import foo` it creates an object called `foo` that materializes the module in my namespace, and everything that is in the `foo` module is now accessible in that `foo` namespace. in ruby, `require "foo"` reads the foo.rb file and then *dumps everything in my current namespace*. and if you don't know what was inside, you're hosed. i hate that.

* the zen of python in general, and "there should be one -- and preferably only one -- obvious way to do it" in particular

great books in python, i usually tell people to start with the python turorial, and then jump to dive into python. you don't need books to get started in python.

the advantages of ruby over python:

* `gem`. python has `easy_install`, but it's nowhere near as good, nowhere near as streamlined, and nowhere as obvious to use.

* the pervasive use of blocks give library creators a very high flexibility, an ability to create behaviors in ways that are much clunkier in python (and python has to add syntax to make that better, see the `with` statement from 2.5)

* linked to the previous point, the pervasiveness of a functional style of programming which i quite dig.

* slightly better metaprogramming support, especially for "simple" metaprogramming (generating methods on the fly), that's both a blessing (you can create lots of cool stuff that works through black magic invocations) and a curse (other people can do it too)

* implicit self. yeah i know the reasoning about python's explicit self, but i'd still like it to be implicit.

but really, what i'd suggest you to do is: try each one for a day or two, then go for the one that "sticks". they're mostly equivalent, and when you'll know one you'll be able to get the other one easily enough.  
tempting, but how would we ever get any work done then? ;)
agreed, i had 7 years of development experience coming out of school, so i wasn't overly worried about my degree helping out.  i mostly used the degree as a reference to my age.
i always wondered why etch had iceweasel instead of firefox but never bothered to actually try and find out. now there's one less unanswered question for me.
well, is work really worth the time we spend working?  i would much rather spend most of my time here.
stack manipulations take time to learn when you move away from storing everything in a named variable.  i highly doubt he could have written a _simple_ word like this.
what? the whole place is a forum - as you just demonstrated.
fear not grimtooth. i fully intend to address the typographic issues when i next work on the site. i will be the first to admit that i made a number of big mistakes with this design and it's not working out how i had hoped.

now i have a better idea of what the site is about i'm in a better decision to produce a design around the content rather than try to force content into a design.
unless he's trying to make a website where users submit and vote on stories. ;-)
now if i could get paid to do that...
no it isn't.  sure the user has the ability to do so, ideally; programming.reddit used to be about interesting development links to articles.

now it is more of the form of "what breakfast do you like before you start programming?"

sure, i have done it in the past, i don't have many interesting links to post and plus it is so easy to do.
thank you.
the us government does not pay that much, silly.
aaah, now there's a trick :) he doesn't know he is programming. he is fascinated by numbers, patterns and reinvents many primitive mathematical concepts all the time.

as a result, i installed the glasgow haskell compiler on his machine and gave him a quick tutorial on how to play with it. an example of how he works, he once said to me "any even number plus any odd number is always an odd number" so after a brief tutorial with quickcheck i told him to try to write that in ghc. he enjoyed it and went on to express other concepts.

as a side note, i also actively keep him away from those nasty imperative languages (i.e. by my own influence should he accidentally google something up). i am still in awe at just how delusional the proponents of these languages are and i fear for my son's well-being in that respect.

he seems to be making good progress as a result.

good luck!
wait, you guys get *paid* to do this? ;)
in the end you're just going to try both and convince yourself, so why not just start now and be done with it?
good point. i should have asked on the #reddit irc channel.
so what breakfast *do* you like before you start programming? i enjoy peanutbutter &amp; jam sandwiches myself.
for one thing, code is generally written once and read many times; that for loop is really easy to write, but everyone who looks at the code afterwards has to work though the parameters of the for loop, trying to extract the salient details.  it's not usually hard, but it adds a bit more work to reading and understanding the code.

and not everything is necessarily syntactic sugar.  sure, 'for elt in element-list' is pretty sugary (but more readable than 'for i from 0 to (length(element-list) - 1): &lt;something with element-list[i]&gt;', but 'element-list.each { |elt| ... }' or 'map (\elt -&gt; ...) element-list' is significantly different.
quickie fixes. jquery has a makearray() method and added return this so that you can continue to chain it.

    jquery.fn.extend({
        log: function(){
            var args = jquery.makearray(arguments);
            args.unshift(this);

            console.log.apply(this, args);
            return this;
        }
    });
programmers don't need breakfast.  the normal concept of breakfast is something that you eat the morning, lunch in the day, dinner at night.  developers work 24/7 so generally i eat when i am hungry so the concept of breakfast is a little foreign.  that could be at 12pm, 5am, 10pm
 8 years experience.

work for a mid-cap company in detroit.

make 97k.

started here about 5 years ago at 72k as a regular software engineer, then got promoted to lead developer because of the "business domain" knowledge i gained by being here for that long. i made about 55k at my last job. 
if you use the ide to generate your for loops, they will always be laid out similarly, but i see your point.
 learn them both.  flip a coin and start with one because they really are that similar.  

both communities are growing rapidly and are very supportive although i would say that it has been my experience that the ruby community is a bit friendlier in general.  

ide and editor support is pretty much equal as well.  pretty much if an editor supports one it supports the other.  

one area where i think ruby out shines python in in the plugin and rubygem communities.   
i'd like to add to your point about "slightly better metaprogramming support" in ruby.  in ruby, it's seen as perfectly acceptable to "monkey patch" builtin objects.  that is, to take something that behaves in one way in standard ruby, and add or change methods to make it behave in another way.  this is actively discouraged in python (and, in fact, impossible in the case of built-in objects like ints and strings).

this isn't necessarily either good or bad.  personally, i don't like it, because it means i have to put more effort into reading code that uses this feature.  because the culture of python discourages it, i (being a python programmer) generally assume it's not being used.  so, when code *does* replace or patch builtin objects, it adds an extra cognitive burden to me trying to understand the code.
i work for a mid-size company (600 employees, mostly manufacturing) with a software engineering team of 10. as of last year, $68k salary, plus two $8k profit-sharing checks each year.
 interesting comment. isn't it dangereous to modify objects at runtime by adding and changing its methods? changing state i can handle (though that can get tricky too). but suddenly changing the behaviour of methods at runtime sounds extremely dangereous. 
   however, abstraction is more than just convenience. instead of:

    y = map (x -&gt; x * x) lst
you get to write:

    y = map (join (*)) lst

though, i assume you're writing scala and not haskell (since =&gt;) which doesn't yet have a join function. [however, i'm working on it.](http://projects.workingmouse.com/public/general-scala/trunk/src/scala/main/com/workingmouse/control/)   
let me try


http://programming.reddit.com/info/5yp23/comments/?addingstufftotheurlsoitislong  

(edit 3) 
the scrollbar appears, but nothing is moved...
(edit 4) 


(edit 5)


and there, will it work?
  

(edit 6)

no, a too long url will create the box... i can't recreate the context either. 


(edit 7)
unsuccessfull 
flip a coin.
the only reason i now consider myself a rails expert is because i spent a lot of time in the debugger seeing how things actually work.  

the internals of rails are fairly abstruse.  methods are defined with names composed at runtime.  you can't grep your way through that.  only by "watching the movie" will you ever understand how rails truly works.

i was very happy to find ruby-debug, but it doesn't look like it can hold a candle to the smalltalk debugger.
that makes your apartment almost four times as roomy as mine.. :p

i don't even own a car. mostly because they, along with everything else, are ridiculously expensive in here!

- a second-hand z3 from 2001 (the wimpy 1.9l version) costs around $28500 apparently.

i just checked, and a brand new bmw 320 costs something between $57000 and $78000 depending on the exact model! now how about that?


wow, this sounds interesting. i don't suppose you have a more elaborate writeup on this elsewhere?
thanks, i've been looking for this method many times.
&gt; you cunt.

how nice.

&gt; &gt; it's the title of the article. that's a perfectly appropriate way of referring to an article.

&gt; of an article that says urls should be hackable.

that url *is* hackable.  all the articles appear under `/articles/`.  delete the article title from the url, and you get a list of articles.

&gt; it's all articles on how to make your site more robot friendly.

this is simply untrue.

* readable url slugs &amp;mdash; about making slugs human-friendly, doesn't mention robots at all.
* question concerning django and templates &amp;mdash; about the admin section for django websites, something that will *never be seen  by a search engine bot*.
* undo form reset for kids who can’t reset good &amp;mdash; about javascript to stop people accidentally hitting the rest button on forms, again nothing to do with bots.
* be careful with jquery &amp;mdash; about writing efficient javascript, once more, something bots don't look at.

i don't get it.  you are blatantly lying about this guy.  why?  do you know him personally or something?

&gt; url's should be unique. that goes without saying.

it *should* go without saying, but duplicate uris are very common and it needs to be pointed out in an article about uri structure.

in fact, duplicate uris are a common black hat seo technique.  yet another example of him arguing *against* black hat seo techniques.

&gt; making them where a user can hack them is nice, but that's not what he's doing.

aside from the uri of the article in question, did you bother actually reading the article?  he says things like:

&gt; &gt; the user must also be able to swap in alternative segment that make sense, like changing “2007” to “2006”

you don't think that's making uris hackable?

&gt; imagine calling up someone on the phone and trying to read his url to them, and getting them to enter it correctly. do you think they will be able to? i don't.

i do.  it's long, but it's comprised of easily recognisable words.  compared with common cms approaches of generating long opaque strings of numbers and letters, it's a big improvement.

furthermore, you are focused on the uri of this particular article as your sole "evidence".  you can see clearly how he arrived at this uri, and the only downside is that it is verbose for articles with long titles.  take a look at the same mechanism applied to some of his other articles:

http://www.andrewingram.net/articles/readable_url_slugs/

http://www.andrewingram.net/articles/be_careful_with_jquery/

do you think they are totally unfriendly for humans?  really?

&gt; look at the url's on any good application, like craigslist or youtube, and they break every suggesting that he's talking about.

those applications are not good because of their uri design, they are good *in spite* of their uri design.

&gt; the only reason to make sure that you don't have two url's pointing at the same content, is so your pagerank doesn't get cut in half.

this is not true.  for example:

* multiple links stop your browser history from working properly; links show up as unvisited if you read the article but at a different uri.
* they slow things down and cost bandwidth; multiple uris lower your cache hit ratio.
* they stop duplicates from being detected on sites like reddit.

as [the w3c puts it](http://www.w3.org/tr/webarch/#uri-aliases):

&gt; &gt; the problem with aliases is that if half of the neighborhood points to one uri for a given resource, and the other half points to a second, different uri for that same resource, the neighborhood is divided. not only is the aliased resource undervalued because of this split, the entire neighborhood of resources loses value because of the missing second-order relationships that should have existed among the referring resources by virtue of their references to the aliased resource.

&gt; &gt; when a uri alias does become common currency, the uri owner should use protocol techniques such as server-side redirects to relate the two resources.

do you think the w3c are giving seo advice here?

&gt; this page gives what some may think is good seo advice. it's nothing more than seo advice

i guess [the w3c are nothing but spammers](http://www.w3.org/2001/tag/doc/metadatainuri-31#convenienturis), right?  and [jakob nielsen too?](http://www.useit.com/alertbox/990321.html)

just what is an ignorant language? oh right, java and ruby are perfect examples.
this bug was introduced in the darcs version about 12 hours ago, and was fixed 30 minutes ago.  time to darcs pull :)
they didn't have a 1.9l in 2001 - at least in the us.  the 1.9 came out over here in 1996, and i think was discontinued in 1998.

we're straying off topic, but i love my car :) if it came down to my apartment or my car, well.. i'd have a futon in one stall of a 2 car garage.
just over 110 in a backwoods area of the mid-atlantic states.  but ... my role is more of a mix between cto and programmer (i have a team of 5).
i don't think ballmer was kidding when he said he was going to sue.
apparently being gutsy means not caring about rendering your app properly.
i pay others so i can do this..
i'm afraid the article i wrote is long gone.
you can apply it to all *iterative* problems, which is the point of this discussion.
ask  a lawyer before you use a piece of software.

thank you microsoft.
 ops 20/hr for the govuhment, oracle database programming 

edit: no degree when i started
the 1.9l was found to be slightly.. lackluster even in europe :)

i can relate to your feelings for your car! bmws can be expected to be very pleasant

any idea what a new 320 might cost over there?

(i'll stop posting off-topic now.. :))



it doesn't matter at all. just pick which one you think you might like better based on the syntax alone, because there is little else that is different.
&gt; as a side note, i also actively keep him away from those nasty imperative languages ... i am still in awe at just how delusional the proponents of these languages are and i fear for my son's well-being in that respect.

sadly i have never moved beyond the imperative.  maybe my son and i can learn haskell together. :)
i'm lazy and i've come to the (logical) conclusion on society: people are typically very dumb and i hate them.

it works out pretty well.
yeah, but the last time i tried to buy strawberries, the farmer swore at me :(.
disagree.

gangsta rappers.  early rock &amp; roll like elvis presley, early jazz.  many other examples.

then there are styles like hardcore electronica &amp; programticaly generated music which i'm sure many people consider nerdy and not hip like pop40 star of the month.
i've been programming for about 5 and a half years now (since i was 12 or so,) and have never gotten paid a dime for it; and i don't mind it that way, either. :)
nice idea!  in that case the fact that i took 8 years to finish college works out in my favor in a youth-obsessed industry.  it's especially cool since i was a fulltime developer during most of that time, so my accomplishments look extraordinary when compressed into an assumed shortened timespan.  i'm taking the dates off my resume right now!
as sjanssen says, looks like you're running the darcs branch, where the resizing issue is fixed.

regarding your second issue, losing focus, are you running `unclutter'? the little tool that hides your cursor -- it is terribly buggy and will cause this problem without the -grab flag set.
that's a triumph of hope over reality.

writing a sufficiently fast program can be impossible with haskell but easy with most other compiled languages (even slow ones like lisp and java), e.g. the ray tracer.

that is why haskell deserves its reputation of being slow: using haskell can prevent your code from running at a competitive speed. this is the main reason i'm unlikely to write a "haskell for scientists".

some haskell compilers happening to implement some forms of deforestation is a red herring. you can easily deforest eager code. your implication that deforesting is "invalid" in eager languages is simply wrong. at best it is not semantics preserving, which is unimportant if the semantics are defined to be unspecified (which is often the case for evaluation order of hofs).

indeed, haskell is often criticized for being all theory and no practice and your example of a theoretical optimization that haskell implements in the face of practical benchmark results that show haskell to be slow is just another example of this.

they don't have the 320 over here, just a 328i($32,400) and 335i($38,900) and the prices for each of those rising as you add x-drive, coupes, convertibles, wagons, etc.
[not](http://en.wikipedia.org/wiki/perspective_%28graphical%29) so! in fact you can find [many](http://en.wikipedia.org/wiki/computer_graphics)  interesting [applications](http://en.wikipedia.org/wiki/music) of [mathematics](http://www.wired.com/culture/lifestyle/news/2002/05/52426) in the arts!
as someone with 6 years of experience and no degree...

you're wrong.   unfortunately it's about what you have.  

i make about 60k per year and i can't even get my foot in the door at 50% of jobs.

i start school next semester.
 &gt; programming then is fun because it gratifies creative longings built deep within us and delights sensibilities we have in common with all men.

frederick p. brooks jr, the mythical man-month

[more on the subject](http://technomancy.us/21/).
err, sorry, i think you misunderstood me.  i finished college in 4 years, but i had been working for the same company for 7 years by then doing web development and flash programming.  i used the degree as a reference for my age in this post, not on my resumes.
then this new definition of "lazy" applies everywhere and, consequently, conveys no information.

because i am very good at it.
 the degree may get you in the door for an interview, but ultimately it'll be your knowledge and experience that gets you the job.  i know far too many people that i graduated with that can't find a decent job because:

a) they have no practical experience, and 

b) they didn't learn anything in school, just enough to pass (which isn't much at marshall). 
both. doubles your chances of getting a job.
  here's the average annual salary accepted by (a self-selected subset of) 2006 graduates of the university of michigan:

computer science bachelors: $66,379

computer science masters: $72,625



http://career.engin.umich.edu/misalary_06.htm  
wait till you have to support yourself.  that altruism goes out the window pretty quick when you have bills to pay.
$109,000 five years after my cs degree in st. louis.
relocate. california is hot for programmers now.

-
clearly you have never been in a dilbert situation in real life.
different people have different experiences.  i dropped out of school my first year.  i haven't made as little as 60k/yr since probably 1997.

i've only *managed* to go a week without being employed that entire time (technically, i had a job, but i pushed off the start date).

perhaps you're in the wrong area, or you just need to be more self-motivated.
at first i thought writing 'debugger' in the code was nasty too, but not so much anymore. what's the big difference between adding it to your code or inserting a breakpoint in the ide? the only real problem there is that you might check in code with a debugger statement in it, but this is easily solved via version control hooks.

lack of exception rewinding is a downside, but it is hardly a common feature in debuggers. i don't think ruby's debugger should be ignored for that reason alone.
no, the most annoying bug is the way the recommended page shows recommendations from all reddits regardless of which (sub)reddit you are in.
you can bet your ass that gangsta rappers, elvis, and hardcore electronica djs all have/had access to more poon than they know what to do with.

how many coders can say that about their code? 
skip the degree.  go get a job at a place where you're the dumb guy.

work there until you're the smart guy.

repeat.
well, i was 10, and my friend told me about this awesome program *qbasic* that's on your computer and it let you make **video games!**

i am addicted to all kinds of programming, but video games have always been my true love.

when i retire, i'm going to spend all my time writing open source video games. :-d
 some new terminology i've been seeing lately:

- "fluent interface". each one of your methods only takes one argument

- "humane interface". you have a bunch of static methods with common english words as names such as 'and', 'with', and you statically import these methods

- "bdd". unit testing with 'assert' replaced by 'should'.

so much innovation these days, its hard to keep up. 
 it seems that wordpress is blocked too. i just post http://programming.reddit.com/info/5yp8r/comments/ but again it don't show on /new 
no, he'll still be making 51k canadian, but it'll be like making $102k us$.
...and you're getting free health care that you won't lose if you lose your job.
on the contrary, lisp predates most of the type theory seen in ocaml, haskell and f#. moreover, this is precisely what makes these modern languages more reliable.

working in what field?  i'm going to guess finance.
it's called rest.
ocaml for mac os x as well.

the normal people recognize that we're doing something they can't possibly do! though... they probably think they could. but sometimes they realize they can't!
you could do that if you wanted to in python. on the other hand, if you're not going to use the function again, you may as well just use a loop instead, so that you don't incur the minor speed penalty you get from launching a function in python and (less importantly) you don't have to think up a function name, since in python multi-statement functions can't be anonymous.
     join f = f &gt;&gt;= id

the point is the type signature. i should have used fmap instead of map earlier, so:

    y = fmap (join (*)) lst

    :type \lst -&gt; fmap (join (*)) lst
    forall a (f :: * -&gt; *). (num a, functor f) =&gt; f a -&gt; f a

note the more abstract function, denoted by its type signature. i'm just pointing it out, in the context of type classes :)
f# is better than other ms tools because so much code runs in both ocaml and f#. we have a lot of commercial code running on the three largest platforms as a direct result of this.

also, the advantages of modern fpls extend far beyond just functional programming: pattern matching is an enormous benefit in many applications.

legal and medical documents. medical insurance.

$55k canadian, toronto
1 year and a bit out of a bachelor degree
yes, but don't a lot of functional-ish languages have crappy loop structures? for example, it's my understanding that common lisp has great map, filter, etc., but there are a couple different, incompatible ways to write for-loops, and you the programmer have to figure out which of them is the best for what you're doing, instead of having a single tool that can cover all the cases simply. 
have fun!

remember, there is always room for beginners and their questions in the haskell community :) feel free to ask me personally if you like.
what about loops with breaks? or loops where you need to retain data from one pass to another (and you don't feel like adding an otherwise pointless data passing parameter to your functions)? you of course can do these things map-style, but i think it's simpler to just for-each loop them.
string doesn't implement your fancy new interface, but you can define a concept that accepts string.
well, i learned today that computer programmers are extremely overpaid.
what about the continuum hypothesis?  
but what will you do?
&gt;$140k and you get to use lisp in your day job?

i hearby proclaim you the god of programming.reddit.com.
what do you do, who do you work for and how can i get a job there too? 
there was a paper by erik meijer which discussed the vast majority of loops in terms of four main types: anamorphisms, catamorphisms, paramorphisms, and hylomorphisms.

these are really cool -- neatly abstracting the concept of "a loop" or, better yet, "an operation over a collection of items". this allows a sufficiently smart compiler (heh) to select an implementation strategy to suit the circumstances. for(int i=0;i&lt;length;i++) is low level. it's like assembly language. if you have say, an simd processor that can handle chunks of the loop in one swift stroke; or perhaps one of those nvidia tesla things, a conventional for-loop no longer applies. to optimize, compilers will have to pick apart the loop and recognize that certain optimizations are applicable.

hence the sufficiently smart compiler for a language which implements looping constructs at a high level of abstraction can be dumber than a sufficiently smart compiler for a language which uses for(;;). :)
$80-130k in the san francisco bay area for programmers with reasonable experience. interesting folks get more than that, or start startups &amp; get v. rich/broke, but if you'd done that you wouldn't be asking...
when someone passes his first-degree initiation in forth, they give him an apron embroidered with the words "i learned to see the spaces".
 this actually brings up an interesting theoretical insight for me.  thanks!

if (edit: perl compatible) regular expression matching is np-hard, and cfg matching is polynomial time, then converting a regular expression to a cfg must also be np-hard.  otherwise we could do regular expression matching via conversion to cfg and cfg matching.

http://perl.plover.com/npc/ 
70k, one year after graduation.
flash programming only 
| would you rather | have your stories | in three panes? |
 adding features to a regular expression engine, until it accepts non-regular languages is fine. but to keep calling it a regular expression is just making people confused. call it what it is, context free languages. 
if you can't get an interview, it doesn't matter what you know.
$52.5k, 1.5 years into my first job out of college. i have a bs in computer science and i live in city where the cost of living is pretty low. also, i'm hoping to have the 'junior' knocked off my title in the near future :)
that's stupid. 

by that argument most languages shouldn't bother considering closures and map/reduce as they do just fine without them.

our toolboxes should be growing with time, not simply trading one imperfect tool for another.
i make $110/hr writing reports and doing maintenance on erp systems. i have no degree or special training. i just know enough technical stuff to get a long and i understand business and listen to peoples problems and fix them. nobody has ever asked about my qualifications, they just hear me asking smart questions about what they are trying to do.

f#?
not when you take into consideration how much effort is involved. we don't read sites like reddit just because we are bored, we need to constantly keep our skills up to date, often on our own time. like lawyers and doctors, our knowledge grows stale quite rapidly. 
interesting. poor performance is the reason i stopped learning haskell, rather than the intrusively of being purely functional.
i'm not in favour of changing code unnecessarily, even ignoring forgetting to remove an expression. it's bitten me a few too many times, despite reviewing code before checking in. that doesn't mention the break in workflow.

i'll have to experiment a bit with the remote debugger.
you know, i always hate it when i make a joke and someone responds seriously.  now i've done it to you.  sorry about that!
&gt; who the hell cares how a word defining a piece of cashable paper is **spelled**!?

there, fixed that for you.
came in handy today.
c++ std::accumulate(elements.begin(), elements.end(),0);

or for a c-array

std::accumulate(elements, elements + length,0);

not quite haskell which is simply
"sum elements" or more complicated as "foldr (+) 0 elements"
**both**. me? i've spent time with python and scheme, so there's no juice in it for me to learn ruby. i'm currently wrestling with erlang so i don't have the time for ruby.
nothing is free.
believe me, doing javascript isn't bad.  in fact, it's probably one of the better stronger languages to learn.  i'd learn java out of necessity, but don't bother getting a java related job.
that certainly is a wild-card. 

right now i don't see it becomming real popular, as vb and c# will be getting a lot of the good things that f# offers. but then again i find myself writing about it a lot on infoq, and i don't even like functional langauges.

no matter how this plays out, it will be interesting. 
morris kline wrote a number of useful math books that teach math as a natural extension of the scientific problems at the time the new mathematical techniques were invented.  because it is more grounded in history and application, this is a fairly intuitive and useful approach to go about learning mathematics.  math folks don't like kline as much because his writing doesn't try and gussy up the math in useless formal language.  instead, he makes it easier for people to understand the important ideas.
degrees mean very little.  look at rich kilmer, he doesn't have a degree either, but he founded rubyforge, and a dozen other startups.  he currently cofounded infoether working with chad fowler on some interesting project for certainty.
that's why i'm all about debian etch. 40 min for a full install from a network mirror. 20 min from a cd. 
 i'm wrapping up my 8th year in it, with about five of those having been spent as a software engineer. i'm currently making just under $60k, but i work in the .edu sector.

the downside is the obviously less-than-market-rate salary. the upside is that i have a laid-back working environment, great benefits, and really, really smart co-workers.

for now, my salary suffices to keep me living comfortably, but i'm sure i'll start shopping myself around a bit once a mortgage and/or kids enter the picture. 

_edit: i have one year of college as an undergrad and a handful of graduate-level cs, math, and linguistics courses under my belt, but no degree._
i worked in a unionized it position for several years.  i would never do it again.

it was my experience that unionization inevitably turns even a highly-skilled job into one requiring no significant skills.  unionization makes it so the main thing preventing your ass from getting fired is not your performance but your union card, ensures that the d- people and the a+ people are making the same money (unless the d- person has been around longer, in which case they get paid more), and puts significant pressure on the best workers to work at a lower level in order not to make other people look bad.  

this leads to the most competent people getting the hell out of there and the least competent sticking around forever.  over time, quality and expectations go down, and the amount of skill required to do the job trends towards zero.  over a few years, this leads to a situation where you get no reprimand other than several month's paid leave for bringing a gun to work and threatening a coworker with it, but you can get fired for checking your email from home at night.

serving a group of unionized users makes things fun, too.  nothing like the union threatening a strike because of your plans to upgrade the old windows nt 4 machines.  somebody decided that having to learn windows xp would be "too stressful" for some users and discriminatory against older employees, and hence would create a hostile working environment.
same here, the submitter must be looking for porn or something...
that'd be fun as hell to write a script to endlessly bug and annoy your loved ones after you die. 
good read, describes the basics and how to get started.  

cant wait to start using the killer factor application.  actually, the factor web server and framework is pretty nice and robust. 



i don't know what's the deal with the downmods lately...  grandparent still makes 51k cad, but yes if the usd drops off the map, he'll be the rich man in north america.
1.5 years out of college, second job, 65k.  started my first job out of college at 50k.
i thought that was "if we give peas a chance the lima beans will feel left out"?
 retired in 2001.
high school dropout[1].
last salaried gig was about $130k, plus benies and incentives.

[1] ok, i didn't finish high school. i got the equivalent of an ms compsci via self study with a few good mentors, challenging work. they call it "continuous quality improvement".

 
more money doesn't mean more happiness.  my last job paid 90k plus big 40% salary bonuses at a large institutional investment company.  i didn't like it.  i now work for a small startup and i'm paid 60k, yet i've never been happier with my work.  
 i got my bachelor's degree in cs a bit over four years ago. i make $50,000 a year at a job in a university where i have been for almost 2 1/2 years. i could make more money at a commercial company, but i have more free time at a university.
my take on python/ruby:

ruby is a better language, better structure, designed mostly correctly from the ground up, good syntax.

python is a better development tool because there's lots and lots of useful code out there for it.  this might change as ruby uses it's recent popularity to "catch up".  if i need to write an application using one of these 2 languages, chances of finding good resources to work from are much more likely in python than in ruby.

ruby (currently) is good and useful for rails, and that's it.  and python frameworks aren't really far behind, and as wsgi catches up, it negates some of the rails effect.

and google uses python, so i do too, since google owns the world.
no, there is simply more demand than supply. the supply is kept low by the requirements of the profession, and that means programmers have earned their relatively high salaries.
this did fix one bug (most of the others are system things, and couldn't possibly be affected by doing this).  unfortunately i don't know *why*.  i obviously need to copy across all my data/config files, but you can guarantee that as soon as i do that, the bugs will come back.
$115k, bs in computer engineering, sf bay area, startup company, i claim about 9 years experience.
high school drop-out, no college. 8 years experience programming, mostly in the financial industry. $180k.
you got off easy. you should have heard what he said to me and my gf when i tried to get some raspberries. my gf cried for a week.

i think he use to be a cobol programmer before he became a farmer.
 i make $12000 a year, without bonuses.
wait? $12000?

yes, that is what evil us corporations pay us outsourcing monkeys ;-)

and all our programmers are at least okay. not even one codinghorror case, afaik. all of them including myself have/will have cs master degree, although it was not high quality education.

overall cost of life in my country is not much cheaper, than in us.

so remember folk, you're very lucky ;-) 
i'm tired of this gupta-like argument about "nothing being free". it's so redundant. 

when people talk about tax based services as free, only real idiots misunderstand. and since real idiots are so uncommon, it's mostly those who don't believe in paying taxes for said services, but are unwilling to phrase it that way.

it's always funny when i keep hearing people say health care is not free in countries that provide universal health care, but have no qualms about saying that they borrow the book for free from a library, or check out a dvd for free from a library.
...anything else? like why, or when, or under what circumstances, or for whom?
   &gt; i know far too many people that i graduated with that can't find a decent job because

um, how about because computer science degrees are designed to teach one how to be a computer scientist, not a software engineer?  there are many *practical* software development issues that are never touched on in cs.  cs theory.  engineering is practice.

universities are not trade schools.  if you want real, practical experience, you have to get it yourself!  no one ever became a master engineer just by reading books, in any profession.  homework only goes so far as a simulation of the real thing.  everything important i learned about software engineering, i learned on my own time (outside classwork) or in internships.

i agree it would be great if someone set up a professional education program for software engineers, but i am not sure it should be universities.  computer science and software engineering should be different (but overlapping) programs in any case. 
can't find a link for that.  do you have one?
behold, the power of... well, lots of languages!

    total = sum(elements)


that's why i try to help with documentation when i'm unfamiliar with the codebase.
upmod for use of [hugeurl](http://hugeurl.com/).
that's what *she* said!
0 =(
well, if you've got perl 5.9:

	m{(?&amp;s)
	  (?(define)
	    (?&lt;s&gt;\((?&amp;b)\))
	    (?&lt;b&gt; | \((?&amp;b)\) | (?&amp;b)(?&amp;b)))}x
&gt; regular expression matching is np-hard

it certainly is o(n) in the length of the text; that is, firmly in p. what is np-complete is matching in the presence of repeated captured subgroups; this is a special case of cdg.

the matching expression in the article follows a fifo discipline when matching a named captured; hence, it is something that could be matched by a push-down automaton and thus context-free.
matching expression?
65-85k, boston area lamp{hp,erl}
employers are required to cover 1/2 of your social security tax. that tax is 12.5% on the first $96k of income, or something like that, i forget the exact amount. but, it amounts to no more than $12k out of the employer's pocket. in general, the _net_ tax on income in the u.s. is around 20%-30%, but it can be much higher or lower if you are particularly bad or good at your tax planning. in my experience, you pay no more in taxes when you are self-employed because you have access to many more deductions, but ymmv.

what makes the largest difference in salary versus contracted revenues is benefits, particularly health benefits. if you're young and healthy, contracting is usually a net win  to the tune of maybe $10,000.

so, if you're making $70,000 contracting, then you should expect to make about $55,000 on salary, give or take.

my personal contracting salary was about $160,000 and when i accepted a full-time offer, i converted that to be about $130,000. i accepted something somewhat lower than that, but it includes an excellent stock and bonus package that should more than make up the difference.

actual education makes a difference, the degree much less so. i've got about 13 years of experience and no college degree, but i have over 140 hours of  coursework and about 1/3rd of a ph.d. degree in mathematics. i'm an educated, articulate person and that comes through in interviews.

you can and should self-educate, however.

also, pay attention to the labor market. if you're living in des moines because that's where you were raised and you can't imagine living anywhere else, then you're eventually going to end up working for.. uhm.. wells fargo? i think that's the 1 big company there. you'll be lucky to ever make $70,000.

silicon valley, seattle, new york, washington d.c., atlanta, and boston are all much, much better labor markets and you will end up wealthier if you move there earlier in your career. in silicon valley, many junior programmers make $70,000.

erm... why?
  a really long winded way of saying that oo problem solving is *sloppy* thinking. "everything should be very concise and in the same module. i don't care if i am rewriting the same method over and over, it is fast since i already wrote it once(duh)."
-paraphrase

i often wonder if there is some blob of text that every uses to talk about oop, or anything for that matter, in which they can convey that they understand it and yet dislike it. or perhaps some people can go into anything and, regardless of the facts, never change their mind.

the last section is indicative of why he would dislike oo. perl is good... hah. perl is good for what it was designed for, as every language is.

edit: quotes no longer work?
&gt; anthropomorphic terminology

this i find especially problematic. in my opinion, it makes very difficult to speak rigorously about the program and its properties.

when you get to the core of oo, it is a rather simple, rather odd syntactic style of programming with dynamically-bound variables. dynamic semantics tend to smear all over the program and makes static reasoning nearly impossible; thus, the cottage industry of dispensers of advice (all essentially incompatible among themselves) about how best to avoid shooting yourself in vital parts of your anatomy with the object-oriented gun.
&gt; real idiots are so uncommon

meanwhile, back on planet earth...
mm.. tig.
that was my point...  as a side note, i didn't get a cs degree, i got an mis degree.  same basic thing at marshall, but with more focus on business, and less on math
 ugh, still no clean solution to the  multiple dimension url space problem: http://www.andrewingram.net/articles/readability_uniqueness_hackability_and_meaning_in_url_design/#comment-5267

yes, we all agree that urls identifying a *single* resource (a blog article, an individual car for sale) should be unique. human friendly if possible (ie, a nice title-based slug) or totally opaque (ie, a car's vin).

however, what i still haven't seen a convincing answer for is how to structure urls when there are *several possible hierarchies*.  i.e., if you've got a shoe site, do you do /boots/cowboy/black/ or /boots/black/cowboy/ ?  both are clearly reasonable.

how are folks dealing with this issue?
thanks! that's exactly what i'm looking for!
indeed, perl and php are horrible for oo. it's half-baked in those languages. c++ isn't any better because it lacks reflection.

i think oo wouldn't get such a bad review from people if smalltalk was used to teach it.
 [here you go](http://citeseer.ist.psu.edu/meijer91functional.html).

a somewhat pedantic note. morphisms\* are actually more general than "generic operations on a collection"; they generalize to algebras and co-algebras, or to min-fixpoints and max-fixpoints of functors, depending on your (categorial) perspective. the "scrap your boilerplate" series of papers deal with the theory and practice of this.

*edit:* slava is right, i was sloppy. i meant, in context, {cata,epi,hylo,para}-morphisms.
i was thinking about upmodding this comment but wasn't sure that i could.  though i probably can.  but i might realize i can't.
careful, you might have just invented a new agile programming method.

"lego driven development"&amp;mdash;you start with a certain set number of "blocks" (keywords), and eventually run out. if you want to keep building, you have to refactor a "block" out of somewhere else.
i need to get back into flash... i did it exclusively for about 3 years, and intermittently for about 2 more.  loved every second of it, i just drifted away, and don't really have the time right now.
 at first i laughed, but honestly, i don't know that that would be a bad thing.

happiness is fairly inexpensive. 
is there an understandable version of this article somewhere? this sounds extremely interesting but i'm not a computer wizard.
oh my god, only $12k?

i'm still an undergrad in brazil and i was really hoping to make more than $20k/yr after i graduate.

nowadays i make about $300/month with two internships (150 each).
only the ones that spend all day on reddit ;)
these are so pathetic that they look fake.

why is the name of the writer of each of these not present?
incidentally, don't fall for the bs that this is an unethical question.  no one is being put on the spot, and anyone who doesn't want to answer can just not answer.

the bizarre idea that it's unethical for you to even remain in the room while people are discussing salaries comes from businesses, not employees, and it exists because businesses have more power to hold down salaries when people know less.  results include overt discrimination in pay scales, with no accountability because no one knows that it's happening.
errr, you are confusing a lot of things.  let me clear some things up:

first of all, regular expressions, regular grammars, and discrete finite automatons are all equivalent representations for the same matching concept.

&gt; if regular expression matching is np-hard

not only is regular expression matching o(n), it can never actually be more than exactly n steps.  np-hard?  are you kidding?

&gt; cfg matching is polynomial time

*what?*  matching context-free grammars is harder than regular expressions.

&gt; converting a regular expression to a cfg must also be np-hard

no, no, no.  a regular expression (in grammar form) is *already* a valid context-free grammar.  in terms of expressiveness, re &lt; cfg.
not only do they look fake; they clearly are. (admittedly, it would be nice if this were explicit in the original.)
if you truly *haveanidea* then you would know that "any man who afflicts the human race with ideas must be prepared to see them misunderstood" (h.l. mencken).  if these are not actual responses, i'm sure they are nevertheless representative.
nunya
it can be, but it's the smalltalk way.  objective c does this by way of categories.  you don't want to just toss every method you think of into object, but sometimes it's just obviously the right thing to do.

for example, in an objc project i was working on, it was *really* convenient for me to have an ``md5'' method on nsstring, so i just added it.
 if you can't get an interview for a programming job you're either looking at the wrong companies (the ones that haven't yet realized education has very little to do with good software engineers) or you're really not all that good. 
$42,000 with no college, using a language i love
pretty funny if you read it all
gotcha, makes sense, i never really understood why it was so taboo.
holy buzzwords there batman. a morphism is just a function which preserves some structure of the objects involved (eg, a linear transformation of vector spaces).

sometimes i wonder if haskell people like to casually drop category theory terms into conversation just to appear smart.
that was helpful...
seconded. went from being a team lead consultant (== prostitute) to "normal" gamedev . was so worth it. even if i hesitated a bit before i jumped.

having fun, competent coworkers and sensible company direction pwns salary any day of the week.
"debugger" is a wholly inadequate term for what smalltalk offers. th introspection-, runtime modification inspection capabilities of the image browser are awesome. 

(i think giles is probably a victim of the gdb-style debugging which does indeed seem a nigh-pathological pastime although necessary in some environments like c systems programming.)

hopefully we will be able to create support for at least close to a smalltalk degree of debugging for [rubinius](http://rubini.us) even though (at this point) it does not look like it will be a fully image-based system.  
a few glasses of wine apparently made me into an anonymous steve yegge. so sorry, but i'm not in the mood for editing, so here's my answer and apparently my life story.

currently i'm running a two-man consulting company with my former cto, "mm". we're doing a short-term project for a bank (ca. 2 months) for $215 per hour. this is high even for me, my last gig paid $148 per hour. don't know how much i'll get for the entire year since i've only worked for three months since i came home from travelling after uni (up to $47k before taxes atm).

learned to read when i was 5 (upside down at first, since i sat across my two year older brother watching him do his homework). punched in my first program from a magazine when i was 6 (on an zx spectrum. made a text-version space invaders clone when i was 11. ripped off my friends by programming a slightly predictable roulette game when i was 12. played around making demos in pascal until i was 15. used visual c++ to program an angband bot, mini-games and backdoor programs to mess with my mates in high school.

didn't really know what i wanted to do, so got a data-entry job after high school. met mm, the cto and one of the founders of the company, who offered me a job as a programmer. $60k per year. he was an incredibly skilled programmer and designer and taught me how to be a great programmer. i also read and read and read and read everything about design, programming and programmers i could manage. was living with my gf for a period with a two hour commute each way, always carrying around a fat stack of articles to read on the bus.

worked there for almost four years, earning about $75k the last year as a tech lead on a medium sized project, being one of the two top programmers in the company. mm was forced out by some venture capitalists, so got a new cto, who taught me how to be a manager. he allowed me to try myself as a tech lead and coached me through it. he wasn't very technically skilled though, and changed the strategy of the firm in a way i didn't like (e.g. porting everything from linux to windows). in addition, the other programmers got paid a lot more than me, even though i created more value than most of them, so i got sick and quit.

went to uni for fun for three years after that. was allowed to replace all the first-year units and some of the second year units with my own choices. tried to do as many hard courses as i could, e.g. advanced algorithms, compiler construction, functional programming, mathematics, etc. this was easier than what i'd been doing the last three years so had a lot of fun in the sun. the amount of vacation you get is awesome.

now i'm planning to "retire" when i'm 35. of course i'll never really retire, since i love programming, but i want to be able to spend a lot of time with my wife, kids, charities etc. 

so wrapping up with some advice for the smart, demotivated kids: set yourself a goal, work hard as hell, become one of the best in your field, keep current, learn how to sell yourself or associate yourself with someone who can. you'll get the freedom to get the jobs you want (that are fun) and obviously lots of cash.


you get paid what you are worth. even when you consider developers in india and china, they wind up making quite a bit more than "average" just like here in na and europe...if it was easy, everybody would be doing it.
well, and for the chance to reproduce in the traditional way.
trying to teach oo with c++ or java is like trying to teach functional with c++ or java. it's utterly ludicrous.

and trying to teach oo with lisp is like trying to teach functional with smalltalk. again it's utterly ludicrous.

there aren't many oo languages (smalltalk and self are the only ones that come to mind) so i don't see why anything other than smalltalk should be used to teach oo.

we live in a ridiculous world.
isn't that what you tell kids who aren't very good at sports, or not very smart, to make them feel better about themselves?
i was under the impression that the free software movement was about *software code* being free to view and modify and release -- precisely what mozilla corp was created to do re: the netscape codebase.

so you can't modify and redistribute a company's logo?  how does that imfringe upon your rights regarding the software?  it *does not.*  

furthermore: gobuntu being "completely useless" if it includes non-free files?  if having a few non-free logo files on your machine gets your panties in a bunch, how about *uninstalling their package and installing one of debian's?* 

i agree with mark on a lot of topics, but when he dives into zealot-mode i just can't take him seriously.

 i, as a dyed-in-the-wool ocaml'er, resent being called "haskell people" `;-)`. you're right, i stand corrected. 
  [hans reiser](http://en.wikipedia.org/wiki/hans_reiser) wrote about this. his essays are tough to read but i think his ideas have plenty of merit.

'[ordering of name components](http://namesys.com/v4/v4.html#ordering_name)', in which he draws a distinction between hierarchical and non-hierarchical names, should get you started.

urls do have a seperator for non-hierarchial path components, i think it was intended to be ';', but this character has been used for other purposes. (i remember this from i don't know where, but i can't find it in the [relevant section](http://tools.ietf.org/html/rfc3986#section-3.3) of the uri syntax rfc.)

to take your example,
/boots;cowboy;black and /boots;black;cowboy would be equivalent urls. 
doesn't the company just pay everyone 6.25% less to cover their part of the ss tax? i think there's good economic reason to believe the worker pays the whole amount either way.
there is a difference between optimization and writing code not slow from the beginning.
you know, i just got goatse'd by someone today.  that and this reference, both in the same day. what is going on. 
90k/yr + &lt;20% bonuses 

10 yrs experience

mostly unix/linux perl, php, java, c, c++, shell scripting, 

sql (ddl, dml, etc) with informix, sybase, oracle, sql-server, mysql, and postgresql.

or course various ides, editors, source control systems and build systems.

jack of all trades, and a master of maybe one.


`giraffe` is a subtype of `animal` in this example.  that's kind of the point.  he's talking about array covariance.  c# (apparently) considers `giraffe[]` as a subtype of `animal[]`.

what he's saying though is that `giraffe[]` is _not_ a subtype of `animal[]`--if it were, it would be substitutable for `animal[]` and safe to put any subtype of `animal` in it, but as it is, it's not even safe to put an instance of class `animal` in it!

so i think what he means by bigger/smaller is to capture what c# considers to be the subtype/supertype relationship, while defining his own such relationship to consist solely of explicit inheritance.
you're wrong.  to correct, take the negation.
downmod for same.
    avi := avi + 1.
if there is anything worthwhile on blogspot, someone will just linkjack it and it will show up on reddit.
sql on the client. good thing?
that looks photoshoped.  i should know, i've seen a lot of 'shops in my time.

seriously though, are you hiring?
i await the factor implementation.
 i wasn't referring to you specifically. i just think in many instances we see very simple programming language concepts being buried underneath impenetrable category theory. it reeks of elitism. go to #haskell and you'll see everybody talking about co-algebra this or monoidal category that but nobody really knows what they're talking about. 
make some minor changes to the source of http://www.wee-url.com and you'll have it.
what are the advantages/disadvantages of sscm over [tailor](http://progetti.arstecnica.it/tailor)?
because it's fun. kinda like solving the puzzles all the time and getting paid for it... ;)
when i'm looking for developers, i don't care much about educational background.  i only talk about it when they have nothing interesting to show.

i interviewed a phd. student recently who had less theoretical knowledge about cs than i did (although a stronger math background).

i'm really unimpressed by what's coming out of a lot of schools nowadays.  just show me that you have a good understanding of something.  i don't care where you got it.

sure, if you have no experience, i'm not going to pay a *lot*, but if starting out is the problem, temporarily lower your standards and impress people technically without drifting too far off the business gameboard.  your first job will probably suck in a lot of ways.  stay there a year or so and look around some.

when you're not at work, go home and do something completely different and challenging.

i know a lot of successful dropouts and loser grads.  the differences between the successful people and the unsuccessful people are mostly their passion and what their aptitudes are good at (/idiocracy).
yes.  see also:  [gears](http://gears.google.com/).
ah, well then.  what do you think would be a good solution?

as much as i hate standards, i have thought that perhaps professional qualifying tests might be good.

most other engineering professions have certification programs.  why not software?

(not that i want to do this.  it would certainly have to be done very well to work.  just an idea)
&gt;and trying to teach oo with lisp is like trying to teach functional with smalltalk.

not true. what about clos?

it may also help to actually implement an oo system in scheme.
this is a quote worth preserving for posterity.
 in production, right? :p 
the junk contains auth info.  making it time dependent makes it hard to script.  they'll move on to more easy prey.

seriously, it is very easy for a black hat to totally fuck up a web *application* that adheres strictly to rest principles.  why make it easy?



 what about blocks in smalltalk? blocks don't make smalltalk into a functional language anymore than clos makes lisp into an oo language. i am sick and tired of people dragging in clos. lisp is not oo, *period*. 
or you live in houston and don't want to do front end web development.
south florida, about 8 years experience, heavy unix/php/mysql, $85k plus bonuses totally around $20k give or take, only tech at my co (for now..)
it all follows the italian paradigm of programming from the gut.  first, there was spaghetti code, then lasgne, and now ravioli. 
discussion of these forms is best served with tortilleni.
been waiting for it...
blogspot.com is blocked?  dang.
 everyone seems to think they know "what oop really is."  why not debate the sub-concepts of oop on their actual merits, instead of arguing about the meaning of a word? 
no, there is just a difference between optimization and premature optimization. some optimizations can be performed right in the design phases yet not be premature. 

writing code not slow is optimization - you have to work extra for it. 
great news. i'd love to see some performance numbers on this. if it's comparable to traditional looping/regexp then i think we'd have a huge win, at least, in traversal syntax.
check out [packrat parsing](http://en.wikipedia.org/wiki/parsing_expression_grammar#implementing_parsers_from_parsing_expression_grammars). it technically doesn't handle all cfgs, but the algorithm is o(n)...
&gt; ruby (currently) is good and useful for rails, and that's it.

actually, if i were to use ruby, it'd be because the language is so strong...rails isn't all that appealing to me (and i have written an application in rails).  it's certainly a fine framework, but the tasks i need to do don't fit the mold very well.  but ruby as a language is fantastic.
does the factor library have a uniform naming scheme?

aspose.pdf.kit is a .net component to edit existing pdf documents supporting window forms and asp.net applications. it also supports for xfa, adding digital signatures to pdf, 14 built-in font styles, modifying acroform, extracting and adding images &amp; text, add or set user-defined xmp metadata, encrypting or decrypting a pdf file, adding watermark or logo and converting pdf file to image formats.
yeah, sometimes. but i would like paid sick days and paid vacations. then again, i like not having to work nights or weekends. tough call.

btw, why the hell did people mod me down? mods are on crack. either that or i have an enemy auto-downmodding me.
ah, the old "no true oo" argument.
we need additional pylons.
it seems to. from looking over it, there are some smart naming conventions. since there's very little syntax in factor (whitespace basically is all you need), words can use characters that most languages can't or don't use.

as an example, factor follows the scheme/ruby tradition of a trailing '?' to show the word will return a boolean (aka char?). there's also the lispy lack of underscores and the use of '-' as word delimiters instead (file-handler as opposed to file_handler). another convention is angled-brackets represent words that will create an object of some sort (my terminology might not be the best here). so for example &lt;file-writer&gt; might be a word that creates a file you'd write to on the stack.

it is a rather clean language. stack-based programming kind of requires that your words be as descriptive as possible and the naming conventions really help.
&gt; indeed, perl and php are horrible for oo.

perl and php have a completely different approach to oo, and it's silly to put them in the same sentence.
love those lectures.

i have a video lecture blog where i have collected most of the maths lectures on the net:

basic maths (algebra review, intermediate algebra, elementary statistics, applied probability, trigonometry, pre-calculus, calculus, same mathematical writing: http://freescienceonline.blogspot.com/2006/06/more-mathematics-and-theoretical.html

intermediate maths (discrete maths, algebra, linear algebra, differential equations, math methods for engineers): http://freescienceonline.blogspot.com/2006/06/free-mathematics-video-courses.html

advanced maths (practice of mathematics, geometry and topology, string theory maths): http://freescienceonline.blogspot.com/2006/09/mathematics-video-lectures.html

have fun :)
ahhh, the old "i'll just use something i found today in wikipedia" comment.
you forgot "world peace" and "for the children"
sorry, i haven't had experience with them but this is the second rant against oo that i've come across in two days. the last one was written because the author was trying to use php's oo system.

i'd like to know what the difference is. could you point me to a link or summarize in a sentence or two? thanks.
i wasn't saying that lisp is oo. i was saying that clos is there and it is a different approach (or it at least it seems that way to me) to oo.

by the way, could you name a good smalltalk interpreter? i'd like more bullets for when i argue against c++ and java.
i'm still waiting for tiramisu.
perhaps people get tripped up by the superficial syntactic similarity.
wow, reading hans' essays hurt my head almost as much as nina's.  ;-o

i think [the new rest book](http://www.oreilly.com/catalog/9780596529260/) discusses this some... i'll post what i dig up.
fair enough.

when something bad happens (or it hits a break), you get dropped into a debugger, and have the option of inspecting the call stack (including seeing the values of bound variables provided the debug level is high enough). this is nice enough, and when you use slime, you have additional option of viewing the source of the function associated with a frame, which is also cool but not world-shaking.

better still is that you can eval arbitrary code in the frame, with access to the variables. slime again provides some convenient options, so you can call those values up in the inspector and all.

lastly, you can rewind the stack to an earlier point and start it up again. this may seem kind of useless, but one of the things that it lets you do is redefine the function where things go wrong and then restart with the now (hopefully) correct version. there have been times where i've been able to fix three bugs in a single test run this way.
i don't know whether certifications are the answer or not.  i don't know why i feel that way, probably because i took 3 out of 4 semesters of cisco classes in high school preparing to get my ccna.  i then realized that since i was going to school it would be a waste of time and money to finish because the certification expires every year and you have to continue to get retested.

i think a low paying internship might be of some benefit, but i don't know how far that would go either.  it would get you the practical experience, and be a good place to gain references.  at the same time, it would be pointless if the internships didn't give you enough responsibility to be of any use.

either way, i think once you've landed your first couple of work experiences, the focus should be (and probably is) your previous experience and references.

this is a really interesting topic, i'll come back and post more after i've thought about it a little while (read: i'm gonna go get drunk).
you missed the joke..

slava hates ruby because the vast ruby library does not conform to his idea of how objects and functions should be named. he also hates people who program in ruby (the dreaded ruby community) because they refuse to follow his idea of how things should be named.

odd that you should point out factor has the ruby style ? at the end of functions.


you don't know the meaning of the word 'paradigm' do you?
he is ranting against the wrong thing. the problem is not the software model. it's human beings and reality. both "the real world" and human beings are famous for being sucky, irrational, chaotic, and driven by random inputs.

you want to sell software? you are going to have to add features. no doubt about that.

oddly enough open source does not seem to suffer **as much** from this disease. most open source software seems to embrace the plug in model where you get the basic toolkit and add the features you want through plug ins.

i know slava can be very negative (i've said as much in a few of my own comments), but in looking at factor recently i've just come to the conclusion that he just has very high standards. slava seems to have a pretty good understanding of multiple languages and he talks some smack about ruby because he knows what has already been done with common lisp and other languages and in some places ruby is a step backwards. but he makes negative statements about python and other languages all the same.

that being said, when i used it, ruby's naming conventions seemed pretty consistent. and slava probably borrowed '?' for predicates from scheme (which ruby did as well).
to be honest i mostly author things in c/c++/java and often in shell scripts. can't really help you here i am afraid
 this will be quite useful. i often find it to be the case that my linux is late. if it has a scheduler i am sure this won't happen anymore. 

i was coming very close to demanding my money back.  
is this boss of which you speak actually you?

if you have to post a submission like this i can but only assume it is in fact the case that you are indeed somewhat incapable of the abstract cognition required to apply the aforementioned techniques.


 &gt;i know slava can be very negative (i've said as much in a few of my own comments)

i would have used the word asshole but whatever.

&gt;slava seems to have a pretty good understanding of multiple languages and he talks some smack about ruby because he knows what has already been done with common lisp and other languages and in some places ruby is a step backwards. but he makes negative statements about python and other languages all the same.

not just ruby. slava shits on people who use the language as well. i guess he doesn't want anybody to use java, ruby, python, perl, or any other language that he doesn't approve of.

oddly enough even though there are ten thousand reasons one can say ruby is bad he chooses the most irrelevant ones like "the library does not have uniform naming standards". 

maybe one day factor will have 1/10th the library of ruby or python or perl and then we can do a real comparison between the naming conventions of libraries, after all it's much easier to have a uniform naming convention when you only have ten libraries.

until then factor will remain a fringe language whose community is represented by a world class asshole.

 
because flickr is owned by yahoo!, whereas google code is owned/run by...uh...google.  i would have hoped that someone using this service would have at least had the common decency to use one of google's image services.
i make $120k with great benefits, 7 years experience, with a good professional reputation and lots of open source experience.  i could probably make more, but not somewhere where i write open source in my day job, and where i like the company as much as i do.  frankly even though i'm in a quite good position professionally, i'm pretty lucky to have found the combination of qualities of the job i'm in; a good job with a good group of people working towards ends i really *want* to work towards, with technology i'm interested in, that actually pays well, is a pretty hard thing to find.

i went to a liberal arts college with a very small cs program of no particular note, and it's never really been a plus or minus for any job i've had.  making notable open source contributions was more important.  probably my blog was even more important than that, which is a little disappointing -- but blogs can have a general appeal that any one piece of software is unlikely to have.
  i've been trying to wrap my mind around factor recently. i kind of blew it off when articles first started popping up on reddit because it was just so different and stack languages frankly seemed really silly.

but if you take a step back and look, factor is pretty impressive, regardless of what kind of language it is. it compiles down to machine code on windows, mac, and linux (i'm really interested in what this means as far as performance is concerned), it has its own gui toolkit and its own very powerful repl/documentation system built with it. it already has a fair number of libraries. interfacing with c code is very simple. it is image-based which allows things like the repl but it still lets you use normal text editors.

i mean really, slava has done more with this language in what 4 years than most languages have done in a decade or more. so you can't help but to wonder if maybe there really is something to stack-based programming.

and you look at that aspect of factor a bit more and it is interesting. factor's words (functions) are a very powerful but simple building block. factor consists more or less  of manipulating the stack. so all a word does is take items off the stack, does something with them, and possibly puts something back on the stack. it is just damn simple. and you can do things with factor words you can't do in most other languages (like implement an if statement/expression). and because keeping the stack in your head can be difficult, factor encourages descriptively-named, concise functions which are easy to reuse. it just gets you developing from the bottom-up from the beginning without worrying about classes and methods and keyword arguments and whatever else can be an impediment in other languages to getting stuff done. that isn't to say factor doesn't have those (one of the few languages with generic functions). factor syntax is simple. there's not much to it, whitespace does most of the work.

i'm always looking for the best language possible (as i'm sure most of you are). i think in the future only lisp via macros or something like factor can offer something that allows the abstraction needed. the thing i like about factor so far is it is fairly easy to understand but still so powerful, maybe even more-so than lisp. and with all the mix-up in the scheme communities and different people's frustrations with common lisp, maybe factor is really *it*. maybe its quick progress over the past few years is a testament to what is possible with it.

i'm not sure, but it is an interesting language. the main thing i'm struggling with at the current time is reading the language effectively. the syntax doesn't get in the way, you just have to get used to things being somewhat backwards. you see an 'if' word and you want to try and read the thing like you would in ruby or python, but you can't, you have to read from left to right, keeping in mind what is on the stack and then once you get to the 'if', know what it is operating on. i'm really hoping i can get to the point where i can read factor reliably, because i like it so far.

has anyone else made the transition from traditional languages to a stack-based language successfully? is there a moment that everything just clicks?

you'll have to pardon me because i tend to get overly excited about new technologies at first. i'll have to see what problems i run to as i use factor more.  
i think when you mean programmers, you mean imperative programmers, those who have already spent quite a bit of time getting good at for loops.
physiologically suited to porn, but got bored with it after a couple years.

wait, do you mean watching it or making it?
a smalltalk interpreter? i think dolphin is the only interpreted smalltalk out there. what are you talking about?
it's all about supply and demand. if you have a master's but are working in a position that only requires basic coding skills and teamwork, then you won't get paid according to your degree because your job won't require that degree.

if you want to maximize your salary, then you should work somewhere that requires (actually needs, not just wants) as many of your skills as possible. this way all of the people who are less skilled than you are filtered out of the resource pool. with fewer viable competitors your pay should go up very quickly.
that's one of the reasons perl 6 won't call them regular expressions, but rather regexes.

[quoth wikipedia:](http://en.wikipedia.org/wiki/perl_6#regular_expressions)

&gt; since perl's pattern-matching constructs have exceeded the capabilities of formal regular expressions for some time, perl 6 documentation will exclusively refer to them as regexes, distancing the term from the formal definition.

well i'll agree that slava should probably tone it down.

one thing to think about though is that matz is routinely recognized for his humility and personable nature. but even matz with that didn't lead ruby to being anything more than an also-ran to python and perl. it took by most people's accounts, an asshole, dhh, to make people take notice. on the backside of that, dhh's personality might at this point be negative to ruby's continued growth. who knows.

i do know that this thread is reminding me way too much of a speech in *team america*. 
ontario, canada.

40 years old, 17 years experience (6 years in russia + 11 years in canada).

russian cs diploma, roughly equivalent to master's degree.

c++, sql, multiple oses and databases, legacy code, 100% maintenance work.

total compensation (salary, bonuses, etc): ~125k/yr $cad.

$80,000 with a bs in cs right out of college.  however, my job is in an extremely high cost of living area so that translates to about $75k anywhere else
based on your description, factor sounds like converting from normal calculators, to hp rpn-style calculators.  it's actually not very hard to wrap your head around and you start enjoying the freedom the stack allows.  sometimes with big problem sets you'd need to keep track of a ton of little intermediate computations, so i'd push em all on the stack and worry about it later when i needed them.  rpn-calc had cool features of rotating the stack, swapping elements and so forth that made it pretty easy to get to where you need to be.  if you used the standard calculators, you'd either have to use the memory buttons, or write out the intermediate calculations on paper.
well, the haskell philosophy definitely argues for having several diverse ways of doing something, so you can pick and choose as is appropriate.

it is all opinion really, balancing the benefits of a single uber-method and the ability to choose the most appropriate method out of several.

i loved using hypercard!
   [perlobj](http://perldoc.perl.org/perlobj.html) and [this chunk of the php manual](http://www.php.net/manual/en/language.oop5.basic.php) may be helpful, though not supremely concise.

briefly: perl classes are just packages which provide (usually) a constructor and a collection of methods. a constructor is just a subroutine which returns a blessed reference, and (instance) methods are just subroutines which expect a blessed reference as their first parameter.

    package thing;

    sub new {
      my $class = shift;
      my $self = bless { @_ }, $class;
      return $self;
    }

    sub defenestrate {
      my $self = shift;
      # ...do stuff here.
    }

    1;

a blessed reference knows what package it's associated with, so that you wind up with syntax that looks like this:

    use thing;
    my $thing = thing-&gt;new(id =&gt; 1);
    $thing-&gt;defenestrate;

there're a few other things, and since this is as much of a basic toolkit for building your own object system as anything, there's a lot to be said about it, but them's the basics (at least if you know how perl references work, which isn't a given).

php seems to provide a bit more syntactic sugar and less flexibility about the nuts and bolts of implementation. you declare classes which contain functions and so forth.   
this link needs more comments. this software was unbelievable at the time, and sold plenty of early macs. now if bill atkinson had only thought to make stacks network-capable... but this was in the pre-ppp pre-internet days when most software was traded on floppies and via 2400 baud modems.

the best and most fun software tools make it easy for anyone to build something with them.
i haven't touched hypercard since middle school (~15 years ago) so take this with a grain of salt, but i would say that the reason hypercard had such a hold on its users was that it was essentially a domain specific language.

hypercard was designed around building graphical apps, and provided everything needed for that very simply. yes you could build the same things now using existing tools, but you would have to spend a good deal of time managing and integrating the tools. hypercard, on the other hand, provided everything for you.

hypercard also had a very shallow learning curve. you could build arbitrarily complex programs in the scripting language, but if you just wanted to put together a slide show, then you didn't have to program at all.
so what makes perl horrible for oo? i ask because elsethread you claim "i haven't had experience with [perl oo]" which makes me suspicious that you're just needlessly bashing perl.
i like ruby the language, but the current interpreter implementation has some problems.  specifically, the details of the garbage collector prevent fork()ed processes from consuming less memory than two processes started separately.  rails uses quite a bit of memory, so the ability to save some by forking would be very nice.  i hope ruby 1.9 or rubinius will soon solve this problem (not sure if ruby 1.9 does; rubinius definitely does but does not support all of ruby at this time).
though i first experimented with programming using basic, it was hypercard that really got me in to it. despite some annoying limitations, it was amazingly accessible - a trait others would do well to emulate.
 now you're being silly, so i went back and read the license again. you should have done this, but i am doing it because i don't like microsoft-bashing.

&gt;(b) patent grant- subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free license under its licensed patents to make, have made, use, sell, offer for sale, import, and/or otherwise dispose of its contribution in the software or derivative works of the contribution in the software.

no, they can't sue you. 
what country?
no, i am his employee. he wants to get more in touch with current technologies.
it still exists, sort of:

[runtime revolution](http://www.runrev.com/)
&gt;now you're being silly, so i went back and read the license again. you should have done this, but i am doing it because i don't like microsoft-bashing.

what's wrong with microsoft bashing? it's just a corporation. it's not like it has feelings or anything.

do you also dislike maytag bashing, mazda bashing, dell bashing, and rockport bashing or is ms somehow special to you?

unfortunately, people with degrees often end up doing the same thing you are :) why not get into haskell or erlang, linux, something that'll stretch you a bit? it takes just as long to build practical skills as it does to get that degree -- and you can actually work with the stuff you learn on #linux.
i guess the fascists are making their way into our community...
&gt; * record - darcs-style interactive change selection during commit

excellent. i am immensely addicted to interactive commits. glad to see more scms are picking the feature up. darcs, hg, svk, (probably) git have it. if your scm of choice doesn't, then you don't know what you're missing!
related: [memo to bob metcalfe re: ethernet](http://reddit.com/info/1xz13/comments).
yeah. and as it turns out, i had to compile it because there wasn't a binary for amd64 for debian. anyway. i hope that i feel inspired to find out how to make .deb packages this weekend.
what's the concurrency model in factor? does the vm support multiple processors?
because dilbert is my hero
 &gt; what's the concurrency model in factor?

co-operative threads. threads yield with explicit calls to `yield` or `sleep`, or when you perform a blocking i/o operation (all i/o is non-blocking internally; reading from a stream pushes the current thread on a queue if there's no data available.)

&gt; does the vm support multiple processors?

no. it will eventually.
well, yeah.  what's the fun in spectacular destruction if no one sees it?
i'm looking to start a career in the field, but i'm not sure where to start. i have limited experience in several different languages, but very little to show for any of it. so the question is, what can i do to get started that will look good on a resume?
i had the exact same experience working for a non-profit research center. i'd never do it again. 
you may be roman, but it's *gnu* to me. 
$40,000 in the same situation.
in fact, if you think about it, that's maybe why a lot of topics aren't covered in school.
chess doesn't put food on the table
neither does painting. happy medium i guess. infinte lego set etc. etc.
 perhaps you were thinking of [matrix uris](http://www.w3.org/designissues/matrixuris.html)?

they never came to be, afaict.

(thanks to chapter 5 of [restful web services](http://www.oreilly.com/catalog/9780596529260/), pp. 117-119)
still live with your parents? if not, what geographic location allows you to live like that?
we have such a system. its called python. :)
\&gt; $100k, but won't tell you how much more :)

bachelor degree only. ~7 years experience.
software engineering, o/s services, network processor, and kernel driver/hacking. 
because i wanted my ass to ballon to clownlike proportions, my conversational abilities to decay, my eyes to be red and sore everyday, my right hand to lose all ability to clench, and my spine to take the shape of a 70 year old's.
are you attending school?  an internship would be a good way to get a foot in the door.
23yo, technical high school drop-out (left mid-9th grade to homeschool myself -- and no, i never bothered with a ged), college drop out (yes i got in), just quit my job earning $130k/yr, 5 wks paid vacation, unmetered sick time, etc., to open a consulting company... currently charging several clients $200/hr along with my business partner. we will raise our rates soon because we could easily fill up every available hour with work at that rate. our projected earnings for the next 12 mos range around $250,000 each with lots of vacation time.

it ain't about a degree. and it's not just about knowing your stuff, either. it's about always being willing to work hard as hell on whatever you need to improve... especially marketing, people skills, networking, your contacts and friendships, etc. 

snowclone alert: show me somebody who claims to be unable to succeed because he has no degree and i will show you somebody who isn't giving his all.

edit: i started programming for real at 15. but i now do a combination of ui work and dev.
i was speaking in aggregate. i only said they weren't that great because of other arguments going on in the comments threads in which people were splitting every visible hair. i was saying that the bar isn't that high, so it isn't worth the extensive arguments going on.
i dislike all forms of stupidity. microsoft bashing is especially irritating due to the frequency with which i encounter it.
because it's cool.
because i'm good at it and actually enjoy doing it?  i'd be doing it even if i wasn't getting paid?

oh... was i supposed to make a penis joke here ? :)
why do you think bashing a corporation is stupid? i don't like gm cars. if i say gm cars suck or that gm is a crappy company which makes crappy products why do you think that makes me stupid?

every consumer has the right to express their dislike of a corporation and/or it's products.

how somebody can think it's stupid for a consumer to express his opinion about a corporation i will never know.

come on notfancy, you secretly wish ocaml had type classes and purity, i can tell ;)
those figures are still accurate as of this past summer - at least as far as the `more evil' one is concerned. ;)
i make 150k salary, plus bonus (typically 15%) and some stock options.  10 years experience, bs and ms in cs from famous places.  good benefits, excellent work environment, low stress.  expensive cost of living, though.

my password is still "temp".  
 i've heard that jdk 1.6 from sun fixes it, but someone would have to check to be sure. 
 not necessarily. there are, in fact, thousands of languages. there aren't thousands of good answers.
isn't easy enough to write your own class to do this?  call me a purist, i'm still not sure it should be built into c or c++.

edit: also thanks for your earlier reply
95k, 8 years professional experience, bs in microbiology, seattle area, mostly c# and .net
my friends and i used it to build simplistic point and click games. it was great fun.
i'm not sure what sort of situation you're in. however, "what can i do to get started that will look good on a resume" seems like the absolutely wrong approach. that goes both for if you want to enjoy it and if you want to be good at it.
i think the biggest thing that plone can learn from rails is this: too much enterprisey complexity sucks. it should not be as difficult as it is to add a new content type. hell, build it into plone. 
 so, i'm still in college. i've had a steady (technical) job for all of college so far (i'm in 4th year) so i have some (good) experience. my school, while it does teach the basics, really tried to teach the class how to learn, not necessarily what to know. so, while i don't know java super well, and i'm not  the best mvc guy around... i do know how to learn. my jobs have been quite different and the current one i hold is a software job shop for aerospace and medical companies. my curiosity and ability to learn different concepts and ideas quickly helps me a lot.

do you have any way of measuring whether or not the candidate is interested in learning more? does it even interest you? i've always found that the curious students make the best programmers/designers, but i have no idea how employers feel about this. 
 &gt; it's mostly those who don't believe in paying taxes for said services, but are unwilling to phrase it that way

who said anything about being unwilling to phrase it that way? that is exactly what i believe.

&gt; it's always funny when i keep hearing people say health care is not free in countries that provide universal health care, but have no qualms about saying that they borrow the book for free from a library, or check out a dvd for free from a library.

i never said that, though.

[edit: okay, *not* a fair downvote. first somebody makes wild assumptions about what i believe and what i'm willing to say, then i merely state that he was wrong about me and i get downvoted?] 
malcontent, microsoft bashing on the basis that "ms is evil, right? we all know that" is about as smart as atheist bashing because "atheists can't have any morality, we all know that".

in other words, it's the domain of fools who make religions out of software. 
do lead developers still get to develop, or do they actually "lead developers"?
my advice would be: "don't".  it's a soul-crushing field, full of antisocial idiots, that soon won't even be profitable.  just listen to the idiots here on programming.reddit, and compare them to real humans.
currently i'm working in a non-tech related field, trying to save up money to go back to school. i have some skill, and i'd really like to be able to use it to bring in some extra income. i agree that only doing something "to look good on a resume" isn't the best approach, i wouldn't even be able to stay motivated to work on a project like that. i would, however, really like to have something to show for the knowledge i'd like to build.
nit: your constructor needs to shift the name of the class off of the argument list, and your bless ought to be the two-argument form with the class name.  otherwise, spot on.
i was following along until one of them mentioned the "ibm says that only a dozen computers will be needed for the whole world" bs and then i had to stop.
&gt; perl is good for what it was designed for, as every language is.

how long did it take java to be adequate for embedded programming?
the pc perspective article that apparently kicked all of this off can be found here: http://www.pcper.com/article.php?aid=455

the post linked here on reddit is mostly a reply to this original blog entry here: http://blogs.intel.com/research/2007/10/real_time_raytracing_the_end_o.html

if you'd like a general explanation or understanding of raytracing, the wikipedia article does a decent job here: http://en.wikipedia.org/wiki/raytracing#broad_description_of_ray_tracing_computer_algorithm
it's scheme-style, not ruby-style. they just nicked it.
you [are](http://programming.reddit.com/user/programmersalary/) a fucking loser. get a job!
&gt;has anyone else made the transition from traditional languages to a stack-based language successfully? is there a moment that everything just clicks?

there most certainly is that moment. i now find using applicative languages to be frustrating on occasion, although more because of what concatenative languages *can be* rather than what they are at this point.
why isn't this already implemented in emacs?
i started working as a web developer for 60000 this year in febuary.  i'm north of detroit michigan.  what would one expect from a good annual review or is there some type of average percent raise that is given after one year?  
wow, i am surprised at some of the numbers i am seeing. i have had internships that have paid a whole lot more than what some of you are working for. an internship at a major company doing software development gets you $50k-$60k had you been working there an entire year. thats for the interns. you might not want to work there forever, but seeing a $30/hr check for 3-6 months out of the year while in school isn't too bad.
you might consider learning something that's not so great on a resume, so that you can more easily learn things that are. i'd start off with scheme and sicp (or htdp if you haven't much programming experience at all). after you tackle those, you shouldn't have much of a problem picking up any mainstream language; even more so if you learn a typed language (ml is a good start) and an oo language (to get used to programming in such a manner).
"it was essentially a domain specific language"

if you include the interface objects that you visually interacted with while programming as part of the language, i would say yes.

i suppose there is a very distant relation to smalltalk, only in the sense that the environment you programmed in and the environment you ran the application in was more or less the same.  you could be running a stack, stop, edit the code attached to some part of the interface, and keep going.

just one more thing that if people would have used the apple version instead of the microsoft knockoff (visual basic), the world would have been a better place sooner.

*sigh*
the wikipedia article is a good start for understanding the basics. the reference links look promising. you might want to check out reviews on the recommended reading for the pov-ray project[1] to see if any of the books listed are worthwhile.

if you find or anyone has recommendations on a good book i'd like to hear it as well.

[1] http://www.povray.org/documentation/view/3.6.1/211/
i've been working on making the frontend interface friendlier since that was posted. you can now simply do:

&gt; kp6 -bcl-ecl -e 'say "hello"'

to run it with ecl, -bcl-sbcl for sbcl etc. then i'm going to add support to the frontend for making stand-alone executables with the sbcl and ecl backends.
the commenter is right. i hadn't thought of this before, but a modern (by which i only mean os-x-compatible) implementation of hypercard would be a perfect fit for an iphone sdk.
 &gt; just quit my job... to open a consulting company... our projected earnings for the next 12 mos range around $250,000 each

hey, you are an entrepreneur, not a programmer. what are you doing in this thread?

:-)


 
i found the test interesting. especially the more difficult tasks in the end.
you know knuth's famous dedication in the art of computer programming:

“this series of books is affectionately dedicated to the type 650 computer once installed at case institute of technology in remembrance of many pleasant evenings.”

if i was to ever dedicate a book to a nostalgic piece of computer technology, it would be hypercard.  i'm still not sure that it has been surpassed as a gui development environment.
rad, now we can get sql injections client side too.
 &gt; why not debate the sub-concepts of oop on their actual merits, instead of arguing about the meaning of a word?

debate something using actual logic instead of semantic quibbling and/or proof-by-assertion? you obviously don't know richard kulisz (aka redditcensoredme). 
agreed.  working on my second time going from dumb guy to smart guy.  it's going much quicker this time.
[if apis were food](http://boredzo.org/blog/archives/2006-11-14/if-apis-were-food)
posting your opinion with no justification is stupid.
start or contribute to an open source project. 
 no, it handles pegs. besides this you need to disambiguate pegs manually to make them work. that's not much unlike the preparation it needs to fit a grammar into an ll(1) parser scheme - with the exception that pegs are more capable dealing with lookaheads.





 
apparently you haven't delved into the active record associations code.
&gt; we will perhaps eventually be writing only small modules which are identified by name as they are used to build larger ones, so that devices like indentation, rather than delimiters, might become feasible for expressing local structure in the source language. -- donald e. knuth, "structured programming with goto statements", computing surveys, vol 6 no 4, dec. 1974
not programming.
 not programming. also, seems mostly false. it didn't blow away any of my extensions. you might just be using extensions which don't support the new version yet. you can either contact the authors to see if you can get them to update the supported version number, or hack the version numbers in them if you think that's safe.
  &gt; the bizarre idea that it's unethical

i don't get the feeling that it's unethical, just that it's uncomfortable.  whether people of similar stature have negotiated more or less than you, it ends up being uncomfortable.  i mean, do you want to tell your (now-)friend you make $10k more than he does?  do you want to hear you're making $10k less than a guy you think you're as good as?

performance reviews are a very difficult thing.  i think companies want them to be secret both to protect the company *and* to protect relationships between employees.

i was offered in the range $80 - 90k salary out of college, with about a fourth of that as signing bonus, and about 2x that in restricted stock.  i had a great deal of oss, part-time, and internships experience under my belt by that time.

&gt; results include overt discrimination in pay scales

how is it discrimination?  no one is *the same person* as someone else, so how do you know what the actual difference is?  even if you have 'similar' background experiences, not everyone has the same (say) interpersonal skills.
fixed.
everyone in india openly discusses salary. none of the problems you mentioned are a big deal.
move.
     how is it not uncomfortable if someone whom you feel is your equal says he is making more than you?

wouldn't you feel like an idiot if others have, among other ways, negotiated strongly to get higher salaries than you?

what if you're *way* better than someone, and he's lazy, but you both make the same amount?  i have not had the others happen to me personally, but i *have* experienced this.  making exactly the same amount as some lazy fool whose personal goal is to *appear* productive.

i'm sort of glad i don't know how much people around me are making.  i would have trouble being content if i knew that someone who was imo less competent was making more!  i would feel like my contributions are not being recognized.  but then, everyman is biased towards himself.  (i try to account for that.  it helps that my co-workers are *extremely* competent)

i've also had an experience where i thought a co-worker was just as good as i am.  but, for whatever reason, he didn't negotiate as well as i did, and got 20% less.  now i feel bad.  what do you do in situations like  this?  there is no good solution.
&gt; like javascript, there was no intrinsic ability to define array variables.

no array variables in javascript?  i don't think that's ever been true.
what about perl regular expressions?  where are they on the chomsky hierarchy?  did you click the link i posted?
&gt; did you click the link i posted?

yes.  i did click the link, and i was angered by the author who seems to look with disdain on computer scientists, and people who bother to properly define "regular language" or "regular expression".  i deleted a previous post i made, because i realized it was too filled with vitriol.

but i'll say it again here: the author is a moron.  she doesn't seem to know much about the proper definition of "regular language", nor care.  that kind of disdain for well-understood theory astonishes and angers me.  i think a software developer should try his or her hardest to understand the theory that underlies their profession.  this one writes condescending phrases like: 

&gt;&gt; so you might be surprised (or
disbelieving) to see a regular expression that does exactly that. the
explanation, of course, is that theory and practice are closer in
theory than in practice: onigurama regular expressions, in common with
many other flavours, are more powerful than the things that computer
scientists call "regular expressions"

uhhh...... **because they are not regular expression*!!  you have simply written a parser for a context-free language.

&gt; what about perl regular expressions? where are they on the chomsky hierarchy?

perl 'expressions' are not regular.  they fall firmly within context-sensitive languages, which is one step **above** even context-free languages.  this is because they have backreferencing, which allows them to match the same full word twice.  context-free languages can match something like "abccba" ( a word and its reverse) but cannot match "abcabc", a word repeated twice, in general.

a proper regular grammar must be in this form:

    a -&gt; bc
    a -&gt; a

(where `a`, `b`, `c`, are productions and `a` is a terminal).   that's the actual, theoretical definition of a regular grammar.  if you take an example like parenthesis matching, you can never fit into a grammar of that form.  it is actually a good exercise to take common grammars of various kinds, like parenthesis matching in cfg:
   expr -&gt; ( b ) 
try to put that in proper regular grammar form (each production's body is 2 other productions, or terminal).  it's a good exercise.

to put in expression (rather than grammar) form, you get grouping and alternation (this|that) and klein-star.  the rest is syntactical sugar.

the last course i took before leaving college was the theory of computation, covering this stuff.  i can show you some simple proofs and the basic theory (offline) if you are interested!  i would caution you, though... because once you're learn it, you're condemned to see software developers the rest of your life misuse terms in the stupidest ways! 

would it be useful if i wrote a wiki page or blog that introduced this kind of theory of computation material, and walked through simple proofs?  it's actually quite a complete, thoughtful subject.  
that said, in most workplaces there's quite a large variance in salary, and it's often not correlated to productivity.

while you're working at the same job, you're almost never happier after finding out how much your co-workers make.

when switching jobs, it helps to know how much people are paid.
that was just plain stupid. 
er. i'm guessing that saving a huge chunk of change from previous years allows him to live like that.

&gt;  how is it not uncomfortable if someone whom you feel is your equal says he is making more than you?

because your salary is not your true worth. people there care more about promotions, respect, and securing management positions.

i understand everything you're saying but the reason you're saying that is because in the american corporate style of business, salary (includes bonus/perks) is the only single variable that determines your worth as an employee.

you're hardworking and make same as your lazy inefficient coworker. so? in a year you'll be promoted to lead dev. and get the well-deserved raise. he won't.

too many people here look at the salary as the only single thing that matters. it's not. i'm in a small company and while i'm being paid nowhere close to competitive wages for my skill &amp; performance, my job has much more growth potential in the next few years than most others that already pay 30-40% above my current salary.

i've had coworkers make more/less than me. so someone's a better salesman than me and someone else isn't. when salaries are hidden, there is no pressure on higher paid employees to perform better than lower paid employees. and no visible incentive for lower paid employees to work harder to get better raises. there is also no pressure on management to give decent raises to anyone because nobody knows who performed well/poor and what the consequences of that were. sure, you can quit if you get no bonus and start elsewhere but then cycle starts again.
i tried on several occasions to scale the learning curve of zope and later plone.  i went to great talks by alan runyan, among others, where i saw amazingly things done in a matter of minutes...but when i tried to replicate it, i hit a brick wall.  i even did some squid-related projects for zope corporation, and so had some of the best zope guys in the world (and amazing engineers, in general) to bounce questions off of...but i never felt in control of the system.

since it was never my actual job (the website was always in support of a project or product, rather than the project or product itself), i could never dig in long enough to really grasp everything.  the learning curve is just too steep.

ror isn't perfect, but it can be learned in manageable chunks...which sets it pretty far apart from zope/plone.
  when you find something that looks intesting on a site that 1) has tons of google ads on it, 2) has lots of chinese text on it, or 3) looks like a forum, just cut and paste a sentence or two into google, and you'll find the original in no time at all:
 

http://news.bbc.co.uk/2/hi/technology/6960896.stm   
hmm.. this is still misleading. what about "nregex: nregex is not a regex"?
20% design/architecture, 60% development (actual coding), 10% project management and 10% whatever the fuck i want to do (spend time on reddit for example).

now this is just how i created my schedule. i have seen some architects/team leads who do very little coding and much more architecture/project management. these are also the people who either become ctos or some other management types or completely lose their luster, and their job.

i love programming so i keep management to a minimum even though my managers want me to be more involved. once you become a technical team leader, you have a choice. also having some kind of business domain knowledge helps a lot.
http://www.hugeurl.com/?zwu0odfjmtg5mgvmmjeyyzflogezmwzmmzq4mdq2mjcmmtmmvm0wd2qyuxlvwgxwv0d4wflusm9wmvl3wkc5v1zsbdnxa2m1ywxkc1dqqlvwbhbqvjbaywmyskvubghotvvwvvztcedzv015u2twvwjhag9uv3n3zuzacvftrlrnaze1vtj0v1zxskhhrzlvvm1orfzwwmfkr1zhv214u2jhdzfwa2qwyzjgc1nuumhsemxwvmpot00xcfzxbuzruja1r1pfwlnubfpvvmtwv2jurxdzvezru0zoclphcfrsvxbzvkzwywqxtkdvbfztylvacvztdgfnrlz0zuzovwjvwtjvbfjhvjfarmizzfdha1povjbat2ntskdtbwxttw1owlyxzdrimkl3tuhowgjhullzbfzhy2xwc1vrzfhir3qzv2tsu1zrmxjjrwxhu0hcsfzqskzlvlzzwkzwv1jwchlwvejhvdjoc2nfagpsbepuvmxoq1dswnjxbgrotvzwnvzxnu9hbep0vwxswmjgwmhzmvpzy2xkdfjtefdivko1vmpjmwexwxdnvvztytfwv1lrwktsrlpxuvhoa1zswjfwmnhhyudfegngbfhhmvpovkrkt2rgtnjarljpvjnowvzxce9imwrhv25stlnhunnvakjztkzvewrhdghwazvhvjj4u1dtskhhrljxtvzwwfkxwktjbvjhvwxkavjtotnwmnhxyjjfefdyze5wvlpuwvrgd1dgbhjarzlqykzwefuydgfirlpzv2xwwgexchjzvwrgzudor2fgaglsbkjvvmtss1qyukdtbkphum1ocfzqtm9wvlphwtnoau1ssnpwmjvtvgxksfvswlvwm1j6vgxav2rhukhkrmroytncnvzhegfjmwr0u2toafjsslhuvvp3vkzacvjuzfnnvkp5vgxat2fxrxdjrwxxylhctfrrwljlrmrzyuzsavjuqnhwv3hrvtfsv1vswlhivvppvfzad2vgvxlkrejwturgevrsvndwmdfxumtov1zfwkxwmvphy21kr1pgze5nrxbkvm10u1mxvxhxwghhu0zavllrwktjrlpxu205bgjhullavwm1yvuxcmjeuldnalzuvkd4a1ngvnnxbfzxykhcwvzhdgfhmk5zv25sa1jtunbwbghdtmxavvnurlvnvnawvw01s1qxwnntbuzvvmxwm1pxehjlv1zjwkzotlzrcdvwr3hhvdjgv1nuulbwrtvywvrgd2fgbhfta1psvmtwevdrwm9hv0y2vm5ov1zfsnzvvezzvjfwc1dsaglivkp5v1d0ywqyvkdwbljrukvkv1rxdhdtvlpyy0vowgjgcfhzmfjpv21fevvrzgfwv1jqvtbvnvyyrkdhrljtvlhcs1zqrmfvmu14vvhsvvdhaghvmfphvmxscldrdgpsbfp4vw10mfyxwnnjrwhxvjnstfluqxhsvkpzvgxau2jfwxpwvvpgt1zculbumd0=
first job out of college, $80k in first few months became $100k after showing promise.  bonuses are in the $20k range, stock was... well, twice all the above, which sorta reveals which company, doesn't it?
mmm should i have put a smiley in my post to show it was a tongue-in-cheek comment?
i love it. 

http://www.hugeurl.com/?oti1odvlyzi3mtdlyjc4nzk2yjqwndfknjyyody4ytqmmtemvm0wd2qyuxlwa2hwv0dovvywzg9jrlz0tvzowfzsbdnxa1jtvjfac2jetlhhmk0xvjbas2myskvubghotvhcuvztefzlrll5vgtsaljtag9uv3n3zuzadgnfdfrnvtvjvm10a1dhskdjsejxtuzwsfrurmfjvkz0umxstmf6rtfwveowvjfawfnrbfjir2hywwxob00xwldxbuzrulrgwlkwzdrvmkpizhpgv2eyuxdzvezru0zoclphcfrsvxbzvkzwa1uyunnjrmryylvacvlrwmflvmryv25kv01erkzvbfjdvjaxdvvuwlzha1pywkvat2ntskdtbwxxujnowfztmhdlr0l4u2tkavnfwlrzbghtv1zwcvjrdfrwbfowwlvoa1ywmuvsa1pxykdoclzqskzlvlzzwkzkagexcfhxbfphvdjodfnrzfriv3hyvwpob1dgwnrnrezrtvvsnvzxnu9hvk5gv2xswmjhafrwmfptvjfkdfjtefdivko1vjj0ak5wwlhta2rqum14afuwaensrlpxu2tabfzswlzvv3h3ykdfelfrbfdwm0jivkrku1yxwnvvbwhtyxpwd1ztcetimljzv25stldhulzuvlpxtlzwdgrhdfhsbvjjvld4c1dtskhhrljatvzwelkyehdsmvjytlzoavjtotnwa1phyjjfevjrzfhiazvxvtboq1lwulzxbmrrykzwefvtddbvmkpivwpcwlzwcdnza2rgzudose9waghnvnbvvlhwr2exzedvbkphum1ocfzqtm9wvlphwtnoau1xulhwmwhvwvzkrlntovvwm1j6vgtavmvxukhkrmrovjfksldwvmfjmwr0u2toafjssmfuvlp3zwxrewvhdgtsa3awwlvaa2fxrxdjrwxxylhctfpxczfwmwrzyuzsae1yqnhwv3hrvtfkr1vsae9wazvzwwtac00xwxlnvwroyxpgv1rsahdwbfl6yurowmeyukdavwrpulzkc1phbfdsvmt5vjj4v1lxrxhxwghhu0zav1lszg9wrmxzy0zkwfzscflzmfu1yvuxwfvrafdnalzuvkd4yvixtnrsbgroytfwsvzgukdvmvl5umtaufyyahbvbghczdfac1peumpnv1j6v2twc1vtsnvrbuzvvmxwm1zrwmfjvkp0zed0u2ezqxdxbfzhytjgv1nszghnmljywwxoq1rgcfhjekzxtvdswldrvtfwmvpzy0zwwfzsskxua2rhujfadvnszfdsvnbqvkzaywmwmhhxwgxovldsb1lycedxvlpyy0vkv2jvcfpzvvpvvjjgcmnfefznvnbiwxpgv2myrkhirk5pu0vkmlzqrmfvmu14vlhowfdhafdzbxhhvlzsclzrdfhsbxh6vjj0mfdhskdjrmxatuzzd1lwvxhxrlz1y0zktmfswk1wakjruzfac1piulnir1jvwvrgd1nwwkhkr0zavm1ssvzxdg9hmup0vws5v2frwkxvmnhrvjfadfjtce5wmuo2vmpkmflxrnntbk5uykdovlzswndnmwxwv25ku2jiqkhwr3htvtjfelfqwldnbljywxpgvmvwslljrkppujnowvdxeg9imkzhykhgvgexchnvbxh3zwxkcldtdghwa3b6wtbaq1yxwxpvbkphvjnnmvzxeenwvtfftuqwpq==
1998 called, it wants it's over paid job back
that would be because ???
(you do realise that watson actually said this?)
&gt; lisp is not oo, period.

why not?
  &gt; admittedly, it would be nice if this were explicit in the original.

given that this is the kind of humor that only works if you get enough of the references to realize that what you're reading is subtle satire, that would spoil the fun.  but sure, the article's abstract (which isn't visible on that page) does indeed give you the necessary background:

&gt; the author ponders how much damage could occur when a reviewer has a bad day.

the pointer to einstein's performance review might also provide a clue or two, of course.  
  &gt; these are so pathetic that they look fake.

so is your comment.

&gt; why is the name of the writer of each of these not present?

because the reviewers are anonymous?  they often are, you know.

why is your name not present, btw? 
it's a bit lame that

http://www.hugeurl.com/?ndjmzddmm2q2ntbmnwe0mzgxntvhzme5mdhhnzq2ntmmmtimvm0wd2qyuxlvwgxxytjov1ywzg9wvll3wkc5aljswjbuvlppv0zac2jetlhhmupuvmpgywmyskvubghotwswefzqqmftmk15u2twvwjhag9uvmhdvvzadgvgwmxsbgw1vkd0c2fssnrhrzlvvjnom1pvwmfkr05gzezstlzuvkpwbtewytfksfnrzgptrupyvfvad1ngulvsbuzqvmtamfvtefnubuy2ulrgv1zfb3dwakzhv0zocmjgsmlsmmhzv1d4b2iwmhhxbgryylvaclvsukdxbgt3wkrsvk1rcelashbhvjjfevvyzfpwrvpyvtbat2nscehjrljtvlhcwlzrwldhmvv5vw5oaljtullzbfzhy1zscldtrmxwbvj5vji1a1ywmuvsa1pwykzkrfzqqxhkvlz1v2xaagexcflxa1zhvdjodfnrzfriv3hyvwpob1dgwnrnsgrsujbsnfuydgthvk5gv2xswmjhafrwmvpxy1zkcmrguldirm93v2xwb2exwxdnvvztytfwwflrzg9jbfpxu2tabfzswlpxa1pryudfegngafhirnbovkrkt2rgsnjhr2htyxpweldxeg9imwrhv25stlnhafbvbte0vjfsvmfhovhsmhbjvld4c1dtskhhrljxtuzwvfzqrmtkrkp0zuzkawewcelwbxbkzuuxr1dsafrhmljxvwtwyvyxwnfubtlsykzwefuydgthbupwvmpawlzwchjzvwrgzudoswjgzfdsvxbvvmtss1rtvkdjrwxvyldovfrxnw9wvmrxvws5uk1rbdrwmwhvwvzkrlntrldha1pivgtayvdhukhkr2hpulhbd1zszdrjmwr0u2toafjsslhuvlp3v0zrefdrdgpivkpivld4a2fxrxdjrwxxylhcs1pvwkplrmrzyuzsae1ssndwv3rhuzfzefvsae9wemxzwwtad2vgvxlkr0zpumxweluyehdxbfpxy0hkwlzxukdavwrpu0u5v1phaghnsej2vmxod1mxuxhxwghquld4vllrwmfjrlpxvg05a2jgcehwbta1vwsxwfvucfdnv2h2v1zas1jstnrsbgrpv0u0mfzhdgfxbvziumtoufyyahbvbghczdfac1peumpnv1iwvtj0b2fgsnntbghvvmxwm1ywwnjlrmryzed0u2ezqjzwa2r6tvzzevjyaghnmljywwxoq1mxcfzwwghuumtwevdrwm9hv0y2vm5ov1zfsnzvvezzvjfwc1dsaglivkp6v1d0ywqyvkdwbljovldsv1rxdhdwmwt3vm1gv01vbdzzvvpvvjjgcmnfefznvnbiwxpks1ixcehirmhtvlhcs1zqrmfvmu14vvhsvvdhaghvmfphvmxscldrdgpsbfp4vw10mfyxwnnjrwhxvjnstfluqxhsvkpzvgxau2jfwxpwvvpgt1zculbumd0=

redirects to 

http://www.hugeurl.com

and not the other way around, though.
runtime revolution is an excellent solution - and is even cross-platform. my favourite has always been [supercard](http://www.supercard.us/), an absolutely brilliant rad environment. sadly, its lack of networking and database support mean that sooner or later, i fear it will go the way of the dodo.
 &gt;  from the valley of the shadow of the outlet mall 

&gt; to customized petwear boutique

&gt; from the trailer of the fry chef

&gt; to the palace of the sheik

&gt; the cash cow lurks!

http://www.youtube.com/watch?v=w0qxzhaudd8

man, there's probably only two of us steve taylor fans here...  the guy's a genius.  a very obscure genius...  
depending how you think that an interpreted smalltalk would be different from any other smalltalk, [gnusmalltalk](http://smalltalk.gnu.org/) might be what you are looking for.
you do realize this is a joke right? these are all seminal papers in computer science.
very similar to me. left after 9th grade to homeschool myself and never officially graduated. earned $120k plus $80k bonuses last job and now now around $190k/yr contracting about 30 hours a week. working on my own startup another 30 hours a week.

i think its about knowing your stuff *and* being willing to work your ass off and constantly analyze what you're doing so you can "work smarter". most people just blindly do what they're told the way they're told to do it. i get paid to actually think.

finding the right people to work for has been my biggest challenge. that's why i'm trying to work for thousands of customers now instead of a small number of business owners, it's a much more straight forward relationship.

&gt;microsoft bashing on the basis that "ms is evil, right?

i guess it depends your definition of evil. ms is a very unethical company who has done many many sleazy and unethical things. it has also been tried in a court of law and found guilty with the verdict upheld in appeals court.

&gt;we all know that" is about as smart as atheist bashing because "atheists can't have any morality, we all know that".

i have no idea what you are trying to say there. perhaps if you rephrased it.

&gt;in other words, it's the domain of fools who make religions out of software.

a consumer complaining about a corporation has nothing to do with religion.

on the other hand a random person who feels compelled to defend a corporation when a consumer says they make crappy products or act unethically is suffering from some sort of a mental illness.

a person who only defends one corporation and lets other consumers say bad things about other corporations is a zealot or a paid shill. 


no justification? i just presumed everybody on programming.reddit.com is familiar with ms products and ms behavior.

are you really that ignorant of the corporation? 
did i claim that the extra optimization possibilities in haskell outweighs the slowness of being lazy?  no.  i know as well as anyone how difficult it is to make haskell  run fast.
you can write haskell code that is as fast, but you often have to sacrifice the nice things about haskell to do so.
so i think we pretty much agree on the speed of haskell.  :)

but i totally disagree about a transformation that doesn't preserve semantics being valid.  if it doesn't preserve semantics it's just broken.

spreading the kind of misconception as the author does is indeed a very bad practise. she's making it sound like there is some kind of conflict between regular expressions (re's) in theory and practise. when there isn't and can never be.
 personally i would like conex, contexps or something like that. :)

as a side-note the all-on-one-line syntax of jsolson's grammar below could look something like

s:(\\(b\\)),b:()|(\\(b\\))|bb 
if you want to see a sound approach to oo, take a look at philip wadler's type classes. to be honest, i'm quite tired of watching a debate among those who, of all people, are the least qualified to comment. 
because any formal meaning opens up a logical contradiction that can be pounced on by any opponent in the debate.

i propose we put down the glossy brochures and abandon the word. it's a failed experiment at best.
perhaps, but then you have no idea of how expressive your expression really can be. and in extension you have no idea of worst case execution time.
does the library have a uniform naming convention?

a tool for svn written in java.

this is like anti matter for programming.reddit.com. 

two hated technologies in one!!!
i don't know what i am missing. :-) could you explain them (very) briefly?
 how long will it take for java to be adequate for anything but big bucks consulting? 
the reddit comments (and the associated downmods, not to mention the mod-swings on my comments) are almost funnier than the article, though.  i wonder what these guys would do if someone posted some pdq bach (1807–1742) stuff...
 php has no approach to oo, their "approach" can be summed up in a single phrase: "completely misunderstand java's already flawed oo approach, and dump it on php". 

there, done. 
$72k (aud), soon to be $77k. python and java work. this is (afaik) considered a pretty good salary  for the area. i'm a bit shocked at how much you american developers make, but then again i'm presuming most of the high wages are in silicon valley, where you're probably living on the poverty line. 
how the hell are people not getting the joke here?!
you don't see how that's depressing?
[thank you, captain obvious](http://reddit.com/info/5ypcu/comments/)!
conex sounds good. i feel that we are talking about context-free grammars together with attributes; we use the later to plug-in context-sensitive features. perhaps, knuth's attribute-grammars are quite close to what's going on with perl's "regexes". 
